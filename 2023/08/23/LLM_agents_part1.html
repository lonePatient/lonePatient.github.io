<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>基于大语言模型的AI Agents—Part 1 | 闲记算法</title><meta name="keywords" content="NLP,Agent,预训练,大型语言模型,LLM,ChatGPT,AI,智能体,GPT4"><meta name="author" content="Weitang Liu"><meta name="copyright" content="Weitang Liu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="代理（Agent）指能自主感知环境并采取行动实现目标的智能体。基于大语言模型（LLM）的 AI Agent 利用 LLM 进行记忆检索、决策推理和行动顺序选择等，把Agent的智能程度提升到了新的高度。LLM驱动的Agent具体是怎么做的呢？接下来的系列分享会介绍 AI Agent 当前最新的技术进展。 什么是AI Agent？ 代理（Agent）这个词来源于拉丁语“agere”，意为“行动”。现">
<meta property="og:type" content="article">
<meta property="og:title" content="基于大语言模型的AI Agents—Part 1">
<meta property="og:url" content="http://lonepatient.top/2023/08/23/LLM_agents_part1.html">
<meta property="og:site_name" content="闲记算法">
<meta property="og:description" content="代理（Agent）指能自主感知环境并采取行动实现目标的智能体。基于大语言模型（LLM）的 AI Agent 利用 LLM 进行记忆检索、决策推理和行动顺序选择等，把Agent的智能程度提升到了新的高度。LLM驱动的Agent具体是怎么做的呢？接下来的系列分享会介绍 AI Agent 当前最新的技术进展。 什么是AI Agent？ 代理（Agent）这个词来源于拉丁语“agere”，意为“行动”。现">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230806160808.webp">
<meta property="article:published_time" content="2023-08-23T23:20:08.000Z">
<meta property="article:modified_time" content="2026-02-27T07:52:12.659Z">
<meta property="article:author" content="Weitang Liu">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="Agent">
<meta property="article:tag" content="预训练">
<meta property="article:tag" content="大型语言模型">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="ChatGPT">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="智能体">
<meta property="article:tag" content="GPT4">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230806160808.webp"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://lonepatient.top/2023/08/23/LLM_agents_part1"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//s4.cnzz.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script async="async" data-pjax="data-pjax" src="https://s4.cnzz.com/z_stat.php?id=1273275888&amp;web_id=1273275888"></script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2026-02-27 07:52:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/backgroud.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><script src="https://at.alicdn.com/t/c/font_3570527_dthoqrrv2tv.css"></script><script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script><script>LA.init({id:"JwRQtLKZggvJH4sJ",ck:"JwRQtLKZggvJH4sJ"})</script><link rel="stylesheet" href="/css/universe.css"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3536467946304280" crossorigin="anonymous"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">281</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">384</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">92</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 网站</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.aitoolist.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集合</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.deepdh.com"><i class="fa-fw fa fa-star"></i><span> AI工具导航</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.ai-lib.club"><i class="fa-fw fa fa-star"></i><span> 人工智能工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ai-bot.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 教程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://learningprompt.wiki/"><i class="fa-fw fa fa-star"></i><span> Prompt教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 在线</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fa fa-star"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230806160808.webp')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">闲记算法</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 网站</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.aitoolist.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集合</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.deepdh.com"><i class="fa-fw fa fa-star"></i><span> AI工具导航</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.ai-lib.club"><i class="fa-fw fa fa-star"></i><span> 人工智能工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ai-bot.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 教程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://learningprompt.wiki/"><i class="fa-fw fa fa-star"></i><span> Prompt教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 在线</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fa fa-star"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">基于大语言模型的AI Agents—Part 1<a class="post-edit-link" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts/LLM_agents_part1.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2023-08-23T23:20:08.000Z" title="发表于 2023-08-23 23:20:08">2023-08-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-02-27T07:52:12.659Z" title="更新于 2026-02-27 07:52:12">2026-02-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">大型语言模型</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">5k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>20分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2023/08/23/LLM_agents_part1.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p><strong>代理（Agent）<strong>指能自主感知环境并采取行动实现目标的</strong>智能体</strong>。基于大语言模型（LLM）的 AI Agent 利用 LLM 进行记忆检索、决策推理和行动顺序选择等，把Agent的智能程度提升到了新的高度。LLM驱动的Agent具体是怎么做的呢？接下来的系列分享会介绍 AI Agent 当前最新的技术进展。</p>
<h2 id="什么是AI-Agent？">什么是AI Agent？</h2>
<p><strong>代理（Agent）<strong>这个词来源于拉丁语“agere”，意为“行动”。现在可以表示在各个领域能够独立思考和行动的人或事物的概念。它强调</strong>自主性和主动性</strong> (<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/tXxCEtAA_W1eS0ti-Yydxg">参考链接</a>)。<strong>智能代理/智能体</strong>是以智能方式行事的代理；Agent感知环境，自主采取行动以实现目标，并可以通过学习或获取知识来提高其性能 (<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/648376562">参考链接</a>)。</p>
<p>可以把<strong>单个Agent</strong>看成是某个方面的<strong>专家</strong>。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230825162214.png" alt=""></p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230825162226.png" alt=""></p>
<p>一个精简的Agent决策流程：</p>
<p><strong>Agent：P（感知）→ P（规划）→ A（行动）</strong></p>
<p>其中：</p>
<ul>
<li>
<p>**感知（Perception）**是指Agent从环境中收集信息并从中提取相关知识的能力。</p>
</li>
<li>
<p>**规划（Planning）**是指Agent为了某一目标而作出的决策过程。</p>
</li>
<li>
<p>**行动（Action）**是指基于环境和规划做出的动作。</p>
</li>
</ul>
<p>其中，<strong>Policy</strong>是Agent做出Action的核心决策，而行动又通过**观察（Observation）**成为进一步Perception的前提和基础，形成自主地闭环学习过程。</p>
<p><strong>类</strong> <strong>LangChain 中的各种<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/5N5H2yqiCKWtM34ngjk6Hw">概念</a></strong> ：</p>
<ul>
<li>
<p><strong>Models</strong>，也就是我们熟悉的调用大模型API。</p>
</li>
<li>
<p><strong>Prompt Templates</strong>，在提示词中引入变量以适应用户输入的提示模版。</p>
</li>
<li>
<p><strong>Chains</strong>，对模型的链式调用，以上一个输出为下一个输入的一部分。</p>
</li>
<li>
<p><strong>Agent</strong>，能自主执行链式调用，以及访问外部工具。</p>
</li>
<li>
<p><strong>Multi-Agent</strong>，多个Agent共享一部分记忆，自主分工相互协作。</p>
</li>
</ul>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230825162735.png" alt=""></p>
<p><strong>LangChain</strong> 中 Agent 和 Chain 的区别：</p>
<blockquote>
<p>The core idea of agents is to use an LLM to <strong>choose a sequence of actions to take</strong>. In <strong>chains</strong>, <strong>a sequence of actions is hardcoded</strong> (in code). In <strong>agents</strong>, a <strong>language model is used as a reasoning engine to determine which actions</strong> to take and in which order.</p>
</blockquote>
<h2 id="背景知识">背景知识</h2>
<p>做决策的过程中，一个很重要的信息来源是 <strong>记忆（Memory）</strong>。作为重要的背景知识，下面简单介绍下都有哪些种类的记忆 (参考<a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2023-06-23-agent/">LLM Powered Autonomous Agents</a>)。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230825162919.png" alt=""></p>
<h3 id="记忆（Memory）">记忆（Memory）</h3>
<p><strong>记忆</strong>可以被定义为获取、储存、保留以及后来检索信息的过程。人脑中有几种类型的记忆。</p>
<ul>
<li>
<p><strong>感觉记忆（Sensory Memory）</strong>：这是记忆的最早阶段，提供在原始刺激结束后保留感官信息（视觉、听觉等）的印象的能力。感觉记忆通常<strong>只持续几秒钟</strong>。子类别包括视觉记忆（iconic memory）、回声记忆（echoic memory）和触觉记忆（haptic memory）。</p>
</li>
<li>
<p><strong>短期记忆（Short-Term Memory, STM）<strong>或工作记忆（Working Memory）：它储存我们当前意识到的信息，以执行复杂的认知任务，如学习和推理。短期记忆被认为有大约7个项目的容量（Miller 1956）并</strong>持续20-30秒</strong>。</p>
</li>
<li>
<p><strong>长期记忆（Long-Term Memory, LTM）</strong>：长期记忆可以储存信息很长一段时间，从<strong>几天到几十年</strong>，其储存容量基本上是无限的。LTM有两个子类型：</p>
</li>
<li>
<ul>
<li><strong>显性 / 陈述记忆（Explicit / declarative memory）</strong>：这是对事实和事件的记忆，指的是那些可以被有意识地回忆的记忆，包括情景记忆（事件和经验）和语义记忆（事实和概念）。</li>
<li><strong>隐性 / 程序记忆（Implicit / procedural memory）</strong>：这种记忆是无意识的，涉及自动执行的技能和例行程序，如骑自行车或在键盘上打字。</li>
</ul>
</li>
</ul>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230825163127.png" alt=""></p>
<p>可以大致考虑以下对应关系：</p>
<ul>
<li>
<p>将<strong>感觉记忆</strong>视为学习原始输入（包括文本、图像或其他模式）的<strong>嵌入表示</strong>；</p>
</li>
<li>
<p>将<strong>短期记忆</strong>视为在<strong>上下文</strong>中（prompt）学习。它是短暂且有限的，因为它受到Transformer的上下文窗口长度的限制。</p>
</li>
<li>
<p>将<strong>长期记忆</strong>视为代理在查询时可以注意到的<strong>外部向量存储</strong>，可以通过快速检索访问。</p>
</li>
</ul>
<h3 id="怎么写好Prompt：ReAct">怎么写好Prompt：ReAct</h3>
<ul>
<li>
<p>Home: <a target="_blank" rel="noopener" href="https://react-lm.github.io/">https://react-lm.github.io/</a></p>
</li>
<li>
<p>LangChain中的ReAct：<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/agents/agent_types/react.html">https://python.langchain.com/docs/modules/agents/agent_types/react.html</a></p>
</li>
</ul>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230825163206.png" alt=""></p>
<p><strong>ReAct 指：Reason and Act 。</strong></p>
<p><strong>特色：</strong></p>
<ul>
<li>
<p>CoT 只是在prompt加入了静态的 “Let’s think step by step”。ReAct 的prompt是动态变化的。</p>
</li>
<li>
<p>CoT 只调用LLM一次即可，ReAct是多次迭代调用LLM。</p>
</li>
</ul>
<blockquote>
<p><strong>ReAct</strong> 可能是当前Agent中使用最多的prompt结构：<strong>少样本</strong> + <strong>Thought</strong>, <strong>Action</strong>, <strong>Observation</strong> 。也是<strong>调用工具</strong>、<strong>推理</strong>和<strong>规划</strong>时常用的prompt结构。</p>
</blockquote>
<p><strong>ReAct</strong> 中迭代使用3个元素：<strong>Thought</strong>, <strong>Action</strong>, <strong>Observation</strong>。其中 <strong>Thought</strong>, <strong>Action</strong> 由 <strong>LLM</strong> 生成，<strong>Observation</strong> 是执行 <strong>Action</strong> 后获得的返回结果。</p>
<ul>
<li>
<p><strong>Step 1</strong> 中，LLM基于 <strong>Question</strong> 先think（reasoning），然后再决定采取什么行动。这样LLM就会生成 <strong>Thought 1</strong> 和 <strong>Action 1</strong> 。执行 <strong>Action 1</strong> 获得 <strong>Observation 1</strong>。</p>
</li>
<li>
<p><strong>Step 2</strong> 中，LLM基于 <strong>Question</strong>，<strong>Thought 1</strong> ，<strong>Action 1</strong> 和 <strong>Observation 1</strong>，汇总所有信息先think（reasoning），然后再决定采取什么行动。这样LLM就会生成 <strong>Thought 2</strong> 和 <strong>Action 2</strong> 。执行 <strong>Action 2</strong> 获得 <strong>Observation 2</strong>。</p>
</li>
<li>
<p><strong>Step 3</strong> 中，LLM基于 <strong>Question</strong>，<strong>Thought 1</strong> ，<strong>Action 1</strong> ，<strong>Observation 1</strong>，<strong>Thought 2</strong> ，<strong>Action 2</strong> 和 <strong>Observation 2</strong>，汇总所有信息先think（reasoning），然后再决定采取什么行动。这样LLM就会生成 <strong>Thought 3</strong> 和 <strong>Action 3</strong> 。执行 <strong>Action 3</strong> 获得 <strong>Observation 3</strong>。</p>
</li>
<li>
<p>以此类推直到 <strong>Action</strong> 表示结束。</p>
</li>
</ul>
<p>具体代码可以参考以下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">webthink</span>(<span class="params">idx=<span class="literal">None</span>, prompt=webthink_prompt, to_print=<span class="literal">True</span></span>):</span><br><span class="line">    question = env.reset(idx=idx)</span><br><span class="line">    <span class="keyword">if</span> to_print:</span><br><span class="line">        <span class="built_in">print</span>(idx, question)</span><br><span class="line">    prompt += question + <span class="string">&quot;\n&quot;</span></span><br><span class="line">    n_calls, n_badcalls = <span class="number">0</span>, <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, <span class="number">8</span>):</span><br><span class="line">        n_calls += <span class="number">1</span></span><br><span class="line">        thought_action = llm(prompt + <span class="string">f&quot;Thought <span class="subst">&#123;i&#125;</span>:&quot;</span>, stop=[<span class="string">f&quot;\nObservation <span class="subst">&#123;i&#125;</span>:&quot;</span>])</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            thought, action = thought_action.strip().split(<span class="string">f&quot;\nAction <span class="subst">&#123;i&#125;</span>: &quot;</span>)</span><br><span class="line">        <span class="keyword">except</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;ohh...&#x27;</span>, thought_action)</span><br><span class="line">            n_badcalls += <span class="number">1</span></span><br><span class="line">            n_calls += <span class="number">1</span></span><br><span class="line">            thought = thought_action.strip().split(<span class="string">&#x27;\n&#x27;</span>)[<span class="number">0</span>]</span><br><span class="line">            action = llm(prompt + <span class="string">f&quot;Thought <span class="subst">&#123;i&#125;</span>: <span class="subst">&#123;thought&#125;</span>\nAction <span class="subst">&#123;i&#125;</span>:&quot;</span>, stop=[<span class="string">f&quot;\n&quot;</span>]).strip()</span><br><span class="line">        obs, r, done, info = step(env, action[<span class="number">0</span>].lower() + action[<span class="number">1</span>:])</span><br><span class="line">        obs = obs.replace(<span class="string">&#x27;\\n&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">        step_str = <span class="string">f&quot;Thought <span class="subst">&#123;i&#125;</span>: <span class="subst">&#123;thought&#125;</span>\nAction <span class="subst">&#123;i&#125;</span>: <span class="subst">&#123;action&#125;</span>\nObservation <span class="subst">&#123;i&#125;</span>: <span class="subst">&#123;obs&#125;</span>\n&quot;</span></span><br><span class="line">        prompt += step_str  <span class="comment"># 之前的 Thought, Action, Observation 都加进来了</span></span><br><span class="line">        <span class="keyword">if</span> to_print:</span><br><span class="line">            <span class="built_in">print</span>(step_str)</span><br><span class="line">        <span class="keyword">if</span> done:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> done:</span><br><span class="line">        obs, r, done, info = step(env, <span class="string">&quot;finish[]&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> to_print:</span><br><span class="line">        <span class="built_in">print</span>(info, <span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    info.update(&#123;<span class="string">&#x27;n_calls&#x27;</span>: n_calls, <span class="string">&#x27;n_badcalls&#x27;</span>: n_badcalls, <span class="string">&#x27;traj&#x27;</span>: prompt&#125;)</span><br><span class="line">    <span class="keyword">return</span> r, info</span><br></pre></td></tr></table></figure>
<p>来源于: <a target="_blank" rel="noopener" href="https://github.com/ysymyth/ReAct/blob/master/hotpotqa.ipynb">https://github.com/ysymyth/ReAct/blob/master/hotpotqa.ipynb</a></p>
<p>上面函数输入的参数 <strong>webthink_prompt</strong> ，长如下样子：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">Solve</span> <span class="string">a</span> <span class="string">question</span> <span class="string">answering</span> <span class="string">task</span> <span class="string">with</span> <span class="string">interleaving</span> <span class="string">Thought,</span> <span class="string">Action,</span> <span class="string">Observation</span> <span class="string">steps.</span> <span class="string">Thought</span> <span class="string">can</span> <span class="string">reason</span> <span class="string">about</span> <span class="string">the</span> <span class="string">current</span> <span class="string">situation,</span> <span class="attr">and Action can be three types:</span> </span><br><span class="line"><span class="string">(1)</span> <span class="string">Search[entity],</span> <span class="string">which</span> <span class="string">searches</span> <span class="string">the</span> <span class="string">exact</span> <span class="string">entity</span> <span class="string">on</span> <span class="string">Wikipedia</span> <span class="string">and</span> <span class="string">returns</span> <span class="string">the</span> <span class="string">first</span> <span class="string">paragraph</span> <span class="string">if</span> <span class="string">it</span> <span class="string">exists.</span> <span class="string">If</span> <span class="string">not,</span> <span class="string">it</span> <span class="string">will</span> <span class="string">return</span> <span class="string">some</span> <span class="string">similar</span> <span class="string">entities</span> <span class="string">to</span> <span class="string">search.</span></span><br><span class="line"><span class="string">(2)</span> <span class="string">Lookup[keyword],</span> <span class="string">which</span> <span class="string">returns</span> <span class="string">the</span> <span class="string">next</span> <span class="string">sentence</span> <span class="string">containing</span> <span class="string">keyword</span> <span class="string">in</span> <span class="string">the</span> <span class="string">current</span> <span class="string">passage.</span></span><br><span class="line"><span class="string">(3)</span> <span class="string">Finish[answer],</span> <span class="string">which</span> <span class="string">returns</span> <span class="string">the</span> <span class="string">answer</span> <span class="string">and</span> <span class="string">finishes</span> <span class="string">the</span> <span class="string">task.</span></span><br><span class="line"><span class="string">Here</span> <span class="string">are</span> <span class="string">some</span> <span class="string">examples.</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Question:</span> <span class="string">What</span> <span class="string">is</span> <span class="string">the</span> <span class="string">elevation</span> <span class="string">range</span> <span class="string">for</span> <span class="string">the</span> <span class="string">area</span> <span class="string">that</span> <span class="string">the</span> <span class="string">eastern</span> <span class="string">sector</span> <span class="string">of</span> <span class="string">the</span> <span class="string">Colorado</span> <span class="string">orogeny</span> <span class="string">extends</span> <span class="string">into?</span></span><br><span class="line"><span class="attr">Thought 1:</span> <span class="string">I</span> <span class="string">need</span> <span class="string">to</span> <span class="string">search</span> <span class="string">Colorado</span> <span class="string">orogeny,</span> <span class="string">find</span> <span class="string">the</span> <span class="string">area</span> <span class="string">that</span> <span class="string">the</span> <span class="string">eastern</span> <span class="string">sector</span> <span class="string">of</span> <span class="string">the</span> <span class="string">Colorado</span> <span class="string">orogeny</span> <span class="string">extends</span> <span class="string">into,</span> <span class="string">then</span> <span class="string">find</span> <span class="string">the</span> <span class="string">elevation</span> <span class="string">range</span> <span class="string">of</span> <span class="string">the</span> <span class="string">area.</span></span><br><span class="line"><span class="attr">Action 1:</span> <span class="string">Search[Colorado</span> <span class="string">orogeny]</span></span><br><span class="line"><span class="attr">Observation 1:</span> <span class="string">The</span> <span class="string">Colorado</span> <span class="string">orogeny</span> <span class="string">was</span> <span class="string">an</span> <span class="string">episode</span> <span class="string">of</span> <span class="string">mountain</span> <span class="string">building</span> <span class="string">(an</span> <span class="string">orogeny)</span> <span class="string">in</span> <span class="string">Colorado</span> <span class="string">and</span> <span class="string">surrounding</span> <span class="string">areas.</span></span><br><span class="line"><span class="attr">Thought 2:</span> <span class="string">It</span> <span class="string">does</span> <span class="string">not</span> <span class="string">mention</span> <span class="string">the</span> <span class="string">eastern</span> <span class="string">sector.</span> <span class="string">So</span> <span class="string">I</span> <span class="string">need</span> <span class="string">to</span> <span class="string">look</span> <span class="string">up</span> <span class="string">eastern</span> <span class="string">sector.</span></span><br><span class="line"><span class="attr">Action 2:</span> <span class="string">Lookup[eastern</span> <span class="string">sector]</span></span><br><span class="line"><span class="attr">Observation 2:</span> <span class="string">(Result</span> <span class="number">1</span> <span class="string">/</span> <span class="number">1</span><span class="string">)</span> <span class="string">The</span> <span class="string">eastern</span> <span class="string">sector</span> <span class="string">extends</span> <span class="string">into</span> <span class="string">the</span> <span class="string">High</span> <span class="string">Plains</span> <span class="string">and</span> <span class="string">is</span> <span class="string">called</span> <span class="string">the</span> <span class="string">Central</span> <span class="string">Plains</span> <span class="string">orogeny.</span></span><br><span class="line"><span class="attr">Thought 3:</span> <span class="string">The</span> <span class="string">eastern</span> <span class="string">sector</span> <span class="string">of</span> <span class="string">Colorado</span> <span class="string">orogeny</span> <span class="string">extends</span> <span class="string">into</span> <span class="string">the</span> <span class="string">High</span> <span class="string">Plains.</span> <span class="string">So</span> <span class="string">I</span> <span class="string">need</span> <span class="string">to</span> <span class="string">search</span> <span class="string">High</span> <span class="string">Plains</span> <span class="string">and</span> <span class="string">find</span> <span class="string">its</span> <span class="string">elevation</span> <span class="string">range.</span></span><br><span class="line"><span class="attr">Action 3:</span> <span class="string">Search[High</span> <span class="string">Plains]</span></span><br><span class="line"><span class="attr">Observation 3: High Plains refers to one of two distinct land regions:</span></span><br><span class="line"><span class="attr">Thought 4:</span> <span class="string">I</span> <span class="string">need</span> <span class="string">to</span> <span class="string">instead</span> <span class="string">search</span> <span class="string">High</span> <span class="string">Plains</span> <span class="string">(United</span> <span class="string">States).</span></span><br><span class="line"><span class="attr">Action 4:</span> <span class="string">Search[High</span> <span class="string">Plains</span> <span class="string">(United</span> <span class="string">States)]</span></span><br><span class="line"><span class="attr">Observation 4:</span> <span class="string">The</span> <span class="string">High</span> <span class="string">Plains</span> <span class="string">are</span> <span class="string">a</span> <span class="string">subregion</span> <span class="string">of</span> <span class="string">the</span> <span class="string">Great</span> <span class="string">Plains.</span> <span class="string">From</span> <span class="string">east</span> <span class="string">to</span> <span class="string">west,</span> <span class="string">the</span> <span class="string">High</span> <span class="string">Plains</span> <span class="string">rise</span> <span class="string">in</span> <span class="string">elevation</span> <span class="string">from</span> <span class="string">around</span> <span class="number">1</span><span class="string">,800</span> <span class="string">to</span> <span class="number">7</span><span class="string">,000</span> <span class="string">ft</span> <span class="string">(550</span> <span class="string">to</span> <span class="number">2</span><span class="string">,130</span> <span class="string">m).[3]</span></span><br><span class="line"><span class="attr">Thought 5:</span> <span class="string">High</span> <span class="string">Plains</span> <span class="string">rise</span> <span class="string">in</span> <span class="string">elevation</span> <span class="string">from</span> <span class="string">around</span> <span class="number">1</span><span class="string">,800</span> <span class="string">to</span> <span class="number">7</span><span class="string">,000</span> <span class="string">ft,</span> <span class="string">so</span> <span class="string">the</span> <span class="string">answer</span> <span class="string">is</span> <span class="number">1</span><span class="string">,800</span> <span class="string">to</span> <span class="number">7</span><span class="string">,000</span> <span class="string">ft.</span></span><br><span class="line"><span class="attr">Action 5:</span> <span class="string">Finish[1,800</span> <span class="string">to</span> <span class="number">7</span><span class="string">,000</span> <span class="string">ft]</span></span><br><span class="line"></span><br><span class="line">[<span class="string">More</span> <span class="string">Examples</span>]<span class="string">...</span></span><br></pre></td></tr></table></figure>
<p>更多prompt结构可以参考 <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/642357544">链接</a> 。</p>
<p>有了上面的基本知识后，我接下来会介绍几篇Agent的代表性工作。本文（Part 1）介绍来自斯坦福的工作，其中主要文字都是原论文直译。</p>
<h2 id="来自斯坦福的虚拟小镇">来自斯坦福的虚拟小镇</h2>
<ul>
<li>
<p><strong><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2304.03442">Generative Agents: Interactive Simulacra of Human Behavior</a></strong>, 2023.04, Stanford</p>
</li>
<li>
<p><strong>代码已开源</strong>：<a target="_blank" rel="noopener" href="https://github.com/joonspk-research/generative_agents">https://github.com/joonspk-research/generative_agents</a></p>
</li>
</ul>
<p><strong>虚拟小镇，一个agent就是一个虚拟人物，25个agents之间的故事。</strong></p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230825171857.png" alt=""></p>
<h3 id="架构">架构</h3>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230825171936.png" alt=""></p>
<p>代理（Agents）感知他们的环境，当前代理所有的感知（完整的经历记录）都被保存在一个名为**“记忆流”（memory stream）<strong>中。基于代理的感知，系统检索相关的记忆，然后使用这些检索到的行为来决定下一个行为。这些检索到的记忆也被用来形成长期</strong>计划**，并创造出更高级的<strong>反思</strong>，这些都被输入到记忆流中以供未来使用。</p>
<h4 id="1-记忆流与检索">1. 记忆流与检索</h4>
<p><strong>记忆流（Memory Stream）<strong>记录了代理（Agent）的所有经历。它是一个内存对象</strong>列表</strong>，其中每个对象包含自然语言描述，创建时间戳和最近访问时间戳。记忆流的最基本元素是<strong>观察（Observation）</strong>，这是代理直接感知的事件。常见的观察包括代理自己执行的行为，或者代理感知到的其他代理或非代理对象执行的行为*（每个Agent都有自己独立的记忆流）*。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230825183233.png" alt=""></p>
<p><strong>检索</strong>功能以代理的当前情况作为输入，检索出一部分记忆流，以传递给语言模型。</p>
<p>排序打分包括三个部分：</p>
<ul>
<li>
<p><strong>近期性（Recency）<strong>为最近访问的记忆对象分配更高的分数，因此刚刚发生的事件或今天早上的事件可能会保留在代理的注意力范围内。在作者的实现中，将近期性视为一个</strong>指数衰减函数</strong>，衰减的对象是自上次检索记忆以来的沙盒游戏小时数。衰减因子是0.99。</p>
</li>
<li>
<p>**重要性（Importance）**通过为代理认为重要的记忆对象分配更高的分数，区分了平凡记忆和核心记忆。例如，一个平凡的事件，如在房间里吃早餐，会产生一个低重要性分数，而与重要的他人分手则会产生一个高分。重要性分数的实现方式有很多种；作者直接使用LLM打分，输出一个整数分数。</p>
</li>
<li>
<ul>
<li><strong>prompt:</strong></li>
</ul>
</li>
</ul>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">On</span> <span class="string">the</span> <span class="string">scale</span> <span class="string">of</span> <span class="number">1</span> <span class="string">to</span> <span class="number">10</span><span class="string">,</span> <span class="string">where</span> <span class="number">1</span> <span class="string">is</span> <span class="string">purely</span> <span class="string">mundane</span> <span class="string">(e.g.,</span> <span class="string">brushing</span> <span class="string">teeth,</span> <span class="string">making</span> <span class="string">bed)</span> <span class="string">and</span> <span class="number">10</span> <span class="string">is</span> <span class="string">extremely</span> <span class="string">poignant</span> <span class="string">(e.g.,</span> <span class="string">a</span> <span class="string">break</span> <span class="string">up,</span> <span class="string">college</span> <span class="string">acceptance),</span> <span class="string">rate</span> <span class="string">the</span> <span class="string">likely</span> <span class="string">poignancy</span> <span class="string">of</span> <span class="string">the</span> <span class="string">following</span> <span class="string">piece</span> <span class="string">of</span> <span class="string">memory.</span></span><br><span class="line">      </span><br><span class="line"><span class="attr">Memory: buying groceries at The Willows Market and Pharmacy Rating:</span> <span class="string">&lt;fill</span> <span class="string">in&gt;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>**相关性（Relevance）**为与当前情况相关的记忆对象分配更高的分数。使用常见的向量检索引擎即可。</li>
</ul>
<p>最终的检索分数是上面三项的加权平均：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext> score </mtext><mo>=</mo><msub><mi>α</mi><mtext>recency </mtext></msub><mo>⋅</mo><mtext> recency </mtext><mo>+</mo><msub><mi>α</mi><mtext>importance </mtext></msub><mo>⋅</mo><mtext> importance </mtext><mo>+</mo><msub><mi>α</mi><mtext>relevance </mtext></msub><mo>⋅</mo><mtext> relevance. </mtext></mrow><annotation encoding="application/x-tex">\text { score }=\alpha_{\text {recency }} \cdot \text { recency }+\alpha_{\text {importance }} \cdot \text { importance }+\alpha_{\text {relevance }} \cdot \text { relevance. }
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord text"><span class="mord"> score </span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7306em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">recency </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7778em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord"> recency </span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.7306em;vertical-align:-0.2861em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3175em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">importance </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.8623em;vertical-align:-0.1944em;"></span><span class="mord text"><span class="mord"> importance </span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.5945em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">relevance </span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord text"><span class="mord"> relevance. </span></span></span></span></span></span></p>
<h4 id="2-反思（Reflection）">2. 反思（Reflection）</h4>
<p><strong>挑战：</strong> 仅配备原始观察记忆的代理，往往难以进行<strong>概括或推理</strong>。</p>
<p>**示例：**用户问 Klaus Mueller：“If you had to choose one person of those you know to spend an hour with, who would it be?” 仅通过观察记忆，代理简单地选择 Klaus 交互最频繁的人：Wolfgang，他的大学宿舍邻居。但是，Wolfgang 和 Klaus 只是偶尔见面，没有深入的互动。一个更理想的回答需要代理从 Klaus 花费数小时在研究项目上的记忆中概括出 Klaus 对研究的热情，并同样认识到 Maria 也在她自己的研究中付出努力（尽管是在不同的领域），从而反映出他们有共同的兴趣。使用下面的方法，当问 Klaus 要与谁共度时间时，Klaus 会选择 Maria 而不是 Wolfgang。</p>
<p>作者引入了第二种类型的记忆，称之为<strong>反思（Reflection）</strong>。**反思是由代理生成的更高级别、更抽象的思考。<strong>因为反思也是一种记忆，所以</strong>在检索时，它们会与其他观察结果一起被包含在内。反思是周期性生成的；<strong>在作者的实现中，<strong>当代理感知到的最新事件的重要性评分之和超过一定阈值时，就会生成反思。<em><em>在实践中，<strong>代理大约每天反思两到三次</strong></em>（一日三省吾身）</em></strong>。</strong></p>
<p>反思的第一步是让代理<strong>确定要反思什么</strong>，通过确定代理最近的经历可以提出哪些问题。作者<strong>用代理记忆流中最近的100条记录</strong>。</p>
<p>例如，“Klaus Mueller is reading a book on gentrification”, “Klaus Mueller is conversing with a librarian about his research project”, “desk at the library is currently unoccupied”）查询LLM，使用prompt：<strong>“Given only the information above, what are 3 most salient high-level questions we can answer about the subjects in the statements?”</strong>，生成候选问题：例如，“What topic is Klaus Mueller passionate about?” 和  “What is the relationship between Klaus Mueller and Maria Lopez?”</p>
<p>第二步，将这些<strong>生成的问题作为检索的查询</strong>，收集每个问题的相关记忆（包括其他反思）。然后使用LLM从中提取<strong>洞见（insight）</strong>，并引用生成洞见对应的特定记录。下面是完整的提示：</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230825183428.png" alt=""></p>
<p>这个过程生成了一些洞见，比如“Klaus Mueller is dedicated to his research on gentrification (because of 1, 2, 8, 15).”。解析并将这个洞见存储为记忆流中的一个反思，包括<strong>指向被引用的内存对象的指针</strong>。</p>
<p>反思（Reflection）明确允许代理不仅反思他们的观察结果，还可以反思其他的反思：例如，上面关于Klaus Mueller的第二个陈述是Klaus之前的反思，而不是他从环境中得到的观察。因此，代理生成了<strong>反思树</strong>：<strong>树的叶节点代表基础观察，非叶节点代表的思考越往树上越抽象和高级。</strong></p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230825183502.png" alt=""></p>
<p>图中包含了3种 <strong>Memory</strong>：<strong>Observation、Reflection、Plan</strong>。</p>
<h4 id="3-计划与响应">3. 计划与响应</h4>
<p>**计划（Plan）**是为了做更长时间的规划。</p>
<p>像反思一样，<strong>计划也被储存在记忆流中（第三种记忆）</strong>，并被包含在检索过程中。这使得代理能够在决定如何行动时，同时考虑<strong>观察、反思和计划</strong>。如果需要，<strong>代理可能在中途改变他们的计划</strong>（即<strong>响应，reacting</strong>）。</p>
<p>为了创建这样的计划，作者的方法是<strong>从上到下，递归地生成更多的细节</strong>。</p>
<p>第一步是创建一个<strong>大致概述一天行程的计划</strong>。为了创建初始计划，使用代理的<strong>摘要描述</strong>（例如，名字，特征，和他们最近经历的总结）和他们<strong>前一天的总结</strong>来提示语言模型。下面是一个完整的示例提示，底部未完成，由LLM完成：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">Name: Eddy Lin (age:</span> <span class="number">19</span><span class="string">)</span> </span><br><span class="line"><span class="attr">Innate traits:</span> <span class="string">friendly,</span> <span class="string">outgoing,</span> <span class="string">hospitable</span> <span class="string">Eddy</span> <span class="string">Lin</span> <span class="string">is</span> <span class="string">a</span> <span class="string">student</span> <span class="string">at</span> <span class="string">Oak</span> <span class="string">Hill</span> <span class="string">College</span> <span class="string">studying</span> <span class="string">music</span> <span class="string">theory</span> <span class="string">and</span> <span class="string">composition.</span> <span class="string">He</span> <span class="string">loves</span> <span class="string">to</span> <span class="string">explore</span> <span class="string">different</span> <span class="string">musical</span> <span class="string">styles</span> <span class="string">and</span> <span class="string">is</span> <span class="string">always</span> <span class="string">looking</span> <span class="string">for</span> <span class="string">ways</span> <span class="string">to</span> <span class="string">expand</span> <span class="string">his</span> <span class="string">knowledge.</span> <span class="string">Eddy</span> <span class="string">Lin</span> <span class="string">is</span> <span class="string">working</span> <span class="string">on</span> <span class="string">a</span> <span class="string">composition</span> <span class="string">project</span> <span class="string">for</span> <span class="string">his</span> <span class="string">college</span> <span class="string">class.</span> <span class="string">He</span> <span class="string">is</span> <span class="string">also</span> <span class="string">taking</span> <span class="string">classes</span> <span class="string">to</span> <span class="string">learn</span> <span class="string">more</span> <span class="string">about</span> <span class="string">music</span> <span class="string">theory.</span> <span class="string">Eddy</span> <span class="string">Lin</span> <span class="string">is</span> <span class="string">excited</span> <span class="string">about</span> <span class="string">the</span> <span class="string">new</span> <span class="string">composition</span> <span class="string">he</span> <span class="string">is</span> <span class="string">working</span> <span class="string">on</span> <span class="string">but</span> <span class="string">he</span> <span class="string">wants</span> <span class="string">to</span> <span class="string">dedicate</span> <span class="string">more</span> <span class="string">hours</span> <span class="string">in</span> <span class="string">the</span> <span class="string">day</span> <span class="string">to</span> <span class="string">work</span> <span class="string">on</span> <span class="string">it</span> <span class="string">in</span> <span class="string">the</span> <span class="string">coming</span> <span class="string">days.</span> </span><br><span class="line"><span class="string">On</span> <span class="string">Tuesday</span> <span class="string">February</span> <span class="number">12</span><span class="string">,</span> <span class="string">Eddy</span> <span class="number">1</span><span class="string">)</span> <span class="string">woke</span> <span class="string">up</span> <span class="string">and</span> <span class="string">completed</span> <span class="string">the</span> <span class="string">morning</span> <span class="string">routine</span> <span class="string">at</span> <span class="number">7</span><span class="string">:00</span> <span class="string">am,</span> [<span class="string">.</span> <span class="string">.</span> <span class="string">.</span> ] <span class="number">6</span><span class="string">)</span> <span class="string">got</span> <span class="string">ready</span> <span class="string">to</span> <span class="string">sleep</span> <span class="string">around</span> <span class="number">10</span> <span class="string">pm.</span></span><br><span class="line"></span><br><span class="line"><span class="string">Today</span> <span class="string">is</span> <span class="string">Wednesday</span> <span class="string">February</span> <span class="number">13</span><span class="string">.</span> <span class="string">Here</span> <span class="string">is</span> <span class="string">Eddy’s</span> <span class="attr">plan today in broad strokes:</span> <span class="number">1</span><span class="string">)</span></span><br></pre></td></tr></table></figure>
<p>这会生成代理<strong>一天计划的大致草图</strong>，分为五到八个部分：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span><span class="string">)</span> <span class="string">wake</span> <span class="string">up</span> <span class="string">and</span> <span class="string">complete</span> <span class="string">the</span> <span class="string">morning</span> <span class="string">routine</span> <span class="string">at</span> <span class="number">8</span><span class="string">:00</span> <span class="string">am,</span> </span><br><span class="line"><span class="number">2</span><span class="string">)</span> <span class="string">go</span> <span class="string">to</span> <span class="string">Oak</span> <span class="string">Hill</span> <span class="string">College</span> <span class="string">to</span> <span class="string">take</span> <span class="string">classes</span> <span class="string">starting</span> <span class="number">10</span><span class="string">:00</span> <span class="string">am,</span> </span><br><span class="line">[<span class="string">.</span> <span class="string">.</span> <span class="string">.</span> ] </span><br><span class="line"><span class="number">5</span><span class="string">)</span> <span class="string">work</span> <span class="string">on</span> <span class="string">his</span> <span class="string">new</span> <span class="string">music</span> <span class="string">composition</span> <span class="string">from</span> <span class="number">1</span><span class="string">:00</span> <span class="string">pm</span> <span class="string">to</span> <span class="number">5</span><span class="string">:00</span> <span class="string">pm,</span> </span><br><span class="line"><span class="number">6</span><span class="string">)</span> <span class="string">have</span> <span class="string">dinner</span> <span class="string">at</span> <span class="number">5</span><span class="string">:30</span> <span class="string">pm,</span> </span><br><span class="line"><span class="number">7</span><span class="string">)</span> <span class="string">finish</span> <span class="string">school</span> <span class="string">assignments</span> <span class="string">and</span> <span class="string">go</span> <span class="string">to</span> <span class="string">bed</span> <span class="string">by</span> <span class="number">11</span><span class="string">:00</span> <span class="string">pm.</span></span><br></pre></td></tr></table></figure>
<p>代理<strong>将此计划保存在记忆流中</strong>，然后<strong>递归分解它以创建更细粒度的动作</strong>，首先是<strong>一小时长的动作块</strong>——例如，Eddy从下午1点到5点的工作计划 “work on his new music composition” 变成：“<strong>1:00 pm</strong>: start by brainstorming some ideas for his music composition […] <strong>4:00 pm</strong>: take a quick break and recharge his creative energy before reviewing and polishing his composition”。然后我们<strong>再次递归分解这个计划，变成5-15分钟的动作块</strong>：例如，“<strong>4:00 pm</strong>: grab a light snack, such as a piece of fruit, a granola bar, or some nuts. <strong>4:05 pm</strong>: take a short walk around his workspace […] <strong>4:50 pm</strong>: take a few minutes to clean up his workspace.”。这个过程可以根据需要的粒度进行调整。</p>
<p><strong>3.1 响应和更新计划（Reacting and Updating Plans）</strong>。代理执行动作循环中的动作，每个时间步骤，它们感知周围的世界，这些感知到的观察结果被存储在它们的记忆流中。这些观察结果输入到LLM，让LLM<strong>决定代理是否应该继续他们现有的计划，或者做出响应（reacting）</strong>。例如，站在画架前画画可能会触发对画架的观察，不太可能引发响应。然而，如果艾迪的父亲约翰记录下他看见艾迪在房子的花园里短暂散步，结果就不同了。下面是prompt，其中 <code>[Agent’s Summary Description]</code> 代表了一个动态生成的、长达一段落的对代理总体目标和性情的总结：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">Agent’s</span> <span class="string">Summary</span> <span class="string">Description</span>] </span><br><span class="line"></span><br><span class="line"><span class="string">It</span> <span class="string">is</span> <span class="string">February</span> <span class="number">13</span><span class="string">,</span> <span class="number">2023</span><span class="string">,</span> <span class="number">4</span><span class="string">:56</span> <span class="string">pm.</span></span><br><span class="line"></span><br><span class="line"><span class="string">John</span> <span class="string">Lin’s</span> <span class="attr">status:</span> <span class="string">John</span> <span class="string">is</span> <span class="string">back</span> <span class="string">home</span> <span class="string">early</span> <span class="string">from</span> <span class="string">work.</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Observation:</span> <span class="string">John</span> <span class="string">saw</span> <span class="string">Eddy</span> <span class="string">taking</span> <span class="string">a</span> <span class="string">short</span> <span class="string">walk</span> <span class="string">around</span> <span class="string">his</span> <span class="string">workplace.</span></span><br><span class="line"></span><br><span class="line"><span class="string">Summary</span> <span class="string">of</span> <span class="string">relevant</span> <span class="string">context</span> <span class="string">from</span> <span class="string">John’s</span> <span class="attr">memory:</span> <span class="string">Eddy</span> <span class="string">Lin</span> <span class="string">is</span> <span class="string">John’s</span> <span class="string">Lin’s</span> <span class="string">son.</span> <span class="string">Eddy</span> <span class="string">Lin</span> <span class="string">has</span> <span class="string">been</span> <span class="string">working</span> <span class="string">on</span> <span class="string">a</span> <span class="string">music</span> <span class="string">composition</span> <span class="string">for</span> <span class="string">his</span> <span class="string">class.</span> <span class="string">Eddy</span> <span class="string">Lin</span> <span class="string">likes</span> <span class="string">to</span> <span class="string">walk</span> <span class="string">around</span> <span class="string">the</span> <span class="string">garden</span> <span class="string">when</span> <span class="string">he</span> <span class="string">is</span> <span class="string">thinking</span> <span class="string">about</span> <span class="string">or</span> <span class="string">listening</span> <span class="string">to</span> <span class="string">music.</span></span><br><span class="line"></span><br><span class="line"><span class="string">Should</span> <span class="string">John</span> <span class="string">react</span> <span class="string">to</span> <span class="string">the</span> <span class="string">observation,</span> <span class="string">and</span> <span class="string">if</span> <span class="string">so,</span> <span class="string">what</span> <span class="string">would</span> <span class="string">be</span> <span class="string">an</span> <span class="string">appropriate</span> <span class="string">reaction?</span></span><br></pre></td></tr></table></figure>
<p>通过两个prompts “<strong>What is [observer]’s relationship with the [observed entity]?</strong>”和“<strong>[Observed entity] is [action status of the observed entity]</strong>”来生成上下文摘要，并<strong>将它们的答案一起总结</strong>。输出建议 “<strong>John could consider asking Eddy about his music composition project</strong>”。然后，<strong>从响应发生的时间开始，重新生成代理的现有计划</strong>。最后，如果行动指示了代理之间需要互动，使用以下方式生成他们的对话。</p>
<p>**3.2 对话。**代理在互动时进行对话。根据它们对彼此的记忆来生成代理的对话。例如，当John开始和Eddy对话时，通过使用他对Eddy的总结记忆以及他决定询问Eddy关于他的&quot;composition project&quot;时的预期响应来生成John的第一句话。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">Agent’s</span> <span class="string">Summary</span> <span class="string">Description</span>]</span><br><span class="line"></span><br><span class="line"><span class="string">It</span> <span class="string">is</span> <span class="string">February</span> <span class="number">13</span><span class="string">,</span> <span class="number">2023</span><span class="string">,</span> <span class="number">4</span><span class="string">:56</span> <span class="string">pm.</span></span><br><span class="line"></span><br><span class="line"><span class="string">John</span> <span class="string">Lin’s</span> <span class="attr">status:</span> <span class="string">John</span> <span class="string">is</span> <span class="string">back</span> <span class="string">home</span> <span class="string">early</span> <span class="string">from</span> <span class="string">work.</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Observation:</span> <span class="string">John</span> <span class="string">saw</span> <span class="string">Eddy</span> <span class="string">taking</span> <span class="string">a</span> <span class="string">short</span> <span class="string">walk</span> <span class="string">around</span> <span class="string">his</span> <span class="string">workplace.</span></span><br><span class="line"></span><br><span class="line"><span class="string">Summary</span> <span class="string">of</span> <span class="string">relevant</span> <span class="string">context</span> <span class="string">from</span> <span class="string">John’s</span> <span class="attr">memory:</span> <span class="string">Eddy</span> <span class="string">Lin</span> <span class="string">is</span> <span class="string">John’s</span> <span class="string">Lin’s</span> <span class="string">son.</span> <span class="string">Eddy</span> <span class="string">Lin</span> <span class="string">has</span> <span class="string">been</span> <span class="string">working</span> <span class="string">on</span> <span class="string">a</span> <span class="string">music</span> <span class="string">composition</span> <span class="string">for</span> <span class="string">his</span> <span class="string">class.</span> <span class="string">Eddy</span> <span class="string">Lin</span> <span class="string">likes</span> <span class="string">to</span> <span class="string">walk</span> <span class="string">around</span> <span class="string">the</span> <span class="string">garden</span> <span class="string">when</span> <span class="string">he</span> <span class="string">is</span> <span class="string">thinking</span> <span class="string">about</span> <span class="string">or</span> <span class="string">listening</span> <span class="string">to</span> <span class="string">music.</span></span><br><span class="line"></span><br><span class="line"><span class="string">John</span> <span class="string">is</span> <span class="string">asking</span> <span class="string">Eddy</span> <span class="string">about</span> <span class="string">his</span> <span class="string">music</span> <span class="string">composition</span> <span class="string">project.</span> <span class="string">What</span> <span class="string">would</span> <span class="string">he</span> <span class="string">say</span> <span class="string">to</span> <span class="string">Eddy?</span></span><br></pre></td></tr></table></figure>
<p>结果：“Hey Eddy, how’s the music composition project for your class coming along?”</p>
<p>从Eddy的角度看，John发起的对话被视为一个他可能想要回应的事件。因此，就像John做的那样，Eddy检索并总结了他与John的关系记忆，以及可能与John在对话中的最后一句话相关的记忆。如果他决定回应，我们会使用他的总结记忆和当前的对话历史来生成Eddy的话语：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">Agent’s</span> <span class="string">Summary</span> <span class="string">Description</span>] </span><br><span class="line"></span><br><span class="line"><span class="string">It</span> <span class="string">is</span> <span class="string">February</span> <span class="number">13</span><span class="string">,</span> <span class="number">2023</span><span class="string">,</span> <span class="number">4</span><span class="string">:56</span> <span class="string">pm.</span></span><br><span class="line"></span><br><span class="line"><span class="string">Eddy</span> <span class="string">Lin’s</span> <span class="attr">status:</span> <span class="string">Eddy</span> <span class="string">is</span> <span class="string">taking</span> <span class="string">a</span> <span class="string">short</span> <span class="string">walk</span> <span class="string">around</span> <span class="string">his</span> <span class="string">workplace.</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Observation:</span> <span class="string">John</span> <span class="string">is</span> <span class="string">initiating</span> <span class="string">a</span> <span class="string">conversation</span> <span class="string">with</span> <span class="string">Eddy.</span></span><br><span class="line"></span><br><span class="line"><span class="string">Summary</span> <span class="string">of</span> <span class="string">relevant</span> <span class="string">context</span> <span class="string">from</span> <span class="string">Eddy’s</span> <span class="attr">memory:</span> <span class="string">Jonn</span> <span class="string">Lin</span> <span class="string">is</span> <span class="string">Eddy</span> <span class="string">Lin’s</span> <span class="string">father.</span> <span class="string">John</span> <span class="string">Lin</span> <span class="string">is</span> <span class="string">caring</span> <span class="string">and</span> <span class="string">is</span> <span class="string">interested</span> <span class="string">to</span> <span class="string">learn</span> <span class="string">more</span> <span class="string">about</span> <span class="string">Eddy</span> <span class="string">Lin’s</span> <span class="string">school</span> <span class="string">work.</span> <span class="string">John</span> <span class="string">Lin</span> <span class="string">knows</span> <span class="string">that</span> <span class="string">Eddy</span> <span class="string">Lin</span> <span class="string">is</span> <span class="string">working</span> <span class="string">on</span> <span class="string">a</span> <span class="string">music</span> <span class="string">composition.</span></span><br><span class="line"></span><br><span class="line"><span class="attr">Here is the dialogue history:</span></span><br><span class="line"></span><br><span class="line"><span class="attr">John:</span> <span class="string">Hey</span> <span class="string">Eddy,</span> <span class="string">how’s</span> <span class="string">the</span> <span class="string">music</span> <span class="string">composition</span> <span class="string">project</span> <span class="string">for</span> <span class="string">your</span> <span class="string">class</span> <span class="string">coming</span> <span class="string">along?</span></span><br><span class="line"></span><br><span class="line"><span class="string">How</span> <span class="string">would</span> <span class="string">Eddy</span> <span class="string">respond</span> <span class="string">to</span> <span class="string">John?</span></span><br></pre></td></tr></table></figure>
<p>这生成了Eddy的回应：“Hey Dad, it’s going well. I’ve been taking walks around the garden to clear my head and get some inspiration.”</p>
<p>这个对话的延续是使用同样的机制生成的，直到两个代理中的一个决定结束对话。</p>
<h3 id="References">References</h3>
<ol>
<li>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/tXxCEtAA_W1eS0ti-Yydxg">大模型下半场，关于Agent的几个疑问</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://lilianweng.github.io/posts/2023-06-23-agent/">LLM Powered Autonomous Agents | Lil’Log</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://github.com/joonspk-research/generative_agents">Generative Agents: Interactive Simulacra of Human Behavior</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s/5N5H2yqiCKWtM34ngjk6Hw">Agent：OpenAI的下一步，亚马逊云科技站在第5层</a></p>
</li>
<li>
<p>ReAct: <a target="_blank" rel="noopener" href="https://react-lm.github.io/">https://react-lm.github.io</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://github.com/joonspk-research/generative_agents">Generative Agents: Interactive Simulacra of Human Behavior</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/642357544">2023年新生代大模型Agents技术,ReAct,Self-Ask,Plan-and-execute,以及AutoGPT, HuggingGPT等应用</a></p>
</li>
<li>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/648376562">LLM-based Agents survey 基于大语言模型多智能代理简单综述及展望</a></p>
</li>
</ol>
<p><a target="_blank" rel="noopener" href="https://www.breezedeus.com/article/ai-agent-part1">阅读原文</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Weitang Liu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://lonepatient.top/2023/08/23/LLM_agents_part1.html">http://lonepatient.top/2023/08/23/LLM_agents_part1.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://lonepatient.top" target="_blank">闲记算法</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/NLP/">NLP</a><a class="post-meta__tags" href="/tags/Agent/">Agent</a><a class="post-meta__tags" href="/tags/%E9%A2%84%E8%AE%AD%E7%BB%83/">预训练</a><a class="post-meta__tags" href="/tags/%E5%A4%A7%E5%9E%8B%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">大型语言模型</a><a class="post-meta__tags" href="/tags/LLM/">LLM</a><a class="post-meta__tags" href="/tags/ChatGPT/">ChatGPT</a><a class="post-meta__tags" href="/tags/AI/">AI</a><a class="post-meta__tags" href="/tags/%E6%99%BA%E8%83%BD%E4%BD%93/">智能体</a><a class="post-meta__tags" href="/tags/GPT4/">GPT4</a></div><div class="post_share"><div class="social-share" data-image="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230806160808.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/08/31/llm_in_1688.html"><img class="prev-cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230831212220.jpeg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">大语言模型在1688电商场景的算法实践</div></div></a></div><div class="next-post pull-right"><a href="/2023/08/22/LLM_inference_optimizing_latency.html"><img class="next-cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230827173120.webp" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">LLM推理加速</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/07/29/LLM_Powered_Autonomous_Agents.html" title="使用LLM构建AI Agents的正确姿势"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230908194136.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-29</div><div class="title">使用LLM构建AI Agents的正确姿势</div></div></a></div><div><a href="/2023/09/05/engineer_Landing_LLM.html" title="如何工程化落地LLM：五类模式加速 AI 应用开发"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230907104310.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-09-05</div><div class="title">如何工程化落地LLM：五类模式加速 AI 应用开发</div></div></a></div><div><a href="/2023/07/30/llm_qa_Embedding_recall.html" title="问答系统使用 Embedding 召回的局限及解决方案"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230907214925.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-07-30</div><div class="title">问答系统使用 Embedding 召回的局限及解决方案</div></div></a></div><div><a href="/2023/03/10/ChatGPT_Research_Report.html" title="ChatGPT 调研报告"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230310095306.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-10</div><div class="title">ChatGPT 调研报告</div></div></a></div><div><a href="/2023/02/27/Illustrating_Reinforcement_Learning_from_Human_Feedback.html" title="Reinforcement Learning from Human Feedback (RLHF)详解"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230328150206.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-02-27</div><div class="title">Reinforcement Learning from Human Feedback (RLHF)详解</div></div></a></div><div><a href="/2023/08/22/LLM_inference_optimizing_latency.html" title="LLM推理加速"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230827173120.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-08-22</div><div class="title">LLM推理加速</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Weitang Liu</div><div class="author-info__description">一个致力于记录技术的博客</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">281</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">384</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">92</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/lonePatient"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/lonePatient" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:liuweitangmath@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://weibo.com/277974397" target="_blank" title="Weibo"><i class="fab fa-weibo"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有任何问题可通过留言板或者微信公众号给我留言，谢谢！<img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/202602201201102.jpg"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFAI-Agent%EF%BC%9F"><span class="toc-number">1.</span> <span class="toc-text">什么是AI Agent？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86"><span class="toc-number">2.</span> <span class="toc-text">背景知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%B0%E5%BF%86%EF%BC%88Memory%EF%BC%89"><span class="toc-number">2.1.</span> <span class="toc-text">记忆（Memory）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%8E%E4%B9%88%E5%86%99%E5%A5%BDPrompt%EF%BC%9AReAct"><span class="toc-number">2.2.</span> <span class="toc-text">怎么写好Prompt：ReAct</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9D%A5%E8%87%AA%E6%96%AF%E5%9D%A6%E7%A6%8F%E7%9A%84%E8%99%9A%E6%8B%9F%E5%B0%8F%E9%95%87"><span class="toc-number">3.</span> <span class="toc-text">来自斯坦福的虚拟小镇</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84"><span class="toc-number">3.1.</span> <span class="toc-text">架构</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-%E8%AE%B0%E5%BF%86%E6%B5%81%E4%B8%8E%E6%A3%80%E7%B4%A2"><span class="toc-number">3.1.1.</span> <span class="toc-text">1. 记忆流与检索</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-%E5%8F%8D%E6%80%9D%EF%BC%88Reflection%EF%BC%89"><span class="toc-number">3.1.2.</span> <span class="toc-text">2. 反思（Reflection）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-%E8%AE%A1%E5%88%92%E4%B8%8E%E5%93%8D%E5%BA%94"><span class="toc-number">3.1.3.</span> <span class="toc-text">3. 计划与响应</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#References"><span class="toc-number">3.2.</span> <span class="toc-text">References</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/02/27/arxiv_papers_2026-02-27.html" title="Arxiv今日论文 | 2026-02-27"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-27"/></a><div class="content"><a class="title" href="/2026/02/27/arxiv_papers_2026-02-27.html" title="Arxiv今日论文 | 2026-02-27">Arxiv今日论文 | 2026-02-27</a><time datetime="2026-02-27T12:30:00.000Z" title="发表于 2026-02-27 12:30:00">2026-02-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/26/arxiv_papers_2026-02-26.html" title="Arxiv今日论文 | 2026-02-26"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-26"/></a><div class="content"><a class="title" href="/2026/02/26/arxiv_papers_2026-02-26.html" title="Arxiv今日论文 | 2026-02-26">Arxiv今日论文 | 2026-02-26</a><time datetime="2026-02-26T12:30:00.000Z" title="发表于 2026-02-26 12:30:00">2026-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/arxiv_papers_2026-02-25.html" title="Arxiv今日论文 | 2026-02-25"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-25"/></a><div class="content"><a class="title" href="/2026/02/25/arxiv_papers_2026-02-25.html" title="Arxiv今日论文 | 2026-02-25">Arxiv今日论文 | 2026-02-25</a><time datetime="2026-02-25T12:30:00.000Z" title="发表于 2026-02-25 12:30:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/2026-02-25-Less-is-Enough-Synthesizing-Diverse-Data-in-Feature-Space-of-LLMs.html" title="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260225222513891.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板"/></a><div class="content"><a class="title" href="/2026/02/25/2026-02-25-Less-is-Enough-Synthesizing-Diverse-Data-in-Feature-Space-of-LLMs.html" title="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板">大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板</a><time datetime="2026-02-25T12:00:00.000Z" title="发表于 2026-02-25 12:00:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/2026-02-25-Midtraining-%E4%B8%AD%E9%97%B4%E8%AE%AD%E7%BB%83-%E6%9E%84%E5%BB%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%90%8E%E8%AE%AD%E7%BB%83%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%A5%E6%A2%81.html" title="mid-training：构建预训练与后训练之间的分布式桥梁"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260225123005910.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="mid-training：构建预训练与后训练之间的分布式桥梁"/></a><div class="content"><a class="title" href="/2026/02/25/2026-02-25-Midtraining-%E4%B8%AD%E9%97%B4%E8%AE%AD%E7%BB%83-%E6%9E%84%E5%BB%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%90%8E%E8%AE%AD%E7%BB%83%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%A5%E6%A2%81.html" title="mid-training：构建预训练与后训练之间的分布式桥梁">mid-training：构建预训练与后训练之间的分布式桥梁</a><time datetime="2026-02-25T00:00:00.000Z" title="发表于 2026-02-25 00:00:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/24/arxiv_papers_2026-02-24.html" title="Arxiv今日论文 | 2026-02-24"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-24"/></a><div class="content"><a class="title" href="/2026/02/24/arxiv_papers_2026-02-24.html" title="Arxiv今日论文 | 2026-02-24">Arxiv今日论文 | 2026-02-24</a><time datetime="2026-02-24T12:30:00.000Z" title="发表于 2026-02-24 12:30:00">2026-02-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/23/arxiv_papers_2026-02-23.html" title="Arxiv今日论文 | 2026-02-23"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-23"/></a><div class="content"><a class="title" href="/2026/02/23/arxiv_papers_2026-02-23.html" title="Arxiv今日论文 | 2026-02-23">Arxiv今日论文 | 2026-02-23</a><time datetime="2026-02-23T12:30:00.000Z" title="发表于 2026-02-23 12:30:00">2026-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/23/Think-Deep,-Not-Just-Long-Measuring-LLM-Reasoning-Effort-via-Deep-Thinking-Tokens.html" title="用&quot;深度思考率&quot;精准度量LLM推理质量"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260223165943195.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="用&quot;深度思考率&quot;精准度量LLM推理质量"/></a><div class="content"><a class="title" href="/2026/02/23/Think-Deep,-Not-Just-Long-Measuring-LLM-Reasoning-Effort-via-Deep-Thinking-Tokens.html" title="用&quot;深度思考率&quot;精准度量LLM推理质量">用&quot;深度思考率&quot;精准度量LLM推理质量</a><time datetime="2026-02-23T12:00:00.000Z" title="发表于 2026-02-23 12:00:00">2026-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/20/arxiv_papers_2026-02-20.html" title="Arxiv今日论文 | 2026-02-20"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-20"/></a><div class="content"><a class="title" href="/2026/02/20/arxiv_papers_2026-02-20.html" title="Arxiv今日论文 | 2026-02-20">Arxiv今日论文 | 2026-02-20</a><time datetime="2026-02-20T12:30:00.000Z" title="发表于 2026-02-20 12:30:00">2026-02-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/20/frontier_training_cn.html" title="前沿大模型训练方法：深度解析与实践指南"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/202602201606857.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="前沿大模型训练方法：深度解析与实践指南"/></a><div class="content"><a class="title" href="/2026/02/20/frontier_training_cn.html" title="前沿大模型训练方法：深度解析与实践指南">前沿大模型训练方法：深度解析与实践指南</a><time datetime="2026-02-20T10:30:00.000Z" title="发表于 2026-02-20 10:30:00">2026-02-20</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2026 By Weitang Liu</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'https://twikoo.lonepatient.top/',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'https://twikoo.lonepatient.top/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo@1.4.11/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (99)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/计算机视觉/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 计算机视觉 (16)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/知识图谱/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 知识图谱 (13)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 深度学习 (139)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="http://lonepatient.top/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230219144729.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-02-18</span><a class="blog-slider__title" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt="">通向AGI之路：大型语言模型（LLM）技术精要</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/07/12/gaiic_2022_ner_top10.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20220712181905.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-07-12</span><a class="blog-slider__title" href="2022/07/12/gaiic_2022_ner_top10.html" alt="">GAIIC2022商品标题识别二等奖获奖解决思路</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2022/07/12/gaiic_2022_ner_top10.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230807190424.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-01-20</span><a class="blog-slider__title" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt="">2025-03|高质量中文预训练模型集合</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>