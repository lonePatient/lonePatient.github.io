<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>深度学习与计算机视觉(PB-13)—ImageNet数据集准备 | 闲记算法</title><meta name="keywords" content="深度学习,计算机视觉,TensorFlow"><meta name="author" content="Weitang Liu"><meta name="copyright" content="Weitang Liu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="前面几节内容中，我们都是对小数据集（相对于工业界而言）进行实验，使用CPU环境也可以完美地实现。接下来，我们将使用ImageNet数据集进行实验，该数据集比较大，需要在GPU环境下进行。在对ImageNet数据进行建模之前，我们首先来认识下ImageNet数据集以及对该数据集进行预处理。">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习与计算机视觉(PB-13)—ImageNet数据集准备">
<meta property="og:url" content="http://lonepatient.top/2018/07/01/Deep_Learning_For_Computer_Vision_With_Python_PB_13.html">
<meta property="og:site_name" content="闲记算法">
<meta property="og:description" content="前面几节内容中，我们都是对小数据集（相对于工业界而言）进行实验，使用CPU环境也可以完美地实现。接下来，我们将使用ImageNet数据集进行实验，该数据集比较大，需要在GPU环境下进行。在对ImageNet数据进行建模之前，我们首先来认识下ImageNet数据集以及对该数据集进行预处理。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-10-25/42580132.jpg">
<meta property="article:published_time" content="2018-07-01T23:27:08.000Z">
<meta property="article:modified_time" content="2026-02-27T07:52:12.655Z">
<meta property="article:author" content="Weitang Liu">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="计算机视觉">
<meta property="article:tag" content="TensorFlow">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-10-25/42580132.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://lonepatient.top/2018/07/01/Deep_Learning_For_Computer_Vision_With_Python_PB_13"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//s4.cnzz.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script async="async" data-pjax="data-pjax" src="https://s4.cnzz.com/z_stat.php?id=1273275888&amp;web_id=1273275888"></script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2026-02-27 07:52:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/backgroud.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><script src="https://at.alicdn.com/t/c/font_3570527_dthoqrrv2tv.css"></script><script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script><script>LA.init({id:"JwRQtLKZggvJH4sJ",ck:"JwRQtLKZggvJH4sJ"})</script><link rel="stylesheet" href="/css/universe.css"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3536467946304280" crossorigin="anonymous"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">281</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">384</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">92</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 网站</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.aitoolist.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集合</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.deepdh.com"><i class="fa-fw fa fa-star"></i><span> AI工具导航</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.ai-lib.club"><i class="fa-fw fa fa-star"></i><span> 人工智能工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ai-bot.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 教程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://learningprompt.wiki/"><i class="fa-fw fa fa-star"></i><span> Prompt教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 在线</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fa fa-star"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-10-25/42580132.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">闲记算法</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 网站</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.aitoolist.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集合</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.deepdh.com"><i class="fa-fw fa fa-star"></i><span> AI工具导航</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.ai-lib.club"><i class="fa-fw fa fa-star"></i><span> 人工智能工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ai-bot.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 教程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://learningprompt.wiki/"><i class="fa-fw fa fa-star"></i><span> Prompt教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 在线</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fa fa-star"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">深度学习与计算机视觉(PB-13)—ImageNet数据集准备<a class="post-edit-link" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts/Deep_Learning_For_Computer_Vision_With_Python_PB_13.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2018-07-01T23:27:08.000Z" title="发表于 2018-07-01 23:27:08">2018-07-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-02-27T07:52:12.655Z" title="更新于 2026-02-27 07:52:12">2026-02-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">7.7k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>29分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2018/07/01/Deep_Learning_For_Computer_Vision_With_Python_PB_13.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>前面几节内容中，我们都是对小数据集（相对于工业界而言）进行实验，使用CPU环境也可以完美地实现。接下来，我们将使用ImageNet数据集进行实验，该数据集比较大，需要在GPU环境下进行。在对ImageNet数据进行建模之前，我们首先来认识下ImageNet数据集以及对该数据集进行预处理。</p>
<span id="more"></span>
<h2 id="ImageNet数据集介绍">ImageNet数据集介绍</h2>
<p>ImageNet是一个计算机视觉系统识别项目，是目前世界上图像识别最大的数据库。是美国斯坦福的计算机科学家，模拟人类的识别系统建立的。能够从图片中识别物体。ImageNet是一个非常有前景的研究项目，未来用在机器人身上，就可以直接辨认物品和人了。超过1400万的图像URL被ImageNet手动注释，以指示图片中的对象;在至少一百万张图像中，还提供了边界框。ImageNet包含2万多个类别; 一个典型的类别，如“气球”或“草莓”，每个类包含数百张图像。</p>
<h3 id="下载地址">下载地址</h3>
<p>ImageNet数据集可以直接从<a target="_blank" rel="noopener" href="http://image-net.org/challenges/LSVRC/2016/download-images-8r28.php">该地址</a>中下载，当然你可以根据对应的任务选择相应的数据集下载即可。</p>
<p><strong>备注</strong>：我花了好几天将官网的数据下载完，速度比较慢，如果你们有需要的，可以留言，我上传到百度网盘，分享给你们（很容易被和谐，所以单独发给你们）。</p>
<h2 id="ImageNet数据说明">ImageNet数据说明</h2>
<p>下载完ImageNet数据集之后，你会发现里面包含了很多文件，虽然磁盘上有将近2百万的图片数据，但是没有一个比较直观的名字,且没有一个很明显的方式能够知道每张图像对应的标签信息，当我们对这些数据集训练一个特定的卷积神经网络时，需要提前进行预处理。</p>
<p>在本节中，首先，我们将分析ImageNet数据文件结构，包括原始图像数据和开发工具包(“DevKit”)。之后，我们将编写一个Python脚本，解析ImageNet文件和对应标签，即将给定的输入文件名映射到相应的标签(每行一个文件名和标签)。</p>
<p>最后，我们利用Tensorflow对数据创建更高效的TFRecord (.tfrecords)文件。当数据大到无法放入内存时，我们可以使用这些文件数据进行训练深度学习模型。后面我们将看到，这种.tfrecords格式不仅比HDF5更紧凑，而且它的I/O效率也更高，使我们能够更快地训练网络。</p>
<p>当数据处理完之后，就方便我们后续对ImageNet数据集从头开始训练自定义的CNNs网络结构。</p>
<h3 id="ImageNet文件结构">ImageNet文件结构</h3>
<p>首先,我们先认识下ImageNet数据文件结构。假设你已经下载完了ILSVRC2016_CLS_LOC.tar.gz文件(数据本身比较大，约166G）。对文件进行解压:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tar -xvf ILSVRC2016_CLS-LOC.tar.gz</span></span><br></pre></td></tr></table></figure>
<p>这个解压相对而言需要花点时间，因为本身数据文件比较多。</p>
<p>解压完成之后，将得到一个名为ILSVRC的目录:</p>
<p>进入ILSVRC文件夹，您将发现三个子目录:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> ILSVRC</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span></span></span><br><span class="line">Annotations  Data  ImageSets</span><br></pre></td></tr></table></figure>
<p>其中:</p>
<ul>
<li>Annotations：物体位置标注数据文件，一般是在物体检测任务中使用到，目前我们可以忽略这个数据集</li>
<li>Data：数据文件夹，这个是我们需要重点关注的，里面包含了train、val和test原始图像数据</li>
<li>ImageSets：图像对应的属性信息</li>
</ul>
<p>进入Data数据目录，我们将看到一个名为CLS-LOC的子目录:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> Data/</span></span><br><span class="line">CLS-LOC</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> Data/CLS-LOC</span></span><br><span class="line">test  train  val</span><br></pre></td></tr></table></figure>
<p>而在子目录，我们将找到我们需要处理的train、val和test数据集。</p>
<p>接下来，我们将重点分析这三个目录文件。</p>
<h3 id="test目录">test目录</h3>
<p>test目录包含10万张图像(1000个类，每一类中都有100个数据)，如:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> -l Data/CLS-LOC/test/ | <span class="built_in">head</span> -n 10</span></span><br><span class="line">-rw-r--r-- 1 lone lone   33889 7月   1  2012 ILSVRC2012_test_00000001.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone  122117 7月   1  2012 ILSVRC2012_test_00000002.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone   26831 7月   1  2012 ILSVRC2012_test_00000003.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone  124722 7月   1  2012 ILSVRC2012_test_00000004.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone   98627 7月   1  2012 ILSVRC2012_test_00000005.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone  211157 7月   1  2012 ILSVRC2012_test_00000006.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone  219906 7月   1  2012 ILSVRC2012_test_00000007.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone  181734 7月   1  2012 ILSVRC2012_test_00000008.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone   10696 7月   1  2012 ILSVRC2012_test_00000009.JPEG</span><br></pre></td></tr></table></figure>
<p>这些数据是没有对应的标签信息，因此，我们无法将这些图像数据直接用于我们的实验。实际上每年都会有一次ILSVRC比赛，使用的数据就是ImageNet数据，为了保证这个比赛公平(并确保没有人作弊)，test数据集的标签是保密的。</p>
<p>首先，每个参赛者/组织使用train和val数据集来训练和评估他们的算法。一旦他们训练好模型，然后就会在test数据集上进行预测。随后将预测结果上传到ImageNet服务器，并与真实标签进行比较（任何情况下，任何参赛者都不能使用test数据集的真实标签）。最后，ImageNet服务器将返回它们的总体精度。</p>
<p>所以，我们将忽略test数据集目录，而是从train数据集中提取一部分子集作为test数据集。这样，我们可以在本地评估整个模型的性能。</p>
<h3 id="train目录">train目录</h3>
<p>train目录中由一系列子目录组成,如下所示：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> -l Data/CLS-LOC/train/ | <span class="built_in">head</span> -n 10</span></span><br><span class="line">drwxr-xr-x 2 lone lone 57344 9月  29  2014 n01440764</span><br><span class="line">drwxr-xr-x 2 lone lone 65536 9月  29  2014 n01443537</span><br><span class="line">drwxr-xr-x 2 lone lone 57344 9月  29  2014 n01484850</span><br><span class="line">drwxr-xr-x 2 lone lone 65536 9月  29  2014 n01491361</span><br><span class="line">drwxr-xr-x 2 lone lone 61440 9月  29  2014 n01494475</span><br><span class="line">drwxr-xr-x 2 lone lone 61440 9月  29  2014 n01496331</span><br><span class="line">drwxr-xr-x 2 lone lone 49152 9月  29  2014 n01498041</span><br><span class="line">drwxr-xr-x 2 lone lone 65536 9月  29  2014 n01514668</span><br><span class="line">drwxr-xr-x 2 lone lone 61440 9月  29  2014 n01514859</span><br></pre></td></tr></table></figure>
<p>这些目录名称看样子好像没有包含任何图像信息。实际上，ImageNet数据集是根据WordNet IDs映射的，称为同义词集或简称为“syn sets”。每个ID映射到特定的数据标签，如金鱼、秃鹰、飞机或吉他。因此，这些文件名实际上是每一类对应的WordNet ID，并且在这些标签子目录中，每个类大约有732到1300张图像。</p>
<p>例如，WordNet ID为n01440764的子目录包含了1300张 “tench”图像，“tench”是一种欧洲淡水鱼，与minnow类很相似(如图13.1所示):</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> -l Data/CLS-LOC/train/n01440764/*.JPEG | <span class="built_in">wc</span> -l</span></span><br><span class="line">1300</span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> -l Data/CLS-LOC/train/n01440764/*.JPEG | <span class="built_in">head</span> -n 5</span></span><br><span class="line">-rw-r--r-- 1 lone lone   13697 6月  11  2012 Data/CLS-LOC/train/n01440764/n01440764_10026.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone    9673 6月  11  2012 Data/CLS-LOC/train/n01440764/n01440764_10027.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone   67029 6月  11  2012 Data/CLS-LOC/train/n01440764/n01440764_10029.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone  146489 6月  11  2012 Data/CLS-LOC/train/n01440764/n01440764_10040.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone    6350 6月  11  2012 Data/CLS-LOC/train/n01440764/n01440764_10042.JPEG</span><br></pre></td></tr></table></figure>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-10-25/42580132.jpg" alt=""></p>
<center>图13.1</center>
因此，对于这些由WordNet IDs命名的train数据集，我们将直接与train_cls.txt进行匹配，可以直接得到数据对应的标签名称。
<h3 id="val目录">val目录</h3>
<p>与test数据集目录类似，val数据集目录包含50000张图像(1000个类中每类有50张图像):</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> -l Data/CLS-LOC/val/*.JPEG | <span class="built_in">wc</span> -l</span></span><br><span class="line">50000</span><br></pre></td></tr></table></figure>
<p>这50000张图像直接存放在一个目录文件夹中，这意味着我们无法使用目录名直接映射得到数据对应的标签名称。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> -l Data/CLS-LOC/val/ | <span class="built_in">head</span> -n 10</span></span><br><span class="line">total 6648996</span><br><span class="line">-rw-r--r-- 1 lone lone  109527 6月  13  2012 ILSVRC2012_val_00000001.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone  140296 6月  13  2012 ILSVRC2012_val_00000002.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone  122660 6月  13  2012 ILSVRC2012_val_00000003.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone   84885 6月  13  2012 ILSVRC2012_val_00000004.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone  130340 6月  13  2012 ILSVRC2012_val_00000005.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone  151397 6月  13  2012 ILSVRC2012_val_00000006.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone  165863 6月  13  2012 ILSVRC2012_val_00000007.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone  107423 6月  13  2012 ILSVRC2012_val_00000008.JPEG</span><br><span class="line">-rw-r--r-- 1 lone lone  114708 6月  13  2012 ILSVRC2012_val_00000009.JPEG</span><br></pre></td></tr></table></figure>
<p>另外，通过检查文件名，我们没有看到类似于WordNet IDs中ID命名格式。但是，在val.txt文件中，提供了val数据集文件名到类标签的映射关系。</p>
<h3 id="ImageSets目录">ImageSets目录</h3>
<p>ImageSets目录中主要存放的是标签的映射关系数据。如下所示:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">$ cd ImageSets/</span><br><span class="line">$ ls</span><br><span class="line">CLS-LOC</span><br><span class="line">$ cd CLS-LOC</span><br><span class="line">$ ls</span><br><span class="line">test.txt  train_cls.txt  train_loc.txt  val.txt</span><br></pre></td></tr></table></figure>
<p>目录中包含了四个txt文件，我们可以忽略test.txt文件，因为我们将从train数据集中构建自己的test数据集。train_cls.txt(其中“cls”代表“分类”)包含了train数据集(1281167张图像)的文件名映射到标签数据，val.txt包含了val数据集(50,000)的标签数据（直接对应index）。即:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">wc</span> -l train_cls.txt val.txt</span></span><br><span class="line"> 1281167 train_cls.txt</span><br><span class="line">   50000 val.txt</span><br><span class="line"> 1331167 total</span><br></pre></td></tr></table></figure>
<p>两个文件总共包含了1331167张需要处理的图像。首先，我们可以看到train_cls.txt文件内容，每行都是由一个基本的图像文件名(没有文件扩展名)和一个唯一的整数ID组成，即:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">head</span> -n 10 train_cls.txt</span></span><br><span class="line">n01440764/n01440764_10026 1</span><br><span class="line">n01440764/n01440764_10027 2</span><br><span class="line">n01440764/n01440764_10029 3</span><br><span class="line">n01440764/n01440764_10040 4</span><br><span class="line">n01440764/n01440764_10042 5</span><br><span class="line">n01440764/n01440764_10043 6</span><br><span class="line">n01440764/n01440764_10048 7</span><br><span class="line">n01440764/n01440764_10066 8</span><br><span class="line">n01440764/n01440764_10074 9</span><br><span class="line">n01440764/n01440764_10095 10</span><br></pre></td></tr></table></figure>
<p>该整数只是一个递增的计数器，没有特殊含义。val.txt也类似，即：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">head</span> -n 10 val.txt</span></span><br><span class="line">ILSVRC2012_val_00000001 1</span><br><span class="line">ILSVRC2012_val_00000002 2</span><br><span class="line">ILSVRC2012_val_00000003 3</span><br><span class="line">ILSVRC2012_val_00000004 4</span><br><span class="line">ILSVRC2012_val_00000005 5</span><br><span class="line">ILSVRC2012_val_00000006 6</span><br><span class="line">ILSVRC2012_val_00000007 7</span><br><span class="line">ILSVRC2012_val_00000008 8</span><br><span class="line">ILSVRC2012_val_00000009 9</span><br><span class="line">ILSVRC2012_val_00000010 10</span><br></pre></td></tr></table></figure>
<p><strong>备注</strong>：这些整数ID并不太有用，除非我们需要确定“黑名单”图像——由ImageNet数据集管理员标记为“黑名单”的图像，由于该图像的类标签过于模糊，因此在评估过程中我们不考虑这些图像。在后部分内容中，我们将遍历所有被列入黑名单的图像，并通过该整数ID映射从数据集中删除。</p>
<p>使用train_cls.txt和val.txt文件，有一个好处就是我们不必使用额外的路径类似<code>paths.list_images</code>将train和val数据列举出。相反，我们只需要遍历这两个文件，并合理拼接图像信息，就可以构建TFRecord文件。</p>
<h3 id="DevKit目录">DevKit目录</h3>
<p>除了下载原始图像本身外，还需要下载ILSVRC2016_devkit.tar.gz。这个文件包含实际的索引文件、validation数据中黑名单图像id和图像文件名映射到相应的实际类标签等数据。将ILSVRC2016_devkit.tar.gz文件放到与ILSVRC同目录并进行解压:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">tar -xvf ILSVRC2016_devkit.tar.gz</span></span><br></pre></td></tr></table></figure>
<p>在ILSVRC目录中，你将会发现新增了一个devkit文件目录:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> ILSVRC/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span></span></span><br><span class="line">Annotations  Data  devkit  ImageSets</span><br></pre></td></tr></table></figure>
<p>进入devkit目录:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> devkit/</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span></span></span><br><span class="line">COPYING  data  evaluation  readme.txt</span><br></pre></td></tr></table></figure>
<p>里面包含了四个文件，这里我们只需要关心data目录即可。在data目录中，你会发现很多文件，都是MATLAB和纯文本(.txt)格式，即:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">cd</span> data</span></span><br><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> -l</span></span><br><span class="line">total 6052</span><br><span class="line">-rw-r--r-- 1 lone lone   10216 6月   1  2016 ILSVRC2015_clsloc_validation_blacklist.txt</span><br><span class="line">-rw-r--r-- 1 lone lone 1167074 6月   1  2016 ILSVRC2015_clsloc_validation_ground_truth.mat</span><br><span class="line">-rw-r--r-- 1 lone lone  194650 6月   1  2016 ILSVRC2015_clsloc_validation_ground_truth.txt</span><br><span class="line">-rw-r--r-- 1 lone lone    6455 6月   1  2016 ILSVRC2015_det_validation_blacklist.txt</span><br><span class="line">-rw-r--r-- 1 lone lone  635183 6月   1  2016 ILSVRC2015_det_validation_ground_truth.mat</span><br><span class="line">-rw-r--r-- 1 lone lone 2219755 9月   3  2016 ILSVRC2015_vid_validation_ground_truth.mat</span><br><span class="line">-rw-r--r-- 1 lone lone 1812198 9月   3  2016 ILSVRC2015_vid_validation_track_ground_truth.mat</span><br><span class="line">-rw-r--r-- 1 lone lone   24366 6月   1  2016 map_clsloc.txt</span><br><span class="line">-rw-r--r-- 1 lone lone    4479 6月   1  2016 map_det.txt</span><br><span class="line">-rw-r--r-- 1 lone lone     598 6月   1  2016 map_vid.txt</span><br><span class="line">-rw-r--r-- 1 lone lone   83277 6月   1  2016 meta_clsloc.mat</span><br><span class="line">-rw-r--r-- 1 lone lone   10355 6月   1  2016 meta_det.mat</span><br><span class="line">-rw-r--r-- 1 lone lone    1685 6月   1  2016 meta_vid.mat</span><br></pre></td></tr></table></figure>
<p>在这个目录中，我们最关心的是以下三个文件:</p>
<ul>
<li>map_clsloc.txt</li>
<li>ILSVRC2015_clsloc_validation_ground_truth.txt</li>
<li>ILSVRC2015_clsloc_validation_blacklist.txt</li>
</ul>
<p>map_clsloc.txt文件主要包含WordNet ID映射到图像真实的类标签数据，比如:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">head</span> -n 10 map_clsloc.txt</span></span><br><span class="line">n02119789 1 kit_fox</span><br><span class="line">n02100735 2 English_setter</span><br><span class="line">n02110185 3 Siberian_husky</span><br><span class="line">n02096294 4 Australian_terrier</span><br><span class="line">n02102040 5 English_springer</span><br><span class="line">n02066245 6 grey_whale</span><br><span class="line">n02509815 7 lesser_panda</span><br><span class="line">n02124075 8 Egyptian_cat</span><br><span class="line">n02417914 9 ibex</span><br><span class="line">n02123394 10 Persian_cat</span><br></pre></td></tr></table></figure>
<p>我们可以看到<br>
n02119789对应到kit_fox类标签。n02096294对应到Australian_terrier（是狗的一种品种）。val目录中的图像不包含任何WordNet ID信息，但是在ImageSets中包含一个val.txt文件，该文件包含了val数据集的文件名（没有图像扩展名），而在ILSVRC2015_clsloc_validation_ground_truth.txt中包含了val数据集的标签，即:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">head</span> -n 10 ILSVRC2015_clsloc_validation_ground_truth.txt</span></span><br><span class="line">490</span><br><span class="line">361</span><br><span class="line">171</span><br><span class="line">822</span><br><span class="line">297</span><br><span class="line">482</span><br><span class="line">13</span><br><span class="line">704</span><br><span class="line">599</span><br><span class="line">164</span><br></pre></td></tr></table></figure>
<p>每一行都只有一个整数。取val.txt的第一行和ILSVRC2015_clsloc_validation_ground_truth的第一行。最后我们得到:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(ILSVRC2015_val_0000000001,490)</span><br></pre></td></tr></table></figure>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-10-25/4037842.jpg" alt=""></p>
<center> 图13.2 </center>
如果我们打开ILSVRC2012_val_00000001.JPEG。我们将看到图13.2中的图像。很明显，这是一种蛇——但是哪种蛇呢?如果我们检查map_clsloc.txt，我们可以看到带有490的类标签ID是WordNet ID=n01751748，它是sea_snake:
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">grep <span class="string">&#x27;490&#x27;</span> map_clsloc.txt</span></span><br><span class="line"></span><br><span class="line">n01751748 490 sea_snake</span><br></pre></td></tr></table></figure>
<p>因此，我们需要同时使用val.txt和ILSVRC2015_clsloc_validation_ground_truth.txt来构建我们的val数据集。</p>
<p>接下来，查看ILSVRC2015_clsloc_validation_blacklist.txt，即:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">head</span> -n 10 ILSVRC2015_clsloc_validation_blacklist.txt</span></span><br><span class="line">36</span><br><span class="line">50</span><br><span class="line">56</span><br><span class="line">103</span><br><span class="line">127</span><br><span class="line">195</span><br><span class="line">199</span><br><span class="line">226</span><br><span class="line">230</span><br><span class="line">235</span><br></pre></td></tr></table></figure>
<p>正如我前面提到的，val数据集中包含一些类标签中过于模糊的图像数据。因此,ILSVRC组织者将这些图像数据标记为“黑名单”,这意味着这些数据不应该包含在val数据集中。在构建val数据集时，我们也需要排除这些黑名单id对应的图像数据。</p>
<p>可以看到，构建ImageNet数据集需要很多文件。我们不仅需要原始图像本身，还需要一些.txt文件，用于从原始train和val数据集中提取相应类标签。接下来，我们将对ImageNet数据进行预处理并保存到TFRecord文件中。</p>
<h2 id="构建ImageNet数据集">构建ImageNet数据集</h2>
<p>对原始的ImageNet数据进行处理，主要是便于后续我们训练一个自定义的CNN网络结构，我们会将原始图像信息保存到TFRecord文件中。另外，我们还需要计算train数据集的RGB通道的均值，并保存磁盘中。</p>
<h3 id="配置文件">配置文件</h3>
<p>我们将按照以下目录结构进行开发流程：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">--- tf_imagenet_alexnet</span><br><span class="line">| |--- pyimagesearch</span><br><span class="line">| |--- config</span><br><span class="line">| | |--- __init__.py</span><br><span class="line">| | |--- imagnet_alexnet_config.py</span><br><span class="line">| |--- imagenet</span><br><span class="line">| |--- outputs/</span><br><span class="line">| |--- build_imagenet.py</span><br><span class="line">| |--- test_alexnet.py</span><br><span class="line">| |--- train_alexnet.py</span><br></pre></td></tr></table></figure>
<p>正如目录和文件名所示，这个配置文件是为AlexNet网络准备的。在config目录中，包含了两个文件:</p>
<ul>
<li><strong>init</strong>.py</li>
<li>imagenet_alexnet_config.py</li>
</ul>
<p><strong>init</strong>.py文件将config转换成Python包，实际上可以通过import语句导入到我们自己的脚本中—这个文件使我们能够在实际配置中使用Python语法/库，从而构建网络时更加方便。imagenet_alexnet_config.py包含我们整个项目的配置信息。</p>
<p>在imagenet目录中新建一个tfrecords目录，主要是存放我们保存的TFRecord文件数据。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">mkdir</span> imagenet/tfrecords</span></span><br></pre></td></tr></table></figure>
<p>build_imagenet.py脚本主要是构建从输入图像文件到输出类标签的映射以及将数据保存到TFRecord文件中。train_alexnet.py脚本主要是在ImageNet数据集上从头开始训练AlexNet网络。最后,test_alexnet.py脚本主要是利用测试集验证AlexNet模型的性能。</p>
<p>本节我们主要是对ImageNet数据进行预处理。主要是完成build_imagenet.py脚本的内容。首先，我们先配置整个项目的配置信息。</p>
<p>打开imagenet_alexnet_config.py并写入以下代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> path</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义Imagenet数据集路径</span></span><br><span class="line">BASE_PATH = <span class="string">&#x27;yourPath/ILSVRC&#x27;</span></span><br></pre></td></tr></table></figure>
<p>首先加载所需模块，这里path是os的一个子模块。path模块包含一个名为path的特殊变量。这是操作系统的路径分隔符。在Unix机器上，路径分隔符是/ -一个示例文件路径可能看起来像path/to/your/file.txt。然而，在Windows上，路径分隔符是\，比如示例文件路径path\your\file.txt。我们希望配置与操作系统无关，因此我们将使用path的sep变量。</p>
<p>然后我们定义个一个base_path，该路径下包含所有原始图像数据信息。</p>
<p>从BASE_PATH中，我们可以拼接出三个更重要的路径:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 基于base path 定义原始图像和工具路径</span></span><br><span class="line">IMAGES_PATH = path.sep.join([BASE_PATH,<span class="string">&#x27;Data/CLS-LOC&#x27;</span>])</span><br><span class="line">IMAGE_SETS_PATH = path.sep.join([BASE_PATH,<span class="string">&#x27;ImageSets/CLS-LOC/&#x27;</span>])</span><br><span class="line">DEVKIT_PATH = path.sep.join([BASE_PATH,<span class="string">&#x27;devkit/data&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>IMAGES_PATH：包含train、val和test数据集。</li>
<li>IMAGE_SETS_PATH：包含重要train_cls.txt和val.txt。</li>
<li>DEVKIT_PATH：是DevKit所在位置的基本路径。</li>
</ul>
<p>接下来，定义WORD_IDS，即map_clsloc.txt文件的路径，它将1000个WordNet ID映射为：</p>
<ul>
<li>唯一的标识整数</li>
<li>实际可读标签。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义WordNet IDs文件路径</span></span><br><span class="line">WORD_IDS = path.sep.join([DEVKIT_PATH,<span class="string">&#x27;map_clsloc.txt&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>为了构建train数据集，我们需要定义TRAIN_LIST，这个路径包含了120万个(部分)train数据的图像文件名:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义training文件路径</span></span><br><span class="line">TRAIN_LIST = path.sep.join([IMAGE_SETS_PATH,<span class="string">&#x27;train_cls.txt&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>接下来，我们需要定义一些val数据集相关配置:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义验证集数据路径以及对应的标签文件路径</span></span><br><span class="line">VAL_LIST = path.sep.join([IMAGE_SETS_PATH,<span class="string">&#x27;val.txt&#x27;</span>])</span><br><span class="line">VAL_LABELS = path.sep.join([DEVKIT_PATH,<span class="string">&#x27;ILSVRC2015_clsloc_validation_ground_truth.txt&#x27;</span>])</span><br><span class="line"><span class="comment"># 定义val blacklisted 文件路径</span></span><br><span class="line">VAL_BLACKLIST = path.sep.join([DEVKIT_PATH,<span class="string">&#x27;ILSVRC2015_clsloc_validation_blacklist.txt&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>VAL_LIST：ImageSets目录中的val.txt文件。<strong>注意</strong>，val.txt列出了50,000个(部分)图像文件名。为了获得val数据的真实标签，我们需要定义val_tags路径—这样我们就可以将文件名和标签组合一起。最后，VAL_BLACKLIST文件包含已被列入黑名单的val数据中的唯一整数id。在构建ImageNet数据集时，我们需要注意确保这些图像不包含在验证数据中。</p>
<p>定义额外一些变量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义类别个数</span></span><br><span class="line"><span class="comment"># 定义我们需要从train数据集中划分一个子集作为test数据集</span></span><br><span class="line">NUM_CLASSES = <span class="number">1000</span></span><br><span class="line">NUM_TEST_IMAGES = <span class="number">50</span> * NUM_CLASSES</span><br></pre></td></tr></table></figure>
<p>ImageNet数据集中包含1000个类别图像，因此，NUM_CLASSES等于1000。为了得到我们的test数据集，我们需要从train数据集中提取一些子集作为test数据集。我们将NUM_TEST_IMAGES设置为50 * 1000 = 50000张图像。</p>
<p>接下来，我们定义保存TFRecord文件路径：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义tfrecord文件的输出路径</span></span><br><span class="line">TF_OUTPUT = <span class="string">&#x27;imagenet&#x27;</span></span><br><span class="line">TRAIN_TFRECORD = path.sep.join([TF_OUTPUT,<span class="string">&#x27;tfrecords/train.tfrecords&#x27;</span>])</span><br><span class="line">VAL_TFRECORD  = path.sep.join([TF_OUTPUT,<span class="string">&#x27;tfrecords/val.tfrecords&#x27;</span>])</span><br><span class="line">TEST_TFRECORD = path.sep.join([TF_OUTPUT,<span class="string">&#x27;tfrecords/test.tfrecords&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>这里稍微提下，在TFRecord文件里保存的是二进制文件信息，而不是图像的numpy数组信息（HDF5保存方式），这样我们能够获得比之前使用的HDF5数据集更好的性能以及更小的磁盘使用量。</p>
<p>在构建数据集时，我们还需要对train数据集计算RGB三个颜色通道的平均值，并保存到磁盘中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义均值文件路径</span></span><br><span class="line">DATASET_MEAN = <span class="string">&#x27;outputs/imagenet_mean.json&#x27;</span></span><br></pre></td></tr></table></figure>
<h3 id="预处理">预处理</h3>
<p>上面，我们完成了配置文件的创建，接下来，我们将处理图像数据，比如获取对应的标签信息，处理黑名单数据等等。在utils子目录中新建一个名为imagenethelper.py的文件，如下目录结构:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">--- pyimagesearch</span><br><span class="line">| |--- __init__.py</span><br><span class="line">| |--- callbacks</span><br><span class="line">| |--- io</span><br><span class="line">| |--- nn</span><br><span class="line">| |--- preprocessing</span><br><span class="line">| |--- utils</span><br><span class="line">| | |--- __init__.py</span><br><span class="line">| | |--- imagenettfrecord.py</span><br><span class="line">| | |--- imagenethelper.py</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="http://xn--imagenethelper-9h01a920b.py">打开imagenethelper.py</a>，并写入以下代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> progressbar</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ImageNetHelper</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,config</span>):</span><br><span class="line">        <span class="comment"># 配置</span></span><br><span class="line">        <span class="variable language_">self</span>.config = config</span><br><span class="line">        <span class="comment"># 标签映射</span></span><br><span class="line">        <span class="variable language_">self</span>.labelMappings = <span class="variable language_">self</span>.buildClassLabels()</span><br><span class="line">        <span class="variable language_">self</span>.valBlacklist = <span class="variable language_">self</span>.buildBlacklist()</span><br></pre></td></tr></table></figure>
<p>上面我们定义了一个ImageNetHelper类。并且只需要传一个config的参数。所有的信息我们将从config变量中提取。</p>
<p>接下来，我们定义一个_pbar函数，该函数主要功能是显示进度条，方便我们实时监控脚本运行情况。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_pbar</span>(<span class="params">self,maxval,name</span>):</span><br><span class="line">    widgets = [name, progressbar.Percentage(), <span class="string">&#x27; &#x27;</span>,</span><br><span class="line">               progressbar.Bar(), <span class="string">&#x27; &#x27;</span>, progressbar.ETA()]</span><br><span class="line">    pbar = progressbar.ProgressBar(maxval=maxval,</span><br><span class="line">                                   widgets=widgets).start()</span><br><span class="line">    <span class="keyword">return</span> pbar</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>maxval: 最大数据量</li>
<li>name：进度条显示名称</li>
</ul>
<p>接着，我们构建一个类标签映射字典:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">buildClassLabels</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># 文件名映射类标签</span></span><br><span class="line">    <span class="comment"># n02110185 3 Siberian_husky</span></span><br><span class="line">    rows = <span class="built_in">open</span>(<span class="variable language_">self</span>.config.WORD_IDS).read().strip().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    labelMappings = &#123;&#125;</span><br></pre></td></tr></table></figure>
<p>读取WORD_IDs文件的全部内容，并构建一个labelMappings字典，其中key为WordNet ID，值为整数类标签。</p>
<p>接下来，遍历整个文件内容，对于每一行，我们分解为一个3元祖，即：</p>
<ul>
<li>WordNet ID (wordID)。</li>
<li>唯一整数类标签ID(标签)。</li>
<li>实际可读标签。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> row <span class="keyword">in</span> rows:</span><br><span class="line">    (wordId,label,hrLabel) = row.split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">    labelMappings[wordId] = <span class="built_in">int</span>(label) - <span class="number">1</span></span><br><span class="line"><span class="keyword">return</span> labelMappings</span><br></pre></td></tr></table></figure>
<p>这里，我们对整数标签值减1，为什么要减1呢?ILSVRC提供的ImageNet工具是使用MATLAB构建的。MATLAB编程语言是单索引的(即从1开始计数)，而Python编程语言是零索引的(我们从0开始计数)。</p>
<p>接下来，处理黑名单id数据:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">buildBlacklist</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># 验证集</span></span><br><span class="line">    rows = <span class="built_in">open</span>(<span class="variable language_">self</span>.config.VAL_BLACKLIST).read()</span><br><span class="line">    rows = <span class="built_in">set</span>(rows.strip().split(<span class="string">&quot;\n&quot;</span>))</span><br><span class="line">    <span class="keyword">return</span> rows</span><br></pre></td></tr></table></figure>
<p>处理train数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">buildTrainingSet</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># 训练数据集</span></span><br><span class="line">    <span class="comment"># n01440764/n01440764_12131 189</span></span><br><span class="line">    rows = <span class="built_in">open</span>(<span class="variable language_">self</span>.config.TRAIN_LIST).read().strip()</span><br><span class="line">    rows = rows.split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line">    paths = []</span><br><span class="line">    labels = []</span><br><span class="line">    probar = <span class="variable language_">self</span>._pbar(name=<span class="string">&#x27;building training set: &#x27;</span>,maxval=<span class="built_in">len</span>(rows))</span><br></pre></td></tr></table></figure>
<p>TRAIN_LIST文件部分内容如下所示，我们将根据该结构提取数据：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">n01440764/n01440764_10026 1</span><br><span class="line">n01440764/n01440764_10027 2</span><br><span class="line">n01440764/n01440764_10029 3</span><br><span class="line">n01440764/n01440764_10040 4</span><br><span class="line">n01440764/n01440764_10042 5</span><br><span class="line">n01440764/n01440764_10043 6</span><br><span class="line">n01440764/n01440764_10048 7</span><br><span class="line">n01440764/n01440764_10066 8</span><br><span class="line">n01440764/n01440764_10074 9</span><br><span class="line">n01440764/n01440764_10095 10</span><br></pre></td></tr></table></figure>
<p>我们需要完成:</p>
<ul>
<li>通过字符拼接，获取完成的图像路径</li>
<li>提取图像对应的类标签</li>
</ul>
<p>对原始数据进行遍历:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i,row <span class="keyword">in</span> <span class="built_in">enumerate</span>(rows):</span><br><span class="line">    (partialPath,imageNum) = row.strip().split(<span class="string">&quot; &quot;</span>)</span><br><span class="line">    <span class="comment"># 原始图像数据路径</span></span><br><span class="line">    path = os.path.sep.join([<span class="variable language_">self</span>.config.IMAGES_PATH,</span><br><span class="line">                             <span class="string">&#x27;train&#x27;</span>,<span class="string">&#x27;&#123;&#125;.JPEG&#x27;</span>.<span class="built_in">format</span>(partialPath)])</span><br><span class="line">    <span class="comment"># wordId</span></span><br><span class="line">    wordId = partialPath.split(<span class="string">&quot;/&quot;</span>)[<span class="number">0</span>]</span><br><span class="line">    label = <span class="variable language_">self</span>.labelMappings[wordId]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>partialPath对应图像的文件名，比如：n01440764/n01440764_10026。</li>
<li>imageNum变量只是一个计数器——它在构建train数据集时没有任何用途，可以忽略。</li>
</ul>
<p>一个完整的图像路径主要由：</p>
<ul>
<li>IMAGES_PATH：该路径包含了train、val和test数据目录</li>
<li>train字符串表示我们处理的train数据集</li>
<li>partialPath:图像的子目录以及文件名</li>
</ul>
<p>比如：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yourPath/ILSVRC/Data/CLS-LOC/train/n15075141/n15075141_999.JPEG</span><br></pre></td></tr></table></figure>
<p>提取完完整图像路径和标签之后，我们对列表进行更新：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">    paths.append(path)</span><br><span class="line">    labels.append(label)</span><br><span class="line">    probar.update(i)</span><br><span class="line">probar.finish()</span><br><span class="line"><span class="keyword">return</span> (np.array(paths),np.array(labels))</span><br></pre></td></tr></table></figure>
<p>val数据处理步骤类似于train数据，即:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">buildValidationSet</span>(<span class="params">self</span>):</span><br><span class="line">    paths = []</span><br><span class="line">    labels = []</span><br><span class="line">    <span class="comment">#验证数据</span></span><br><span class="line">    <span class="comment"># ILSVRC2012_val_00000001 1</span></span><br><span class="line">    valFilenames = <span class="built_in">open</span>(<span class="variable language_">self</span>.config.VAL_LIST).read()</span><br><span class="line">    valFilenames = valFilenames.strip().split(<span class="string">&#x27;\n&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 验证集对应的标签</span></span><br><span class="line">    <span class="comment"># 490</span></span><br><span class="line">    valLabels = <span class="built_in">open</span>(<span class="variable language_">self</span>.config.VAL_LABELS).read()</span><br><span class="line">    valLabels = valLabels.strip().split(<span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>构建完整的图像路径和对应的标签信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">probar = <span class="variable language_">self</span>._pbar(name=<span class="string">&#x27;building validation set: &#x27;</span>,maxval=<span class="built_in">len</span>(valFilenames))</span><br><span class="line"><span class="keyword">for</span> i,(row,label) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(valFilenames,valLabels)):</span><br><span class="line">    (partialPath,imageNum)  =  row.strip().split(<span class="string">&quot; &quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> imageNum  <span class="keyword">in</span> <span class="variable language_">self</span>.valBlacklist:</span><br><span class="line">        <span class="keyword">continue</span></span><br><span class="line">    <span class="comment">#val数据集真实图片数据</span></span><br><span class="line">    path = os.path.sep.join([<span class="variable language_">self</span>.config.IMAGES_PATH,<span class="string">&#x27;val&#x27;</span>,</span><br><span class="line">                             <span class="string">&quot;&#123;&#125;.JPEG&quot;</span>.<span class="built_in">format</span>(partialPath)])</span><br><span class="line">    paths.append(path)</span><br><span class="line">    labels.append(<span class="built_in">int</span>(label) - <span class="number">1</span>)</span><br><span class="line">    probar.update(i)</span><br><span class="line">probar.finish()</span><br><span class="line"><span class="keyword">return</span> (np.array(paths),np.array(labels))</span><br></pre></td></tr></table></figure>
<p>其中，我们增加一个黑名单id判断逻辑，如果该图像对应的id落在黑名单列表中，则直接过滤掉该图像信息。</p>
<p>以上我们完成图像数据的处理，接下来，我们将构建一个ImageNetTfrecord类，主要负责将图像数据写入TFRecord文件中。</p>
<h3 id="TFRecord">TFRecord</h3>
<p>前面我们提到对于小数据，我们使用的是HDF5进行保存数据（我们直接将图像的numpy数组信息存入HDF5中），对于大数据集，我们建议使用TFRecord文件进行存储（当然，这里我们是使用Tensorflow框架为前提条件）。在该部分，我们将学习如何将我们的数据转换为Tensorflow标准格式。对于如何将原始数据转化为tfrecords文件，可以参考<a href="https://lonepatient.top/2018/06/01/tensorflow_tfrecord.html">该篇文章</a>，这里就不做详细描述。</p>
<p>总的来说，在我们将数据存储到TFRecord文件之前，我们应该将它填入名为Example的协议缓冲区中。</p>
<p>然后，我们将协议缓冲区序列化为字符串并将其写入TFRecord文件，协议缓冲区示例包含功能。</p>
<p>Feature是一种描述数据的协议，可以有三种类型：bytes，float和int64。 总之，要存储数据，您需要按照以下步骤操作：</p>
<ul>
<li>使用tf.python_io.TFRecordWriter打开TFRecord文件</li>
<li>使用tf.train.Int64List，tf.train.BytesList或tf.train.FloatList将数据转换为该功能的正确数据类型</li>
<li>使用tf.train.Feature创建一个功能，并将转换后的数据传递给它</li>
<li>使用tf.train.Example创建一个示例协议缓冲区，并将该功能传递给它</li>
<li>使用example.SerializeToString（）将Example序列化为字符串</li>
<li>使用writer.write将序列化示例写入TFRecord文件</li>
</ul>
<p>接下来，我们将按照上述步骤实现将数据保存到TFRecord文件的功能，在pyimagesearch的子目录utils中新建一个名为imagenettfrecord.py的文件，并写入以下代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> path</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ImageNetTfrecord</span>(<span class="title class_ inherited__">object</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,tfrecord_name</span>):</span><br><span class="line">        <span class="variable language_">self</span>.tfrecord_name = tfrecord_name</span><br><span class="line">        <span class="variable language_">self</span>.tfwriter = tf.python_io.TFRecordWriter(<span class="variable language_">self</span>.tfrecord_name)</span><br></pre></td></tr></table></figure>
<p>首先，我们创建了一个ImageNetTfrecord类，该类只有一个参数，即:</p>
<ul>
<li>tfrecord_name: 保存数据的TFRecord文件路径</li>
</ul>
<p>并且，我们初始化了一个TFRecord文件写入器—tfwriter</p>
<p>接下来，我们定义数据类型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_int64_feature</span>(<span class="params">self,value</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Wrapper for inserting int64 features into Example proto.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(value, <span class="built_in">list</span>):</span><br><span class="line">        value = [value]</span><br><span class="line">    <span class="keyword">return</span> tf.train.Feature(int64_list=tf.train.Int64List(value=value))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_float_feature</span>(<span class="params">self,value</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Wrapper for inserting float features into Example proto.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(value, <span class="built_in">list</span>):</span><br><span class="line">        value = [value]</span><br><span class="line">    <span class="keyword">return</span> tf.train.Feature(float_list=tf.train.FloatList(value=value))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">_bytes_feature</span>(<span class="params">self,value</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Wrapper for inserting bytes features into Example proto.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))</span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>：在类型转换中，每一个value都是使用list进行包装的，即value=[value]</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_process_image</span>(<span class="params">self,filename</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Process a single image file.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">with</span> tf.gfile.FastGFile(filename, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        image_data = f.read()</span><br><span class="line">        <span class="keyword">return</span> image_data</span><br></pre></td></tr></table></figure>
<p>这里我们使用tf.gfile.FastGFile该函数获取图像数据，该image_data不是图像的numpy数组数据，而是一个二进制信息。</p>
<p>接下来，将image_data保存到TFRecord文件中:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_save_one</span>(<span class="params">self,label,filename,isTrain=<span class="literal">True</span></span>):</span><br><span class="line">    image_data = <span class="variable language_">self</span>._process_image(filename)</span><br><span class="line">    name = path.split(filename)[-<span class="number">1</span>]</span><br><span class="line">    <span class="keyword">if</span> isTrain:</span><br><span class="line">        example = tf.train.Example(features=tf.train.Features(feature=&#123;</span><br><span class="line">                    <span class="string">&#x27;image&#x27;</span>: <span class="variable language_">self</span>._bytes_feature(tf.compat.as_bytes(image_data)),</span><br><span class="line">                    <span class="string">&#x27;label&#x27;</span>: <span class="variable language_">self</span>._int64_feature(label),</span><br><span class="line">                    <span class="string">&#x27;name&#x27;</span>: <span class="variable language_">self</span>._bytes_feature(tf.compat.as_bytes(name))</span><br><span class="line">                &#125;))</span><br><span class="line">        <span class="variable language_">self</span>.tfwriter.write(example.SerializeToString())</span><br></pre></td></tr></table></figure>
<p>如果数据类型为test，由于test数据集没有对应标签信息，因此这里我们默认使用-1代替。即:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    label = <span class="built_in">int</span>(-<span class="number">1</span>)</span><br><span class="line">    example = tf.train.Example(features=tf.train.Features(feature=&#123;</span><br><span class="line">            <span class="string">&#x27;image&#x27;</span>: <span class="variable language_">self</span>._bytes_feature(tf.compat.as_bytes(image_data)),</span><br><span class="line">            <span class="string">&#x27;label&#x27;</span>: <span class="variable language_">self</span>._int64_feature(label),</span><br><span class="line">            <span class="string">&#x27;name&#x27;</span>: <span class="variable language_">self</span>._bytes_feature(tf.compat.as_bytes(name))</span><br><span class="line">        &#125;))</span><br><span class="line">    <span class="variable language_">self</span>.tfwriter.write(example.SerializeToString())</span><br></pre></td></tr></table></figure>
<h3 id="构建TFRecord和均值文件">构建TFRecord和均值文件</h3>
<p>像前几节的build_*.py脚本一样，build_imagenet.py主要实现:</p>
<ul>
<li>建立training数据集</li>
<li>建立validation数据集</li>
<li>从training数据集中提取一小部分子集作为testing数据集</li>
<li>将数据集写入TFRecord文件，并保存到磁盘中</li>
<li>计算train数据集的RGB通道均值数据，并保存到磁盘中</li>
</ul>
<p>在pyimagesearch根目录下，新建一个名为build_imagenet.py文件，并写入以下代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#encoding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> imagenet_alexnet_config <span class="keyword">as</span> config</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.utils.imagenethelper <span class="keyword">import</span> ImageNetHelper</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.utils.imagenettfrecord <span class="keyword">import</span> ImageNetTfrecord</span><br></pre></td></tr></table></figure>
<p>这里加载了我们之前构建好的配置模块imagenet_alexnet_config，以及数据预处理模块ImageNetHelper和写入TFRecord文件模块ImageNetTfrecord。</p>
<p>接下来，构建training数据集和validation数据集以及对应的标签数据：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;[INFO] loading image paths...&#x27;</span>)</span><br><span class="line">inh = ImageNetHelper(config)</span><br><span class="line">(trainPaths,trainLabels) = inh.buildTrainingSet()</span><br><span class="line">(valPaths,valLabels) = inh.buildValidationSet()</span><br></pre></td></tr></table></figure>
<p>然后，我们从trainPaths和trainlabel提取出NUM_TEST_IMAGES大小数据量，作为我们的testing数据，即:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;[INFO] constructing splits...&#x27;</span>)</span><br><span class="line">split = train_test_split(trainPaths,trainLabels,</span><br><span class="line">                         test_size = config.NUM_TEST_IMAGES,stratify=trainLabels,</span><br><span class="line">                         random_state=<span class="number">42</span>)</span><br><span class="line">trainPaths,testPaths,trainLabels,testLabels = split</span><br></pre></td></tr></table></figure>
<p>接着，我们将三类数据集合并到一个datasets列表中:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">datasets = [</span><br><span class="line">    (<span class="string">&#x27;train&#x27;</span>,trainPaths,trainLabels,config.TRAIN_TFRECORD),</span><br><span class="line">    (<span class="string">&#x27;val&#x27;</span>,valPaths,valLabels,config.VAL_TFRECORD),</span><br><span class="line">    (<span class="string">&#x27;test&#x27;</span>,testPaths,testLabels,config.TEST_TFRECORD)</span><br><span class="line">]</span><br><span class="line">(R,G,B) = [],[],[]</span><br></pre></td></tr></table></figure>
<p>其中，列表中的每一个value由一个4元组组成，即:</p>
<ul>
<li>数据的类型</li>
<li>图像数据路径</li>
<li>图像数据对应标签</li>
<li>TFRecord文件名</li>
</ul>
<p>接下来，遍历datasets数据列表:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (dType,paths,labels,outputPath) <span class="keyword">in</span> datasets:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;[INFO] building &#123;&#125;...&#x27;</span>.<span class="built_in">format</span>(outputPath))</span><br><span class="line">    inr = ImageNetTfrecord(outputPath)</span><br><span class="line"></span><br><span class="line">    probar = inh._pbar(name=<span class="string">&#x27;Building %s List: &#x27;</span>%dType,maxval=<span class="built_in">len</span>(paths))</span><br></pre></td></tr></table></figure>
<p>首先，初始化ImageNetTfrecord类，用来将数据写入TFRecord文件中，其次，调用inh类中的进度条函数_pbar，该函数有助于我们实时掌握数据处理过程。</p>
<p>对每一类型数据集进行遍历:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i,(path,label)) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(paths,labels)):</span><br><span class="line">    inr._save_one(label=label, filename=path, isTrain=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment">#　如果是train数据，则计算RGB均值信息</span></span><br><span class="line">    <span class="keyword">if</span> dType == <span class="string">&#x27;train&#x27;</span>:</span><br><span class="line">        image = cv2.imread(path)</span><br><span class="line">        (b,g,r) = cv2.mean(image)[:<span class="number">3</span>]</span><br><span class="line">        R.append(r)</span><br><span class="line">        G.append(g)</span><br><span class="line">        B.append(b)</span><br><span class="line">        probar.update(i)</span><br><span class="line">probar.finish()</span><br><span class="line">inr.tfwriter.close()</span><br></pre></td></tr></table></figure>
<p>将每条数据写入TFRecord文件中，如果数据类型为train，我们还需计算该数据集的RGB颜色通道均值，并更新相应的通道列表数据。</p>
<p>最后，将均值文件写入磁盘中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;[INFO] serializing means...&#x27;</span>)</span><br><span class="line">D = &#123;<span class="string">&#x27;R&#x27;</span>:np.mean(R),<span class="string">&#x27;G&#x27;</span>:np.mean(G),<span class="string">&#x27;B&#x27;</span>:np.mean(B)&#125;</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(config.DATASET_MEAN,<span class="string">&#x27;w&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    f.write(json.dumps(D))</span><br></pre></td></tr></table></figure>
<p>以上，我们完成了整个执行脚本的构建，接着执行build_imagenet.py脚本，完成整个数据处理工作:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python build_imagenet.py</span></span><br><span class="line">[INFO] loading image paths...</span><br><span class="line">building training set: 100% |########################################################| Time:  0:00:02</span><br><span class="line">building validation set: 100% |########################################################| Time:  0:00:00</span><br><span class="line">[INFO] constructing splits...</span><br><span class="line">[INFO] building imagenet/tfrecords/train.tfrecords...</span><br><span class="line">Building train List:   0% |</span><br></pre></td></tr></table></figure>
<p>由于train数据集，我们需要用cv2模块读取图像的numpy数组数据，并计算RGB通道均值数据，因此相对于val和test数据，我们需要更多的时间处理train数据集。并且由于我们所需要做的只是将图像路径和标签写入文件(不需要额外的I/O)，所以val数据和test数据会很快的写入TFRecord文件中并保存到磁盘中。</p>
<p>当执行完之后，你将在imagenet目录中tfrecords子目录中看到三个文件；</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">ls</span> -lht</span></span><br><span class="line">5.4G  test.tfrecords</span><br><span class="line">6.1G  val.tfrecords</span><br><span class="line">132G  train.tfrecords</span><br></pre></td></tr></table></figure>
<p>我们可以看到train.tfrecords文件是最大的，达到了132G。val.tfrecords文件为6.1G和test.tfrecords文件大小为5.4G。这样做的好处是，我们可以将整个ImageNet数据集有效地压缩到压缩记录文件中。压缩不仅节省了我们的磁盘空间，而且由于需要执行的I/O操作更少，它还将大大加快训练过程。</p>
<p>这种方法与HDF5方法不同，HDF5方法需要存储每个图像的原始数字数组信息。如果我们使用HDF5(256x256x3图像)存储ImageNet，结果文件将超过1.9TB，所以对于大数据集，使用TFRecord文件进行存储比较合理。</p>
<h2 id="总结">总结</h2>
<p>在本章中，我们学习了如何预处理ImageNet数据集。首先，我们介绍了ImageNet数据文件结构以及数据说明，之后，我们构建了整个项目的配置文件，一般而言，配置文件不会怎么变化，接着，我们创建了两个py脚本，一个是关于ImageNet数据处理脚本，另一个是将数据写入TFRecord文件脚本。最后，脚本build_imagenet.py完成了整个数据集构造过程。后面，我们将直接从TFRecord文件中读取数据，并训练深度学习模型。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Weitang Liu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://lonepatient.top/2018/07/01/Deep_Learning_For_Computer_Vision_With_Python_PB_13.html">http://lonepatient.top/2018/07/01/Deep_Learning_For_Computer_Vision_With_Python_PB_13.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://lonepatient.top" target="_blank">闲记算法</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a><a class="post-meta__tags" href="/tags/TensorFlow/">TensorFlow</a></div><div class="post_share"><div class="social-share" data-image="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-10-25/42580132.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2018/07/01/Conditional-Random-Fields.html"><img class="prev-cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-9-16/38419367.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">条件随机场-CRF</div></div></a></div><div class="next-post pull-right"><a href="/2018/06/29/The_whole_process_of_knowledge_graph_construction_from_bottom_to_top.html"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">一文揭秘！自底向上构建知识图谱全过程</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2018/02/18/Deep_Learning_For_Computer_Vision_With_Python_PB_02.html" title="深度学习与计算机视觉(PB-02)-数据增强"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/48983125.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-02-18</div><div class="title">深度学习与计算机视觉(PB-02)-数据增强</div></div></a></div><div><a href="/2018/02/25/Deep_Learning_For_Computer_Vision_With_Python_PB_03.html" title="深度学习与计算机视觉(PB-03)-特征提取"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/35317806.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-02-25</div><div class="title">深度学习与计算机视觉(PB-03)-特征提取</div></div></a></div><div><a href="/2018/03/02/Deep_Learning_For_Computer_Vision_With_Python_PB_04.html" title="深度学习与计算机视觉(PB-04)-rank-N准确度"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/91735389.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-03-02</div><div class="title">深度学习与计算机视觉(PB-04)-rank-N准确度</div></div></a></div><div><a href="/2018/03/09/Deep_Learning_For_Computer_Vision_With_Python_PB_05.html" title="深度学习与计算机视觉(PB-05)-网络微调"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/6867281.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-03-09</div><div class="title">深度学习与计算机视觉(PB-05)-网络微调</div></div></a></div><div><a href="/2018/03/16/Deep_Learning_For_Computer_Vision_With_Python_PB_06.html" title="深度学习与计算机视觉(PB-06)-模型集成"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/44239955.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-03-16</div><div class="title">深度学习与计算机视觉(PB-06)-模型集成</div></div></a></div><div><a href="/2018/03/25/Deep_Learning_For_Computer_Vision_With_Python_PB_07.html" title="深度学习与计算机视觉(PB-07)-优化算法"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/6419968.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-03-25</div><div class="title">深度学习与计算机视觉(PB-07)-优化算法</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Weitang Liu</div><div class="author-info__description">一个致力于记录技术的博客</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">281</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">384</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">92</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/lonePatient"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/lonePatient" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:liuweitangmath@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://weibo.com/277974397" target="_blank" title="Weibo"><i class="fab fa-weibo"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有任何问题可通过留言板或者微信公众号给我留言，谢谢！<img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/202602201201102.jpg"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#ImageNet%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.</span> <span class="toc-text">ImageNet数据集介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BD%E5%9C%B0%E5%9D%80"><span class="toc-number">1.1.</span> <span class="toc-text">下载地址</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#ImageNet%E6%95%B0%E6%8D%AE%E8%AF%B4%E6%98%8E"><span class="toc-number">2.</span> <span class="toc-text">ImageNet数据说明</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#ImageNet%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84"><span class="toc-number">2.1.</span> <span class="toc-text">ImageNet文件结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#test%E7%9B%AE%E5%BD%95"><span class="toc-number">2.2.</span> <span class="toc-text">test目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#train%E7%9B%AE%E5%BD%95"><span class="toc-number">2.3.</span> <span class="toc-text">train目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#val%E7%9B%AE%E5%BD%95"><span class="toc-number">2.4.</span> <span class="toc-text">val目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ImageSets%E7%9B%AE%E5%BD%95"><span class="toc-number">2.5.</span> <span class="toc-text">ImageSets目录</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DevKit%E7%9B%AE%E5%BD%95"><span class="toc-number">2.6.</span> <span class="toc-text">DevKit目录</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9E%84%E5%BB%BAImageNet%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.</span> <span class="toc-text">构建ImageNet数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">3.1.</span> <span class="toc-text">配置文件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">3.2.</span> <span class="toc-text">预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TFRecord"><span class="toc-number">3.3.</span> <span class="toc-text">TFRecord</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9E%84%E5%BB%BATFRecord%E5%92%8C%E5%9D%87%E5%80%BC%E6%96%87%E4%BB%B6"><span class="toc-number">3.4.</span> <span class="toc-text">构建TFRecord和均值文件</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">4.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/02/27/arxiv_papers_2026-02-27.html" title="Arxiv今日论文 | 2026-02-27"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-27"/></a><div class="content"><a class="title" href="/2026/02/27/arxiv_papers_2026-02-27.html" title="Arxiv今日论文 | 2026-02-27">Arxiv今日论文 | 2026-02-27</a><time datetime="2026-02-27T12:30:00.000Z" title="发表于 2026-02-27 12:30:00">2026-02-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/26/arxiv_papers_2026-02-26.html" title="Arxiv今日论文 | 2026-02-26"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-26"/></a><div class="content"><a class="title" href="/2026/02/26/arxiv_papers_2026-02-26.html" title="Arxiv今日论文 | 2026-02-26">Arxiv今日论文 | 2026-02-26</a><time datetime="2026-02-26T12:30:00.000Z" title="发表于 2026-02-26 12:30:00">2026-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/arxiv_papers_2026-02-25.html" title="Arxiv今日论文 | 2026-02-25"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-25"/></a><div class="content"><a class="title" href="/2026/02/25/arxiv_papers_2026-02-25.html" title="Arxiv今日论文 | 2026-02-25">Arxiv今日论文 | 2026-02-25</a><time datetime="2026-02-25T12:30:00.000Z" title="发表于 2026-02-25 12:30:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/2026-02-25-Less-is-Enough-Synthesizing-Diverse-Data-in-Feature-Space-of-LLMs.html" title="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260225222513891.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板"/></a><div class="content"><a class="title" href="/2026/02/25/2026-02-25-Less-is-Enough-Synthesizing-Diverse-Data-in-Feature-Space-of-LLMs.html" title="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板">大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板</a><time datetime="2026-02-25T12:00:00.000Z" title="发表于 2026-02-25 12:00:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/2026-02-25-Midtraining-%E4%B8%AD%E9%97%B4%E8%AE%AD%E7%BB%83-%E6%9E%84%E5%BB%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%90%8E%E8%AE%AD%E7%BB%83%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%A5%E6%A2%81.html" title="mid-training：构建预训练与后训练之间的分布式桥梁"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260225123005910.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="mid-training：构建预训练与后训练之间的分布式桥梁"/></a><div class="content"><a class="title" href="/2026/02/25/2026-02-25-Midtraining-%E4%B8%AD%E9%97%B4%E8%AE%AD%E7%BB%83-%E6%9E%84%E5%BB%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%90%8E%E8%AE%AD%E7%BB%83%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%A5%E6%A2%81.html" title="mid-training：构建预训练与后训练之间的分布式桥梁">mid-training：构建预训练与后训练之间的分布式桥梁</a><time datetime="2026-02-25T00:00:00.000Z" title="发表于 2026-02-25 00:00:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/24/arxiv_papers_2026-02-24.html" title="Arxiv今日论文 | 2026-02-24"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-24"/></a><div class="content"><a class="title" href="/2026/02/24/arxiv_papers_2026-02-24.html" title="Arxiv今日论文 | 2026-02-24">Arxiv今日论文 | 2026-02-24</a><time datetime="2026-02-24T12:30:00.000Z" title="发表于 2026-02-24 12:30:00">2026-02-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/23/arxiv_papers_2026-02-23.html" title="Arxiv今日论文 | 2026-02-23"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-23"/></a><div class="content"><a class="title" href="/2026/02/23/arxiv_papers_2026-02-23.html" title="Arxiv今日论文 | 2026-02-23">Arxiv今日论文 | 2026-02-23</a><time datetime="2026-02-23T12:30:00.000Z" title="发表于 2026-02-23 12:30:00">2026-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/23/Think-Deep,-Not-Just-Long-Measuring-LLM-Reasoning-Effort-via-Deep-Thinking-Tokens.html" title="用&quot;深度思考率&quot;精准度量LLM推理质量"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260223165943195.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="用&quot;深度思考率&quot;精准度量LLM推理质量"/></a><div class="content"><a class="title" href="/2026/02/23/Think-Deep,-Not-Just-Long-Measuring-LLM-Reasoning-Effort-via-Deep-Thinking-Tokens.html" title="用&quot;深度思考率&quot;精准度量LLM推理质量">用&quot;深度思考率&quot;精准度量LLM推理质量</a><time datetime="2026-02-23T12:00:00.000Z" title="发表于 2026-02-23 12:00:00">2026-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/20/arxiv_papers_2026-02-20.html" title="Arxiv今日论文 | 2026-02-20"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-20"/></a><div class="content"><a class="title" href="/2026/02/20/arxiv_papers_2026-02-20.html" title="Arxiv今日论文 | 2026-02-20">Arxiv今日论文 | 2026-02-20</a><time datetime="2026-02-20T12:30:00.000Z" title="发表于 2026-02-20 12:30:00">2026-02-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/20/frontier_training_cn.html" title="前沿大模型训练方法：深度解析与实践指南"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/202602201606857.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="前沿大模型训练方法：深度解析与实践指南"/></a><div class="content"><a class="title" href="/2026/02/20/frontier_training_cn.html" title="前沿大模型训练方法：深度解析与实践指南">前沿大模型训练方法：深度解析与实践指南</a><time datetime="2026-02-20T10:30:00.000Z" title="发表于 2026-02-20 10:30:00">2026-02-20</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2026 By Weitang Liu</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'https://twikoo.lonepatient.top/',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'https://twikoo.lonepatient.top/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo@1.4.11/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (99)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/计算机视觉/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 计算机视觉 (16)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/知识图谱/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 知识图谱 (13)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 深度学习 (139)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="http://lonepatient.top/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230219144729.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-02-18</span><a class="blog-slider__title" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt="">通向AGI之路：大型语言模型（LLM）技术精要</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/07/12/gaiic_2022_ner_top10.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20220712181905.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-07-12</span><a class="blog-slider__title" href="2022/07/12/gaiic_2022_ner_top10.html" alt="">GAIIC2022商品标题识别二等奖获奖解决思路</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2022/07/12/gaiic_2022_ner_top10.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230807190424.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-01-20</span><a class="blog-slider__title" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt="">2025-03|高质量中文预训练模型集合</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>