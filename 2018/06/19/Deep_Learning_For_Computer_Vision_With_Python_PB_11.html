<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>深度学习与计算机视觉(PB-11)-GoogLeNet | 闲记算法</title><meta name="keywords" content="深度学习,计算机视觉"><meta name="author" content="Weitang Liu"><meta name="copyright" content="Weitang Liu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="在本节中，我们将研究Szegedy等人在2014年的论文《Going Deeper With Convolutions》中提出的GoogLeNet架构。这篇论文之所以重要，主要是:">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习与计算机视觉(PB-11)-GoogLeNet">
<meta property="og:url" content="http://lonepatient.top/2018/06/19/Deep_Learning_For_Computer_Vision_With_Python_PB_11.html">
<meta property="og:site_name" content="闲记算法">
<meta property="og:description" content="在本节中，我们将研究Szegedy等人在2014年的论文《Going Deeper With Convolutions》中提出的GoogLeNet架构。这篇论文之所以重要，主要是:">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/79935692.jpg">
<meta property="article:published_time" content="2018-06-19T23:27:08.000Z">
<meta property="article:modified_time" content="2026-02-27T07:52:12.655Z">
<meta property="article:author" content="Weitang Liu">
<meta property="article:tag" content="深度学习">
<meta property="article:tag" content="计算机视觉">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/79935692.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://lonepatient.top/2018/06/19/Deep_Learning_For_Computer_Vision_With_Python_PB_11"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//s4.cnzz.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script async="async" data-pjax="data-pjax" src="https://s4.cnzz.com/z_stat.php?id=1273275888&amp;web_id=1273275888"></script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2026-02-27 07:52:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/backgroud.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><script src="https://at.alicdn.com/t/c/font_3570527_dthoqrrv2tv.css"></script><script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script><script>LA.init({id:"JwRQtLKZggvJH4sJ",ck:"JwRQtLKZggvJH4sJ"})</script><link rel="stylesheet" href="/css/universe.css"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3536467946304280" crossorigin="anonymous"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">281</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">384</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">92</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 网站</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.aitoolist.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集合</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.deepdh.com"><i class="fa-fw fa fa-star"></i><span> AI工具导航</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.ai-lib.club"><i class="fa-fw fa fa-star"></i><span> 人工智能工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ai-bot.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 教程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://learningprompt.wiki/"><i class="fa-fw fa fa-star"></i><span> Prompt教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 在线</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fa fa-star"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/79935692.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">闲记算法</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 网站</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.aitoolist.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集合</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.deepdh.com"><i class="fa-fw fa fa-star"></i><span> AI工具导航</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.ai-lib.club"><i class="fa-fw fa fa-star"></i><span> 人工智能工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ai-bot.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 教程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://learningprompt.wiki/"><i class="fa-fw fa fa-star"></i><span> Prompt教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 在线</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fa fa-star"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">深度学习与计算机视觉(PB-11)-GoogLeNet<a class="post-edit-link" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts/Deep_Learning_For_Computer_Vision_With_Python_PB_11.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2018-06-19T23:27:08.000Z" title="发表于 2018-06-19 23:27:08">2018-06-19</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-02-27T07:52:12.655Z" title="更新于 2026-02-27 07:52:12">2026-02-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">14.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>52分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2018/06/19/Deep_Learning_For_Computer_Vision_With_Python_PB_11.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>在本节中，我们将研究Szegedy等人在2014年的论文《Going Deeper With Convolutions》中提出的GoogLeNet架构。这篇论文之所以重要，主要是:</p>
<span id="more"></span>
<ul>
<li>
<p>与AlexNet和VGGNet网络结构相比，模型非常小(整个权重文件大小约为28MB)。并且从论文中，我们可以看到作者使用Global Average Pooling代替了全连接层，一方面减小了模型的大小，另一方面加深了整个网络的深度。CNN中的大部分权重都来自于全连接FC层，如果删除FC层，那么模型权重个数会减少很多且可以节省计算的内存消耗。</p>
</li>
<li>
<p>Szegedy等人在构建整体网络结构时，利用了Network in Network（NIN）结构。在此之前的AlexNet、VGG等结构都是堆叠式神经网络，即其中一个网络层的输出直接输入到另一个网络层。原论文中，作者在搭建网络结构时，多次使用一个微结构——我们即将看到的Inception模块，该模块将输入分割成许多不同的分支，然后再重新连接成一个输出。</p>
</li>
</ul>
<p>具体来说，Inception模块是对输入做了四个分支，分别用不同尺寸的filter进行卷积或者池化，最后再在特征维度上拼接到一起。直观感觉上在多个尺度上同时进行卷积，能提取到不同尺寸的特征。特征更为丰富也意味着最后分类判断时更为准确。</p>
<p>除了Inception模块，目前，研究者也提出了一些微结构模块，比如ResNet[24]中的Residual模块和squeezeNet中的Fire模块。在这节中，我们主要讨论Inception模块。一旦了解了Inception模块的组件以及功能，我们就可以自己实现一个小型的GoogLeNet——“MiniGoogLeNet”，然后，我们将在CIFAR-10数据集上训练“MiniGoogLeNet”网络结构。最后，我们将探讨cs231n课程的tiny ImageNet任务[4]——这个任务是斯坦福大学的cs231n卷积神经网络课程[39]的实践项目的一个任务，tiny ImagesNet任务只使用ImageNet的一部分数据。我们将在tiny ImageNet数据集上从头到尾训练一个GoogLeNet网络，并获得一个不错的名次。</p>
<h2 id="Inception-模块">Inception 模块</h2>
<p>目前，一些state-of-the-art的卷积神经网络（如ResNet等）都使用了微结构——也称为network-in-network模块，最初由Lin等人提出。整体的网络结构是由一些微结构模块与传统的网络层（如CONV，POOL等）堆叠而成。本文中，我们主要讨论Inception模块。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/79935692.jpg" alt=""></p>
<center>图11.1 Inception模块</center>
Inception模块的基本结构如图11.1所示，整个GoogLeNet网络结构就是由多个这样的Inception模块串联起来的。Inception模块的主要贡献有两个：
<ul>
<li>使用1x1的卷积进行升降维</li>
<li>在多个尺寸上同时进行卷积再聚合</li>
</ul>
<p>Inception模块对输入做了四个分支，分别用不同尺寸的filter进行卷积或者池化，最后再在特征维度上拼接在一起，这种全新的结构有什么好处呢？Szegedy从多个角度进行解释：</p>
<ul>
<li>在卷积层中，我们很难确定使用多大的filter。5x5?3x3?1x1?既然很难决定，那么全部都学习，让模型决定哪个更好，在Inception模块中，包含了三种大小的filter，即5x5、3x3和1x1大小的filter。Inception模块对输入做了四个分支，并行计算四个分支，然后再将这四个分支的输出连接成一个整体模块的输出。GoogLeNet网络结构主要是由多个Inception模块和传统的网络层堆叠而成，总的来说，Inception模块使得GoogLeNet网络既能学习局部特征（小卷积），又能学习抽象特征（大卷积）。</li>
<li>从直观感觉上在多个尺度上同时进行卷积，能提取到不同尺度的特征。特征更为丰富也意味着最后分类判断时更加准确。</li>
<li>利用稀疏矩阵分解成密集矩阵计算的原理来加快收敛速度。举个例子下图左侧是个稀疏矩阵（很多元素都为0，不均匀分布在矩阵中），和一个2x2的矩阵进行卷积，需要对稀疏矩阵中的每一个元素进行计算；如果像右图那样把稀疏矩阵分解成2个子密集矩阵，再和2x2矩阵进行卷积，稀疏矩阵中0较多的区域就可以不用计算，计算量就大大降低。这个原理应用到inception上就是要在特征维度上进行分解！传统的卷积层的输入数据只和一种尺度（比如3x3）的卷积核进行卷积，输出固定维度（比如256个特征）的数据，所有256个输出特征基本上是均匀分布在3x3尺度范围上，这可以理解成输出了一个稀疏分布的特征集；而inception模块在多个尺度上提取特征（比如1x1，3x3，5x5），输出的256个特征就不再是均匀分布，而是相关性强的特征聚集在一起（比如1x1的的96个特征聚集在一起，3x3的96个特征聚集在一起，5x5的64个特征聚集在一起），这可以理解成多个密集分布的子特征集。这样的特征集中因为相关性较强的特征聚集在了一起，不相关的非关键特征就被弱化，同样是输出256个特征，inception方法输出的特征“冗余”的信息较少。用这样的“纯”的特征集层层传递最后作为反向计算的输入，自然收敛的速度更快。</li>
</ul>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/87024204.jpg" alt=""></p>
<ul>
<li>Hebbin赫布原理。Hebbin原理是神经科学上的一个理论，解释了在学习的过程中脑中的神经元所发生的变化，用一句话概括就是fire togethter, wire together。赫布认为“两个神经元或者神经元系统，如果总是同时兴奋，就会形成一种‘组合’，其中一个神经元的兴奋会促进另一个的兴奋”。比如狗看到肉会流口水，反复刺激后，脑中识别肉的神经元会和掌管唾液分泌的神经元会相互促进，“缠绕”在一起，以后再看到肉就会更快流出口水。用在inception结构中就是要把相关性强的特征汇聚到一起。这有点类似上面的解释2，把1x1，3x3，5x5的特征分开。因为训练收敛的最终目的就是要提取出独立的特征，所以预先把相关性强的特征汇聚，就能起到加速收敛的作用。</li>
</ul>
<p>从图11.1中，可以看到有多个1x1卷积模块，这样的卷积有什么用处呢？</p>
<ul>
<li>在相同尺寸的感受野中叠加更多的卷积，能提取到更丰富的特征。这个观点来自于<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1312.4400.pdf">Network in Network</a>。</li>
</ul>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/46038919.jpg" alt=""></p>
<p>上图左侧是是传统的卷积层结构（线性卷积），在一个尺度上只有一次卷积；上图右是Network in Network结构（NIN结构），先进行一次普通的卷积（比如3x3），紧跟再进行一次1x1的卷积，对于某个像素点来说1x1卷积等效于该像素点在所有特征上进行一次全连接的计算，所以右侧图的1x1卷积画成了全连接层的形式，需要注意的是NIN结构中无论是第一个3x3卷积还是新增的1x1卷积，后面都紧跟着激活函数（比如relu）。将两个卷积串联，就能组合出更多的非线性特征。举个例子，假设第1个3x3卷积＋激活函数近似于f1(x)=ax2+bx+c，第二个1x1卷积＋激活函数近似于f2(x)=mx2+nx+q，那f1(x)和f2(f1(x))比哪个非线性更强，更能模拟非线性的特征？答案是显而易见的。NIN的结构和传统的神经网络中多层的结构有些类似，后者的多层是跨越了不同尺寸的感受野（通过层与层中间加pool层），从而在更高尺度上提取出特征；NIN结构是在同一个尺度上的多层（中间没有pool层），从而在相同的感受野范围能提取更强的非线性。</p>
<ul>
<li>使用1x1卷积进行降维，降低了计算复杂度。下图中间3x3卷积和5x5卷积前的1x1卷积都起到了这个作用。当某个卷积层输入的特征数较多，对这个输入进行卷积运算将产生巨大的计算量；如果对输入先进行降维，减少特征数后再做卷积计算量就会显著减少。下图是优化前后两种方案的乘法次数比较，同样是输入一组有192个特征、32x32大小，输出256组特征的数据，第一张图直接用3x3卷积实现，需要192x256x3x3x32x32=452984832次乘法；第二张图先用1x1的卷积降到96个特征，再用3x3卷积恢复出256组特征，需要192x96x1x1x32x32+96x256x3x3x32x32=245366784次乘法，使用1x1卷积降维的方法节省了一半的计算量。有人会问，用1x1卷积降到96个特征后特征数不就减少了么，会影响最后训练的效果么？答案是否定的，只要最后输出的特征数不变（256组），中间的降维类似于压缩的效果，并不影响最终训练的结果。</li>
</ul>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/24853266.jpg" alt=""></p>
<h3 id="Inception">Inception</h3>
<p>接下来，我们看看Inception的各个分支组件，如图11.1所示</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/79935692.jpg" alt=""></p>
<center>图11.1 Inception模块</center>
**注意**: 在每个CONV层之后都会使用一个激活函数(ReLU)。为了节省空间，这个激活函数没有在图11.1中显示。当我们实现GoogLeNet时，我们会在Inception模块中使用激活函数。
<p>Inception模块中的第一个分支是由多个1x1大小的filters组成，1x1卷积可以从输入层中学习到局部特征。</p>
<p>第二个分支中，先对输入层使用了1x1的卷积，不仅可以学习局部特征，而且还可以起到降维的作用。当某个卷积层输入的特征数较多，对这个输入进行卷积运算将产生巨大的计算量；如果对输入先进行降维，减少特征数后再做卷积计算量就会显著减少。因此，在第二个分支中，先使用1x1的CONV后再使用3x3的卷积，整体的计算量小于直接使用3x3的卷积的计算量。</p>
<p>第三个分支类似于第二个分支结构，只不过第三个分支中使用的是5x5的卷积。</p>
<p>第四个分支跟之前的分支不太一样，先对输入层使用了3x3的max pooling，<strong>注意</strong>，pooling层的步长为1，作者认为pooling也能起到提取特征的作用，而且pooling后没有减少数据的尺寸。然后紧接着1x1的卷积。</p>
<p>最后，将四个分支的输出在特征维度上连接在一起组成一个inception模块的输出。<strong>特别注意</strong>，在实现过程中，需要通过零填充，以确保每个分支的输出具有相同的大小，从而可以拼接在一起。</p>
<h3 id="Miniception">Miniception</h3>
<p>GoogLeNet网络由图11.1所示的Inception模块和传统的网络层堆叠组成，并且在ImageNet数据集（输入特征图像为224x224x3）获得了惊人的结果。实际中，我们的数据集并没有ImageNet那么大，所以对于小数据集（或特征图像大小很小），我们将简化Inception模块。</p>
<p>&quot;Miniception&quot;模块主要从<a target="_blank" rel="noopener" href="https://twitter.com/ericjang11">@ericjang11</a>和<a target="_blank" rel="noopener" href="https://twitter.com/pluskid">@pluskid</a>的一条推文中了解到，他们在训练CIFAR-10数据集时使用了一个更小的Inception变体，如图11.2——来自于Zhang等人2017年出版的《Understanding Deep Learning Requires Re-Thinking Generalization》。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/79220723.jpg" alt=""></p>
<center>图11.2 miniception 模块结构以及整个网络结构</center>
图11.2显示了上部分展示了各个模块的组件，下部分显示了整个MiniGoogLeNet模型结构，其中:
<ul>
<li>conv_module：由卷积层，BN层和激活函数组成。</li>
<li>inception_model:由1x1卷积和3x3卷积组成</li>
<li>downsample_module:由3x3卷积（步长为2)和3x3的max pooling（步长为2）组成</li>
</ul>
<p>这些模块堆叠在一起组成了一个MiniGoogLeNet网络结构，如图11.2下所示。另外，作者在激活函数之前增加了BN层(可能是因为Szegedy等人也同样处理了)，而在实际中我们搭建CNN模型结构时，一般建议是把BN层放在激活函数之后。在本节中，我们主要按照原作者的方式进行，将BN放在激活函数之前，以便复现结果，当然在个人实验中，可以尝试将两者位置调换下，看看性能如何。</p>
<p>在下一节中，我们将实现MiniGoogLeNet架构，并在CIFAR-10数据集上进行训练。</p>
<h2 id="MiniGoogLeNet-on-CIFAR-10">MiniGoogLeNet on CIFAR-10</h2>
<p>首先，我们将使用Miniception模块实现MiniGoogLeNet网络架构。然后，我们将在CIFAR-10数据集上训练MiniGoogLeNet结构。</p>
<h3 id="MiniGoogLeNet">MiniGoogLeNet</h3>
<p>首先，我们开始搭建MiniGoogLeNet网络结构。<a target="_blank" rel="noopener" href="http://xn--pyimagesearchnn-xz3xj03id81jrwb3593a.xn--convminigooglenet-ts50a2wzb9qn58ih2pvh7bec9atey.py">在pyimagesearch项目中的nn.conv模块中新建一个名为minigooglenet.py</a>，如下目录结构:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">--- pyimagesearch</span><br><span class="line">| |--- __init__.py</span><br><span class="line">| |--- callbacks</span><br><span class="line">| |--- io</span><br><span class="line">| |--- nn</span><br><span class="line">| | |--- __init__.py</span><br><span class="line">| | |--- conv</span><br><span class="line">| | | |--- __init__.py</span><br><span class="line">| | | |--- alexnet.py</span><br><span class="line">| | | |--- lenet.py</span><br><span class="line">| | | |--- minigooglenet.py</span><br><span class="line">| | | |--- minivggnet.py</span><br><span class="line">| | | |--- fcheadnet.py</span><br><span class="line">| | | |--- shallownet.py</span><br><span class="line">| |--- preprocessing</span><br><span class="line">| |--- utils</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="http://xn--minigooglenet-2q0zy87a.py">打开minigooglenet.py</a>，并写入以下代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 加载所需模块</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Activation</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> concatenate</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br></pre></td></tr></table></figure>
<p>需要注意的是，前面我们提到了GoogLeNet并不是传统的堆叠式神经网络，因此，我们不能使用keras中Sequential类，而是使用keras的另一个模型类Model，使用Model类，我们可以轻松的完成有分支的微结构，比如Inception模块，另外，concatenate函数可以按照给定的维度方向将多个输入进行连接。</p>
<p>我们将按图11.2所示的结构，搭建MiniGoogLeNet模型。首先，我们定义conv_module:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MiniGoogLeNet</span>:</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">conv_module</span>(<span class="params">x,K,kX,kY,stride,chanDim,padding=<span class="string">&#x27;same&#x27;</span></span>):</span><br><span class="line">        <span class="comment"># define a CONV =&gt; BN =&gt; RELU pattern</span></span><br><span class="line">        x = Conv2D(K,(kX,kY),strides = stride,padding=padding)(x)</span><br><span class="line">        x = BatchNormalization(axis=chanDim)(x)</span><br><span class="line">        x = Activation(<span class="string">&#x27;relu&#x27;</span>)(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>conv_module主要由卷积层，BN层和激活层组成。其中:</p>
<ul>
<li>x: 网络层的输入</li>
<li>K: CONV层的filter个数</li>
<li>kX和kY: filter的大小</li>
<li>stride: 步长</li>
<li>padding: 填充模式，默认是’same’，即保持输入跟输出的大小一致。</li>
</ul>
<p>从上，我们看到，Model类与Sequential类构建模型的方式不一样，Sequential类主要使用的是model.add模式，而Model类主要是使用是function()(x)形式,如下模板：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">output = Layer(parameters)(input)</span><br></pre></td></tr></table></figure>
<p>我们在搭建非堆叠式网络时，主要使用该模板进行构建。整个conv_module结构如图11.3所示：</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/33402589.jpg" alt=""></p>
<center>图11.3 conv_module </center>
整个流程为CONV => BN => ACT，**注意**，这个模块没有任何分支。
<p>下面，我们定义Inception_module:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">inception_module</span>(<span class="params">x,numK1x1,numK3x3,chanDim</span>):</span><br><span class="line">    <span class="comment"># 拼接两个CONV层</span></span><br><span class="line">    conv_1x1 = MiniGoogLeNet.conv_module(x,numK1x1,<span class="number">1</span>,<span class="number">1</span>,(<span class="number">1</span>,<span class="number">1</span>),chanDim)</span><br><span class="line">    conv_3x3 = MiniGoogLeNet.conv_module(x,numK3x3,<span class="number">3</span>,<span class="number">3</span>,(<span class="number">1</span>,<span class="number">1</span>),chanDim)</span><br><span class="line">    x = concatenate([conv_1x1,conv_3x3],axis = chanDim)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>x: 输入层</li>
<li>numK1x1：1x1的filter个数</li>
<li>numK3x3：3x3的filter个数</li>
<li>chanDim：通道维度</li>
</ul>
<p><strong>注意</strong>：Mininception模块主要两组卷积分支组成——1x1的CONV和3x3的CONV。整个inception_module结构如图11.4所示：</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/96204254.jpg" alt=""></p>
<center>图11.4 inception_module </center>
接下来，我们定义downsample_module，即降低输入层的维度:
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">downsample_module</span>(<span class="params">x,K,chanDim</span>):</span><br><span class="line">    <span class="comment"># 定义CONV和POOL，并拼接</span></span><br><span class="line">    conv_3x3 = MiniGoogLeNet.conv_module(x,K,<span class="number">3</span>,<span class="number">3</span>,(<span class="number">2</span>,<span class="number">2</span>),chanDim,padding=<span class="string">&#x27;valid&#x27;</span>)</span><br><span class="line">    pool = MaxPooling2D((<span class="number">3</span>,<span class="number">3</span>),strides=(<span class="number">2</span>,<span class="number">2</span>))(x)</span><br><span class="line">    x = concatenate([conv_3x3,pool],axis = chanDim)</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>x: 输入层</li>
<li>K：filter的个数</li>
<li>chanDim:  特征维度</li>
</ul>
<p>整个downsample_module结构如图11.5所示：</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/21857331.jpg" alt=""></p>
<center>图11.5 downsample_module</center>
接下来，我们将以上组件进行拼接一起，搭建MiniGoogLeNet结构:
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build</span>(<span class="params">width,height,depth,classes</span>):</span><br><span class="line">    inputShape =(height,width,depth)</span><br><span class="line">    chanDim = -<span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> K.image_data_format() == <span class="string">&quot;channels_first&quot;</span>:</span><br><span class="line">        inputShape = (depth,height,width)</span><br><span class="line">        chanDim = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>width：特征图像的宽度</li>
<li>height：特征图像的高度</li>
<li>depth：通道数</li>
<li>classes：类别个数</li>
</ul>
<p>定义MiniGoogLeNet的输入层和第一个conv_module:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输入层和第一个CONV层</span></span><br><span class="line">inputs= Input(shape = inputShape)</span><br><span class="line">x = MiniGoogLeNet.conv_module(inputs,<span class="number">96</span>,<span class="number">3</span>,<span class="number">3</span>,(<span class="number">1</span>,<span class="number">1</span>),chanDim)</span><br></pre></td></tr></table></figure>
<p>第一个conv_module模块中由96个3x3的filters组成。在第一个conv_module之后我们堆叠两个inception模块，以及一个downsample_module:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 两个Inception和一个downsample层</span></span><br><span class="line">x = MiniGoogLeNet.inception_module(x,<span class="number">32</span>,<span class="number">32</span>,chanDim)</span><br><span class="line">x = MiniGoogLeNet.inception_module(x,<span class="number">32</span>,<span class="number">48</span>,chanDim)</span><br><span class="line">x = MiniGoogLeNet.downsample_module(x,<span class="number">80</span>,chanDim)</span><br></pre></td></tr></table></figure>
<p>第一个inception模块中，包含32个1x1的filters和32个3x3的filters，因此第一个inception模块的输出有K = 32+32=64个filters。</p>
<p>第二个inception模块中，包含32个1x1的filters和48个3x3的filters，因此第二个inception模块的输出有K = 32+48=80个filters。</p>
<p>downsample_module对输入进行降维，但是保持filters的个数不变。</p>
<p>接下来，我们将四个Inception模块叠加在一起，让GoogLeNet学习更深入、更丰富的特征:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 四个Inception和一个downsample层</span></span><br><span class="line">x = MiniGoogLeNet.inception_module(x,<span class="number">112</span>,<span class="number">48</span>,chanDim)</span><br><span class="line">x = MiniGoogLeNet.inception_module(x,<span class="number">96</span>,<span class="number">64</span>,chanDim)</span><br><span class="line">x = MiniGoogLeNet.inception_module(x,<span class="number">80</span>,<span class="number">80</span>,chanDim)</span><br><span class="line">x = MiniGoogLeNet.inception_module(x,<span class="number">48</span>,<span class="number">96</span>,chanDim)</span><br><span class="line">x = MiniGoogLeNet.downsample_module(x,<span class="number">96</span>,chanDim)</span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>：这里inception模块中的1x1的filters和3x3的filters的个数变化，有的inception模块中1x1的filter的个数大于3x3的filter的个数，而有的inception模块中3x3的filter的个数大于1x1的filter的个数。Szegedy等人经过多次实验证明了这种交替变化模式是有效的。后面，我们搭建更深的GoogLeNet结构时，也会看到这种变化。</p>
<p>如图11.2所示，接着我们将堆叠两个inception模块，之后拼接average pooling层和dropout层:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 两个Inception和global POOL ，dropout</span></span><br><span class="line">x = MiniGoogLeNet.inception_module(x,<span class="number">176</span>,<span class="number">160</span>,chanDim)</span><br><span class="line">x = MiniGoogLeNet.inception_module(x,<span class="number">176</span>,<span class="number">160</span>,chanDim)</span><br><span class="line">x = AveragePooling2D((<span class="number">7</span>,<span class="number">7</span>))(x)</span><br><span class="line">x = Dropout(<span class="number">0.5</span>)(x) <span class="comment">#防止过拟合</span></span><br></pre></td></tr></table></figure>
<p>最后一个inception模块输出的特征图像大小为7x7x336，经过7x7的average pooling层之后，特征图像大小变为1x1x336。在AlexNet和VGG之前，基本上所有的基于神经网络的机器学习算法都要在卷积层之后添加全连接来进行特征的向量化，但是我们注意到，全连接层有一个非常致命的弱点就是<strong>参数量过大</strong>，特别是与最后一个卷积层相连的全连接层。那么我们有没有办法将其替代呢？当然有，就是GAP（global average pooling）——对每一个feature map内部取平均，将每一个feature map变成一个值，从而多少个feature map就变成了多少维的向量，然后就可以直接输入到softmax中。因此，上面我们得到了1x1x336的特征图像，所以没必要使用全连接层，直接将1x1x336拉平成一个336维度的向量，如下图所示：</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/40423453.jpg" alt=""></p>
<p>最后，添加分类器——software:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># softmax分类器</span></span><br><span class="line">x = Flatten()(x)</span><br><span class="line">x = Dense(classes)(x)</span><br><span class="line">x = Activation(<span class="string">&#x27;softmax&#x27;</span>)(x)</span><br><span class="line"><span class="comment"># 建立模型</span></span><br><span class="line">model = Model(inputs,x,name=<span class="string">&#x27;googlenet&#x27;</span>)</span><br><span class="line"><span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>
<p>以上，完成了整个MinGoogLeNet网络结构的搭建，接下来，我们将在CIFAR-10数据集上进行训练。</p>
<h3 id="Training-MiniGoogLeNet-on-CIFAR-10">Training MiniGoogLeNet on CIFAR-10</h3>
<p>新建一个名为googlenet_cifar10.py文件，并写入以下代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment">#加载所需模块</span></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelBinarizer</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.nn.conv <span class="keyword">import</span> minigooglenet <span class="keyword">as</span> MGN</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.callbacks <span class="keyword">import</span> trainingmonitor <span class="keyword">as</span> TM</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> LearningRateScheduler</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> SGD</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> cifar10</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure>
<p>与之前不同的是，这里我们新加载了一个LearningRateScheduler类的，这意味着优化器将以一个特定的学习率进行训练。我们将对学习率进行多项式衰减，计算公式如下:</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>α</mi><mo>=</mo><msub><mi>α</mi><mn>0</mn></msub><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>e</mi><mi mathvariant="normal">/</mi><msub><mi>e</mi><mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub><msup><mo stretchy="false">)</mo><mi>p</mi></msup></mrow><annotation encoding="application/x-tex">\alpha = \alpha_0 * (1 - e / e_{max}) ^p 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6153em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">∗</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">e</span><span class="mord">/</span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">ma</span><span class="mord mathnormal mtight">x</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7144em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">p</span></span></span></span></span></span></span></span></span></span></span></span></p>
<p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>α</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\alpha_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em;">α</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0037em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>为初始学习率，e为当前epoch，emax为我们一开始设定的最大迭代次数，p为多项式的幂。通过公式，我们可以看到每个epoch的学习率不是固定的，并且随着迭代不断深度，学习率将逐渐衰减为零。</p>
<p>在实际应用中，我们往往将p设置为1.0，即为线性衰减模式。图11.6显示了对不同的p值所做的实验结果，在迭代次数，初始学习率固定的情况下，随着p值的增加，学习率下降得越快。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/69706898.jpg" alt=""></p>
<center>图11.6 不同p值实验 </center>
实现这个学习率衰减函数:
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 总的迭代次数</span></span><br><span class="line">NUM_EPOCHS = <span class="number">70</span></span><br><span class="line"><span class="comment">#初始学习率</span></span><br><span class="line">INIT_LR = <span class="number">5e-3</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">poly_decay</span>(<span class="params">epoch</span>):</span><br><span class="line">    <span class="comment"># 初始最大迭代次数和学习率</span></span><br><span class="line">    maxEpochs = NUM_EPOCHS</span><br><span class="line">    baseLR = INIT_LR</span><br><span class="line">    power = <span class="number">1.0</span></span><br><span class="line">    <span class="comment"># 以多项式的方式衰减学习率</span></span><br><span class="line">    alpha = baseLR * (<span class="number">1</span> - (epoch / <span class="built_in">float</span>(maxEpochs))) ** power</span><br><span class="line">    <span class="keyword">return</span> alpha</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>epoch：为当前训练的epoch</li>
</ul>
<p>解析命令行参数:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义命令行参数</span></span><br><span class="line">ap = argparse.ArgumentParser()</span><br><span class="line">ap.add_argument(<span class="string">&#x27;-m&#x27;</span>,<span class="string">&#x27;--model&#x27;</span>,required=<span class="literal">True</span>,<span class="built_in">help</span> = <span class="string">&#x27;path to output model&#x27;</span>)</span><br><span class="line">ap.add_argument(<span class="string">&#x27;-o&#x27;</span>,<span class="string">&#x27;--output&#x27;</span>,required=<span class="literal">True</span>,<span class="built_in">help</span>=<span class="string">&#x27;path to output directory (logs,plots,etc.)&#x27;</span>)</span><br><span class="line">args = <span class="built_in">vars</span>(ap.parse_args())</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>model： 训练好的模型保存文件路径</li>
<li>output: 输出保存路径，比如log、plots等</li>
</ul>
<p>从磁盘读取CIFAR-10数据集，并进行零均值化和标签编码处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载训练数据集和测试数据集</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[INFO] loading CIFAR-10 data...&quot;</span>)</span><br><span class="line">((trainX,trainY),(testX,testY))  = cifar10.load_data()</span><br><span class="line">trainX = trainX.astype(<span class="string">&quot;float&quot;</span>)</span><br><span class="line">testX = testX.astype(<span class="string">&quot;float&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#计算均值</span></span><br><span class="line">mean = np.mean(trainX,axis = <span class="number">0</span>)</span><br><span class="line">trainX -= mean</span><br><span class="line">testX -= mean</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标签编码化</span></span><br><span class="line">lb = LabelBinarizer()</span><br><span class="line">trainY = lb.fit_transform(trainY)</span><br><span class="line">testY = lb.fit_transform(testY)</span><br></pre></td></tr></table></figure>
<p>为了提高精度和防止过拟合，我们增加数据增强处理：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据增强</span></span><br><span class="line">aug = ImageDataGenerator(width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">                         height_shift_range = <span class="number">0.1</span>,</span><br><span class="line">                         horizontal_flip = <span class="literal">True</span>,</span><br><span class="line">                         fill_mode = <span class="string">&#x27;nearest&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>回调函数列表中，TrainingMonitor函数功能主要是监控训练过程指标的变化，LearningRateScheduler主要是更新学习率：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 回调,监控</span></span><br><span class="line">figPath = os.path.sep.join([args[<span class="string">&#x27;output&#x27;</span>],<span class="string">&#x27;&#123;&#125;.png&#x27;</span>.<span class="built_in">format</span>(os.getpid())])</span><br><span class="line">jsonPath = os.path.sep.join([args[<span class="string">&#x27;output&#x27;</span>],<span class="string">&quot;&#123;&#125;.json&quot;</span>.<span class="built_in">format</span>(os.getpid())])</span><br><span class="line">callbacks = [TM.TrainingMonitor(figPath,jsonPath = jsonPath),</span><br><span class="line">             LearningRateScheduler(poly_decay)]</span><br></pre></td></tr></table></figure>
<p>最后，我们开始训练网络:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化优化器和模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[INFO] compiling model...&quot;</span>)</span><br><span class="line">opt= SGD(lr = INIT_LR,momentum = <span class="number">0.9</span>)</span><br><span class="line">model = MGN.MiniGoogLeNet.build(width=<span class="number">32</span>,height = <span class="number">32</span>,depth=<span class="number">3</span>,classes = <span class="number">10</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(loss = <span class="string">&#x27;categorical_crossentropy&#x27;</span>,optimizer=opt,metrics = [<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="comment"># 训练网络</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[INFO] training network...&quot;</span>)</span><br><span class="line">model.fit_generator(aug.flow(trainX,trainY,batch_size = <span class="number">64</span>),</span><br><span class="line">                    validation_data = (testX,testY),steps_per_epoch = <span class="built_in">len</span>(trainX) // <span class="number">64</span>,</span><br><span class="line">                    epochs = NUM_EPOCHS,callbacks = callbacks,verbose = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存模型到磁盘中</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[INFO] serializing network...&quot;</span>)</span><br><span class="line">model.save(args[<span class="string">&#x27;model&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>初始化学习率lr=INIT_LR,一旦训练开始，学习率将通过learningrescheduler进行更新。</p>
<h3 id="实验1">实验1</h3>
<p>在给定数据集情况下，我们往往需要通过多次实验，以获得一个良好的结果，如何根据上一次实验的结果，调整下一次实验的方案，这个过程很重要。一开始，当我们刚刚开始涉足深度学习时候——仅仅看到一段代码、理解它的功能、执行它并查看输出就足够了。</p>
<p>但是，当我们深入学习时，我们将使用更高级的模型架构以及面对更加有挑战性的问题，这时候，我们需要了解模型背后的学习过程，需要检查结果，然后根据结果是否需要进一步更新参数，这将对我们提高实验能力很有帮助。</p>
<p>在我们的第一个实验中,令初始学习率为1e-3并且使用线性衰减进行更新，优化器为SGD算法，总的迭代次数设置为70——这里可能有一个疑问，为何epochs为70，而不是更大或者更小，主要是：</p>
<ul>
<li>
<p>先验知识。当你阅读了数百篇深度学习论文、博客文章和教程以及多次实验之后，你将会发现一些数据集的模式。在本例中，从大家对CIFAR-10数据集的实验中可知，训练CIFAR-10数据集所需的epochs大约在50-100次左右，而且网络结构越深(有正则化情况下)，学习率就越低，这通常会使我们的网络训练时间更长。所以，对于第一个实验，我们将epochs设置为70，然后我们可以根据实验的结果来决定是否应该使用更多/更少的epochs。</p>
</li>
<li>
<p>避免过拟合。从之前的实验中，我们知道，在训练CIFAR-10数据集时，即使加入了正则化和数据增强方法，我们最终仍然会发生过拟合问题。因此，我们在实验中将epochs设置为70，而不是80-100左右——这个区间可能更容易发生过拟合问题。</p>
</li>
</ul>
<p>运行以下命令，进行训练网络:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python googlenet_cifar10.py --output output --model output/minigooglenet_cifar10.hdf5</span></span><br></pre></td></tr></table></figure>
<p>从打印的结果以及图11.7左上，可知70次迭代训练之后，模型的准确度为88.15%。另外，从图中可以看到在第40次epoch之后，train_loss和val_loss曲线基本上成相对比例下降且在第70次epoch，train_loss和val_loss似乎还有下降的趋势。因此，在给定epochs下，我们可以尝试加快训练速度，即加大学习率。</p>
<h3 id="实验2">实验2</h3>
<p>在第二个实验中，我们将增大学习率，令lr=1e-2，其余保持不变。然后运行下面命令进行第二次训练网络:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python googlenet_cifar10.py --output output --model output/minigooglenet_cifar10.hdf5</span></span><br></pre></td></tr></table></figure>
<p>结果如图11.7右上角所示，在70次迭代训练结束之后，模型的准确率大约为<strong>92.19%</strong>，虽然准确率比第一个实验提高了一点，但是，我们详细观察train_loss变化曲线，很明显在第60次迭代之后，train_loss接近0，也就是说准确度接近100%。</p>
<p>虽然我们提高了模型在验证集上的准确度，但是，很明显我们发生了过拟合——在第20次epoch之后，train_loss和val_loss之间的差距很明显变大。</p>
<p>结合两个实验，或许我们可以对学习率取一个1e-3到1e-2的中间值，以达到一个平衡点，比如设置lr=5e-3，这样，或许可以获得一个不错的准确度，又能一定程度上降低过拟合风险。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/24575337.jpg" alt=""></p>
<center>图11.7 三次实验结果</center>
* 值得注意的是，如果你发现模型的训练损失为0.0和准确度为100%，这时候，你一定要密切关注模型在验证数据集上的loss和accuracy曲线变化。如果你发现train_loss和val_loss之间存在明显的差距，那么肯定是模型发生了过拟合。这时候需要对模型的参数进行调整，引入更多的正则化技术，调整学习率等。*
<h3 id="实验3">实验3</h3>
<p>在第三个实验中，将学习率调整为5e-3，其余保持不变。运行以下命令：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python googlenet_cifar10.py --output output --model output/minigooglenet_cifar10.hdf5</span></span><br></pre></td></tr></table></figure>
<p>结果如图11.7下所示，在70次迭代训练之后，模型的准确度为<strong>90.79%</strong>——低于第二个实验，高于第一个实验。虽然同样也发生了过拟合问题，但是是可以接受的。</p>
<p>更重要的是，训练损失并没有完全降到零，训练精度也没有达到100%。而且train_acc和val_acc之间的差距是合理的。</p>
<p>在这一点上，我们可以认为这个实验是可以接受的(或许我们应该做更多的实验来减少过拟合问题)——我们已经成功地在CIFAR-10数据集上训练MiniGoogLeNet模型，并且准确度达到了90%以上，比之前所有关于CIFAR-10的实验结果都要好。</p>
<p>从实验2和实验3中，我们很明显的看到模型发生了过拟合，因此，我们可以考虑增加更多的正则化技术，下一节中，我们将对模型权重应用l2正则化以降低过拟合。</p>
<p>接下来，我们将在tiny ImageNet数据集中训练GoogLeNet模型——这里我们不再使用MinGoogLeNet模型架构，而是重新定义一个更深的GoogLeNet网络结构，类似于原始论文中架构。</p>
<h2 id="Tiny-ImageNet">Tiny ImageNet</h2>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/52970935.jpg" alt=""></p>
<center>图11.8 tiny inagenet数据集样本</center>
tiny ImageNet视觉识别挑战(如图11.8)是cs231n斯坦福大学关于卷积神经网络课程的实践一部分[39]。学生们可以对该数据集从零开始训练CNN进行分类，也可以通过微调进行迁移学习(不允许通过特征提取进行迁移学习)。
<p>tiny ImageNet数据集实际上是完整的ImageNet数据集的子集(因此不能使用特征提取)，它包含200个不同的类。对于一张图片，若果我们进行随机猜测，则准确率为1/200 = 0.5%，因此，CNN模型至少需要获得0.5%才能证明它具有区分能力。</p>
<p>每个类包含500张训练图像、50张验证图像和50张测试图像。由于我们无法访问用于评估tiny ImageNet测试图像的服务器，所以我们将使用一部分训练集来形成我们自己的测试集，以便我们可以评估算法的性能。</p>
<p>**需要注意的是：**tiny imagenet数据集中的所有图片大小为64x64x3.</p>
<p>在某些方面，经过调整图像大小的tiny ImageNet比ILSVR（图像更大）更具挑战性。在ILSVRC中，我们可以自由地调整图像大小、裁剪等操作。然而，对于tiny ImageNet，丢弃了很多图片。因此，在tiny ImageNet上获得一个合理的rank-1和rank-5的准确度并不像我们想象的那么容易。</p>
<p>在接下来的几小节中，我们将学习如何获取tiny ImageNet数据集，了解其结构，并创建用于训练、验证和测试图像的HDF5文件。</p>
<h3 id="下载Tiny-ImageNet数据集">下载Tiny ImageNet数据集</h3>
<p>该数据集可以从<a target="_blank" rel="noopener" href="https://tiny-imagenet.herokuapp.com/">官网地址</a>下载。</p>
<h3 id="Tiny-ImageNet目录结构">Tiny ImageNet目录结构</h3>
<p>解压数据压缩包之后，可以看到整个数据目录结构如下:</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">--- tiny-imagenet-200</span><br><span class="line">| |--- test</span><br><span class="line">| |--- train</span><br><span class="line">| |--- val</span><br><span class="line">| |--- wnids.txt</span><br><span class="line">| |--- words.txt</span><br></pre></td></tr></table></figure>
<p>train目录包含了200个子目录，每一个子目录名字都是由n和数字组成，对应WordNet（词典）ID。每个WordNet ID映射到一个特定的单词/对象。我们可以从words.txt文件中遍历wordNet ID获取对应的标签名称。</p>
<p>在开始训练GoogLeNet之前，我们首先需要编写一个脚本来解析这些文件并将它们转换为HDF5格式。</p>
<h3 id="Tiny-ImageNet-HDF5">Tiny ImageNet HDF5</h3>
<p>为了好维护项目，我们需要养成一个良好的习惯——一个项目一个目录，首先定义GoogLeNet项目目录结构：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">--- deepergooglenet</span><br><span class="line">| |--- config</span><br><span class="line">| | |--- __init__.py</span><br><span class="line">| | |--- tiny_imagenet_config.py</span><br><span class="line">| |--- build_tiny_imagenet.py</span><br><span class="line">| |--- rank_accuracy.py</span><br><span class="line">| |--- train.py</span><br><span class="line">| |--- output/</span><br><span class="line">| | |--- checkpoints/</span><br><span class="line">| | |--- tiny-image-net-200-mean.json</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>tiny_imagenet_config.py： 配置文件</li>
<li>build_tiny_imagenet.py：将tiny ImageNet数据转化为HDF5数据集</li>
<li>rank_accuracy.py: 计算rank-N准确度</li>
<li><a target="_blank" rel="noopener" href="http://train.py">train.py</a>：训练模型</li>
</ul>
<p>首先，我们对整个项目的配置文件进行设置，打开tiny_imagenet_config.py，并写入以下代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> path</span><br><span class="line"></span><br><span class="line"><span class="comment">#训练数据集和验证数据集路径</span></span><br><span class="line">TRAIN_IAMGES = <span class="string">&quot;../datasets/tiny-imagenet-200/train&quot;</span></span><br><span class="line">VAL_IMAGES = <span class="string">&quot;../datasets/tiny-imagenet-200/val/images&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证数据集与标签映射文件</span></span><br><span class="line">VAL_MAPPINGS = <span class="string">&quot;../datasets/tiny-imagenet-200/val/val_annotations.txt&quot;</span></span><br></pre></td></tr></table></figure>
<p>接下来，定义词典路径：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># WordNet hierarchy文件路径</span></span><br><span class="line">WORDNET_IDS = <span class="string">&#x27;../datasets/tiny-imagenet-200/wnids.txt&#x27;</span></span><br><span class="line">WORD_LABELS = <span class="string">&#x27;../datasets/tiny-imagenet-200/words.txt&#x27;</span></span><br></pre></td></tr></table></figure>
<p>由于我们无法获取tiny imagenet测试数据集的标签，因此，需要从train数据集中划分一部分当做测试集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从train数据中构造test数据</span></span><br><span class="line">NUM_CLASSES = <span class="number">200</span></span><br><span class="line">NUM_TEST_IMAGES = <span class="number">50</span> * NUM_CLASSES</span><br></pre></td></tr></table></figure>
<p>定义hdf5数据保存路径：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义输出路径</span></span><br><span class="line">TRAIN_HDF5 = <span class="string">&quot;../datasets/tiny-imagenet-200/hdf5/train.hdf5&quot;</span></span><br><span class="line">VAL_HDF5 = <span class="string">&quot;../datasets/tiny-imagenet-200/hdf5/val.hdf5&quot;</span></span><br><span class="line">TEST_HDF5 = <span class="string">&quot;../datasets/tiny-imagenet-200/hdf5/test.hdf5&quot;</span></span><br></pre></td></tr></table></figure>
<p>RGB均值文件保路径：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据均值文件</span></span><br><span class="line">DATASET_MEAN = <span class="string">&quot;output/tiny-image-net-200-mean.json&quot;</span></span><br></pre></td></tr></table></figure>
<p>模型输出和日志/图保存路径:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 输出路径和性能结果</span></span><br><span class="line">OUTPUT_PATH = <span class="string">&quot;output&quot;</span></span><br><span class="line">MODEL_PATH = path.sep.join([OUTPUT_PATH,<span class="string">&quot;checkpoints/epoch_70.hdf5&quot;</span>])</span><br><span class="line">FIG_PATH = path.sep.join([OUTPUT_PATH,<span class="string">&#x27;deepergooglenet_tinyimagenet.png&quot;])</span></span><br><span class="line"><span class="string">JSON_PATH = path.sep.join([OUTPUT_PATH,&#x27;</span>deepergooglenet_tinyimagenet.json<span class="string">&#x27;])</span></span><br></pre></td></tr></table></figure>
<p>接下来，我们将数据转化为HDF5数据集，打开build_tiny_imagenet.py，并写入以下代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 加载所需模块</span></span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> tiny_imagenet_config <span class="keyword">as</span> config</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.io <span class="keyword">import</span> hdf5datasetwriter <span class="keyword">as</span> HDFW</span><br><span class="line"><span class="keyword">from</span> imutils <span class="keyword">import</span> paths</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> progressbar</span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> os</span><br></pre></td></tr></table></figure>
<p>获取数据路径并提取对应的标签信息：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取训练数据</span></span><br><span class="line">trainPaths  = <span class="built_in">list</span>(paths.list_images(config.TRAIN_IMAGES))</span><br><span class="line"><span class="comment"># 提取对应标签</span></span><br><span class="line">trainLabels = [p.split(os.path.sep)[-<span class="number">3</span>] <span class="keyword">for</span> p <span class="keyword">in</span> trainPaths]</span><br><span class="line"><span class="comment"># one-hot 编码</span></span><br><span class="line">le = LabelEncoder()</span><br><span class="line">trainLabels = le.fit_transform(trainLabels)</span><br></pre></td></tr></table></figure>
<p>需要注意：数据目录格式需要满足以下结构：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tiny-imagenet-200/train/&#123;wordnet_id&#125;/&#123;unique_filename&#125;.JPG</span><br></pre></td></tr></table></figure>
<p>将数据划分为训练集跟测试集（由于我们没有真实的测试数据集对应的标签）：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据分割</span></span><br><span class="line">split = train_test_split(trainPaths,trainLabels,</span><br><span class="line">                        test_size = config.NUM_TEST_IMAGES,</span><br><span class="line">                        stratify = trainLabels,</span><br><span class="line">                        random_state = <span class="number">42</span>)</span><br><span class="line">(trainPaths,testPaths,trainLabels,testLabels) = split</span><br></pre></td></tr></table></figure>
<p>处理验证集数据:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 读取验证书籍，并映射对应标签</span></span><br><span class="line">M = <span class="built_in">open</span>(config.VAL_MAPPINGS).read().strip().split(<span class="string">&quot;\n&quot;</span>)</span><br><span class="line">M = [r.split(<span class="string">&quot;\t&quot;</span>)[:<span class="number">2</span>] <span class="keyword">for</span> r <span class="keyword">in</span> M]</span><br><span class="line">valPaths = [os.path.sep.join([config.VAL_PATHS,m[<span class="number">0</span>]]) <span class="keyword">for</span> m <span class="keyword">in</span> M]</span><br><span class="line">valLabels = le.transform([m[<span class="number">1</span>] <span class="keyword">for</span> m <span class="keyword">in</span> M])</span><br></pre></td></tr></table></figure>
<p>分别将训练数据集、验证数据集和测试数据集写入HDF5数据集中:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 遍历数据元祖</span></span><br><span class="line"><span class="keyword">for</span> (dType,paths,labels,outputPath) <span class="keyword">in</span> datasets:</span><br><span class="line">    <span class="comment"># 初始化HDF5写入</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[INFO] building &#123;&#125; ....&quot;</span>.<span class="built_in">format</span>(outputPath))</span><br><span class="line">    writer = HDFW.HDF5DatasetWriter((<span class="built_in">len</span>(paths),<span class="number">64</span>,<span class="number">64</span>,<span class="number">3</span>),outputPath)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化进度条</span></span><br><span class="line">    widgets = [<span class="string">&#x27;Building Dataset: &#x27;</span>,progressbar.Percentage(),<span class="string">&quot; &quot;</span>, progressbar.Bar(),<span class="string">&quot; &quot;</span>,progressbar.ETA()]</span><br><span class="line">    pbar = progressbar.ProgressBar(maxval = <span class="built_in">len</span>(paths), widgets = widgets).start()</span><br></pre></td></tr></table></figure>
<p>遍历每一张图片，并写入HDF5中：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 遍历图像路径</span></span><br><span class="line"><span class="keyword">for</span> (i,(path,label)) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(paths,labels)):</span><br><span class="line">    <span class="comment"># 从磁盘中读取数据</span></span><br><span class="line">    image = cv2.imread(path)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#计算均值</span></span><br><span class="line">    <span class="keyword">if</span> dType == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">        (b,g,r) = cv2.mean(image)[:<span class="number">3</span>]</span><br><span class="line">        R.append(r)</span><br><span class="line">        G.append(g)</span><br><span class="line">        B.append(b)</span><br><span class="line">    <span class="comment"># 将图像跟标签写入HDF5中</span></span><br><span class="line">    writer.add([image],[label])</span><br><span class="line">    pbar.update(i)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭数据库</span></span><br><span class="line">pbar.finish()</span><br><span class="line">writer.close()</span><br></pre></td></tr></table></figure>
<p>同样，如果是训练数据集中，我们进行计算RGB通道均值，并将其保存到磁盘文件中:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#保存均值文件</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[INFO] serializing means...&quot;</span>)</span><br><span class="line">D = &#123;<span class="string">&quot;R&quot;</span>:np.mean(R),<span class="string">&quot;G&quot;</span>:np.mean(G),<span class="string">&quot;B&quot;</span>:np.mean(B)&#125;</span><br><span class="line">f = <span class="built_in">open</span>(config.DATASET_MEAN,<span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">f.write(json.dumps(D))</span><br><span class="line">f.close()</span><br></pre></td></tr></table></figure>
<p>执行以下命令，以完成数据转换过程:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python build_tiny_imagenet.py</span></span><br><span class="line">[INFO] building ../datasets/tiny-imagenet-200/hdf5/train.hdf5...</span><br><span class="line">Building Dataset: 100% |####################################| Time: 0:00:36</span><br><span class="line">[INFO] building ../datasets/tiny-imagenet-200/hdf5/val.hdf5...</span><br><span class="line">Building Dataset: 100% |####################################| Time: 0:00:04</span><br><span class="line">[INFO] building ../datasets/tiny-imagenet-200/hdf5/test.hdf5...</span><br><span class="line">Building Dataset: 100% |####################################| Time: 0:00:05</span><br><span class="line">[INFO] serializing means...</span><br></pre></td></tr></table></figure>
<p>使用h5py模块对文件进行检验:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> h5py</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>filenames = [<span class="string">&quot;train.hdf5&quot;</span>, <span class="string">&quot;val.hdf5&quot;</span>, <span class="string">&quot;test.hdf5&quot;</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> filename <span class="keyword">in</span> filenames:</span><br><span class="line"><span class="meta">... </span>db = h5py.File(filename, <span class="string">&quot;r&quot;</span>)</span><br><span class="line"><span class="meta">... </span><span class="built_in">print</span>(db[<span class="string">&quot;images&quot;</span>].shape)</span><br><span class="line"><span class="meta">... </span>db.close()</span><br><span class="line">...</span><br><span class="line">(<span class="number">90000</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>)</span><br><span class="line">(<span class="number">10000</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>)</span><br><span class="line">(<span class="number">10000</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p>我们将在这些HDF5数据集上训练GoogLeNet模型。</p>
<h2 id="DeeperGoogLeNet-on-Tiny-ImageNet">DeeperGoogLeNet on Tiny ImageNet</h2>
<p>前面我们完成了对tiny imagenet的HDF5数据集形式转换，下面，我们将对其进行训练GooLeNet网络——注意，这里我们不是训练MiniGoogLeNet网络，因此我们需要重新定义inception模块（使用原始结构，即图11.1）。</p>
<p>首先，我们将重新定义inception模块，并使用新的inception模块搭建更深的GoogLeNet模型，然后在tiny imagenet数据集上训练该网络结构，最后，对模型进行评估性能。</p>
<h3 id="Implementing-DeeperGoogLeNet">Implementing DeeperGoogLeNet</h3>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/37327889.jpg" alt=""></p>
<center>图11.9 GoogLeNet结构图</center>
我们将按图11.9显示的结构实现GoogLeNet网络，与原始的论文中的GoogLeNet网络结构有两个主要的区别：
<ul>
<li>
<p>在第一个CONV层中，我们不使用7x7个且步长为2x2的filter，而是使用5x5且步长为1x1的filter。因为tiny imagenet图像数据的大小为64x64x3，从而我们定义的GoogLeNet网络结构只接受大小为64x64x3的输入图像，而原论文中的GoogLeNet接受的是224x224x3的输入图像，如果我们使用7x7个且步长为2x2的filter，则我们将过快地减少输入尺寸。</p>
</li>
<li>
<p>稍微地简化下GoogLeNet，即少了两个inception模块——在Szegedy的原始论文中，在avergae pooling操作之前增加了两个inception模块。</p>
</li>
</ul>
<p>接下来，实现GoogLeNet模型，首先，在pyimagesearch项目中nn.conv子模块中，新建一个名为deeergooglenet.py文件，如下目录结构：</p>
<figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">--- pyimagesearch</span><br><span class="line">| |--- __init__.py</span><br><span class="line">| |--- callbacks</span><br><span class="line">| |--- io</span><br><span class="line">| |--- nn</span><br><span class="line">| | |--- __init__.py</span><br><span class="line">| | |--- conv</span><br><span class="line">| | | |--- __init__.py</span><br><span class="line">| | | |--- alexnet.py</span><br><span class="line">| | | |--- deepergooglenet.py</span><br><span class="line">| | | |--- lenet.py</span><br><span class="line">| | | |--- minigooglenet.py</span><br><span class="line">| | | |--- minivggnet.py</span><br><span class="line">| | | |--- fcheadnet.py</span><br><span class="line">| | | |--- shallownet.py</span><br><span class="line">| |--- preprocessing</span><br><span class="line">| |--- utils</span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="http://xn--deeergooglenet-9h01a920b.py">打开deeergooglenet.py</a>，并写入以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 加载所需模块</span></span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> AveragePooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Activation</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dropout</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Flatten</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Input</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> concatenate</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br></pre></td></tr></table></figure>
<p>接下来，搭建整个网络的主体架构，首先，我们定义一个conv_module函数，该函数负责接收输入层，执行CONV =&gt; BN =&gt; RELU，然后返回输出。通常，我倾向于将BN放在RELU之后，但是由于我们正在复制Szegedy等工作，所以把BN放在激活层之前，代码如下:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DeeperGoogLeNet</span>:</span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">conv_module</span>(<span class="params">x,K,kX,kY,stride,chanDim,</span></span><br><span class="line"><span class="params">                    padding=<span class="string">&#x27;same&#x27;</span>,reg=<span class="number">0.0005</span>,name=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="comment"># 初始化名称</span></span><br><span class="line">        (convName,bnName,actName) = (<span class="literal">None</span>,<span class="literal">None</span>,<span class="literal">None</span>)</span><br><span class="line">        <span class="keyword">if</span> name <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            convName = name + <span class="string">&quot;_conv&quot;</span></span><br><span class="line">            bnName = name +<span class="string">&quot;_bn&quot;</span></span><br><span class="line">            actName = name +<span class="string">&quot;_act&quot;</span></span><br><span class="line">        <span class="comment"># CONV=&gt;BN=&gt;RELU</span></span><br><span class="line">        x = Conv2D(K,(kX,kY),strides = stride,padding=padding,</span><br><span class="line">                   kernel_regularizer = l2(reg),name = convName)(x)</span><br><span class="line">        x = BatchNormalization(axis = chanDim,name= bnName)(x)</span><br><span class="line">        x = Activation(<span class="string">&#x27;relu&#x27;</span>,name = actName)(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>x: 网络层的输入。</li>
<li>K: 卷积层的filters个数。</li>
<li>kX和kY: filter的大小</li>
<li>stride: 步长，通常我们使用1x1，若果需要降低维度，可以使用更大的步长。</li>
<li>chanDim: 通道维度</li>
<li>padding: 填充方式</li>
<li>reg: L2正则项系数。</li>
<li>name： 网络层名称</li>
</ul>
<p>conv_module结构如下：</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/2420090.jpg" alt=""></p>
<center>图11.10 conv_module</center>
接下来，定义inception_module，按照图11.1进行设计:
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">inception_module</span>(<span class="params">x,num1x1,num3x3Reduce,num3x3,</span></span><br><span class="line"><span class="params">                     num5x5Reduce,num5x5,num1x1Proj,chanDim,stage,reg=<span class="number">0.0005</span></span>):</span><br><span class="line">    <span class="comment"># 定义inception模块中的第一个分支，即1x1卷积</span></span><br><span class="line">    first = DeeperGoogLeNet.conv_module(x,num1x1,<span class="number">1</span>,<span class="number">1</span>,</span><br><span class="line">                                        (<span class="number">1</span>,<span class="number">1</span>),chanDim,reg = reg,name = stage+<span class="string">&quot;_first&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>num1x1：第一个分支中1x1的filter的个数</li>
<li>num3x3Reduce：第二个分支中1x1的filter的个数，这里变量名称主要是表明下一层是3x3的卷积层</li>
<li>num3x3：第二个分支中，3x3的filter的个数</li>
<li>num5x5Reduce：第三个分支中，1x1的filter的个数</li>
<li>num5x5：第三个分支中，5x5的filter的个数</li>
<li>num1x1Proj：第四个分支中，1x1的filter的个数</li>
<li>chanDim：通道维度</li>
<li>stage：第几阶段</li>
<li>reg：l2正则系数，默认为0.0005</li>
</ul>
<p>Inception模块对输入做了四个分支，分别用不同尺寸的filter进行卷积或者池化，最后再在特征维度上拼接到一起.</p>
<p>第一个分支仅仅执行一系列的1x1大小的卷积——主要学习局部特征。</p>
<p>第二个分支首先通过1x1的卷积来实现降维，然后通过3x3的卷积进行扩展——对应num3x3Reduce</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义Inception模块的第二分支</span></span><br><span class="line"><span class="comment"># 主要由1x1和3x3卷积组成</span></span><br><span class="line">second= DeeperGoogLeNet.conv_module(x,num3x3Reduce,<span class="number">1</span>,<span class="number">1</span>,</span><br><span class="line">                                    (<span class="number">1</span>,<span class="number">1</span>),chanDim,reg = reg,name = stage+<span class="string">&quot;_second1&quot;</span>)</span><br><span class="line">second = DeeperGoogLeNet.conv_module(second,num3x3,<span class="number">3</span>,<span class="number">3</span>,(<span class="number">1</span>,<span class="number">1</span>),chanDim,reg = reg,name = stage+<span class="string">&quot;_second2&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>第三个分支与第二个分支类似，只是将3x3的卷积换成5x5的卷积:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义Inception模块的第三分支</span></span><br><span class="line"><span class="comment">#主要是由5x5和1x1组成</span></span><br><span class="line">third = DeeperGoogLeNet.conv_module(x,num5x5Reduce,<span class="number">1</span>,<span class="number">1</span>,</span><br><span class="line">                                    (<span class="number">1</span>,<span class="number">1</span>),chanDim,reg=reg,name=stage+<span class="string">&#x27;_third1&#x27;</span>)</span><br><span class="line">third = DeeperGoogLeNet.conv_module(third,num5x5,<span class="number">5</span>,<span class="number">5</span>,(<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">                                    chanDim,reg=reg,name=stage+<span class="string">&#x27;_third2&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>Inception模块的第四个分支，先进行pooling操作，然后进行1x1的卷积:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义Inception模块的第四分支</span></span><br><span class="line"><span class="comment">#主要由1x1卷积和maxPooling组成</span></span><br><span class="line">fourth = MaxPooling2D((<span class="number">3</span>,<span class="number">3</span>),strides=(<span class="number">1</span>,<span class="number">1</span>),</span><br><span class="line">                      padding=<span class="string">&#x27;same&#x27;</span>,name=stage+<span class="string">&#x27;_pool&#x27;</span>)(x)</span><br><span class="line">fourth = DeeperGoogLeNet.conv_module(fourth,num1x1Proj,</span><br><span class="line">                                     <span class="number">1</span>,<span class="number">1</span>,(<span class="number">1</span>,<span class="number">1</span>),chanDim,reg=reg,name=stage+<span class="string">&#x27;fourth&#x27;</span>)</span><br></pre></td></tr></table></figure>
<p>作者认为max pooling也有提取特征的作用，所以这一分支使用了max pooling层。2014年，大多数(如果不是全部的话)在ImageNet数据集中获得高性能的卷积神经网络都采用了max pooling。因此，人们认为CNN应该应用max pooling。虽然GoogLeNet在Inception模块之外也应用了max pooling，但是Szegedy等人将max pooling应用到inception模块的一个分支中。</p>
<p>接下来，我们将各个分支的输出进行拼接，整合成一个inception模块的输出:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将四个分支拼接在一起</span></span><br><span class="line">x = concatenate([first,second,third,fourth],axis=chanDim, name=stage+<span class="string">&#x27;_mixed&#x27;</span>)</span><br><span class="line"><span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>
<p>我们将参数设置为：:</p>
<ul>
<li>num1x1=64</li>
<li>num3x3Reduce=96</li>
<li>num3x3=128</li>
<li>num5x5Reduce=16</li>
<li>num5x5=32</li>
<li>num1x1Proj=32</li>
</ul>
<p>并对inception模块的详细结构进行可视化，如11.11所示：</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/78026393.jpg" alt=""></p>
<center>图11.11 完整的inception 模块</center>
通过三种不同大小的filters，即1x1、3x3和5x5，inception模块可以同时学习到通用(5x5和3x3)的特征和局部(1x1)的特征。在训练的优化过程，模型会自动对分支和层进行优化——本质上可以理解为一个“通用的”模块，在给定迭代次数情况下，它将学习到最佳的特性集合(小卷积学到的局部特征，大卷积学习到的抽象特征)。图11.11显示Inception模块的输出是256——这是每个分支输出拼接而成，64+128+32+32 = 256。
<p>定义好了inception_module，接下来构建完整的DeeperGoogLeNet网络结构:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@staticmethod</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">build</span>(<span class="params">width,height,depth,classes,reg = <span class="number">0.0005</span></span>):</span><br><span class="line">    <span class="comment"># 初始化shape</span></span><br><span class="line">    inputShape = (height,width,depth)</span><br><span class="line">    chanDim = -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">#判断keras后端</span></span><br><span class="line">    <span class="keyword">if</span> K.iamge_data_format() == <span class="string">&quot;channels_first&quot;</span>:</span><br><span class="line">        inputShape = (depth,height,width)</span><br><span class="line">        chanDim = <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>width：输入图像的宽度</li>
<li>height：输入图像的高度</li>
<li>depth：输入图像的深度</li>
<li>classes：数据的类别个数</li>
<li>reg：l2正则系数</li>
</ul>
<p>根据上面的图11.9，第一个block将执行CONV =&gt;POOL =&gt; (CONV * 2) =&gt;POOL的序列:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义模型的输入层，卷积层，POOL层等，</span></span><br><span class="line"><span class="comment"># 主要是Inception模块之前</span></span><br><span class="line"><span class="comment"># CONV =&gt; POOL =&gt;(CONV * 2)=&gt;POOL</span></span><br><span class="line">inputs = Input(shape = inputShape)</span><br><span class="line">x = DeeperGoogLeNet.conv_module(inputs,<span class="number">64</span>,<span class="number">5</span>,<span class="number">5</span>,(<span class="number">1</span>,<span class="number">1</span>),chanDim,reg=reg,name=<span class="string">&#x27;block1&#x27;</span>)</span><br><span class="line">x = MaxPooling2D((<span class="number">3</span>,<span class="number">3</span>),strides=(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">&#x27;same&#x27;</span>,name=<span class="string">&#x27;pool1&#x27;</span>)(x)</span><br><span class="line">x = DeeperGoogLeNet.conv_module(x,<span class="number">64</span>,<span class="number">1</span>,<span class="number">1</span>,(<span class="number">1</span>,<span class="number">1</span>),chanDim,reg=reg,name=<span class="string">&#x27;block2&#x27;</span>)</span><br><span class="line">x = DeeperGoogLeNet.conv_module(x,<span class="number">192</span>,<span class="number">3</span>,<span class="number">3</span>,(<span class="number">1</span>,<span class="number">1</span>),chanDim,reg=reg,name=<span class="string">&#x27;block3&#x27;</span>)</span><br><span class="line">x = MaxPooling2D((<span class="number">3</span>,<span class="number">3</span>),strides=(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">&#x27;same&#x27;</span>,name=<span class="string">&#x27;pool2&#x27;</span>)(x)</span><br></pre></td></tr></table></figure>
<p>接下来，我们加入两个inception模块(3a和3b)，然后，紧接着max pooling层，即inception =&gt; inception =&gt; pool序列:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在POOL层之后，接着两个Inception层</span></span><br><span class="line">x = DeeperGoogLeNet.inception_module(x,<span class="number">64</span>,<span class="number">96</span>,<span class="number">128</span>,<span class="number">16</span>,,<span class="number">32</span>,<span class="number">32</span>,chanDim,<span class="string">&#x27;3a&#x27;</span>,reg=reg)</span><br><span class="line">x = DeeperGoogLeNet.inception_module(x,<span class="number">128</span>,<span class="number">128</span>,<span class="number">192</span>,<span class="number">32</span>,<span class="number">96</span>,<span class="number">64</span>,chanDim,<span class="string">&#x27;3b&#x27;</span>,reg=reg)</span><br><span class="line">x = MaxPooling2D((<span class="number">3</span>,<span class="number">3</span>),strides=(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">&#x27;same&#x27;</span>,</span><br><span class="line">                 name=<span class="string">&#x27;pool3&#x27;</span>)(x)</span><br></pre></td></tr></table></figure>
<p>整个网络中的所有参数值都是直接取自于Szegedy等原论文——作者在多次实验调参之后得到的。仔细观察，我们会发现inception模块的通用模式:</p>
<ul>
<li>Inception模块的第一个分支中1x1的filters的个数小于或等于第二个分支和第三个分支中1x1的filters的个数。</li>
<li>第二个分支和第三个分支中，1x1的filters的个数总是小于3x3的filters的个数或者5x5的filters的个数。</li>
<li>第二个分支的filters总是大于第三个分支的filters，既可以减小模型的大小，又可以提高训练和预测速度。</li>
<li>第四个分支的1x1的filters的个数总是小于第一个分支的1x1的filters的个数。</li>
<li>无论哪个分支，随着网络深度越深，filters的个数越多（或者保持不变）。</li>
</ul>
<p>总的来说，我们仍然遵循与之前的CNNs相同的经验法则——网络越深，特征图像越小，而filters的个数越多。</p>
<p>接下来，我们将5个Inception模块(4a-4e)叠加在一起，然后紧接着一个max pooling层，这样网络变得越深，将学习到更加丰富的特征:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在POOLing层之后，紧接着5个Inception模块</span></span><br><span class="line">x = DeeperGoogLeNet.inception_module(x,<span class="number">192</span>,<span class="number">96</span>,<span class="number">208</span>,<span class="number">16</span>,<span class="number">48</span>,<span class="number">64</span>,chanDim,<span class="string">&#x27;4a&#x27;</span>,reg=reg)</span><br><span class="line">x = DeeperGoogLeNet.inception_module(x,<span class="number">160</span>,<span class="number">112</span>,<span class="number">224</span>,<span class="number">24</span>,<span class="number">64</span>,<span class="number">64</span>,chanDim,<span class="string">&#x27;4b&#x27;</span>,reg=reg)</span><br><span class="line">x = DeeperGoogLeNet.inception_module(x,<span class="number">128</span>,<span class="number">128</span>,<span class="number">256</span>,<span class="number">24</span>,<span class="number">84</span>,<span class="number">64</span>,chanDim,<span class="string">&#x27;4c&#x27;</span>,reg=reg)</span><br><span class="line">x = DeeperGoogLeNet.inception_module(x,<span class="number">112</span>,<span class="number">144</span>,<span class="number">288</span>,<span class="number">32</span>,<span class="number">64</span>,<span class="number">64</span>,chanDim,<span class="string">&#x27;4d&#x27;</span>,reg = reg)</span><br><span class="line">x = DeeperGoogLeNet.inception_module(x,<span class="number">256</span>,<span class="number">160</span>,<span class="number">320</span>,<span class="number">32</span>,<span class="number">128</span>,<span class="number">128</span>,chanDim,<span class="string">&#x27;4e&#x27;</span>,reg=reg)</span><br><span class="line">x = MaxPooling2D((<span class="number">3</span>,<span class="number">3</span>),strides=(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">&#x27;same&#x27;</span>,name=<span class="string">&#x27;pool4&#x27;</span>)(x)</span><br></pre></td></tr></table></figure>
<p>最后一个max pooling层的输出为4x4xclases。以往，到这一步，我们会使用全连接层进行向量化，而由于全连接层参数巨大且需要消耗巨大的内存，为了同样得到向量化的结果，我们使用4x4的average pooling将特征图像大小调整为1x1xclasses:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义avg Pool层，dropout层</span></span><br><span class="line">x = AveragePooling2D((<span class="number">4</span>,<span class="number">4</span>),name=<span class="string">&#x27;pool5&#x27;</span>)(x)</span><br><span class="line">x = Dropout(<span class="number">0.4</span>,name=<span class="string">&#x27;do&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># softmax分类器</span></span><br><span class="line">x = Flatten(name=<span class="string">&#x27;flatten&#x27;</span>)(x)</span><br><span class="line">x = Dense(classes,kernel_regularizer=l2(reg),</span><br><span class="line">          name=<span class="string">&#x27;labels&#x27;</span>)(x)</span><br><span class="line">x = Activation(<span class="string">&#x27;softmax&#x27;</span>,name=<span class="string">&#x27;softmax&#x27;</span>)(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型</span></span><br><span class="line">model = Model(inputs,x,name=<span class="string">&#x27;googlenet&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> model</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>注</strong>: 一般，对于dropout层的概率我们通常设置为50%，这里概率值为40%，主要是原始论文中也为40%。</p>
<h3 id="training-DeeperGoogLeNet-on-Tiny-ImageNet">training DeeperGoogLeNet on Tiny ImageNet</h3>
<p>完成了整个GoogLeNet模型结构搭建之后，接下来，我们将在tiny imagenet数据集上进行训练，并对性能进行评估。</p>
<p>新建一个名为train.py文件，并写入以下代码:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 加载所需模块</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.use(<span class="string">&quot;Agg&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> tiny_imagenet_config <span class="keyword">as</span> config</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.preprocessing <span class="keyword">import</span> imagetoarraypreprocessor <span class="keyword">as</span> ITA</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.preprocessing <span class="keyword">import</span> simplespreprocessor <span class="keyword">as</span> SP</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.preprocessing <span class="keyword">import</span> meanpreprocessor <span class="keyword">as</span> MP</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.callbacks <span class="keyword">import</span> epochcheckpoint <span class="keyword">as</span> ECP</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.callbacks <span class="keyword">import</span> trainingmonitor <span class="keyword">as</span> TM</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.io <span class="keyword">import</span> hdf5datasetgenerator <span class="keyword">as</span> HDFG</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.nn.conv <span class="keyword">import</span> deepergooglenet <span class="keyword">as</span> DGN</span><br><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"><span class="keyword">from</span> keras.optimizers <span class="keyword">import</span> Adam</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="keyword">import</span> keras.backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">import</span> json</span><br></pre></td></tr></table></figure>
<p>解析命令行参数:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 解析命令行参数</span></span><br><span class="line">ap = argparse.ArgumentParser()</span><br><span class="line">ap.add_argument(<span class="string">&#x27;-c&#x27;</span>,<span class="string">&#x27;--checkpoints&#x27;</span>,required=<span class="literal">True</span>,</span><br><span class="line">                <span class="built_in">help</span>=<span class="string">&#x27;path to output checkpoint directory&#x27;</span>)</span><br><span class="line">ap.add_argument(<span class="string">&#x27;-m&#x27;</span>,<span class="string">&#x27;--model&#x27;</span>,<span class="built_in">type</span>=<span class="built_in">str</span>,</span><br><span class="line">                <span class="built_in">help</span>=<span class="string">&#x27;path to *specific* model checkpoint to load&#x27;</span>)</span><br><span class="line">ap.add_argument(<span class="string">&#x27;-s&#x27;</span>,<span class="string">&#x27;--start_epoch&#x27;</span>,<span class="built_in">type</span> = <span class="built_in">int</span>,default=<span class="number">0</span>,</span><br><span class="line">                <span class="built_in">help</span>=<span class="string">&#x27;epoch to restart training at&#x27;</span>)</span><br><span class="line">args=<span class="built_in">vars</span>(ap.parse_args())</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>其中：</p>
<ul>
<li>checkpoints：监控模型训练过程，我们经常在训练模型时，希望保存某一时刻训练的模型，以方便下次迭代接着训练，这时候我们就需要使用到checkpoints</li>
<li>model： 模型保存路径</li>
<li>start_epoch：下次训练开始的epoch</li>
</ul>
<p>为了获得良好的准确率以及降低过拟合风险，我们对训练数据进行数据增强处理:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 数据增强</span></span><br><span class="line">aug = ImageDataGenerator(rotation_range=<span class="number">18</span>,zoom_range=<span class="number">0.15</span>,</span><br><span class="line">                         width_shift_range=<span class="number">0.2</span>,height_shift_range=<span class="number">0.2</span>,shear_range=<span class="number">0.15</span>,</span><br><span class="line">                         horizontal_flip=<span class="literal">True</span>,fill_mode=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 RGB均值文件</span></span><br><span class="line">means = json.loads(<span class="built_in">open</span>(config.DATASET_MEAN).read())</span><br></pre></td></tr></table></figure>
<p>初始化图像预处理以及训练数据集和验证数据集：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 初始化预处理</span></span><br><span class="line">sp = SP.SimplePreprocessor(<span class="number">64</span>,<span class="number">64</span>) <span class="comment"># 调整图像大小</span></span><br><span class="line">mp = MP.MeanPreprocessor(means[<span class="string">&#x27;R&#x27;</span>],means[<span class="string">&#x27;G&#x27;</span>],means[<span class="string">&#x27;B&#x27;</span>]) <span class="comment"># 零均值化</span></span><br><span class="line">iap = ITA.ImageToArrayPreprocessor() <span class="comment"># 转化为array数组</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练数据集和验证书籍生成器</span></span><br><span class="line">trainGen = HDFG.HDF5DatasetGenerator(config.TRAIN_HDF5,<span class="number">64</span>,aug = aug,</span><br><span class="line">                                preprocessors=[sp,mp,iap],classes=config.NUM_CLASSES)</span><br><span class="line">valGen = HDFG.HDF5DatasetGenerator(config.VAL_HDF5,<span class="number">64</span>,</span><br><span class="line">                              preprocessors=[sp,mp.iap],classes=config.NUM_CLASSES)</span><br></pre></td></tr></table></figure>
<p><strong>需要注意的是</strong>：上面数据生成过程中，我们将原始图像大小调整为64x64x3。</p>
<p>接下来，我们开始训练DeeperGoogLeNet网络:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 如果不存在checkpoints 模型，则直接初始化模型</span></span><br><span class="line"><span class="keyword">if</span> args[<span class="string">&#x27;model&#x27;</span>] <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[INFO] compiling model....&quot;</span>)</span><br><span class="line">    model = DGN.DeeperGoogLeNet.build(width=<span class="number">64</span>,height=<span class="number">64</span>,depth=<span class="number">3</span>,classes=config.NUM_CLASSES,reg=<span class="number">0.0002</span>)</span><br><span class="line">    <span class="comment"># 优化器</span></span><br><span class="line">    opt=Adam(<span class="number">1e-3</span>)</span><br><span class="line">    <span class="comment"># 编译模型</span></span><br><span class="line">    model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,optimizer=opt,</span><br><span class="line">                  metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure>
<p>若未指定需要加载的checkpoints模型，我们从头开始训练GoogLeNet，否则，我们需要从磁盘中加载checkpoints模型，然后接着训练:</p>
<p><strong>注</strong>： 后面的实验中将看到为什么我们将正则化系数设置为0.0002</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 否则，直接从磁盘中加载checkpoint模型，接着训练</span></span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[INFO] loading &#123;&#125;...&quot;</span>.<span class="built_in">format</span>(args[<span class="string">&#x27;model&#x27;</span>]))</span><br><span class="line">    model = load_model(args[<span class="string">&#x27;model&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新学习率</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[INFO] old learning rate:&#123;&#125;&quot;</span>.<span class="built_in">format</span>(K.get_value(model.optimizer.lr)))</span><br><span class="line">    K.set_value(model.optimizer.lr,<span class="number">1e-5</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;[INFO] new learning rate: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(K.get_value(model.optimizer.lr)))</span><br></pre></td></tr></table></figure>
<p>初始化回调函数：EpochCheckpoint主要是默认每5次epoch将模型保存到磁盘中，TrainingMonitor主要是用于监控训练过程:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 回调函数</span></span><br><span class="line">callbacks = [</span><br><span class="line">        ECP.EpochCheckpoint(args[<span class="string">&#x27;checkpoints&#x27;</span>],every=<span class="number">5</span>,startAt = args[<span class="string">&#x27;start_epoch&#x27;</span>]),</span><br><span class="line">        TM.TrainingMonitor(config.FIG_PATH,joinPath=config.JSON_PATH,startAt = args[<span class="string">&#x27;start_epoch&#x27;</span>])</span><br><span class="line">        ]</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>训练网络：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#训练网络</span></span><br><span class="line">model.fit_generator(</span><br><span class="line">        trainGen.generator(),</span><br><span class="line">        steps_per_epoch = trainGen.numImages // <span class="number">64</span>,</span><br><span class="line">        validation_data = valGen.generator(),</span><br><span class="line">        validation_steps = valGen.numImages // <span class="number">64</span>,</span><br><span class="line">        epochs = <span class="number">10</span>,</span><br><span class="line">        max_queue_size = <span class="number">64</span> * <span class="number">2</span>,</span><br><span class="line">        callbacks = callbacks,</span><br><span class="line">        verbose = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭数据库</span></span><br><span class="line">trainGen.close()</span><br><span class="line">valGen.close()</span><br></pre></td></tr></table></figure>
<p>我们将根据网络训练过程中的loss/accuracy变化曲线来决定epochs个数，以及将根据模型的性能是否更新学习率或者增加early stopping技术。</p>
<h3 id="性能评估">性能评估</h3>
<p>新建一个名为rank_accuracy.py脚本，并写入以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># 加载所需模块</span></span><br><span class="line"><span class="keyword">from</span> config <span class="keyword">import</span> tiny_imagenet_config <span class="keyword">as</span> config</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.preprocessing <span class="keyword">import</span> imagetoarraypreprocessor <span class="keyword">as</span> ITA</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.preprocessing <span class="keyword">import</span> simplespreprocessor <span class="keyword">as</span> SP</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.preprocessing <span class="keyword">import</span> meanpreprocessor <span class="keyword">as</span> MP</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.io <span class="keyword">import</span> hdf5datasetgenerator <span class="keyword">as</span> HDFG</span><br><span class="line"><span class="keyword">from</span> pyimagesearch.utils.ranked <span class="keyword">import</span> rank5_accuracy</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"><span class="keyword">import</span> json</span><br></pre></td></tr></table></figure>
<p>同train数据集预处理过程一样：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载RGB均值文件</span></span><br><span class="line">means = json.loads(<span class="built_in">open</span>(config.DATASET_MEAN).read())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化预处理</span></span><br><span class="line">sp = SP.SimplePreprocessor(<span class="number">64</span>,<span class="number">64</span>)</span><br><span class="line">mp = MP.MeanPreprocessor(means[<span class="string">&#x27;R&#x27;</span>],means[<span class="string">&#x27;G&#x27;</span>],means[<span class="string">&#x27;B&#x27;</span>])</span><br><span class="line">iap = ITA.ImageToArrayPreprocessor()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化测试数据集生成器</span></span><br><span class="line">testGen = HDFG.HDF5DatasetGenerator(config.TEST_HDF5,<span class="number">64</span>,preprocessors = [sp,mp,iap],classes=config.NUM_CLASSES)</span><br></pre></td></tr></table></figure>
<p>加载训练好的模型对test数据集进行预测:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载预训练好的模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[INFO] loading model ...&quot;</span>)</span><br><span class="line">model = load_model(config.MODEL_PATH)</span><br></pre></td></tr></table></figure>
<p>之前在训练过程中，我们设置了checkpoints，因此，我们可以加载checkpoints模型对test数据集进行预测，从而可以观察随着epochs的增加，准确度是如何变化的。</p>
<p>计算rank-1和rank-5准确度:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对测试集进行预测</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[INFO] predicting on test data...&quot;</span>)</span><br><span class="line">predictions = model.predict_generator(testGen.generator(),steps = testGen.numImages // <span class="number">64</span>,max_queue_size = <span class="number">64</span> * <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算rank-1和rank5准确度</span></span><br><span class="line">(rank1,rank5) = rank5_accuracy(predictions,testGen.db[<span class="string">&#x27;labels&#x27;</span>])</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[INFO] rank-1: &#123;:.2f&#125;%&quot;</span>.<span class="built_in">format</span>(rank1 * <span class="number">100</span>))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;[INFO] rank-5: &#123;:.2f&#125;%&quot;</span>.foramt(rank5 * <span class="number">100</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#关闭数据库</span></span><br><span class="line">testGen.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="DeeperGoogLeNet-Experiments">DeeperGoogLeNet Experiments</h3>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/83914900.jpg" alt=""></p>
<center>表11.1 不同epoch对应不同的学习率</center>
下面，我们将在tiny imagenet数据集上进行四个独立的实验——每次训练不同参数的DeeperGoogLeNet。在每次实验后，我们对实验结果进行评估，然后根据结果正确地更新超参数或者网络架构以提高准确度。
<p><strong>说明</strong>：整个实验调参过程对于新手而言很有帮助，想提高深度学习算法的效果，需要多次进行实验。另外，在训练网络过程中，应该关注哪些参数，以及如何去优化参数。</p>
<p>最后，<strong>需要注意的是</strong>，有些实验需要对deepergooglenet.py和train.py代码进行修改。</p>
<h4 id="DeeperGoogLeNet-实验1">DeeperGoogLeNet: 实验1</h4>
<p>假我们第一次在tiny ImageNet数据集上训练一个网络，在给定网络框架时，我们该使用多深的网络结构？我们知道原始的GoogLeNet在是完整的imagnet数据集上训练，考虑到tiny imagenet数据只是imagenet数据集的一部分，一开始我们可能会觉得并不需要训练一个像原GoogLeNet那么深的网络，因此，我们删除DeeperGoogLeNet网络中的4a-4e模块（inception模块），从而得到一个更浅的网络架构。</p>
<p>在第七章中，我们提到在第一次实验中，我们应该首先尝试SGD训练网络，如果有需要，我们可以选择更高级的优化算法。因此，首先，我们使用初始学习率为1e-2，动量为0.9的SGD算法进行训练网络。</p>
<p><strong>需要注意</strong>：以下实验需要根据条件对代码进行修改。</p>
<p>运行以下命令进行训练:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python train.py --checkpoints output/checkpoints</span></span><br></pre></td></tr></table></figure>
<p>接下来，我们将根据表11.1所示的学习率进行实验——意味着在25次epoch后，停止训练，然后降低了学习率为1e-3，并将epochs重新设置为10，运行以下命令接着训练：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python train.py --checkpoints output/checkpoints \</span></span><br><span class="line"><span class="language-bash">--model output/checkpoints/epoch_25.hdf5 --start_epoch 25</span></span><br></pre></td></tr></table></figure>
<p>在第35次epoch，停止训练，并降低学习率为1e-4，epochs为10，然后运行以下命令接着训练：</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python train.py --checkpoints output/checkpoints \</span></span><br><span class="line"><span class="language-bash">--model output/checkpoints/epoch_35.hdf5 --start_epoch 35</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>三次实验结果如图11.12所示：</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/26852416.jpg" alt=""></p>
<center>图11.12 三次实验结果</center>
从图中可知大约在第15个epoch之后，train_loss和val_loss出现了差距。到第25次epoch时，差距变得更明显了。所以，我们把学习率降低了一个数量级，带来的效果是提高了accuracy和减小了loss。但是我们仔细观察loss和accuracy曲线变化，在这之后，模型基本停滞了，loss和Accuracy曲线基本上没有什么变化，甚至在第35次epoch，我们再次降低学习率为1e-4，也没有带来明显的效果。
<p>在第40次epoch结束时，模型完全停滞，loss和Accuracy曲线完全没有变化。如果我们不再尝试更低的学习率话，那么我们可以在45次epoch就停止训练。在本实验中，从图可知，在第65次epoch之后(loss和Accuracy没有发生变化)，我们停止了训练网络，并且当前模型在验证集上的rank-1的准确率为52.25%。在降低学习率情况下，模型的性能趋向于稳定，如果我们想要提高模型的准确率，那么我们还需要尝试其他方法，比如我们在第7章中提高的更高级的优化算法。</p>
<h4 id="DeeperGoogLeNet-实验2">DeeperGoogLeNet: 实验2</h4>
<p>在第二个实验中，我们将使用更高级的优化算法——Adam。对于tiny imagenet数据集，一开始我们会认为模型深度已经够深了，没必要再加深网络（一方面我们也不知道应该对模型加多深，另一方面深度学习网络本身训练相当耗时），因此我们从优化器方面入手。Adam算法的默认初始学习率1e-3，我们将按照表11.2来调整学习率。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/26144600.jpg" alt=""></p>
<center>表11.2 左：实验2， 右：实验3</center>
整个训练过程如图11.12(右上角)所示，看起来似乎与实验1很相似。一开始，val_loss迅速下降，但是，到第10次epoch之后，train_loss明显要小于val_loss，并且差距有可能进一步拉大，因此，我们在第20次epoch降低了学习率(否则有可能会发生过拟合)。在第20次epoch降低学习率之后，甚至在第30次epoch第二次降低学习率，val_acc似乎没有提高，模型仍然是停滞状态。但是，在第40次epoch结束时，我们仔细对比第一个实验，发现val_loss比第一个实验低，准确率更高。
<p>通过将SGD替换为Adam，模型在验证集上的rank-1准确度提高到了54.20%，增加了近2%。但是，在第一次降低学习率之后，仍然存在模型停滞问题。</p>
<h4 id="DeeperGoogLeNet-Experiment-3">DeeperGoogLeNet: Experiment #3</h4>
<p>在实验2中，我们使用了更高级的优化算法，但是仍然存在模型停滞问题，调整学习率，val_acc却没有发生变化，或许是由于网络不够深，无法捕捉到tiny imagenet数据集中更有区分能力的特征。因此，我们决定加深模型深度，新增inception模块(4a-4e)，使得GoogLeNet网络变得更深，能够学习到更深、更具有区分的特征。</p>
<p>在实验2的基础上，我们在实验3中，Adam使用默认的学习率1e-3，l2正则系数调整为0.0002，学习率更新方式按照表11.2（右）进行。</p>
<p>整个实验结果如11.12（下）所示，从图中可以发现，模型即没有发生停滞也没有发生严重的过拟合问题，并且模型在验证集上的rank-1准确度为55.77%，比实验2提高了1.5%左右。</p>
<p>接下来，我们加载训练好的模型，并对测试集进行预测:</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">python rank_accuracy.py</span></span><br><span class="line">[INFO] loading model...</span><br><span class="line">[INFO] predicting on test data...</span><br><span class="line">[INFO] rank-1: 54.38%</span><br><span class="line">[INFO] rank-5: 78.96%</span><br></pre></td></tr></table></figure>
<p>从结果中，可知rank-1准确度为54.38%，对应错误率为1-0.5438 =0.4562，由图11.13所示，该结果可以在tiny imagenet排行榜上获得第7名。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/19130016.jpg" alt=""></p>
<center>图11.13 tiny imagenet排行榜</center>
对于有兴趣进一步提高DeeperGoogLeNet准确度的读者，可以尝试进行以下实验:
<ul>
<li>将conv_module更改为使用CONV =&gt; RELU =&gt; BN，而不是使用原始的CONV =&gt; BN=&gt; RELU。</li>
<li>尝试使用ELUs代替ReLUs，可能会提升0.5~11% 左右。</li>
</ul>
<h2 id="总结">总结</h2>
<p>在本章中，首选，我们回顾了Szgedy等的工作，介绍了著名的Inception模块。Inception模块是一个微型体系结构的例子，目前state-of-the-art的卷积神经网络倾向于使用某种形式的微结构。</p>
<p>然后，我们应用Inception模块创建了两个不同结构的GoogLeNet网络：</p>
<ul>
<li>一个在cifar-10数据上进行训练——MiniGoogLeNet</li>
<li>一个在tiny imagenet数据上训练——DeeperGoogLeNet</li>
</ul>
<p>在CIFAR-10数据上，准确率为90.81%，比之前任何实验的结果都好。在tiny ImageNet数据集上，rank-1准确率为54.38%和rank-5准确率为78.96%，在tiny ImageNet排行榜上获得第7名（前几名都是使用在ImageNet数据集上预先训练过的网络进行微调得到)。</p>
<p>本文完整代码下载地址: <a target="_blank" rel="noopener" href="https://github.com/lonePatient/Deep_Learning_For_Computer_Vision_With_Python">github</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Weitang Liu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://lonepatient.top/2018/06/19/Deep_Learning_For_Computer_Vision_With_Python_PB_11.html">http://lonepatient.top/2018/06/19/Deep_Learning_For_Computer_Vision_With_Python_PB_11.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://lonepatient.top" target="_blank">闲记算法</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></div><div class="post_share"><div class="social-share" data-image="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-24/79935692.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2018/06/25/Deep_Learning_For_Computer_Vision_With_Python_PB_12.html"><img class="prev-cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-31/72842727.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">深度学习与计算机视觉(PB-12)-ResNet</div></div></a></div><div class="next-post pull-right"><a href="/2018/06/10/How%20to%20easily%20do%20Topic%20Modeling%20with%20LSA,%20PLSA,%20LDA%20&amp;%20lda2Vec.html"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">一文读懂如何用LSA、PSLA、LDA和lda2vec进行主题建模</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2018/02/18/Deep_Learning_For_Computer_Vision_With_Python_PB_02.html" title="深度学习与计算机视觉(PB-02)-数据增强"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/48983125.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-02-18</div><div class="title">深度学习与计算机视觉(PB-02)-数据增强</div></div></a></div><div><a href="/2018/02/25/Deep_Learning_For_Computer_Vision_With_Python_PB_03.html" title="深度学习与计算机视觉(PB-03)-特征提取"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/35317806.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-02-25</div><div class="title">深度学习与计算机视觉(PB-03)-特征提取</div></div></a></div><div><a href="/2018/03/02/Deep_Learning_For_Computer_Vision_With_Python_PB_04.html" title="深度学习与计算机视觉(PB-04)-rank-N准确度"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/91735389.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-03-02</div><div class="title">深度学习与计算机视觉(PB-04)-rank-N准确度</div></div></a></div><div><a href="/2018/03/09/Deep_Learning_For_Computer_Vision_With_Python_PB_05.html" title="深度学习与计算机视觉(PB-05)-网络微调"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/6867281.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-03-09</div><div class="title">深度学习与计算机视觉(PB-05)-网络微调</div></div></a></div><div><a href="/2018/03/16/Deep_Learning_For_Computer_Vision_With_Python_PB_06.html" title="深度学习与计算机视觉(PB-06)-模型集成"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/44239955.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-03-16</div><div class="title">深度学习与计算机视觉(PB-06)-模型集成</div></div></a></div><div><a href="/2018/03/25/Deep_Learning_For_Computer_Vision_With_Python_PB_07.html" title="深度学习与计算机视觉(PB-07)-优化算法"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/18-7-25/6419968.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2018-03-25</div><div class="title">深度学习与计算机视觉(PB-07)-优化算法</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Weitang Liu</div><div class="author-info__description">一个致力于记录技术的博客</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">281</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">384</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">92</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/lonePatient"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/lonePatient" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:liuweitangmath@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://weibo.com/277974397" target="_blank" title="Weibo"><i class="fab fa-weibo"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有任何问题可通过留言板或者微信公众号给我留言，谢谢！<img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/202602201201102.jpg"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#Inception-%E6%A8%A1%E5%9D%97"><span class="toc-number">1.</span> <span class="toc-text">Inception 模块</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Inception"><span class="toc-number">1.1.</span> <span class="toc-text">Inception</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Miniception"><span class="toc-number">1.2.</span> <span class="toc-text">Miniception</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MiniGoogLeNet-on-CIFAR-10"><span class="toc-number">2.</span> <span class="toc-text">MiniGoogLeNet on CIFAR-10</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MiniGoogLeNet"><span class="toc-number">2.1.</span> <span class="toc-text">MiniGoogLeNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Training-MiniGoogLeNet-on-CIFAR-10"><span class="toc-number">2.2.</span> <span class="toc-text">Training MiniGoogLeNet on CIFAR-10</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C1"><span class="toc-number">2.3.</span> <span class="toc-text">实验1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C2"><span class="toc-number">2.4.</span> <span class="toc-text">实验2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C3"><span class="toc-number">2.5.</span> <span class="toc-text">实验3</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tiny-ImageNet"><span class="toc-number">3.</span> <span class="toc-text">Tiny ImageNet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8B%E8%BD%BDTiny-ImageNet%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.1.</span> <span class="toc-text">下载Tiny ImageNet数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tiny-ImageNet%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"><span class="toc-number">3.2.</span> <span class="toc-text">Tiny ImageNet目录结构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Tiny-ImageNet-HDF5"><span class="toc-number">3.3.</span> <span class="toc-text">Tiny ImageNet HDF5</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#DeeperGoogLeNet-on-Tiny-ImageNet"><span class="toc-number">4.</span> <span class="toc-text">DeeperGoogLeNet on Tiny ImageNet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Implementing-DeeperGoogLeNet"><span class="toc-number">4.1.</span> <span class="toc-text">Implementing DeeperGoogLeNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#training-DeeperGoogLeNet-on-Tiny-ImageNet"><span class="toc-number">4.2.</span> <span class="toc-text">training DeeperGoogLeNet on Tiny ImageNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0"><span class="toc-number">4.3.</span> <span class="toc-text">性能评估</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#DeeperGoogLeNet-Experiments"><span class="toc-number">4.4.</span> <span class="toc-text">DeeperGoogLeNet Experiments</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#DeeperGoogLeNet-%E5%AE%9E%E9%AA%8C1"><span class="toc-number">4.4.1.</span> <span class="toc-text">DeeperGoogLeNet: 实验1</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DeeperGoogLeNet-%E5%AE%9E%E9%AA%8C2"><span class="toc-number">4.4.2.</span> <span class="toc-text">DeeperGoogLeNet: 实验2</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DeeperGoogLeNet-Experiment-3"><span class="toc-number">4.4.3.</span> <span class="toc-text">DeeperGoogLeNet: Experiment #3</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">5.</span> <span class="toc-text">总结</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/02/27/arxiv_papers_2026-02-27.html" title="Arxiv今日论文 | 2026-02-27"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-27"/></a><div class="content"><a class="title" href="/2026/02/27/arxiv_papers_2026-02-27.html" title="Arxiv今日论文 | 2026-02-27">Arxiv今日论文 | 2026-02-27</a><time datetime="2026-02-27T12:30:00.000Z" title="发表于 2026-02-27 12:30:00">2026-02-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/26/arxiv_papers_2026-02-26.html" title="Arxiv今日论文 | 2026-02-26"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-26"/></a><div class="content"><a class="title" href="/2026/02/26/arxiv_papers_2026-02-26.html" title="Arxiv今日论文 | 2026-02-26">Arxiv今日论文 | 2026-02-26</a><time datetime="2026-02-26T12:30:00.000Z" title="发表于 2026-02-26 12:30:00">2026-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/arxiv_papers_2026-02-25.html" title="Arxiv今日论文 | 2026-02-25"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-25"/></a><div class="content"><a class="title" href="/2026/02/25/arxiv_papers_2026-02-25.html" title="Arxiv今日论文 | 2026-02-25">Arxiv今日论文 | 2026-02-25</a><time datetime="2026-02-25T12:30:00.000Z" title="发表于 2026-02-25 12:30:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/2026-02-25-Less-is-Enough-Synthesizing-Diverse-Data-in-Feature-Space-of-LLMs.html" title="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260225222513891.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板"/></a><div class="content"><a class="title" href="/2026/02/25/2026-02-25-Less-is-Enough-Synthesizing-Diverse-Data-in-Feature-Space-of-LLMs.html" title="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板">大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板</a><time datetime="2026-02-25T12:00:00.000Z" title="发表于 2026-02-25 12:00:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/2026-02-25-Midtraining-%E4%B8%AD%E9%97%B4%E8%AE%AD%E7%BB%83-%E6%9E%84%E5%BB%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%90%8E%E8%AE%AD%E7%BB%83%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%A5%E6%A2%81.html" title="mid-training：构建预训练与后训练之间的分布式桥梁"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260225123005910.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="mid-training：构建预训练与后训练之间的分布式桥梁"/></a><div class="content"><a class="title" href="/2026/02/25/2026-02-25-Midtraining-%E4%B8%AD%E9%97%B4%E8%AE%AD%E7%BB%83-%E6%9E%84%E5%BB%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%90%8E%E8%AE%AD%E7%BB%83%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%A5%E6%A2%81.html" title="mid-training：构建预训练与后训练之间的分布式桥梁">mid-training：构建预训练与后训练之间的分布式桥梁</a><time datetime="2026-02-25T00:00:00.000Z" title="发表于 2026-02-25 00:00:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/24/arxiv_papers_2026-02-24.html" title="Arxiv今日论文 | 2026-02-24"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-24"/></a><div class="content"><a class="title" href="/2026/02/24/arxiv_papers_2026-02-24.html" title="Arxiv今日论文 | 2026-02-24">Arxiv今日论文 | 2026-02-24</a><time datetime="2026-02-24T12:30:00.000Z" title="发表于 2026-02-24 12:30:00">2026-02-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/23/arxiv_papers_2026-02-23.html" title="Arxiv今日论文 | 2026-02-23"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-23"/></a><div class="content"><a class="title" href="/2026/02/23/arxiv_papers_2026-02-23.html" title="Arxiv今日论文 | 2026-02-23">Arxiv今日论文 | 2026-02-23</a><time datetime="2026-02-23T12:30:00.000Z" title="发表于 2026-02-23 12:30:00">2026-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/23/Think-Deep,-Not-Just-Long-Measuring-LLM-Reasoning-Effort-via-Deep-Thinking-Tokens.html" title="用&quot;深度思考率&quot;精准度量LLM推理质量"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260223165943195.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="用&quot;深度思考率&quot;精准度量LLM推理质量"/></a><div class="content"><a class="title" href="/2026/02/23/Think-Deep,-Not-Just-Long-Measuring-LLM-Reasoning-Effort-via-Deep-Thinking-Tokens.html" title="用&quot;深度思考率&quot;精准度量LLM推理质量">用&quot;深度思考率&quot;精准度量LLM推理质量</a><time datetime="2026-02-23T12:00:00.000Z" title="发表于 2026-02-23 12:00:00">2026-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/20/arxiv_papers_2026-02-20.html" title="Arxiv今日论文 | 2026-02-20"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-20"/></a><div class="content"><a class="title" href="/2026/02/20/arxiv_papers_2026-02-20.html" title="Arxiv今日论文 | 2026-02-20">Arxiv今日论文 | 2026-02-20</a><time datetime="2026-02-20T12:30:00.000Z" title="发表于 2026-02-20 12:30:00">2026-02-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/20/frontier_training_cn.html" title="前沿大模型训练方法：深度解析与实践指南"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/202602201606857.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="前沿大模型训练方法：深度解析与实践指南"/></a><div class="content"><a class="title" href="/2026/02/20/frontier_training_cn.html" title="前沿大模型训练方法：深度解析与实践指南">前沿大模型训练方法：深度解析与实践指南</a><time datetime="2026-02-20T10:30:00.000Z" title="发表于 2026-02-20 10:30:00">2026-02-20</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2026 By Weitang Liu</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'https://twikoo.lonepatient.top/',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'https://twikoo.lonepatient.top/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo@1.4.11/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (99)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/计算机视觉/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 计算机视觉 (16)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/知识图谱/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 知识图谱 (13)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 深度学习 (139)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="http://lonepatient.top/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230219144729.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-02-18</span><a class="blog-slider__title" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt="">通向AGI之路：大型语言模型（LLM）技术精要</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/07/12/gaiic_2022_ner_top10.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20220712181905.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-07-12</span><a class="blog-slider__title" href="2022/07/12/gaiic_2022_ner_top10.html" alt="">GAIIC2022商品标题识别二等奖获奖解决思路</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2022/07/12/gaiic_2022_ner_top10.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230807190424.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-01-20</span><a class="blog-slider__title" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt="">2025-03|高质量中文预训练模型集合</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>