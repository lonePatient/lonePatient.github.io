<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>BERT-Pre-training of Deep Bidirectional Transformers for Language Understanding | 闲记算法</title><meta name="keywords" content="NLP,BERT,Transformer"><meta name="author" content="Weitang Liu"><meta name="copyright" content="Weitang Liu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本文介绍一种新的语言表征模型BERT—基于Transformers的双向编码器表示。异于最新语言表征模型，BERT基于所有层的左、右语境来预训练深度双向表征。BERT是首个大批句子层面和词块层面任务中取得当前最优性能的表征模型，性能超越许多使用任务特定架构的系统，刷新11项NLP任务当前最优性能记录，堪称最强NLP预训练模型！未来可能成为新行业基础。本文参考网上各大文章，整理翻译了BERT论文，在">
<meta property="og:type" content="article">
<meta property="og:title" content="BERT-Pre-training of Deep Bidirectional Transformers for Language Understanding">
<meta property="og:url" content="http://lonepatient.top/2018/12/20/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding.html">
<meta property="og:site_name" content="闲记算法">
<meta property="og:description" content="本文介绍一种新的语言表征模型BERT—基于Transformers的双向编码器表示。异于最新语言表征模型，BERT基于所有层的左、右语境来预训练深度双向表征。BERT是首个大批句子层面和词块层面任务中取得当前最优性能的表征模型，性能超越许多使用任务特定架构的系统，刷新11项NLP任务当前最优性能记录，堪称最强NLP预训练模型！未来可能成为新行业基础。本文参考网上各大文章，整理翻译了BERT论文，在">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121221353.jpg">
<meta property="article:published_time" content="2018-12-20T23:27:08.000Z">
<meta property="article:modified_time" content="2025-10-31T07:26:14.534Z">
<meta property="article:author" content="Weitang Liu">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="BERT">
<meta property="article:tag" content="Transformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121221353.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://lonepatient.top/2018/12/20/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//s4.cnzz.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script async="async" data-pjax="data-pjax" src="https://s4.cnzz.com/z_stat.php?id=1273275888&amp;web_id=1273275888"></script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-10-31 07:26:14'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/backgroud.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><script src="https://at.alicdn.com/t/c/font_3570527_dthoqrrv2tv.css"></script><script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script><script>LA.init({id:"JwRQtLKZggvJH4sJ",ck:"JwRQtLKZggvJH4sJ"})</script><link rel="stylesheet" href="/css/universe.css"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3536467946304280" crossorigin="anonymous"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">266</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">306</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">70</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 网站</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.aitoolist.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集合</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.deepdh.com"><i class="fa-fw fa fa-star"></i><span> AI工具导航</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.ai-lib.club"><i class="fa-fw fa fa-star"></i><span> 人工智能工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ai-bot.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 教程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://learningprompt.wiki/"><i class="fa-fw fa fa-star"></i><span> Prompt教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 在线</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fa fa-star"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121221353.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">闲记算法</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 网站</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.aitoolist.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集合</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.deepdh.com"><i class="fa-fw fa fa-star"></i><span> AI工具导航</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.ai-lib.club"><i class="fa-fw fa fa-star"></i><span> 人工智能工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ai-bot.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 教程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://learningprompt.wiki/"><i class="fa-fw fa fa-star"></i><span> Prompt教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 在线</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fa fa-star"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">BERT-Pre-training of Deep Bidirectional Transformers for Language Understanding<a class="post-edit-link" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2018-12-20T23:27:08.000Z" title="发表于 2018-12-20 23:27:08">2018-12-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-10-31T07:26:14.534Z" title="更新于 2025-10-31 07:26:14">2025-10-31</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/">自然语言处理</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86/%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/">预训练语言模型</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">10.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>33分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2018/12/20/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本文介绍一种新的语言表征模型BERT—基于Transformers的双向编码器表示。异于最新语言表征模型，BERT基于所有层的左、右语境来预训练深度双向表征。BERT是首个大批句子层面和词块层面任务中取得当前最优性能的表征模型，性能超越许多使用任务特定架构的系统，刷新11项NLP任务当前最优性能记录，堪称最强NLP预训练模型！未来可能成为新行业基础。本文参考网上各大文章，整理翻译了<strong>BERT</strong>论文，在自己学习的同时也分享给大家，欢迎交流指教。</p>
<span id="more"></span>
<h2 id="摘要">摘要</h2>
<p>本文介绍一种称之为BERT的新语言表征模型，即Transformers的双向编码器表征量(BidirectionalEncoder Representations from Transformers)。不同于最近的语言表征模型(Peters等，2018; Radford等，2018)，BERT旨在基于所有层的左、右语境来预训练深度双向表征。因此，预训练的BERT表征可以仅用一个额外的输出层进行微调，进而为很多任务(如问答和语言推理)创建当前最优模型，无需对任务特定架构做出大量修改。</p>
<p>BERT的概念很简单，但实验效果很强大。它刷新了11个NLP任务的当前最优结果，包括将GLUE基准提升至80.4%(7.6%的绝对改进)、将MultiNLI的准确率提高到86.7%(5.6%的绝对改进)，以及将SQuADv1.1问答测试F1的得分提高至93.2分(1.5分绝对提高)——比人类性能还高出2.0分。</p>
<h2 id="介绍">介绍</h2>
<p>预训练的语言模型已被证明可有效改进许多自然语言处理任务(Dai and Le, 2015;Peters等，2017, 2018; Radford等，2018; Howard and Ruder, 2018)。这些任务包括句子级任务，如自然语言推理inference(Bowman等，2015; Williams等，2018)和paraphrasing(Dolan and Brockett, 2005)，旨在通过整体分析来预测句子之间的关系；以及词块级任务，如命名实体识别(Tjong Kim Sang andDe Meulder, 2003)和SQuAD问题回答(Rajpurkar等，2016)，其中模型需要在词块级别生成细粒度输出。</p>
<p>将预训练语言表征应用于下游任务有两种现有策略：基于特征feature-based和微调fine-tuning。基于特征的方法，例如ELMo(Peters等，2018)，使用特定于任务的架构，其包括将预训练表征作为附加特征。微调方法，例如Generative Pre-trained Transformer(OpenAIGPT生成型预训练变换器)(Radford等，2018)，引入了最小的任务特定参数，并通过简单地微调预训练参数在下游任务中进行训练。在之前　的工作中，两种方法在预训练期间共享相同的目标函数，它们使用单向语言模型来学习通用语言表征。</p>
<p>我们认为，当前技术严重制约了预训练表征的能力，特别是对于微调方法。其主要局限在于标准语言模型是单向的，这限制了可以在预训练期间使用的架构类型。例如，在OpenAI GPT，作者用一个从左到右的架构，其中每个词块只能注意 Transformer自注意层中的前验词块(Vaswani等，2017)。这种局限对于句子层面任务而言是次优选择，对于词块级任务的方法，则可能是毁灭性的。在这种任务中应用基于词块级微调法，如SQuAD问答(Rajpurkar等，2016)，结合两个方向语境至关重要。</p>
<p>在本论文，我们提出BERT模型：Transformer的双向编码器表征量(Bidirectional Encoder Representations fromTransformers)，改进了基于微调的方法。BERT通过提出一个新的预训练目标：“maskedlanguage model“（MLM)，来自Cloze任务(Taylor，1953)的启发，来解决前面提到的单向局限。该MLM随机地从输入中遮蔽一些词块，并且，目标是仅基于该遮蔽词语境语境来预测其原始词汇id（类似于CBOW）。不像从左到右的语言模型预训练，该MLM目标允许表征融合左右两侧语境语境，这允许我们预训练一个深度双向Transformers。除了该MLM，我们还引入了一个“下一句预测”(next sentence prediction)任务，该任务联合预训练文本对表征量。<br>
　　<br>
我们的论文贡献如下：</p>
<ul>
<li>我们证明了双向预训练对语言表征量的重要性。与Radford等人(2018)不同，其使用单向语言模型进行预训练，BERT使用MLM来实现预训练的深度双向表征量。这也与Peters等人(2018)形成对比，其使用由独立训练的从左到右和从右到左LMs(语言模型)的浅层串联。</li>
<li>我们展示了预训练表征量能消除许多重型工程任务特定架构的需求。BERT是第一个基于微调的表征模型，它在大量的句子级和词块级任务上实现了最先进的性能，优于许多具有任务特定架构的系统。</li>
<li>BERT刷新了11项NLP任务的最高水平。因此，我们报告了广泛的BERT消融，证明我们模型的双向性质是最重要的新贡献。</li>
</ul>
<h2 id="相关工作">相关工作</h2>
<p>预训练通用语言表征有很长历史，本节我们简要回顾中这些最常用的方法。</p>
<h3 id="基于特征方法">基于特征方法</h3>
<p>广泛采用的单词表征学习，已经是数十年的活跃研究领域，包括非神经(Brown等，1992; Ando and Zhang, 2005; Blitzer等，2006)和神经(Collobert andWeston, 2008; Mikolov等，2013; Pennington等，2014)方法。预训练的单词嵌入被认为是现代NLP系统的组成部分，与从头学习的嵌入相比提供了显着的改进(Turian等，2010)。</p>
<p>这些方法已经被推广到更粗的粒度，如句子嵌入(Kiros等，2015; Logeswaran and Lee, 2018)或段落嵌入(Le and Mikolov, 2014)。与传统词嵌入一样，这些学习到的表征通常用作下游模型中的特征。</p>
<p>ELMo(Peters等，2017)将传统的词嵌入研究概括为不同维度。他们建议从语言模型中提取语境敏感型特征。把语境字词嵌入与现有任务特定架构集成时，ELMo针对一些主要的NLP基准(Peters et al., 2018)提出了最先进的技术，包括关于SQUAD问答(Rajpurkar等，2016)，情绪分析(Socher等，2013)，以及命名实体识别(Tjong Kim Sang和De Meulder，2003)。</p>
<h3 id="微调方法">微调方法</h3>
<p>一种源于语言模型(LMs)的迁移学习新趋势，是微调前预训练一些LM目标上的模型架构，该微调是相同型号的一种监督下游任务(Dai and Le, 2015;Howard and Ruder, 2018; Radford等，2018)。这些方法的优点是几乎没有参数需要从头开始学习。至少部分是由于这一优势，OpenAIGPT(Radford等，2018)在许多句子级别任务的GLUE基准(Wang等，2018)，取得此前最好测试结果。</p>
<h3 id="利用监督数据迁移学习">利用监督数据迁移学习</h3>
<p>虽然无监督预训练的优势在于可获得的数据量几乎无限，但也有工作表明从具有大型数据集的监督任务中可有效迁移，例如自然语言推理(Conneau等，2017)和机器翻译(Mc-Cann等，2017)。在NLP之外，计算机视觉研究也证明了从大型预训练模型迁移学习的重要性，其中一个有效的方法是微调在ImageNet上预训练的模型(Deng等，2009; Yosinski等，2014)。</p>
<h2 id="BERT">BERT</h2>
<p>我们在本节介绍BERT及其详细实现。我们先介绍BERT的模型架构和输入表征。然后，我们将在3.3节中介绍预训练任务，即本文的核心创新。预训练程序和微调程序分别在第3.4节和第3.5节中详述。最后，第3.6节讨论了BERT和OpenAIGPT之间的差异。</p>
<h3 id="模型架构">模型架构</h3>
<p>BERT模型架构是一种多层双向变换器（Transformer）编码器，基于Vaswani等人(2017年)描述并在tensor2tensor库发行的原始实现。因为变换器的使用最近变得无处不在，我们架构的实施有效地等同于原始实现，所以我们会忽略模型架构详尽的背景描述，并向读者推荐Vaswani等人(2017)的优秀指南，如“注释变换器”。(<a target="_blank" rel="noopener" href="http://nlp.seas.harvard.edu/2018/04/03/attention.html">http://nlp.seas.harvard.edu/2018/04/03/attention.html</a>)</p>
<p>在这项工作中，我们把层数(即Transformer blocks变换器块)表征为L，隐节点大小表征为H，自注意力数目表征为A。在所有情况下，我们设置前馈/过滤器的尺寸为4H，如H=768时为3072，H=1024时为4096。我们主要报告在两种模型尺寸上的结果：</p>
<ul>
<li>BERT_base：L=12，H=768，A=12，总参数=110M</li>
<li>BERT_large：L=24，H=1024，A=16，总参数=340M</li>
</ul>
<p>选择的BERT_base模型尺寸等同于OpenAIGPT模型尺寸，以进行比较。然而，重要的是，BERT变换器使用双向自注意，而GPT变换器使用受限自注意，每个词块只能注意其左侧语境。我们注意到，在文献中，双向变换器通常指称为“变换器编码器”，而其左侧语境版本被称为“变换器解码器”，因为它可用于文本生成。BERT，OpenAIGPT和ELMo之间的比较如图1所示。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121221353.jpg" alt=""></p>
<center>图1：预训练模型架构间差异。BERT使用双向变换器，OpenAI GPT使用从左到右的变换器，ELMo使用独立训练的从左到右和从右到左LSTM级联来生成下游任务的特征。三种模型中只有BERT表征基于所有层左右两侧语境。</center>
### 输入表征
<p>我们的输入表征(input representation)能在一个词块序列中明确地表征单个文本句子或一对文本句子(例如，[Question,Answer])。(注：在整个这项工作中，“句子”可以是连续文本的任意跨度，而不是实际的语言句子。“序列”指BERT的输入词块序列，其可以是单个句子或两个句子打包在一起。)对于给定词块，其输入表征通过对相应词块的词块嵌入、段嵌入和位嵌入求和来构造。图2给出了我们的输入表征的直观表征。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121221656.jpg" alt=""></p>
<center> 图2：BERT输入表征。输入嵌入是词块嵌入、段嵌入和位嵌入的总和。</center>
具体是：
<ul>
<li>我们使用WordPiece嵌入(Wu等，2016)和30,000个词块表。我们用##表征分词。</li>
<li>我们使用学习的位置嵌入，支持的序列长度最多为512个词块。</li>
<li>每个序列的第一个词块始终是特殊分类嵌入([CLS])。对应该词块的最终隐藏状态(即，变换器输出)被用作分类任务的聚合序列表征。对于非分类任务，将忽略此向量。</li>
<li>句子对被打包成单个序列。我们以两种方式区分句子。首先，我们用特殊词块([SEP])将它们分开。其次，我们添加一个学习句子A嵌入到第一个句子的每个词块中，一个句子B嵌入到第二个句子的每个词块中。</li>
<li>对于单句输入，我们只使用句子A嵌入。</li>
</ul>
<h3 id="预训练任务">预训练任务</h3>
<p>与Peters等人(2018)和Radford等人(2018)不同，我们不使用传统的从左到右或从右到左的语言模型来预训练BERT。相反，我们使用两个新型无监督预测任务对BERT进行预训练，如本节所述。</p>
<h4 id="任务-1：MLM">任务#1：MLM</h4>
<p>直观地说，有理由相信深度双向模型比左向右模型或从左到右和右到左模型的浅层连接更严格。遗憾的是，标准条件语言模型只能从左到右或从右到左进行训练，因为双向调节将允许每个单词在多层语境中间接地“看到自己”。</p>
<p>为了训练深度双向表征，我们采用一种直接方法，随机遮蔽输入词块的某些部分，然后仅预测那些被遮蔽词块。我们将这个过程称为“遮蔽LM”(MLM)，尽管它在文献中通常被称为Cloze完形任务(Taylor, 1953)。在这种情况下，对应于遮蔽词块的最终隐藏向量被馈送到词汇表上的输出softmax函数中，如在标准LM中那样预测所有词汇的概率。在我们所有实验中，我们随机地遮蔽蔽每个序列中所有WordPiece词块的15％。与去噪自动编码器(Vincent等，2008)相反，我们只预测遮蔽单词而不是重建整个输入。</p>
<p>虽然这确实允许我们获得双向预训练模型，但该方法有两个缺点。首先，我们正在创建预训练和微调之间的不匹配，因为在微调期间从未看到[MASK]词块。为了缓解这个问题，我们并不总是用实际的[MASK]词块替换“遮蔽”单词。相反，训练数据生成器随机选择15％的词块，例如，在句子：我的狗是毛茸茸的，它选择毛茸茸的。然后完成以下过程：</p>
<ul>
<li>并非始终用[MASK]替换所选单词，数据生成器将执行以下操作：</li>
<li>80％的时间：用[MASK]词块替换单词，例如，my dog is hairy → my dog is [MASK]</li>
<li>10％的时间：用随机词替换遮蔽词，例如，my dog is hairy → my dog is apple</li>
<li>10％的时间：保持单词不变，例如，my dog is hairy → my dog is hairy.。这样做的目的是将该表征偏向于实际观察到的单词。</li>
</ul>
<p>变换器编码器不知道它将被要求预测哪些单词或哪些单词已被随机单词替换，因此它被迫保持每个输入词块的分布式语境表征。此外，因为随机替换只发生在所有词块的1.5％(即15％的10％)，这似乎不会损害模型的语言理解能力。</p>
<p>使用MLM的第二个缺点是每批中只预测了15％的词块，这表明模型可能需要更多的预训练步骤才能收敛。在5.3节中，我们证明MLM的收敛速度略慢于从左到右的模型(预测每个词块)，但MLM模型在实验上的改进远远超过所增加的训练成本。</p>
<h4 id="任务-2：下一句预测">任务#2：下一句预测</h4>
<p>很多重要的下游任务，例如问答(QA)和自然语言推理(NLI)，都是基于对两个文本句子间关系的理解，而这种关系并非通过语言建模直接获得。为了训练一个理解句子关系的模型，我们预训练了一个二值化下一句预测任务，该任务可以从任何单语语料库中轻松生成。具体来说，选择句子A和B作为预训练样本：B有50%的可能是A的下一句，也有50%的可能是来自语料库的随机句子。例如：<br>
　　<br>
Input=[CLS] the man went to [MASK] store [SEP]<br>
he bought a gallon [MASK] milk [SEP]<br>
Label=IsNext</p>
<p>Input=[CLS] the man [MASK] to the store [SEP]<br>
penguin [MASK] are flight ##less birds [SEP]<br>
Label=NotNext</p>
<p>我们完全随机选择这些NotNext语句，最终预训练模型在此任务中达到97％-98％的准确率。尽管它很简单，但我们在5.1节中证明，面向该任务的预训练对QA和NLI都非常有益。</p>
<h3 id="预训练过程">预训练过程</h3>
<p>BERT预训练过程主要遵循现有的语言模型预训练文献。对于预训练语料库，我们使用BooksCorpus(800M单词)(Zhu等，2015)和英语维基百科(2,500M单词)的串联。对于维基百科，我们只提取文本段落并忽略列表、表格和题头。至关重要的是，使用文档级语料库而不是洗牌式(乱词序)句子级语料库，例如Billion Word Benchmark(Chelba等，2013)，以便提取长的连续序列。</p>
<p>为了生成每个训练输入序列，我们从语料库中采样两个文本跨度，我们将其称为“句子”，即使它们通常比单个句子长得多(但也可以更短)。第一个句子接收A嵌入，第二个句子接收B嵌入。B有50％可能刚好是A嵌入后的下一个句子，亦有50％可能是个随机句子，此乃为“下一句预测”任务而做。对它们采样，使其组合长度≦512个词块。该LM遮蔽应用于具有15％统一掩蔽率的WordPiece词块化之后，并且不特别考虑部分字块。</p>
<p>我们训练批量大小为256个序列(256个序列$\star$512个词块=128,000个词块/批次)，持续1,000,000个步骤，这比33亿个单词语料库大约40个周期。我们使用Adam(学习程序)，设其学习率为1e-4，β1=0.9，β2=0.999，L2权重衰减为0.01，学习率预热超过前10,000步以上以及线性衰减该学习率。我们在所有层上使用0.1的丢失概率。在OpenAIGPT之后，我们使用gelu激活(Hendrycks和Gimpel, 2016)而不是标准relu。训练损失是平均的遮蔽LM可能性和平均的下一句子预测可能性的总和。</p>
<p>在Pod配置的4个云TPU上进行了BERTBASE训练(总共16个TPU芯片)。(注:<a target="_blank" rel="noopener" href="https://cloudplatform.googleblog.com/2018/06/Cloud-TPU-now-offers-preemptible-pricing-and-globalavailability.html">https://cloudplatform.googleblog.com/2018/06/Cloud-TPU-now-offers-preemptible-pricing-and-globalavailability.html</a>) 在16个云TPU(总共64个TPU芯片)进行了BERTLARGE训练。每次预训练需4天完成。</p>
<h3 id="微调过程">微调过程</h3>
<p>对于序列级分类任务，BERT微调很简单。为了获得输入序列的固定维度池化表征，我们对该输入第一个词块采取最终隐藏状态(例如，该变换器输出)，通过对应于特殊[CLS]词嵌入来构造。我们将该向量表示为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>∈</mo><msup><mi>R</mi><mi>H</mi></msup></mrow><annotation encoding="application/x-tex">C \in R^H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span></span></span></span></span></span></span></span></span></span></span>。微调期间添加的唯一新参数是分类层向量<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi>R</mi><mrow><mi>K</mi><mi>x</mi><mi>H</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W \in R^{KxH}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mord mathnormal mtight">x</span><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span></span></span></span></span></span></span></span></span></span></span></span>，其中K是分类器标签的数量。该标签概率<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>∈</mo><msup><mi>R</mi><mi>K</mi></msup></mrow><annotation encoding="application/x-tex">P\in R^K</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span></span></span>用标准softmax函数，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo>=</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>C</mi><msup><mi>W</mi><mi>T</mi></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P=softmax(CW^T)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>计算。BERT和W的所有参数都经过联动地微调，以最大化正确标签的对数概率。对于跨度级和词块级预测任务，必须以任务特定方式稍微修改上述过程。详情见第4节的相应小节。</p>
<p>对于微调，大多数模型超参数与预训练相同，但批量大小、学习率和训练周期数量除外。丢失概率始终保持在0.1。最佳超参数值是特定于任务的，但我们发现以下范围的可能值可以在所有任务中很好地工作：</p>
<ul>
<li>批量大小：16,32</li>
<li>学习率(Adam)：5e-5,3e-5,2e-5</li>
<li>周期数量：3,4</li>
</ul>
<p>我们还观察到，大数据集(如100k+词块的训练样例)对超参数选择的敏感性远小于小数据集。微调通常非常快，因此需合理简单地对上述参数进行详尽搜索，并选择开发集上性能最佳的模型。</p>
<h3 id="BERT和OpenAI-GPT比较">BERT和OpenAI GPT比较</h3>
<p>与BERT最具可比性的现有预训练方法是OpenAI GPT，它在大型文本语料库中训练左到右的变换器LM。实际上，许多BERT设计决策被有意地选择为尽可能接近GPT，以便最细微地比较这两种方法。这项工作的核心论点是占主要经验改进的3.3节中提出的两个新型预训练任务，但我们注意到BERT和GPT在如何训练之间还存在其他一些差异：</p>
<ul>
<li>GPT在BooksCorpus(800M单词)训练；BERT在BooksCorpus(800M单词)和维基百科(2,500M单词)训练。</li>
<li>GPT使用一种句子分隔符([SEP])和分类符词块([CLS])，它们仅在微调时引入；BERT在预训练期间学习[SEP]，[CLS]和句子A/B嵌入。</li>
<li>GPT用一个批量32,000单词训练1M步；BERT用一个批量128,000单词训练1M步。</li>
<li>GPT对所有微调实验使用的5e-5相同学习率；BERT选择特定于任务的微调学习率，在开发集表现最佳。</li>
</ul>
<p>为了分离这些差异的影响，我们在5.1节进行了消融实验，证明大多数改进实际上来自新型预训练任务。</p>
<h2 id="实验">实验</h2>
<p>在本节中，我们将介绍11个NLP任务的BERT微调结果。</p>
<h3 id="GLUE数据集">GLUE数据集</h3>
<p>通用语言理解评估(GLUE)基准(Wang等，2018)是各种自然语言理解任务的集合。大多数GLUE数据集已存在多年，但GLUE的目的是：(1) 使用规范的Train、Dev和Test拆分发行这些数据集； (2) 设置评估服务器以减轻评估不一致事件和测试集过度拟合。GLUE不会为测试集分发标签，用户必须将其预测上传到GLUE服务器进行评估，并限制提交的数量。</p>
<p>GLUE基准包括以下数据集，其描述最初在Wang等人(2018)的文章中进行了总结：</p>
<ul>
<li>
<p>MNLI: 多类型自然语言推理是一项大规模的众包蕴涵分类任务(Williams等，2018)。给定一对句子，目标是预测第二句与第一句相比是蕴涵、矛盾还是中立。</p>
</li>
<li>
<p>QQP: Quora问题对是一个二元分类任务，其目的是确定Quora上提出的两个问题是否在语义上是等价的(Chen等，2018)。</p>
</li>
<li>
<p>QNLI: 问题自然语言推理是斯坦福问题答疑数据集(Rajpurkar等，2016)的一个版本，已被转换为二元分类任务(Wang等，2018)。正例是(问题，句子)对包含正确答案，而负例是(问题，句子)来自同一段落，不包含答案。</p>
</li>
<li>
<p>SST-2: 斯坦福情感树库2是一个二元单句分类任务，由从电影评论中提取的句子和人类注释的情绪组成(Socher等，2013)。</p>
</li>
<li>
<p>CoLA: 语言可接受性语料库是一个二元单句分类任务，其目标是预测英语句子在语言上是否“可接受”(Warstadt等，2018)。</p>
</li>
<li>
<p>STS-B: 语义文本相似性基准是从新闻标题和其他来源中提取的句子对的集合(Cer等，2017)。它们用1到5的分数进行注释，表示两个句子在语义上的相似程度。</p>
</li>
<li>
<p>MRPC: 微软研究院解释语料库由从在线新闻源自动提取的句子对组成，其中人类注释是否该对中的句子是否在语义上相等(Dolan和Brockett，2005)。</p>
</li>
<li>
<p>RTE: 识别文本蕴涵是类似于MNLI的二进制蕴涵任务，但训练数据少得多(Bentivogli等，2009)。(注：请注意，本文仅报告单任务微调结果。多任务微调方法可能会进一步推动结果。例如，我们确实观察到MNLI多任务培训对RTE的实质性改进。)</p>
</li>
<li>
<p>WNLI: 威诺格拉德自然语言推理是一个源自(Levesque等，2011)的小型自然语言推理数据集。GLUE网页指出，该数据集的构建存在问题，并且每个提交给GLUE训练过的系统的性能都比预测大多数类别的65.1基线准确度差。(注：<a target="_blank" rel="noopener" href="https://gluebenchmark.com/faq">https://gluebenchmark.com/faq</a>) 因此，我们将这一组排除在OpenAIGPT的公平性之外。对于我们的GLUE提交，我们总是预测其大多数的类。</p>
</li>
</ul>
<h4 id="GLUE结果">GLUE结果</h4>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121222625.jpg" alt=""></p>
<p>图3：我们的任务特定模型是由向BERT添加一个额外输出层而形成的，因此一小部分参数需要从头开始学习。</p>
<p>在该任务中，(a)和(b)是序列级任务，©和(d)是词块级任务。图中E代表其输入嵌入，Ti代表词块i的语境表征，[CLS]是分类输出的特殊符号，[SEP]是分割非连续词块序列的特殊符号。</p>
<p>对GLUE微调，我们呈现了第3节中描述的输入序列或序列对，并使用对应于第一个输入词块([CLS])的最终隐藏向量C∈RH作为聚合表征。这都呈现在可视化图3(a)和(b)中。在微调期间引入的唯一新参数是分类层<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi><mo>∈</mo><msup><mi>R</mi><mrow><mi>K</mi><mo>×</mo><mi>H</mi></mrow></msup></mrow><annotation encoding="application/x-tex">W∈R^{K×H}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7224em;vertical-align:-0.0391em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span><span class="mbin mtight">×</span><span class="mord mathnormal mtight" style="margin-right:0.08125em;">H</span></span></span></span></span></span></span></span></span></span></span></span>，其中K是标签数量。我们用C和W计算标准分类损失，即<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi><mi>o</mi><mi>g</mi><mo stretchy="false">(</mo><mi>s</mi><mi>o</mi><mi>f</mi><mi>t</mi><mi>m</mi><mi>a</mi><mi>x</mi><mo stretchy="false">(</mo><mi>C</mi><msup><mi>W</mi><mi>T</mi></msup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">log(softmax(CW^T))</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mopen">(</span><span class="mord mathnormal">so</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">t</span><span class="mord mathnormal">ma</span><span class="mord mathnormal">x</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span></span></span></span></span></span></span></span><span class="mclose">))</span></span></span></span>。</p>
<p>对所有GLUE任务，我们均在其数据上使用一个批量大小为32和3个周期。对于每项任务，我们用学习率5e-5,4e-5,3e-5和2e-5做了微调，并选择了在其Dev集上性能最佳的那一个。此外，对于BERTLARGE，我们发现微调有时在小数据集上不稳定(如，某些运行会产生退化结果)，因此我们运行了几次随机重启并选择了在Dev集上性能最佳的模型。通过随机重启，我们使用相同的预训练检查点，但执行不同的微调数据混洗和分类器层初始化。我们注意到GLUE数据集分布不包括其测试标签，我们只为每个BERT_base和BERT_large做单一的GLUE评估服务器提交。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121222727.jpg" alt=""></p>
<p>表1：GLUE测试结果，评分来自其GLUE评估服务器。每个任务下面的数字代表该训练样本数量。“Average”列与GLUE官方分数略微不同，因为我们排除了有问题的WNLI集。</p>
<ul>
<li>OpenAI GPT = (L=12, H=768, A=12)；</li>
<li>BERT_base = (L=12, H=768, A=12)；</li>
<li>BERT_large  = (L=24, H=1024,A=16)。</li>
</ul>
<p>BERT和OpenAI GPT是单模型、单任务。所有结果来自于以下地址：<a target="_blank" rel="noopener" href="https://gluebenchmark.com/leaderboard">https://gluebenchmark.com/leaderboard</a> 和 <a target="_blank" rel="noopener" href="https://blog.openai.com/language-unsupervised/">https://blog.openai.com/language-unsupervised/</a></p>
<p>结果如表1所示。BERT_base和BERT_large在所有任务上的性能均优于所有现有系统，相对于最先进水平，平均准确度提高了4.4％和6.7％。请注意，BERT_base和OpenAIGPT在其注意遮蔽之外的模型架构几乎相同。对于规模最大、报道最广泛的GLUE任务，MNLI、BERT的绝对精度提高了4.7％，超过了最先进水平。在官方GLUE排行榜8上，BERT_large得分为80.4，而该排行榜系统登顶的OpenAIGPT在本文撰写之日获得72.8分。(注 <a target="_blank" rel="noopener" href="https://gluebenchmark.com/leaderboard">https://gluebenchmark.com/leaderboard</a>)</p>
<p>有趣的是，BERT_large在所有任务中都明显优于BERT_base，即使训练数据非常少的那些也是如此。第5.2节更全面地探讨了BERT模型尺寸的影响。</p>
<h3 id="斯坦福问答数据集-SQuAD-v1-1">斯坦福问答数据集 SQuAD v1.1</h3>
<p>Standford问题回答数据集(SQuAD)是一种100k众包问答对的集合(Rajpurkar等，2016)。给出一个问题和包含答案的来自维基百科的一个段落，任务是预测该段落中的其答案文本的跨度。例如：</p>
<ul>
<li>
<p>Input Question:<br>
Where do water droplets collide with ice crystals to form precipitation?</p>
</li>
<li>
<p>Input Paragraph:<br>
…  Precipitation forms as smaller droplets coalesce via collision with other rain drops or ice crystals within a cloud.  …</p>
</li>
<li>
<p>Output Answer:<br>
within a cloud</p>
</li>
</ul>
<p>这种类型的跨度预测任务与GLUE的序列分类任务完全不同，但我们能以简单的方式调整BERT以在SQuAD上运行。与GLUE一样，我们将输入问题和段落表示为单个打包序列，问题使用A嵌入和使用B嵌入的段落。在微调期间学习的唯一新参数是起始矢量S∈RH和结束矢量E∈RH。让来自BERT的第i个输入词块的最终隐藏向量表示为Ti∈RH。请参见可视化图3©。然后，单词 i 作为答案跨度开始的概率被计算为Ti和S之间的点积(dot product)，跟随着段落中所有单词的softmax：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub><mo>=</mo><mfrac><msup><mi>e</mi><mrow><mi>S</mi><mo>⋅</mo><msub><mi>T</mi><mi>i</mi></msub></mrow></msup><mrow><mi mathvariant="normal">∣</mi><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>j</mi></msub><msup><mi>e</mi><mrow><mi>S</mi><mo>⋅</mo><msub><mi>T</mi><mi>j</mi></msub></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">P_{i} = \frac{e^{S\cdot T_i}}{|sum_j e^{S\cdot T_j}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4904em;vertical-align:-0.9721em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mord mathnormal">u</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7834em;"><span style="top:-3.0051em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="mbin mtight">⋅</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05764em;">S</span><span class="mbin mtight">⋅</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.1389em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9721em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>相同公式用于其答案跨度的末端，最大评分范围用作其预测。训练目标是正确的开始和结束位置的log似然(log-likelihood)。</p>
<p>我们以学习率5e-5批量大小32来训练3个周期。推理时，由于结束预测不以开始为条件，我们添加了在开始后必须结束的约束，但是没有使用其他启发式方法。词块化标记跨度与原始非词块化输入对齐，以做评估。</p>
<p>结果呈现在表2。SQuAD用很严格的测试过程，其提交者必须人工联系SQuAD组织者以在一个隐藏测试集上运行他们的系统，因此我们只提交了我们最好的系统进行测试。该表显示的结果是我们向SQuAD提交的第一个也是唯一的测试。我们注意到SQuAD排行榜最好高结果没有最新的可用公共系统描述，并且在训练他们的系统时可以使用任何公共数据。因此，我们通过我们提交的系统中使用非常适度的数据增强，在SQuAD和TriviaQA(Joshi等，2017)上联合训练。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121223110.jpg" alt=""></p>
<p>表2：SQuAD结果。本BERT集成是使用不同预训练检查点和微调种子(fine-tuning seed)的7x系统。</p>
<p>我们性能最佳的系统在整体排名中优于顶级排行榜系统+1.5 F1项，在单一系统中优于+1.3 F1项。事实上，我们的单一BERT模型在F1得分方面优于顶级全体系统。如果我们只微调SQuAD(没有TriviaQA)，我们将失去0.1-0.4的F1得分，但仍然大幅超越所有现有系统。</p>
<h3 id="命名实体识别">命名实体识别</h3>
<p>为了评估词块标记任务的性能，我们在CoNLL 2003命名实体识别(NER)数据集上微调BERT。该数据集由200k个训练单词组成，这些单词已注释为Person，Organization，Location，Miscellaneous，和其它(非命名实体)。</p>
<p>为做微调，我们将最终隐藏表征Ti∈RH提供给每个词块i到NER标签集上的分类层。此预测不以周围预测为条件(即，非自回归和无CRF)。为了使其与WordPiece词块化相兼容，我们将每个CoNLL词块化输入单词提供给我们的WordPiece词块化器，并使用与第一个子标记相对应的隐藏状态作为分类器的输入。例如：</p>
<p><em>Jim　Hen　##son　was　a　puppet　##eer</em><br>
<em>I-PER　I-PER　X　O　O　O　X</em></p>
<p>在没有对X做预测的情况下。由于WordPiece词块化边界是一个该输入的已知部分，因此对训练和测试都做了预测。图3(d)中还给出了可视化呈现。一种事例WordPiece模型用于NER，而非事例模型用于所有其他任务。</p>
<p>结果呈现在表3中。BERTLARGE优于现有SOTA——具有多任务学习(Clark等，2018)的跨视图训练，在CoNLL-2003NER测试中达+0.2。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121223326.jpg" alt=""></p>
<p>表3：CoNLL-2003命名实体识别结果。超参数通过开发集来选择，得出的开发和测试分数是使用这些超参数进行五次随机重启的平均值。</p>
<h3 id="对抗生成情境数据集（SWAG）">对抗生成情境数据集（SWAG）</h3>
<p>此对抗生成情境(SWAG)数据集包含113k个句子对的完成样例，用于评估基础常识推理(Zellers等，2018)。</p>
<p>给定一个视频字幕数据集中的某一个句子，任务是在四个选项中决定最合理的后续。例如：</p>
<p>A girl is going across a set of monkey bars.  She<br>
(i) jumps up across the monkey bars.<br>
(ii) struggles onto the bars to grab her head.<br>
(iii) gets to the end and stands on a wooden plank.<br>
(iv) jumps up and does a back flip.</p>
<p>调到SWAG数据集的BERT，类似于其GLUE适配。对于每个样本，我们构造四个输入序列，每个输入序列包含给定句子(句子A)和可能后续(句子B)的串联。我们引入的唯一任务特定参数是一个矢量V∈RH，其具有最终聚合表征Ci∈RH的点积代表每个选择i的得分。概率分布是四种选择的softmax：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>P</mi><mi>i</mi></msub><mo>=</mo><mfrac><msup><mi>e</mi><mrow><mi>V</mi><mo>⋅</mo><msub><mi>G</mi><mi>i</mi></msub></mrow></msup><mrow><mi mathvariant="normal">∣</mi><mi>s</mi><mi>u</mi><msub><mi>m</mi><mi>j</mi></msub><msup><mi>e</mi><mrow><mi>V</mi><mo>⋅</mo><msub><mi>G</mi><mi>j</mi></msub></mrow></msup></mrow></mfrac></mrow><annotation encoding="application/x-tex">P_{i} = \frac{e^{V \cdot G_i}}{|sum_j e^{V \cdot G_j}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8333em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em;">P</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.4904em;vertical-align:-0.9721em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5183em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathnormal">s</span><span class="mord mathnormal">u</span><span class="mord"><span class="mord mathnormal">m</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7834em;"><span style="top:-3.0051em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span><span class="mbin mtight">⋅</span><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.22222em;">V</span><span class="mbin mtight">⋅</span><span class="mord mtight"><span class="mord mathnormal mtight">G</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.9721em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>
<p>我们用学习率2e-5批量大小16，对此模型做了3个周期的微调。结果呈现在表4。BERTLARGE的性能优于该作者ESIM+ELMo系统的基线达+27.1％。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121223441.jpg" alt=""></p>
<p>表4：SWAG开发和测试精度。测试结果由SWAG作者们对其隐藏标签进行评分。如SWAG论文所述，人类性能是用100个样本测量的。</p>
<h2 id="Ablation-Studies">Ablation Studies</h2>
<p>虽然我们已经演示了极其强大的实验结果，但到目前为止所呈现的结果并未分离BERT框架各个方面的具体贡献。在本节中，我们将对BERT多个方面进行消模实验，以便更好地了解它们的相对重要性。(译注：Quora上对ablation study的解释：An ablation study typicallyrefers to removing some “feature” of the model or algorithm, and seeing howthat affects performance. 消模实验通常是指删除模型或算法的某些“特征”，并查看如何影响性能。ablation study是为研究模型中提出的一些结构是否有效而设计的实验。比如你提出了某结构，但要想确定这个结构是否有利于最终效果，就要将去掉该结构的模型与加上该结构的模型所得到的结果进行对比。ablation study直译为“消融研究”，意译是“模型简化测试”或“消模实验”。)</p>
<h3 id="预训练任务的影响">预训练任务的影响</h3>
<p>我们的核心主张之一是BERT的深度双向性，这是通过遮蔽LM预训练实现的，是BERT与以前工作相比最重要的改进。为证明这一主张，我们评估了两个使用完全相同预训练数据、微调方案和变换器超参数的BERTBASE新模型：</p>
<ul>
<li>无NSP：一种使用“遮蔽LM”(MLM)训练但没有“下一句预测”(NSP)任务的模型。</li>
<li>LTR＆NoNSP：使用从左到右(LTR)LM而不是MLM训练的模型。在这种情况下，我们预测每个输入单词，不应用任何遮蔽。左侧约束也用于微调，因为我们发现使用左侧语境预训练和双向语境微调，效果总是更差。此外，该模型在没有NSP任务的情况下做了预训练。这与OpenAIGPT直接相当，但使用我们更大的训练数据集、我们的输入表征和我们的微调方案。</li>
</ul>
<p>结果显示在表5中。我们首先检查NSP任务带来的影响。我们可以看到，删除NSP会严重损害QNLI，MNLI和SQuAD的性能。这些结果表明，我们的预训练方法对于获得先前提出的强有力的实证结果至关重要。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121223559.jpg" alt=""></p>
<p>表5：用BERTBASE架构做的预训练任务消融。“无NSP”是无下一句话预测任务的训练。“LTR＆无NSP”用作从左到右的LM，没有下一个句子预测，如OpenAI GPT的训练。“+ BiLSTM”在微调期间在“LTR +无NSP”模型上添加随机初始化BiLSTM。</p>
<p>接下来，我们通过比较“No NSP”与“LTR＆No NSP”来评估训练双向表征的影响。LTR模型在所有任务上的性能都比MLM模型差，在MRPC和SQuAD上有极大下降。对于SQuAD，直观清楚的是LTR模型在跨度和词块预测方面性能非常差，因为其词块级隐藏状态没有右侧语境。对于MRPC，目前尚不清楚性能不佳是由于其小数据量还是该任务本质，但我们发现这种不良性能在有很多随机重启的完整超参数扫描(full hyperparameter sweep)中是一致的。</p>
<p>为了诚心尝试加强该LTR系统，我们试着在其上面添加一个随机初始化BiLSTM做微调。这确实显着提升了SQuAD结果，但结果仍比预训练双向模型差得多。它还影响所有四个GLUE任务的性能。</p>
<p>我们认识到，也可以训练独立的LTR和RTL模型，并将每个词块表示为这两个模型的串联，如ELMo所做的那样。但是：(a) 这是单一双向模型的两倍代价；(b) 对于像QA这样的任务来说，这是不直观的，因为RTL模型无法对其问题的答案作出规定；© 它的强度远低于深度双向模型，因为深度双向模型可以选择使用左或右语境。</p>
<h3 id="模型大小的影响">模型大小的影响</h3>
<p>在本节，我们将探讨模型大小对微调任务准确性的影响。我们训练了许多具有不同层数、隐藏单元和注意头的BERT模型，与此同时，使用与前面描述的相同的超参数和训练过程。</p>
<p>选定GLUE任务的结果如表6所示。此表中，我们报告了5次随机重启微调的平均DevSet开发集精度。我们可以看到，较大的模型导致所有四个数据集的严格精度提高，即使对于仅有3,600个标记训练样例的MRPC，并且与预训练任务有很大不同。同样令人惊讶的是，我们能够在相对于现有文献已经相当大的模型之上实现这种显著改进。例如，Vaswani等人(2017)探索的其最大变换器，是(L=6，H=1024，A=16)有100M参数的编码器，我们在文献中找到的最大变换器是(L=64，H=512，A=2)有235M参数(Al-Rfou等，2018)。相比之下，BERTBASE包含110M参数，BERTLARGE包含340M参数。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121223624.jpg" alt=""></p>
<p>表6：BERT模型大小的消融。#L=层数; #H=隐藏的大小; #A=关注头数。“LM(ppl)”是保持训练数据的遮蔽LM混乱。</p>
<p>众所周知，增加模型尺寸将导致机器翻译和语言建模等大型任务的持续改进，这可通过表6中所示该LM训练数据的复杂性来证明。但是，我们相信这是第一个证明扩展到极端模型尺寸的工作也可以在非常小规模的任务上实现大幅改进，前提是该模型已经过充分预训练。</p>
<h3 id="训练步数的影响">训练步数的影响</h3>
<p>图4呈现了从已预训练k步的检查点进行微调后的MNLI Dev精度。这使我们可以回答以下问题：</p>
<ol>
<li>
<p>问题：BERT是否真的需要如此大量预训练(128,000字/批$\star$1,000,000步)才能实现高微调精度？<br>
答：是的，当训练1M步时，BERTBASE在MNLI上实现了近1.0％的额外准确度，而步数为500k。</p>
</li>
<li>
<p>问题：MLM预训练是否比LTR预训练收敛慢，因为每批只有15％的单词被预测而不是每个单词？<br>
答：MLM模型的收敛速度略慢于LTR模型。然而，就绝对精度而言，MLM模型几乎立即开始优于LTR模型。</p>
</li>
</ol>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121223704.jpg" alt=""></p>
<p>图4：多次训练步骤的消融。这显示了微调后的MNLI精度，从已经预训练了k步的模型参数开始。x轴是k的值。</p>
<h3 id="基于特征的BERT方法">基于特征的BERT方法</h3>
<p>到目前为止呈现的所有BERT结果都使用了微调方法，其中将一个简单分类层添加到预训练模型，并且所有参数在下游任务上联合微调。然而，基于特征的方法具有某些优点，其固定特征从预训练模型中提取。首先，并非所有NLP任务都可以通过变换器编码器架构轻松表示，因此需要添加特定于任务的模型架构。其次，主要计算益处在于能够一旦预计算其训练数据的一个高开销表征，就在该表征顶部使用较少开销模型运行多次实验。</p>
<p>在本节中，我们通过在CoNLL-2003 NER任务上生成类似ELMo预训练的语境表征，来评估基于特征的方法中BERT性能如何。为此，我们用4.3节相同的输入表征，但用其来自一层或多层的激活，而不微调任何BERT参数。这些语境嵌入用作分类层之前随机初始化的双层768维BiLSTM作为输入。</p>
<p>结果显示在表7中。性能最佳的方法是连接来自预训练变换器其顶部四个隐藏层的词块表征，微调此整个模型后仅为0.3 F1。这表明BERT对于微调和基于特征的方法都是有效的。</p>
<p><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121223720.jpg" alt=""></p>
<p>表7：用BERT和CoNLL-2003 NER基于特征的方法消模。将来自此指定层的激活做组合，并馈送到双层BiLSTM中，而不向BERT反向传播。</p>
<h2 id="结论">结论</h2>
<p>近期实验改进表明，使用迁移学习语言模型展示出的丰富、无监督预训练，是许多语言理解系统的集成部分。特别是，这些结果使得即使低资源任务，也能从很深的单向架构中受益。我们的主要贡献是将这些发现进一步推广到深度双向架构，允许其相同的预训练模型去成功解决一系列广泛的NLP任务。</p>
<p>虽然实验结果很强，在某些情况下超过人类性能，但重要的未来工作是研究BERT能不能捕获其语言现象。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Weitang Liu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://lonepatient.top/2018/12/20/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding.html">http://lonepatient.top/2018/12/20/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://lonepatient.top" target="_blank">闲记算法</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/NLP/">NLP</a><a class="post-meta__tags" href="/tags/BERT/">BERT</a><a class="post-meta__tags" href="/tags/Transformer/">Transformer</a></div><div class="post_share"><div class="social-share" data-image="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20190121221353.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2018/12/30/pytorch-styleguide.html"><img class="prev-cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210905124914.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">PyTorch常用代码段</div></div></a></div><div class="next-post pull-right"><a href="/2018/12/06/Pytorch-deep-learning.html"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Pytorch深度学习入门</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/05/16/ALBEF.html" title="Align before Fuse：Vision and Language Representation Learning with Momentum Distillation"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20231013155249.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-05-16</div><div class="title">Align before Fuse：Vision and Language Representation Learning with Momentum Distillation</div></div></a></div><div><a href="/2023/06/16/BLIP.html" title="BLIP：Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20231017163401.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-16</div><div class="title">BLIP：Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation</div></div></a></div><div><a href="/2023/06/16/BLIP2.html" title="BLIP-2：Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20231017202735.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-06-16</div><div class="title">BLIP-2：Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models</div></div></a></div><div><a href="/2019/09/28/2019_daguan_info_extract_competition.html" title="2019达观杯信息提取第九名方案"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/092819170162_0sk2ppt_1.Jpeg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-09-28</div><div class="title">2019达观杯信息提取第九名方案</div></div></a></div><div><a href="/2023/03/02/8-bit_Matrix_Multiplication_transformers_Hugging_Face_Transformers.html" title="用于大型Transformer的8-bit矩阵乘法介绍"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230324140620.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-03-02</div><div class="title">用于大型Transformer的8-bit矩阵乘法介绍</div></div></a></div><div><a href="/2019/10/20/ALBERT.html" title="ALBERT-A Lite BERT For Self-Supervised Learning Of Language Representations"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/20200726122519.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-10-20</div><div class="title">ALBERT-A Lite BERT For Self-Supervised Learning Of Language Representations</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Weitang Liu</div><div class="author-info__description">一个致力于记录技术的博客</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">266</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">306</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">70</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/lonePatient"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/lonePatient" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:liuweitangmath@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://weibo.com/277974397" target="_blank" title="Weibo"><i class="fab fa-weibo"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有任何问题可通过留言板或者微信公众号给我留言，谢谢！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%91%98%E8%A6%81"><span class="toc-number">1.</span> <span class="toc-text">摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.</span> <span class="toc-text">介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-number">3.</span> <span class="toc-text">相关工作</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%89%B9%E5%BE%81%E6%96%B9%E6%B3%95"><span class="toc-number">3.1.</span> <span class="toc-text">基于特征方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83%E6%96%B9%E6%B3%95"><span class="toc-number">3.2.</span> <span class="toc-text">微调方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%A9%E7%94%A8%E7%9B%91%E7%9D%A3%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0"><span class="toc-number">3.3.</span> <span class="toc-text">利用监督数据迁移学习</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#BERT"><span class="toc-number">4.</span> <span class="toc-text">BERT</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E6%9E%B6%E6%9E%84"><span class="toc-number">4.1.</span> <span class="toc-text">模型架构</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E4%BB%BB%E5%8A%A1"><span class="toc-number">4.2.</span> <span class="toc-text">预训练任务</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1-1%EF%BC%9AMLM"><span class="toc-number">4.2.1.</span> <span class="toc-text">任务#1：MLM</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BB%BB%E5%8A%A1-2%EF%BC%9A%E4%B8%8B%E4%B8%80%E5%8F%A5%E9%A2%84%E6%B5%8B"><span class="toc-number">4.2.2.</span> <span class="toc-text">任务#2：下一句预测</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="toc-number">4.3.</span> <span class="toc-text">预训练过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BE%AE%E8%B0%83%E8%BF%87%E7%A8%8B"><span class="toc-number">4.4.</span> <span class="toc-text">微调过程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#BERT%E5%92%8COpenAI-GPT%E6%AF%94%E8%BE%83"><span class="toc-number">4.5.</span> <span class="toc-text">BERT和OpenAI GPT比较</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C"><span class="toc-number">5.</span> <span class="toc-text">实验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#GLUE%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">5.1.</span> <span class="toc-text">GLUE数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#GLUE%E7%BB%93%E6%9E%9C"><span class="toc-number">5.1.1.</span> <span class="toc-text">GLUE结果</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%AF%E5%9D%A6%E7%A6%8F%E9%97%AE%E7%AD%94%E6%95%B0%E6%8D%AE%E9%9B%86-SQuAD-v1-1"><span class="toc-number">5.2.</span> <span class="toc-text">斯坦福问答数据集 SQuAD v1.1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%91%BD%E5%90%8D%E5%AE%9E%E4%BD%93%E8%AF%86%E5%88%AB"><span class="toc-number">5.3.</span> <span class="toc-text">命名实体识别</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%8A%97%E7%94%9F%E6%88%90%E6%83%85%E5%A2%83%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%88SWAG%EF%BC%89"><span class="toc-number">5.4.</span> <span class="toc-text">对抗生成情境数据集（SWAG）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Ablation-Studies"><span class="toc-number">6.</span> <span class="toc-text">Ablation Studies</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E4%BB%BB%E5%8A%A1%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">6.1.</span> <span class="toc-text">预训练任务的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E5%A4%A7%E5%B0%8F%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">6.2.</span> <span class="toc-text">模型大小的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%AD%A5%E6%95%B0%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">6.3.</span> <span class="toc-text">训练步数的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%89%B9%E5%BE%81%E7%9A%84BERT%E6%96%B9%E6%B3%95"><span class="toc-number">6.4.</span> <span class="toc-text">基于特征的BERT方法</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BB%93%E8%AE%BA"><span class="toc-number">7.</span> <span class="toc-text">结论</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/10/31/arxiv_papers_2025-10-31.html" title="Arxiv今日论文 | 2025-10-31"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2025-10-31"/></a><div class="content"><a class="title" href="/2025/10/31/arxiv_papers_2025-10-31.html" title="Arxiv今日论文 | 2025-10-31">Arxiv今日论文 | 2025-10-31</a><time datetime="2025-10-31T10:30:00.000Z" title="发表于 2025-10-31 10:30:00">2025-10-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/10/30/arxiv_papers_2025-10-30.html" title="Arxiv今日论文 | 2025-10-30"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2025-10-30"/></a><div class="content"><a class="title" href="/2025/10/30/arxiv_papers_2025-10-30.html" title="Arxiv今日论文 | 2025-10-30">Arxiv今日论文 | 2025-10-30</a><time datetime="2025-10-30T10:30:00.000Z" title="发表于 2025-10-30 10:30:00">2025-10-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/10/29/arxiv_papers_2025-10-29.html" title="Arxiv今日论文 | 2025-10-29"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2025-10-29"/></a><div class="content"><a class="title" href="/2025/10/29/arxiv_papers_2025-10-29.html" title="Arxiv今日论文 | 2025-10-29">Arxiv今日论文 | 2025-10-29</a><time datetime="2025-10-29T10:30:00.000Z" title="发表于 2025-10-29 10:30:00">2025-10-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/10/28/arxiv_papers_2025-10-28.html" title="Arxiv今日论文 | 2025-10-28"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2025-10-28"/></a><div class="content"><a class="title" href="/2025/10/28/arxiv_papers_2025-10-28.html" title="Arxiv今日论文 | 2025-10-28">Arxiv今日论文 | 2025-10-28</a><time datetime="2025-10-28T10:30:00.000Z" title="发表于 2025-10-28 10:30:00">2025-10-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/10/27/arxiv_papers_2025-10-27.html" title="Arxiv今日论文 | 2025-10-27"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2025-10-27"/></a><div class="content"><a class="title" href="/2025/10/27/arxiv_papers_2025-10-27.html" title="Arxiv今日论文 | 2025-10-27">Arxiv今日论文 | 2025-10-27</a><time datetime="2025-10-27T10:30:00.000Z" title="发表于 2025-10-27 10:30:00">2025-10-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By Weitang Liu</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'https://twikoo.lonepatient.top/',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'https://twikoo.lonepatient.top/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo@1.4.11/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (95)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/计算机视觉/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 计算机视觉 (16)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/知识图谱/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 知识图谱 (13)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 深度学习 (135)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><a class="magnet_link_more"  href="http://lonepatient.top/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230219144729.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-02-18</span><a class="blog-slider__title" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt="">通向AGI之路：大型语言模型（LLM）技术精要</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/07/12/gaiic_2022_ner_top10.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20220712181905.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-07-12</span><a class="blog-slider__title" href="2022/07/12/gaiic_2022_ner_top10.html" alt="">GAIIC2022商品标题识别二等奖获奖解决思路</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2022/07/12/gaiic_2022_ner_top10.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230807190424.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-01-20</span><a class="blog-slider__title" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt="">2025-03|高质量中文预训练模型集合</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>