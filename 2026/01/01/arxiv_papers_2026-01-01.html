<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv今日论文 | 2026-01-01 | 闲记算法</title><meta name="keywords" content="Arxiv"><meta name="author" content="Weitang Liu"><meta name="copyright" content="Weitang Liu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要内容为 2026-01-01 从Arxiv.org论文网站获取的最新论文列表，自动更新，按照NLP、CV、ML、AI、IR五个大方向区分，若需要邮件定时接收，请在评论区留下你的邮箱号。 说明：每日论文数据从Arxiv.org获取，每天早上12:00左右定时自动更新。  友情提示: 如何您需要邮箱接收每日论文数据，请在评论处留下你的邮箱。  目录  概览 自然语言处理CL 人工智能AI">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv今日论文 | 2026-01-01">
<meta property="og:url" content="http://lonepatient.top/2026/01/01/arxiv_papers_2026-01-01.html">
<meta property="og:site_name" content="闲记算法">
<meta property="og:description" content="本篇博文主要内容为 2026-01-01 从Arxiv.org论文网站获取的最新论文列表，自动更新，按照NLP、CV、ML、AI、IR五个大方向区分，若需要邮件定时接收，请在评论区留下你的邮箱号。 说明：每日论文数据从Arxiv.org获取，每天早上12:00左右定时自动更新。  友情提示: 如何您需要邮箱接收每日论文数据，请在评论处留下你的邮箱。  目录  概览 自然语言处理CL 人工智能AI">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png">
<meta property="article:published_time" content="2026-01-01T10:30:00.000Z">
<meta property="article:modified_time" content="2026-02-27T07:52:12.753Z">
<meta property="article:author" content="Weitang Liu">
<meta property="article:tag" content="Arxiv">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://lonepatient.top/2026/01/01/arxiv_papers_2026-01-01"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//s4.cnzz.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script async="async" data-pjax="data-pjax" src="https://s4.cnzz.com/z_stat.php?id=1273275888&amp;web_id=1273275888"></script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2026-02-27 07:52:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/backgroud.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><script src="https://at.alicdn.com/t/c/font_3570527_dthoqrrv2tv.css"></script><script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script><script>LA.init({id:"JwRQtLKZggvJH4sJ",ck:"JwRQtLKZggvJH4sJ"})</script><link rel="stylesheet" href="/css/universe.css"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3536467946304280" crossorigin="anonymous"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">281</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">384</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">92</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 网站</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.aitoolist.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集合</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.deepdh.com"><i class="fa-fw fa fa-star"></i><span> AI工具导航</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.ai-lib.club"><i class="fa-fw fa fa-star"></i><span> 人工智能工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ai-bot.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 教程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://learningprompt.wiki/"><i class="fa-fw fa fa-star"></i><span> Prompt教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 在线</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fa fa-star"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">闲记算法</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 网站</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.aitoolist.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集合</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.deepdh.com"><i class="fa-fw fa fa-star"></i><span> AI工具导航</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.ai-lib.club"><i class="fa-fw fa fa-star"></i><span> 人工智能工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ai-bot.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 教程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://learningprompt.wiki/"><i class="fa-fw fa fa-star"></i><span> Prompt教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 在线</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fa fa-star"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv今日论文 | 2026-01-01<a class="post-edit-link" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts/arxiv_papers_2026-01-01.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2026-01-01T10:30:00.000Z" title="发表于 2026-01-01 10:30:00">2026-01-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-02-27T07:52:12.753Z" title="更新于 2026-02-27 07:52:12">2026-02-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E6%9C%AF%E4%BC%9A%E8%AE%AE/">学术会议</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E6%9C%AF%E4%BC%9A%E8%AE%AE/Arxiv/">Arxiv</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">189.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>905分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2026/01/01/arxiv_papers_2026-01-01.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要内容为 2026-01-01 从<a target="_blank" rel="noopener" href="https://arxiv.org">Arxiv.org</a>论文网站获取的最新论文列表，自动更新，按照NLP、CV、ML、AI、IR五个大方向区分，若需要邮件定时接收，请在评论区留下你的邮箱号。</p>
<div class="note info flat"><p>说明：每日论文数据从<a target="_blank" rel="noopener" href="https://arxiv.org">Arxiv.org</a>获取，每天早上12:00左右定时自动更新。</p>
</div>
<div class="note warning flat"><p>友情提示: 如何您需要<strong>邮箱</strong>接收每日论文数据，请在评论处留下你的邮箱。</p>
</div>
<h2 id="目录">目录</h2>
<ul>
<li><a href="#%E6%A6%82%E8%A7%88">概览</a></li>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86">自然语言处理CL</a></li>
<li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">人工智能AI</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习LG</a></li>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">计算机视觉CV</a></li>
<li><a href="#%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2">信息检索IR</a></li>
</ul>
<h3 id="概览-2026-01-01">概览 (2026-01-01)</h3>
<p>今日共更新<strong>606</strong>篇论文,其中:</p>
<ul>
<li><strong>自然语言处理</strong>共<strong>87</strong>篇(Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>))</li>
<li><strong>人工智能</strong>共<strong>179</strong>篇(Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>))</li>
<li><strong>计算机视觉</strong>共<strong>124</strong>篇(Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>))</li>
<li><strong>机器学习</strong>共<strong>176</strong>篇(Machine Learning (cs.LG))</li>
</ul>
<h3 id="自然语言处理">自然语言处理</h3>
<div class="note orange no-icon flat"><p>[NLP-0] Scaling Open-Ended <mark class="hl-label green">Reasoning</mark>  to Predict the Future</p>
<p>【速读】： 该论文旨在解决高风险决策中基于不确定未来进行推理的问题，核心挑战在于如何训练语言模型以准确、可靠地生成开放性预测。解决方案的关键在于构建一个名为OpenForesight的自动化数据集，通过从每日新闻中合成新颖的预测问题，并采用离线新闻语料库确保训练与评估过程中不泄露未来信息；同时，利用小规模验证集优化检索机制和强化学习（Reinforcement Learning, RL）的奖励函数，最终获得性能优越且校准良好的预测模型OpenForecaster 8B，其在多个基准测试上展现出优于大型专有模型的能力，并实现了开源以推动相关研究发展。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25070">https://arxiv.org/abs/2512.25070</a><br>
<strong>作者</strong>: Nikhil Chandak,Shashwat Goel,Ameya Prabhu,Moritz Hardt,Jonas Geiping<br>
<strong>机构</strong>: Max Planck Institute for Intelligent Systems (马克斯·普朗克智能系统研究所); ELLIS Institute Tübingen (图宾根ELLIS研究所); Tübingen AI Center (图宾根人工智能中心); University of Tübingen (图宾根大学)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  45 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:High-stakes decision making involves reasoning under uncertainty about the future. In this work, we train language models to make predictions on open-ended forecasting questions. To scale up training data, we synthesize novel forecasting questions from global events reported in daily news, using a fully automated, careful curation recipe. We train the Qwen3 thinking models on our dataset, OpenForesight. To prevent leakage of future information during training and evaluation, we use an offline news corpus, both for data generation and retrieval in our forecasting system. Guided by a small validation set, we show the benefits of retrieval, and an improved reward function for reinforcement learning (RL). Once we obtain our final forecasting system, we perform held-out testing between May to August 2025. Our specialized model, OpenForecaster 8B, matches much larger proprietary models, with our training improving the accuracy, calibration, and consistency of predictions. We find calibration improvements from forecasting training generalize across popular benchmarks. We open-source all our models, code, and data to make research on language model forecasting broadly accessible.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-1] Many Minds from One Model: Bayesian Transformers for Population Intelligence</p>
<p>【速读】： 该论文旨在解决现代Transformer模型在训练中普遍存在的“单向思维”问题，即通过优化得到单一确定性参数集，导致模型行为缺乏多样性且难以支持群体智能式的决策机制。为应对这一挑战，作者提出Population Bayesian Transformers (B-Trans)，其核心创新在于引入一种贝叶斯动机的后验代理（posterior proxy），将归一化层中的偏置型偏移量视为具有高斯变分近似的随机变量，从而在不训练完整贝叶斯神经网络的前提下，从预训练权重中采样出多样且连贯的模型实例。关键在于通过冻结序列级别的采样噪声以保证生成过程中的时序一致性，同时利用群体预测聚合实现更优的探索能力，在零样本生成、带可验证奖励的强化学习（RLVR）及无标签强化学习任务中均展现出优于确定性基线的语义多样性和任务性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25063">https://arxiv.org/abs/2512.25063</a><br>
<strong>作者</strong>: Diji Yang,Yi Zhang<br>
<strong>机构</strong>: University of California Santa Cruz (加州大学圣克鲁兹分校)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Despite their scale and success, modern transformers are almost universally trained as single-minded systems: optimization produces one deterministic set of parameters, representing a single functional hypothesis about the data. Motivated by the idea that intelligence emerge from many minds, we propose Population Bayesian Transformers (B-Trans), which transform a standard Large Language Model into a Bayesian Transformer model to supports sampling diverse yet coherent model instances from a single set of pre-trained weights. B-Trans introduces a Bayesian-motivated posterior proxy by treating the bias-like offsets in normalization layers as stochastic variables with a Gaussian variational approximation, inducing a distribution over model behavior without the cost of training full Bayesian neural networks. Sampling from this proxy yields a set of model instances with diverse behaviors while maintaining general competence. To preserve coherence within each generation, we freeze the sampled noise at the sequence level, enforcing temporal consistency across tokens. B-Trans allows for population-level decision-making, where aggregating predictions across sampled individuals significantly enhances exploration. Experiments across zero-shot generation, Reinforcement Learning with Verifiable Rewards (RLVR), and RL without explicit labels demonstrate that B-Trans effectively leverage the wisdom of crowds, yielding superior semantic diversity while achieving better task performance compared to deterministic baselines.         Subjects:  Machine Learning (cs.LG); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)  Cite as: arXiv:2512.25063 [cs.LG]    (or  arXiv:2512.25063v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.25063">https://doi.org/10.48550/arXiv.2512.25063</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-2] AdaGReS:Adaptive Greedy Context Selection via Redundancy-Aware Scoring for Token-Budgeted <mark class="hl-label green">RAG</mark></p>
<p>【速读】： 该论文旨在解决检索增强生成（Retrieval-Augmented Generation, RAG）中因标准Top-k检索返回冗余或近似重复文本块而导致的token预算浪费和下游生成质量下降的问题。解决方案的关键在于提出AdaGReS框架，其核心是设计一个集合级目标函数，同时优化查询-文本块相关性与组内冗余惩罚，并通过基于边际增益的贪心选择策略在token预算约束下进行高效上下文筛选；此外，该方法引入一种闭式、实例自适应的相关性-冗余权衡参数校准机制，无需人工调参即可根据候选池统计特征和预算限制动态调整，从而实现更优的冗余控制与上下文质量提升。理论分析进一步表明，该目标函数在实际嵌入相似度条件下具有ε-近似子模性，为贪心选择提供了近最优性保证。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25052">https://arxiv.org/abs/2512.25052</a><br>
<strong>作者</strong>: Chao Peng,Bin Wang,Zhilei Long,Jinfang Sheng<br>
<strong>机构</strong>: Central South University (中南大学); Yizhi Intelligent (YZInt) (易智智能)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
<strong>备注</strong>:  Preprint. Under review</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Retrieval-augmented generation (RAG) is highly sensitive to the quality of selected context, yet standard top-k retrieval often returns redundant or near-duplicate chunks that waste token budget and degrade downstream generation. We present AdaGReS, a redundancy-aware context selection framework for token-budgeted RAG that optimizes a set-level objective combining query-chunk relevance and intra-set redundancy penalties. AdaGReS performs greedy selection under a token-budget constraint using marginal gains derived from the objective, and introduces a closed-form, instance-adaptive calibration of the relevance-redundancy trade-off parameter to eliminate manual tuning and adapt to candidate-pool statistics and budget limits. We further provide a theoretical analysis showing that the proposed objective exhibits epsilon-approximate submodularity under practical embedding similarity conditions, yielding near-optimality guarantees for greedy selection. Experiments on open-domain question answering (Natural Questions) and a high-redundancy biomedical (drug) corpus demonstrate consistent improvements in redundancy control and context quality, translating to better end-to-end answer quality and robustness across settings.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-3] Modeling Language as a Sequence of Thoughts</p>
<p>【速读】： 该论文旨在解决传统Transformer语言模型在生成自然文本时因依赖表面级共现统计而缺乏全局一致的实体与事件潜在表征的问题，这导致了关系方向错误（如父子反转陷阱）、上下文理解偏差以及数据利用效率低下等缺陷。其解决方案的关键在于提出Thought Gestalt (TG)模型，这是一种递归式Transformer架构，通过双层抽象建模语言：一是词元（token）级别，二是句子级别的“思想状态”（thought states）。TG在生成每句话时交叉注意力于先前句子表示的记忆池，并使用相同参数集和单一目标函数（下一个词的交叉熵损失）同步优化词元与句子表征；通过保留句子表示写入记忆的计算图，未来词元损失的梯度可反向传播至跨注意力机制，从而优化早期句子向量的生成参数，实现更高效且具逻辑一致性的语言建模。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25026">https://arxiv.org/abs/2512.25026</a><br>
<strong>作者</strong>: Nasim Borazjanizadeh,James McClelland<br>
<strong>机构</strong>: Stanford University (斯坦福大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Transformer language models can generate strikingly natural text by modeling language as a sequence of tokens. Yet, by relying primarily on surface-level co-occurrence statistics, they fail to form globally consistent latent representations of entities and events, lack of which contributes to brittleness in relational direction (e.g., reversal curse), contextualization errors, and data inefficiency. On the other hand, cognitive science shows that human comprehension involves converting the input linguistic stream into compact, event-like representations that persist in memory while verbatim form is short-lived. Motivated by this view, we introduce Thought Gestalt (TG) model, a recurrent Transformer that models language at two levels of abstraction - tokens and sentence-level “thought” states. TG generates the tokens of one sentence at a time while cross-attending to a memory of prior sentence representations. In TG, token and sentence representations are generated using the same set of model parameters and trained with a single objective, the next-token cross-entropy: by retaining the computation graph of sentence representations written to memory, gradients from future token losses flow backward through cross-attention to optimize the parameters generating earlier sentence vectors. In scaling experiments, TG consistently improves efficiency over matched GPT-2 runs, among other baselines, with scaling fits indicating GPT-2 requires ~5-8% more data and ~33-42% more parameters to match TG’s loss. TG also reduces errors on relational direction generalization on a father-son reversal curse probe.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-4] MAMA-Memeia! Multi-Aspect Multi-<mark class="hl-label green">Agent</mark>  Collaboration for Depressive Symptoms Identification in Memes <mark class="hl-label red">AAAI2026</mark></p>
<p>【速读】： 该论文旨在解决如何有效识别社交媒体中用户通过表情包（meme）表达的抑郁症状这一问题。当前，表情包已从单纯的幽默交流工具演变为承载复杂情绪表达的重要载体，尤其在反映抑郁情绪方面具有潜在价值，但缺乏系统性的检测方法。解决方案的关键在于提出MAMAMemeia框架，这是一个基于临床心理学认知分析疗法（Cognitive Analytic Therapy, CAT）能力的多智能体多维度协作讨论机制，通过结合大语言模型（Large Language Model, LLM）生成的解释与人工标注的语义信息，显著提升了对抑郁相关表情包的识别性能，在宏平均F1分数上较现有最优方法提升7.55%，并确立了新的基准。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25015">https://arxiv.org/abs/2512.25015</a><br>
<strong>作者</strong>: Siddhant Agarwal,Adya Dhuler,Polly Ruhnke,Melvin Speisman,Md Shad Akhtar,Shweta Yadav<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  Accepted by AAAI 2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Over the past years, memes have evolved from being exclusively a medium of humorous exchanges to one that allows users to express a range of emotions freely and easily. With the ever-growing utilization of memes in expressing depressive sentiments, we conduct a study on identifying depressive symptoms exhibited by memes shared by users of online social media platforms. We introduce RESTOREx as a vital resource for detecting depressive symptoms in memes on social media through the Large Language Model (LLM) generated and human-annotated explanations. We introduce MAMAMemeia, a collaborative multi-agent multi-aspect discussion framework grounded in the clinical psychology method of Cognitive Analytic Therapy (CAT) Competencies. MAMAMemeia improves upon the current state-of-the-art by 7.55% in macro-F1 and is established as the new benchmark compared to over 30 methods.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-5] Classifying long legal documents using short random chunks</p>
<p>【速读】： 该论文旨在解决法律文书分类中因文档长度过长导致基于Transformer的模型难以高效处理的问题，尤其在计算资源受限或对时效性要求较高的场景下。其解决方案的关键在于采用一种混合架构：利用DeBERTa V3提取短文本片段（每段最大128个token）的语义特征，并通过LSTM对随机选取的48个片段进行聚合建模，从而有效压缩输入规模并保留关键信息；同时，借助Temporal构建可靠的部署流水线，在CPU环境下实现稳定且高效的批量处理，平均处理100份文件耗时498秒，最终模型达到加权F-score为0.898的分类性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24997">https://arxiv.org/abs/2512.24997</a><br>
<strong>作者</strong>: Luis Adrián Cabrera-Diego<br>
<strong>机构</strong>: Jus Mundi (Jus Mundi)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Classifying legal documents is a challenge, besides their specialized vocabulary, sometimes they can be very long. This means that feeding full documents to a Transformers-based models for classification might be impossible, expensive or slow. Thus, we present a legal document classifier based on DeBERTa V3 and a LSTM, that uses as input a collection of 48 randomly-selected short chunks (max 128 tokens). Besides, we present its deployment pipeline using Temporal, a durable execution solution, which allow us to have a reliable and robust processing workflow. The best model had a weighted F-score of 0.898, while the pipeline running on CPU had a processing median time of 498 seconds per 100 files.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-6] CPJ: Explainable Agricultural Pest Diagnosis via Caption-Prompt-Judge with <mark class="hl-label green">LLM</mark> -Judged Refinement</p>
<p>【速读】： 该论文旨在解决农业病害诊断中模型依赖昂贵的监督微调（supervised fine-tuning）且在领域偏移（domain shift）下性能下降的问题。其核心解决方案是提出一种无需训练的少样本框架 Caption–Prompt–Judge (CPJ)，通过结构化、可解释的图像描述增强 Agri-Pest 视觉问答（VQA）任务。CPJ 的关键在于利用大视觉语言模型（vision-language models, VLMs）生成多角度图像描述，并通过 LLM-as-Judge 模块迭代优化这些描述，进而驱动双答案视觉问答流程，实现病害识别与管理建议的联合推理，从而在不进行微调的情况下显著提升诊断准确性和可解释性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24947">https://arxiv.org/abs/2512.24947</a><br>
<strong>作者</strong>: Wentao Zhang,Tao Fang,Lina Lu,Lifei Wang,Weihe Zhong<br>
<strong>机构</strong>: 1. 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  This paper is 6 pages in length and contains 2 figures. Tao Fang (Corresponding Author), Lina Lu (Co-corresponding Author)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Accurate and interpretable crop disease diagnosis is essential for agricultural decision-making, yet existing methods often rely on costly supervised fine-tuning and perform poorly under domain shifts. We propose Caption–Prompt–Judge (CPJ), a training-free few-shot framework that enhances Agri-Pest VQA through structured, interpretable image captions. CPJ employs large vision-language models to generate multi-angle captions, refined iteratively via an LLM-as-Judge module, which then inform a dual-answer VQA process for both recognition and management responses. Evaluated on CDDMBench, CPJ significantly improves performance: using GPT-5-mini captions, GPT-5-Nano achieves \textbf+22.7 pp in disease classification and \textbf+19.5 points in QA score over no-caption baselines. The framework provides transparent, evidence-based reasoning, advancing robust and explainable agricultural diagnosis without fine-tuning. Our code and data are publicly available at: this https URL.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-7] RAIR: A Rule-Aware Benchmark Uniting Challenging Long-Tail and Visual Salience Subset for E-commerce Relevance Assessment</p>
<p>【速读】： 该论文旨在解决当前电商搜索相关性评估基准缺乏足够复杂性的问题，导致行业在生成式 AI（Generative AI）相关性模型的评估上缺乏统一标准。其解决方案的关键在于提出一个名为 Rule-Aware benchmark with Image for Relevance assessment (RAIR) 的中文数据集，该数据集基于真实场景构建，建立了标准化的相关性评估框架，并引入一套通用规则作为评估基础；同时，RAIR 设计了三个子集——通用子集、长尾难点子集和视觉显著性子集，分别用于评估模型的基础能力、极限性能以及多模态理解能力，从而为 LLM 和视觉语言模型（VLM）提供全面、可比较的评测基准。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24943">https://arxiv.org/abs/2512.24943</a><br>
<strong>作者</strong>: Chenji Lu,Zhuo Chen,Hui Zhao,Zhenyi Wang,Pengjie Wang,Jian Xu,Bo Zheng<br>
<strong>机构</strong>: Taobao &amp; Tmall Group of Alibaba(淘宝与天猫集团阿里巴巴); Alibaba(阿里巴巴)<br>
<strong>类目</strong>: Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Search relevance plays a central role in web e-commerce. While large language models (LLMs) have shown significant results on relevance task, existing benchmarks lack sufficient complexity for comprehensive model assessment, resulting in an absence of standardized relevance evaluation metrics across the industry. To address this limitation, we propose Rule-Aware benchmark with Image for Relevance assessment(RAIR), a Chinese dataset derived from real-world scenarios. RAIR established a standardized framework for relevance assessment and provides a set of universal rules, which forms the foundation for standardized evaluation. Additionally, RAIR analyzes essential capabilities required for current relevance models and introduces a comprehensive dataset consists of three subset: (1) a general subset with industry-balanced sampling to evaluate fundamental model competencies; (2) a long-tail hard subset focus on challenging cases to assess performance limits; (3) a visual salience subset for evaluating multimodal understanding capabilities. We conducted experiments on RAIR using 14 open and closed-source models. The results demonstrate that RAIR presents sufficient challenges even for GPT-5, which achieved the best performance. RAIR data are now available, serving as an industry benchmark for relevance assessment while providing new insights into general LLM and Visual Language Model(VLM) evaluation.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-8] Iterative Deployment Improves <mark class="hl-label green">Planning</mark>  Skills in <mark class="hl-label green">LLM</mark> s</p>
<p>【速读】： 该论文旨在解决如何通过迭代部署大型语言模型（Large Language Models, LLMs）来持续提升其在规划任务中的性能问题。解决方案的关键在于：每次迭代中，用户基于前一版本模型的输出结果进行数据筛选与标注，并用于微调下一版本模型；这一过程本质上构成了外层强化学习（Reinforcement Learning, RL）机制，其中奖励函数是隐式定义的，而非显式设定。该方法不仅显著提升了模型的规划能力，还促发了超出初始模型能力的泛化行为，如生成更长的计划序列，同时揭示了一种无需显式奖励信号即可实现性能进化的替代训练范式。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24940">https://arxiv.org/abs/2512.24940</a><br>
<strong>作者</strong>: Augusto B. Corrêa,Yoav Gelberg,Luckeciano C. Melo,Ilia Shumailov,André G. Pereira,Yarin Gal<br>
<strong>机构</strong>: University of Oxford (牛津大学); AI Sequrity Company (AI安全公司); UFRGS (联邦里奥格兰德 do Sul大学)<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We show that iterative deployment of large language models (LLMs), each fine-tuned on data carefully curated by users from the previous models’ deployment, can significantly change the properties of the resultant models. By testing this mechanism on various planning domains, we observe substantial improvements in planning skills, with later models displaying emergent generalization by discovering much longer plans than the initial models. We then provide theoretical analysis showing that iterative deployment effectively implements reinforcement learning (RL) training in the outer-loop (i.e. not as part of intentional model training), with an implicit reward function. The connection to RL has two important implications: first, for the field of AI safety, as the reward function entailed by repeated deployment is not defined explicitly, and could have unexpected implications to the properties of future model deployments. Second, the mechanism highlighted here can be viewed as an alternative training regime to explicit RL, relying on data curation rather than explicit rewards.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-9] Vibe Coding Interface Flattening</p>
<p>【速读】： 该论文试图解决的问题是：生成式 AI（Generative AI）驱动的“ vibe coding”现象如何重构编程实践及其背后的权力结构，尤其是在看似民主化技术能力的同时，如何通过接口扁平化（interface flattening）将控制权和意义建构权力重新分配给模型与协议提供者。解决方案的关键在于从媒介物质性（materialist media theory）视角出发，揭示 vibe coding 并非对传统编程界面的简单简化，而是通过远程计算基础设施、延迟与连接性、结构化输出、工具调用机制及如 Model Context Protocol 等互操作标准，使原本分散在编程社区中的符号劳动与能力被集中化、私有化，并导致责任模糊化与新的依赖关系形成。这一分析为理解 AI 介导的人机交互的政治经济学提供了批判性框架。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24939">https://arxiv.org/abs/2512.24939</a><br>
<strong>作者</strong>: Hongrui Jin<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Human-Computer Interaction (cs.HC); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  16 pages, 1 figure</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language models are reshaping programming by enabling ‘vibe coding’: the development of softwares through natural-language interaction with model-driven toolchains. This article argues that vibe coding is best understood as interface flattening, a reconfiguration in which previously distinct modalities (GUI, CLI, and API) appear to converge into a single conversational surface, even as the underlying chain of translation from intention to machinic effect lengthens and thickens. Drawing on Friedrich Kittler’s materialist media theory and Alexander Galloway’s account of interfaces as sites of protocol control, the paper situates programming as a historically localised interface arrangement rather than an essential relation to computation. Through a materialist reconstruction of the contemporary vibe-coding stack, it shows how remote compute infrastructures, latency and connectivity, structured outputs, function/tool calling, and interoperability standards such as the Model Context Protocol relocate control and meaning-making power to model and protocol providers. The apparent democratisation of technical capability therefore depends on new dependencies and new literacies. By foregrounding the tension between experiential flattening and infrastructural thickening, I demonstrate how LLM-mediated development redistributes symbolic labour/power, obscures responsibility, and privatises competencies previously dispersed across programming communities, contributing a critical lens on the political economy of AI-mediated human-computer interaction.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-10] Adaptive Dependency-aware Prompt Optimization Framework for Multi-Step <mark class="hl-label green">LLM</mark>  Pipeline</p>
<p>【速读】： 该论文旨在解决多步大语言模型（Large Language Model, LLM）流水线中提示词（prompt）优化难题，特别是由于缺乏步骤级监督信号和步骤间依赖关系导致的联合优化困难问题。现有端到端提示优化方法在上述条件下表现不佳，常出现次优或不稳定的更新结果。其解决方案的关键在于提出ADOPT框架——一种自适应的依赖感知提示优化方法，通过显式建模每个LLM步骤与最终任务结果之间的依赖关系，实现类似解析导数的文本梯度估计；同时将文本梯度估计与梯度更新解耦，将多提示优化转化为灵活的单提示优化步骤，并引入基于Shapley值的机制动态分配优化资源，从而提升优化的准确性与鲁棒性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24933">https://arxiv.org/abs/2512.24933</a><br>
<strong>作者</strong>: Minjun Zhao,Xinyu Zhang,Shuai Zhang,Deyang Li,Ruifeng Shi<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multi-step LLM pipelines invoke large language models multiple times in a structured sequence and can effectively solve complex tasks, but their performance heavily depends on the prompts used at each step. Jointly optimizing these prompts is difficult due to missing step-level supervision and inter-step dependencies. Existing end-to-end prompt optimization methods struggle under these conditions and often yield suboptimal or unstable updates. We propose ADOPT, an Adaptive Dependency-aware Prompt Optimization framework for multi-step LLM pipelines. ADOPT explicitly models the dependency between each LLM step and the final task outcome, enabling precise text-gradient estimation analogous to computing analytical derivatives. It decouples textual gradient estimation from gradient updates, reducing multi-prompt optimization to flexible single-prompt optimization steps, and employs a Shapley-based mechanism to adaptively allocate optimization resources. Experiments on real-world datasets and diverse pipeline structures show that ADOPT is effective and robust, consistently outperforming state-of-the-art prompt optimization baselines.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-11] BEDA: Belief Estimation as Probabilistic Constraints for Performing Strategic Dialogue Acts <mark class="hl-label red">AAMAS2026</mark></p>
<p>【速读】： 该论文旨在解决战略对话中代理（agent）执行不同对话行为时，如何有效利用信念估计结果以指导生成的问题。现有方法虽能准确估计信念，但缺乏将这些信念转化为具体对话行为的机制。解决方案的关键在于将信念估计建模为概率约束，并通过BEDA框架实现：该框架包含世界集合、信念估计器和条件生成器，其中条件生成器根据推断出的信念选择并生成符合战略意图的对话行为（如对抗性或对齐性行为）。这一机制使模型在多个任务场景下（如对抗性、合作性和谈判场景）均显著优于基线方法，证明了将信念估计作为约束来驱动生成是一种简洁且通用的有效策略。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24885">https://arxiv.org/abs/2512.24885</a><br>
<strong>作者</strong>: Hengli Li,Zhaoxin Yu,Qi Shen,Chenxi Li,Mengmeng Wang,Tinglang Wu,Yipeng Kang,Yuxuan Wang,Song-Chun Zhu,Zixia Jia,Zilong Zheng<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Computer Science and Game Theory (<a target="_blank" rel="noopener" href="http://cs.GT">cs.GT</a>); Multiagent Systems (<a target="_blank" rel="noopener" href="http://cs.MA">cs.MA</a>)<br>
<strong>备注</strong>:  Accepted by AAMAS 2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Strategic dialogue requires agents to execute distinct dialogue acts, for which belief estimation is essential. While prior work often estimates beliefs accurately, it lacks a principled mechanism to use those beliefs during generation. We bridge this gap by first formalizing two core acts Adversarial and Alignment, and by operationalizing them via probabilistic constraints on what an agent may generate. We instantiate this idea in BEDA, a framework that consists of the world set, the belief estimator for belief estimation, and the conditional generator that selects acts and realizes utterances consistent with the inferred beliefs. Across three settings, Conditional Keeper Burglar (CKBG, adversarial), Mutual Friends (MF, cooperative), and CaSiNo (negotiation), BEDA consistently outperforms strong baselines: on CKBG it improves success rate by at least 5.0 points across backbones and by 20.6 points with GPT-4.1-nano; on Mutual Friends it achieves an average improvement of 9.3 points; and on CaSiNo it achieves the optimal deal relative to all baselines. These results indicate that casting belief estimation as constraints provides a simple, general mechanism for reliable strategic dialogue.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-12] mHC: Manifold-Constrained Hyper-Connections</p>
<p>【速读】： 该论文旨在解决超连接（Hyper-Connections, HC）架构在扩展残差连接宽度和多样化连接模式时所引发的三大问题：一是破坏了残差连接固有的恒等映射（identity mapping）性质，导致训练不稳定和可扩展性受限；二是引入显著的内存访问开销。解决方案的关键在于提出流形约束超连接（Manifold-Constrained Hyper-Connections, mHC），通过将HC的残差连接空间投影到特定流形（manifold）上，恢复恒等映射性质，同时结合严格的基础设施优化以保障计算效率。实验证明，mHC在大规模训练中表现出更强的有效性和优越的可扩展性，为拓扑结构设计提供了新思路。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24880">https://arxiv.org/abs/2512.24880</a><br>
<strong>作者</strong>: Zhenda Xie,Yixuan Wei,Huanqi Cao,Chenggang Zhao,Chengqi Deng,Jiashi Li,Damai Dai,Huazuo Gao,Jiang Chang,Liang Zhao,Shangyan Zhou,Zhean Xu,Zhengyan Zhang,Wangding Zeng,Shengding Hu,Yuqing Wang,Jingyang Yuan,Lean Wang,Wenfeng Liang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recently, studies exemplified by Hyper-Connections (HC) have extended the ubiquitous residual connection paradigm established over the past decade by expanding the residual stream width and diversifying connectivity patterns. While yielding substantial performance gains, this diversification fundamentally compromises the identity mapping property intrinsic to the residual connection, which causes severe training instability and restricted scalability, and additionally incurs notable memory access overhead. To address these challenges, we propose Manifold-Constrained Hyper-Connections (mHC), a general framework that projects the residual connection space of HC onto a specific manifold to restore the identity mapping property, while incorporating rigorous infrastructure optimization to ensure efficiency. Empirical experiments demonstrate that mHC is effective for training at scale, offering tangible performance improvements and superior scalability. We anticipate that mHC, as a flexible and practical extension of HC, will contribute to a deeper understanding of topological architecture design and suggest promising directions for the evolution of foundational models.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-13] Let It Flow: <mark class="hl-label green">Agent</mark> ic Crafting on Rock and Roll Building the ROME Model within an Open <mark class="hl-label green">Agent</mark> ic Learning Ecosystem</p>
<p>【速读】： 该论文旨在解决当前开源社区中缺乏端到端、系统化基础设施来支持智能体大语言模型（Agent LLMs）在真实环境中的多轮交互式开发问题。其核心挑战在于如何高效地优化模型权重、生成高质量轨迹数据以及实现上下文工程的自动化。解决方案的关键在于提出一个名为Agentic Learning Ecosystem (ALE)的基础架构，包含三个核心组件：ROLL（用于权重优化的后训练框架）、ROCK（用于轨迹生成的沙箱环境管理器）和iFlow CLI（用于高效上下文工程的代理框架）。其中，创新性地引入了基于语义交互片段的策略对齐算法（Interaction-based Policy Alignment, IPA），通过在语义单元而非单个token上分配信用，显著提升了长时程训练的稳定性，并结合百万级轨迹数据合成协议构建了开源智能体模型ROME，验证了该生态系统的有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24873">https://arxiv.org/abs/2512.24873</a><br>
<strong>作者</strong>: Weixun Wang,XiaoXiao Xu,Wanhe An,Fangwen Dai,Wei Gao,Yancheng He,Ju Huang,Qiang Ji,Hanqi Jin,Xiaoyang Li,Yang Li,Zhongwen Li,Shirong Lin,Jiashun Liu,Zenan Liu,Tao Luo,Dilxat Muhtar,Yuanbin Qu,Jiaqiang Shi,Qinghui Sun,Yingshui Tan,Hao Tang,Runze Wang,Yi Wang,Zhaoguo Wang,Yanan Wu,Shaopan Xiong,Binchen Xu,Xander Xu,Yuchi Xu,Qipeng Zhang,Xixia Zhang,Haizhou Zhao,Jie Zhao,Shuaibing Zhao,Baihui Zheng,Jianhui Zheng,Suhang Zheng,Yanni Zhu,Mengze Cai,Kerui Cao,Xitong Chen,Yue Dai,Lifan Du,Tao Feng,Tao He,Jin Hu,Yijie Hu,Ziyu Jiang,Cheng Li,Xiang Li,Jing Liang,Chonghuan Liu,ZhenDong Liu,Haodong Mi,Yanhu Mo,Junjia Ni,Shixin Pei,Jingyu Shen,XiaoShuai Song,Cecilia Wang,Chaofan Wang,Kangyu Wang,Pei Wang,Tao Wang,Wei Wang,Ke Xiao,Mingyu Xu,Tiange Xu,Nan Ya,Siran Yang,Jianan Ye,Yaxing Zang,Duo Zhang,Junbo Zhang,Boren Zheng,Wanxi Deng,Ling Pan,Lin Qu,Wenbo Su,Jiamang Wang,Wei Wang,Hu Wei,Minggang Wu,Cheng Yu,Bing Zhao,Zhicheng Zheng,Bo Zheng<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  36 pages, 15 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Agentic crafting requires LLMs to operate in real-world environments over multiple turns by taking actions, observing outcomes, and iteratively refining artifacts. Despite its importance, the open-source community lacks a principled, end-to-end ecosystem to streamline agent development. We introduce the Agentic Learning Ecosystem (ALE), a foundational infrastructure that optimizes the production pipeline for agent LLMs. ALE consists of three components: ROLL, a post-training framework for weight optimization; ROCK, a sandbox environment manager for trajectory generation; and iFlow CLI, an agent framework for efficient context engineering. We release ROME (ROME is Obviously an Agentic Model), an open-source agent grounded by ALE and trained on over one million trajectories. Our approach includes data composition protocols for synthesizing complex behaviors and a novel policy optimization algorithm, Interaction-based Policy Alignment (IPA), which assigns credit over semantic interaction chunks rather than individual tokens to improve long-horizon training stability. Empirically, we evaluate ROME within a structured setting and introduce Terminal Bench Pro, a benchmark with improved scale and contamination control. ROME demonstrates strong performance across benchmarks like SWE-bench Verified and Terminal Bench, proving the effectiveness of the ALE infrastructure.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-14] Encyclo-K: Evaluating <mark class="hl-label green">LLM</mark> s with Dynamically Composed Knowledge Statements</p>
<p>【速读】： 该论文旨在解决现有大语言模型（Large Language Models, LLMs）评估基准在问题层面构建时所面临的三大局限：易受数据污染（data contamination）、仅能进行单一知识点评估以及高度依赖领域专家标注带来的高成本。其解决方案的核心在于提出一种基于知识陈述（knowledge statements）的新型评测框架Encyclo-K，将知识单元从问题层级重构为独立的知识陈述，并在测试时通过随机采样动态组合这些陈述生成评估问题。这一设计有效克服了上述限制：利用组合空间的庞大性防止记忆泄露，确保模型排名稳定；每道题目整合8–10个陈述以实现多知识点综合评估；标注过程仅需格式合规性验证，大幅降低人力成本。实验表明，Encyclo-K具有强区分度和挑战性，能够可靠地衡量LLMs对细粒度学科知识的综合理解能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24867">https://arxiv.org/abs/2512.24867</a><br>
<strong>作者</strong>: Yiming Liang,Yizhi Li,Yantao Du,Ge Zhang,Jiayi Zhou,Yuchen Wu,Yinzhu Piao,Denghui Cao,Tong Sun,Ziniu Li,Li Du,Bo Lei,Jiaheng Liu,Chenghua Lin,Zhaoxiang Zhang,Wenhao Huang,Jiajun Zhang<br>
<strong>机构</strong>: ByteDance(字节跳动); Institute of Automation, Chinese Academy of Sciences (中国科学院自动化研究所)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Benchmarks play a crucial role in tracking the rapid advancement of large language models (LLMs) and identifying their capability boundaries. However, existing benchmarks predominantly curate questions at the question level, suffering from three fundamental limitations: vulnerability to data contamination, restriction to single-knowledge-point assessment, and reliance on costly domain expert annotation. We propose Encyclo-K, a statement-based benchmark that rethinks benchmark construction from the ground up. Our key insight is that knowledge statements, not questions, can serve as the unit of curation, and questions can then be constructed from them. We extract standalone knowledge statements from authoritative textbooks and dynamically compose them into evaluation questions through random sampling at test time. This design directly addresses all three limitations: the combinatorial space is too vast to memorize, and model rankings remain stable across dynamically generated question sets, enabling reliable periodic dataset refresh; each question aggregates 8-10 statements for comprehensive multi-knowledge assessment; annotators only verify formatting compliance without requiring domain expertise, substantially reducing annotation costs. Experiments on over 50 LLMs demonstrate that Encyclo-K poses substantial challenges with strong discriminative power. Even the top-performing OpenAI-GPT-5.1 achieves only 62.07% accuracy, and model performance displays a clear gradient distribution–reasoning models span from 16.04% to 62.07%, while chat models range from 9.71% to 50.40%. These results validate the challenges introduced by dynamic evaluation and multi-statement comprehensive understanding. These findings establish Encyclo-K as a scalable framework for dynamic evaluation of LLMs’ comprehensive understanding over multiple fine-grained disciplinary knowledge statements.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-15] Big AI is accelerating the metacrisis: What can we do?</p>
<p>【速读】： 该论文试图解决当前全球面临的生态、意义与语言危机正汇聚成一种“元危机”（metacrisis），而大型人工智能（Big AI）正在加速这一进程的问题。其核心症结在于语言工程师过度追求可扩展性叙事，忽视伦理价值，将关键技术人才输送给寡头和腐败统治者，并以价值中立的方式开发新技术。解决方案的关键在于探索替代路径，运用集体智慧设计以人类繁荣（human flourishing）为核心的自然语言处理（NLP）未来，确保技术发展服务于地球生命系统的可持续性与人类福祉。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24863">https://arxiv.org/abs/2512.24863</a><br>
<strong>作者</strong>: Steven Bird<br>
<strong>机构</strong>: Charles Darwin University (查尔斯达尔文大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>)<br>
<strong>备注</strong>:  9 pages, 1 figure</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The world is in the grip of ecological, meaning, and language crises which are converging into a metacrisis. Big AI is accelerating them all. Language engineers are playing a central role, persisting with a scalability story that is failing humanity, supplying critical talent to plutocrats and kleptocrats, and creating new technologies as if the whole endeavour was value-free. We urgently need to explore alternatives, applying our collective intelligence to design a life-affirming future for NLP that is centered on human flourishing on a living planet.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-16] PrivacyBench: A Conversational Benchmark for Evaluating Privacy in Personalized AI</p>
<p>【速读】： 该论文旨在解决个性化AI代理（Personalized AI Agents）在访问用户数字足迹（如私密邮件、聊天记录和购买历史）时所引发的隐私泄露风险问题，特别是系统因缺乏社会情境感知能力而可能无意中暴露用户秘密，从而威胁数字福祉。解决方案的关键在于提出PrivacyBench基准测试框架，其包含嵌入敏感信息的社会语境化数据集，并通过多轮对话评估机制量化秘密保护能力；实验表明，当前基于检索增强生成（Retrieval-Augmented Generation, RAG）的模型在26.56%的交互中泄露秘密，即使采用隐私意识提示（privacy-aware prompt）也仅将泄漏率降至5.12%，但根本问题仍在于检索机制无差别访问敏感数据，导致隐私保护责任全部压在生成器上，形成单点故障，因此亟需从架构层面引入隐私原生设计（privacy-by-design）的结构性保障措施。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24848">https://arxiv.org/abs/2512.24848</a><br>
<strong>作者</strong>: Srija Mukhopadhyay,Sathwik Reddy,Shruthi Muthukumar,Jisun An,Ponnurangam Kumaraguru<br>
<strong>机构</strong>: International Institute of Information Technology Hyderabad (国际信息科技学院海得拉巴分校); Indiana University (印第安纳大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  11 pages, 2 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Personalized AI agents rely on access to a user’s digital footprint, which often includes sensitive data from private emails, chats and purchase histories. Yet this access creates a fundamental societal and privacy risk: systems lacking social-context awareness can unintentionally expose user secrets, threatening digital well-being. We introduce PrivacyBench, a benchmark with socially grounded datasets containing embedded secrets and a multi-turn conversational evaluation to measure secret preservation. Testing Retrieval-Augmented Generation (RAG) assistants reveals that they leak secrets in up to 26.56% of interactions. A privacy-aware prompt lowers leakage to 5.12%, yet this measure offers only partial mitigation. The retrieval mechanism continues to access sensitive data indiscriminately, which shifts the entire burden of privacy preservation onto the generator. This creates a single point of failure, rendering current architectures unsafe for wide-scale deployment. Our findings underscore the urgent need for structural, privacy-by-design safeguards to ensure an ethical and inclusive web for everyone.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-17] riangulation as an Acceptance Rule for Multilingual Mechanistic Interpretability <mark class="hl-label red">NEURIPS2025</mark></p>
<p>【速读】： 该论文旨在解决多语言语言模型（Multilingual Language Models）在不同语言、文字和文化环境下行为不可预测的问题，其核心挑战在于现有机制解释缺乏因果严谨性和跨环境稳定性。解决方案的关键是提出“三角验证”（triangulation）这一接受准则，要求机制性解释必须满足必要性（ablation实验破坏目标行为）、充分性（patching激活转移行为）以及不变性（在参考家族中保持方向稳定且强度足够），从而通过因果干预和跨环境交叉验证过滤掉仅在单一环境中成立的虚假电路，实现可证伪的机制解释标准。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24842">https://arxiv.org/abs/2512.24842</a><br>
<strong>作者</strong>: Yanan Long<br>
<strong>机构</strong>: StickFlux Labs<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
<strong>备注</strong>:  NeurIPS 2025 Workshop Evaluating the Evolving LLM Lifecycle: Benchmarks, Emergent Abilities, and Scaling</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multilingual language models achieve strong aggregate performance yet often behave unpredictably across languages, scripts, and cultures. We argue that mechanistic explanations for such models should satisfy a \emphcausal standard: claims must survive causal interventions and must \emphcross-reference across environments that perturb surface form while preserving meaning. We formalize \emphreference families as predicate-preserving variants and introduce \emphtriangulation, an acceptance rule requiring necessity (ablating the circuit degrades the target behavior), sufficiency (patching activations transfers the behavior), and invariance (both effects remain directionally stable and of sufficient magnitude across the reference family). To supply candidate subgraphs, we adopt automatic circuit discovery and \emphaccept or reject those candidates by triangulation. We ground triangulation in causal abstraction by casting it as an approximate transformation score over a distribution of interchange interventions, connect it to the pragmatic interpretability agenda, and present a comparative experimental protocol across multiple model families, language pairs, and tasks. Triangulation provides a falsifiable standard for mechanistic claims that filters spurious circuits passing single-environment tests but failing cross-lingual invariance.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-18] Practising responsibility: Ethics in NLP as a hands-on course</p>
<p>【速读】： 该论文试图解决的问题是：随着自然语言处理（Natural Language Processing, NLP）系统日益普及，如何在NLP教育中有效整合伦理考量，以应对学术界与工业界快速演进带来的挑战，并培养学生的批判性思维能力，而不仅仅是传统技术训练。解决方案的关键在于采用以主动学习（active learning）为核心的教学方法，包括互动式课堂、实践操作活动以及“以教促学”（learning by teaching）策略，通过四年的跨机构、跨教育层级和跨学科的教学实践不断优化课程内容，并产出可复用的教学资源与面向多元受众的学生自主开发的教育产品，从而为教育工作者提供将社会影响因素融入课程设计的可行路径。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24825">https://arxiv.org/abs/2512.24825</a><br>
<strong>作者</strong>: Malvina Nissim,Viviana Patti,Beatrice Savoldi<br>
<strong>机构</strong>: University of Groningen (格罗宁根大学); University of Turin (都灵大学); Fondazione Bruno Kessler (布鲁诺·凯勒基金会)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:As Natural Language Processing (NLP) systems become more pervasive, integrating ethical considerations into NLP education has become essential. However, this presents inherent challenges in curriculum development: the field’s rapid evolution from both academia and industry, and the need to foster critical thinking beyond traditional technical training. We introduce our course on Ethical Aspects in NLP and our pedagogical approach, grounded in active learning through interactive sessions, hands-on activities, and “learning by teaching” methods. Over four years, the course has been refined and adapted across different institutions, educational levels, and interdisciplinary backgrounds; it has also yielded many reusable products, both in the form of teaching materials and in the form of actual educational products aimed at diverse audiences, made by the students themselves. By sharing our approach and experience, we hope to provide inspiration for educators seeking to incorporate social impact considerations into their curricula.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-19] Compute-Accuracy Pareto Frontiers for Open-Source <mark class="hl-label green">Reasoning</mark>  <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark></p>
<p>【速读】： 该论文旨在解决大语言模型（Large Language Models, LLMs）在复杂推理任务中因生成长推理序列而导致的显著计算负担问题，尤其是在工业应用中，模型选择不仅依赖于准确率，还需综合考虑资源约束与推理成本。其解决方案的关键在于开展一种面向推理时计算（test-time-compute aware）的评估方法，通过绘制数学与推理密集型基准测试下的帕累托前沿（Pareto frontiers），系统性地比较当代及旧版开源LLMs的性能与效率权衡；研究发现混合专家（Mixture of Experts, MoE）架构在该设定下能较好平衡性能与效率，并揭示了推理时计算存在饱和点——即超过某一阈值后，准确率提升趋于平缓，表明扩展推理能力无法突破模型固有的复杂性限制。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24776">https://arxiv.org/abs/2512.24776</a><br>
<strong>作者</strong>: Ákos Prucs,Márton Csutora,Mátyás Antal,Márk Marosi<br>
<strong>机构</strong>: E-Group Research; Budapest University of Technology and Economics<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) are demonstrating rapid improvements on complex reasoning benchmarks, particularly when allowed to utilize intermediate reasoning steps before converging on a final solution. However, current literature often overlooks the significant computational burden associated with generating long reasoning sequences. For industrial applications, model selection depends not only on raw accuracy but also on resource constraints and inference costs. In this work, we conduct a test-time-compute aware evaluation of both contemporary and older open-source LLMs, mapping their Pareto frontiers across math- and reasoning-intensive benchmarks. Our findings identify the Mixture of Experts (MoE) architecture as a strong candidate to balance performance and efficiency in our evaluation setting. Furthermore, we trace the trajectory of Pareto efficiency over time to derive an emergent trend regarding accuracy gain per unit of compute. Finally, we demonstrate that there is a saturation point for inference-time compute. Beyond a certain threshold, accuracy gains diminish, indicating that while extended reasoning capabilities are beneficial, they cannot overcome intrinsic model limitations regarding specific complexities.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-20] Uncertainty-aware Semi-supervised Ensemble Teacher Framework for Multilingual Depression Detection</p>
<p>【速读】： 该论文旨在解决从社交媒体文本中检测抑郁情绪的挑战性问题，尤其针对不同语言风格、非正式表达以及多语言环境下标注数据稀缺等难题。其核心解决方案是提出一种强健的半监督多语言抑郁检测网络（Semi-SMDNet），关键创新在于融合教师-学生伪标签机制、集成学习与数据增强策略：通过一组教师模型进行软投票生成伪标签，并采用基于不确定性的阈值过滤低置信度样本以降低噪声；同时引入置信度加权训练方法，聚焦于高可靠性伪标签样本，从而显著提升跨语言鲁棒性。实验证明该框架在阿拉伯语、孟加拉语、英语和西班牙语数据集上均优于强基线模型，有效缩小了资源丰富与资源匮乏场景下的性能差距。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24772">https://arxiv.org/abs/2512.24772</a><br>
<strong>作者</strong>: Mohammad Zia Ur Rehman,Velpuru Navya,Sanskar,Shuja Uddin Qureshi,Nagendra Kumar<br>
<strong>机构</strong>: Indian Institute of Technology Indore (印度理工学院英迪拉普尔分校)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Detecting depression from social media text is still a challenging task. This is due to different language styles, informal expression, and the lack of annotated data in many languages. To tackle these issues, we propose, Semi-SMDNet, a strong Semi-Supervised Multilingual Depression detection Network. It combines teacher-student pseudo-labelling, ensemble learning, and augmentation of data. Our framework uses a group of teacher models. Their predictions come together through soft voting. An uncertainty-based threshold filters out low-confidence pseudo-labels to reduce noise and improve learning stability. We also use a confidence-weighted training method that focuses on reliable pseudo-labelled samples. This greatly boosts robustness across languages. Tests on Arabic, Bangla, English, and Spanish datasets show that our approach consistently beats strong baselines. It significantly reduces the performance gap between settings that have plenty of resources and those that do not. Detailed experiments and studies confirm that our framework is effective and can be used in various situations. This shows that it is suitable for scalable, cross-language mental health monitoring where labelled resources are limited.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-21] BIOME-Bench: A Benchmark for Biomolecular Interaction Inference and Multi-Omics Pathway Mechanism Elucidation from Scientific Literature</p>
<p>【速读】： 该论文旨在解决多组学（multi-omics）研究中基于通路富集（pathway enrichment, PE）分析方法所面临的结构性局限，如通路资源更新滞后、功能冗余以及对分子状态和干预措施敏感性不足等问题。同时，现有利用大语言模型（large language models, LLMs）改进PE解释的研究受限于缺乏标准化的端到端多组学通路机制解析基准，导致评估局限于小规模人工标注数据集或临时案例，阻碍了可复现的进展。解决方案的关键在于提出BIOME-Bench——一个通过严格四阶段工作流构建的基准测试平台，用于系统评估LLMs在生物分子相互作用推断（Biomolecular Interaction Inference）和端到端多组学通路机制解析（end-to-end Multi-Omics Pathway Mechanism Elucidation）两项核心能力上的表现，并开发了相应的评估协议，在多个主流模型上开展全面实验，揭示当前模型在精细生物分子关系类型区分和生成忠实、鲁棒的通路级机制解释方面仍存在显著不足。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24733">https://arxiv.org/abs/2512.24733</a><br>
<strong>作者</strong>: Sibo Wei,Peng Chen,Lifeng Dong,Yin Luo,Lei Wang,Peng Zhang,Wenpeng Lu,Jianbin Guo,Hongjun Yang,Dajun Zeng<br>
<strong>机构</strong>: Beijing Wenge Technology Co., Ltd(北京文革科技有限公司); China Academy of Chinese Medical Sciences(中国中医科学院); Institute of Automation, Chinese Academy of Sciences(中国科学院自动化研究所); Tianjin University(天津大学); Qilu University of Technology (Shandong Academy of Sciences)(齐鲁工业大学（山东省科学院）); School of New Media and Communication, Tianjin University(天津大学新媒体与传播学院); School of Artificial Intelligence, University of Chinese Academy of Sciences(中国科学院大学人工智能学院)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multi-omics studies often rely on pathway enrichment to interpret heterogeneous molecular changes, but pathway enrichment (PE)-based workflows inherit structural limitations of pathway resources, including curation lag, functional redundancy, and limited sensitivity to molecular states and interventions. Although recent work has explored using large language models (LLMs) to improve PE-based interpretation, the lack of a standardized benchmark for end-to-end multi-omics pathway mechanism elucidation has largely confined evaluation to small, manually curated datasets or ad hoc case studies, hindering reproducible progress. To address this issue, we introduce BIOME-Bench, constructed via a rigorous four-stage workflow, to evaluate two core capabilities of LLMs in multi-omics analysis: Biomolecular Interaction Inference and end-to-end Multi-Omics Pathway Mechanism Elucidation. We develop evaluation protocols for both tasks and conduct comprehensive experiments across multiple strong contemporary models. Experimental results demonstrate that existing models still exhibit substantial deficiencies in multi-omics analysis, struggling to reliably distinguish fine-grained biomolecular relation types and to generate faithful, robust pathway-level mechanistic explanations.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-22] MUSIC: MUlti-Step Instruction Contrast for Multi-Turn Reward Models</p>
<p>【速读】： 该论文旨在解决多轮对话（multi-turn conversations）质量评估难题，尤其是在训练大型语言模型（LLMs）时缺乏高效、自动化且可靠的评估手段的问题。现有方法主要依赖于基于单轮对话的偏好数据集（preference datasets），难以捕捉多轮交互中的复杂语义连贯性和上下文依赖关系，导致训练出的奖励模型（reward models, RMs）性能受限。论文提出的关键解决方案是MUSIC（MUlti-Step Instruction Contrast），一种无监督的数据增强策略，通过合成跨多个对话轮次存在差异的对比对话对，显著提升了多轮奖励模型的判别能力。实验表明，基于MUSIC增强的数据训练的多轮RM在与先进私有LLM评委的一致性上优于基线方法，同时保持了对标准单轮RM基准任务的性能不下降。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24693">https://arxiv.org/abs/2512.24693</a><br>
<strong>作者</strong>: Wenzhe Li,Shujian Zhang,Wenxuan Zhou,John Lambert,Chi Jin,Andrew Hard,Rajiv Mathews,Lun Wang<br>
<strong>机构</strong>: Princeton University (普林斯顿大学); Google DeepMind<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Evaluating the quality of multi-turn conversations is crucial for developing capable Large Language Models (LLMs), yet remains a significant challenge, often requiring costly human evaluation. Multi-turn reward models (RMs) offer a scalable alternative and can provide valuable signals for guiding LLM training. While recent work has advanced multi-turn \textittraining techniques, effective automated \textitevaluation specifically for multi-turn interactions lags behind. We observe that standard preference datasets, typically contrasting responses based only on the final conversational turn, provide insufficient signal to capture the nuances of multi-turn interactions. Instead, we find that incorporating contrasts spanning \textitmultiple turns is critical for building robust multi-turn RMs. Motivated by this finding, we propose \textbfMUlti-\textbfStep \textbfInstruction \textbfContrast (MUSIC), an unsupervised data augmentation strategy that synthesizes contrastive conversation pairs exhibiting differences across multiple turns. Leveraging MUSIC on the Skywork preference dataset, we train a multi-turn RM based on the Gemma-2-9B-Instruct model. Empirical results demonstrate that our MUSIC-augmented RM outperforms baseline methods, achieving higher alignment with judgments from advanced proprietary LLM judges on multi-turn conversations, crucially, without compromising performance on standard single-turn RM benchmarks.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-23] R-Debater: Retrieval-Augmented Debate Generation through Argumentative Memory <mark class="hl-label red">AAMAS2026</mark></p>
<p>【速读】： 该论文旨在解决生成式 AI (Generative AI) 在多轮辩论中缺乏立场一致性、证据支撑不足以及对话连贯性差的问题。其解决方案的关键在于提出 R-Debater 框架，该框架基于修辞学与记忆研究，通过构建 argumentative memory（论点记忆）机制，整合一个用于检索案例证据和历史辩论动作的辩论知识库，并结合角色驱动的智能体（role-based agent）来跨轮次生成结构清晰、逻辑一致且立场稳定的论辩内容，从而显著提升单轮与多轮辩论的质量。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24684">https://arxiv.org/abs/2512.24684</a><br>
<strong>作者</strong>: Maoyuan Li,Zhongsheng Wang,Haoyuan Li,Jiamou Liu<br>
<strong>机构</strong>: University of Auckland (奥克兰大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Accepteed by AAMAS 2026 full paper</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present R-Debater, an agentic framework for generating multi-turn debates built on argumentative memory. Grounded in rhetoric and memory studies, the system views debate as a process of recalling and adapting prior arguments to maintain stance consistency, respond to opponents, and support claims with evidence. Specifically, R-Debater integrates a debate knowledge base for retrieving case-like evidence and prior debate moves with a role-based agent that composes coherent utterances across turns. We evaluate on standardized ORCHID debates, constructing a 1,000-item retrieval corpus and a held-out set of 32 debates across seven domains. Two tasks are evaluated: next-utterance generation, assessed by InspireScore (subjective, logical, and factual), and adversarial multi-turn simulations, judged by Debatrix (argument, source, language, and overall). Compared with strong LLM baselines, R-Debater achieves higher single-turn and multi-turn scores. Human evaluation with 20 experienced debaters further confirms its consistency and evidence use, showing that combining retrieval grounding with structured planning yields more faithful, stance-aligned, and coherent debates across turns.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-24] Do <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  Know What They Are Capable Of?</p>
<p>【速读】： 该论文试图解决的问题是：大型语言模型（Large Language Models, LLMs）是否具备自我评估能力，即能否准确预测自身在特定任务中的成功概率，并在多步骤代理任务中随着进展调整判断；同时，LLMs能否通过上下文中的失败经验学习改进任务决策，尤其是在高失败成本场景下。解决方案的关键在于设计实验来量化LLMs的预测准确性、分析其在多步任务中的过自信趋势、以及检验其是否能从失败经验中调整行为——研究发现，尽管多数LLMs表现出优于随机水平的判别能力，但普遍存在过自信现象，且仅部分模型能从失败中学习以减少过度乐观，从而改善决策；这表明当前LLMs代理的核心瓶颈在于缺乏对自身能力的清醒认知，进而导致理性决策与实际表现之间的脱节。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24661">https://arxiv.org/abs/2512.24661</a><br>
<strong>作者</strong>: Casey O. Barkan,Sid Black,Oliver Sourbut<br>
<strong>机构</strong>: RAND Corporation (兰德公司); UK AI Security Institute (英国人工智能安全研究所); The Future of Life Foundation (生命未来研究所)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  23 pages, 8 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We investigate whether large language models (LLMs) can predict whether they will succeed on a given task and whether their predictions improve as they progress through multi-step tasks. We also investigate whether LLMs can learn from in-context experiences to make better decisions about whether to pursue a task in scenarios where failure is costly. All LLMs we tested are overconfident, but most predict their success with better-than-random discriminatory power. We find that newer and larger LLMs generally do not have greater discriminatory power, though Claude models do show such a trend. On multi-step agentic tasks, the overconfidence of several frontier LLMs worsens as they progress through the tasks, and reasoning LLMs perform comparably to or worse than non-reasoning LLMs. With in-context experiences of failure, some but not all LLMs reduce their overconfidence leading to significantly improved decision making, while others do not. Interestingly, all LLMs’ decisions are approximately rational given their estimated probabilities of success, yet their overly-optimistic estimates result in poor decision making. These results suggest that current LLM agents are hindered by their lack of awareness of their own capabilities. We discuss the implications of LLMs’ awareness of their capabilities for AI misuse and misalignment risks.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-25] Youtu-<mark class="hl-label green">LLM</mark> : Unlocking the Native <mark class="hl-label green">Agent</mark> ic Potential for Lightweight <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark></p>
<p>【速读】： 该论文旨在解决轻量级语言模型（LLM）在具备高效计算能力的同时，如何系统性地提升其推理与规划能力的问题，尤其是使其具备原生的智能体（agent）特性。传统小型模型通常依赖蒸馏技术来压缩大模型的能力，但难以真正内化复杂的认知行为。解决方案的关键在于三个方面：一是采用紧凑的多潜空间注意力（Multi-Latent Attention, MLA）架构并结合STEM导向的词汇表设计，支持128k长上下文窗口，在低内存占用下实现鲁棒的长程推理和状态追踪；二是构建“常识-STEM-智能体”分阶段训练课程，通过从通用常识到复杂STEM及代理任务的数据分布渐进式迁移，确保模型获得深层认知能力而非表面对齐；三是引入可扩展的代理中段训练机制，利用多样化数据构造策略合成数学、编程和工具使用等领域的丰富轨迹，使模型有效内化规划与反思行为。实验证明，Youtu-LLM在子2B参数规模下达到当前最优性能，尤其在代理相关任务上显著优于现有基线。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24618">https://arxiv.org/abs/2512.24618</a><br>
<strong>作者</strong>: Junru Lu,Jiarui Qin,Lingfeng Qiao,Yinghui Li,Xinyi Dai,Bo Ke,Jianfeng He,Ruizhi Qiao,Di Yin,Xing Sun,Yunsheng Wu,Yinsong Liu,Shuangyin Liu,Mingkong Tang,Haodong Lin,Jiayi Kuang,Fanxu Meng,Xiaojuan Tang,Yunjia Xi,Junjie Huang,Haotong Yang,Zhenyi Shen,Yangning Li,Qianwen Zhang,Yifei Yu,Siyu An,Junnan Dong,Qiufeng Wang,Jie Wang,Keyu Chen,Wei Wen,Taian Guo,Zhifeng Shen,Daohai Yu,Jiahao Li,Ke Li,Zongyi Li,Xiaoyu Tan<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  57 pages, 26 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce Youtu-LLM, a lightweight yet powerful language model that harmonizes high computational efficiency with native agentic intelligence. Unlike typical small models that rely on distillation, Youtu-LLM (1.96B) is pre-trained from scratch to systematically cultivate reasoning and planning capabilities. The key technical advancements are as follows: (1) Compact Architecture with Long-Context Support: Built on a dense Multi-Latent Attention (MLA) architecture with a novel STEM-oriented vocabulary, Youtu-LLM supports a 128k context window. This design enables robust long-context reasoning and state tracking within a minimal memory footprint, making it ideal for long-horizon agent and reasoning tasks. (2) Principled “Commonsense-STEM-Agent” Curriculum: We curated a massive corpus of approximately 11T tokens and implemented a multi-stage training strategy. By progressively shifting the pre-training data distribution from general commonsense to complex STEM and agentic tasks, we ensure the model acquires deep cognitive abilities rather than superficial alignment. (3) Scalable Agentic Mid-training: Specifically for the agentic mid-training, we employ diverse data construction schemes to synthesize rich and varied trajectories across math, coding, and tool-use domains. This high-quality data enables the model to internalize planning and reflection behaviors effectively. Extensive evaluations show that Youtu-LLM sets a new state-of-the-art for sub-2B LLMs. On general benchmarks, it achieves competitive performance against larger models, while on agent-specific tasks, it significantly surpasses existing SOTA baselines, demonstrating that lightweight models can possess strong intrinsic agentic capabilities.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-26] Recursive Language Models</p>
<p>【速读】： 该论文旨在解决大语言模型（Large Language Models, LLMs）在处理超长输入提示（prompt）时受限于固定上下文窗口（context window）的问题。解决方案的关键在于提出递归语言模型（Recursive Language Models, RLMs），这是一种推理时的通用策略，将长提示视为外部环境，使LLM能够程序化地检查、分解并递归调用自身来处理提示片段，从而突破原始模型上下文长度限制，并在多个长上下文任务中显著优于基线模型和常见长上下文处理方法，同时保持相近或更低的单次查询成本。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24601">https://arxiv.org/abs/2512.24601</a><br>
<strong>作者</strong>: Alex L. Zhang,Tim Kraska,Omar Khattab<br>
<strong>机构</strong>: MIT CSAIL (麻省理工学院计算机科学与人工智能实验室)<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  9 pages, 33 with Appendix</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We study allowing large language models (LLMs) to process arbitrarily long prompts through the lens of inference-time scaling. We propose Recursive Language Models (RLMs), a general inference strategy that treats long prompts as part of an external environment and allows the LLM to programmatically examine, decompose, and recursively call itself over snippets of the prompt. We find that RLMs successfully handle inputs up to two orders of magnitude beyond model context windows and, even for shorter prompts, dramatically outperform the quality of base LLMs and common long-context scaffolds across four diverse long-context tasks, while having comparable (or cheaper) cost per query.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-27] Understanding and Steering the Cognitive Behaviors of <mark class="hl-label green">Reasoning</mark>  Models at Test-Time</p>
<p>【速读】： 该论文旨在解决大语言模型（Large Language Models, LLMs）在复杂任务中依赖长链式思维（Chain-of-Thought, CoT）推理时存在的效率低下和推理不稳定问题，具体表现为生成过多无用token导致高延迟，以及推理过程在浅层思考与冗余重复之间波动。解决方案的关键在于识别出与特定认知行为（如验证和回溯）相关联的注意力头（attention heads），并通过轻量级干预在推理阶段对这些头进行定向调控：首先通过离线校准步骤确定认知头并构建头特异性引导向量，随后在推理时旋转隐藏表示以抑制对应方向上的成分，从而自适应地抑制低效推理行为。该方法称为CREST（Cognitive REasoning Steering at Test-time），无需训练即可显著提升准确率（最高达17.5%）并降低计算开销（token使用减少37.6%）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24574">https://arxiv.org/abs/2512.24574</a><br>
<strong>作者</strong>: Zhenyu Zhang,Xiaoxia Wu,Zhongzhu Zhou,Qingyang Wu,Yineng Zhang,Pragaash Ponnusamy,Harikaran Subbaraj,Jue Wang,Shuaiwen Leon Song,Ben Athiwaratkun<br>
<strong>机构</strong>: University of Texas at Austin (德克萨斯大学奥斯汀分校); Together AI; University of Sydney (悉尼大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) often rely on long chain-of-thought (CoT) reasoning to solve complex tasks. While effective, these trajectories are frequently inefficient, leading to high latency from excessive token generation, or unstable reasoning that alternates between underthinking (shallow, inconsistent steps) and overthinking (repetitive, verbose reasoning). In this work, we study the structure of reasoning trajectories and uncover specialized attention heads that correlate with distinct cognitive behaviors such as verification and backtracking. By lightly intervening on these heads at inference time, we can steer the model away from inefficient modes. Building on this insight, we propose CREST, a training-free method for Cognitive REasoning Steering at Test-time. CREST has two components: (1) an offline calibration step that identifies cognitive heads and derives head-specific steering vectors, and (2) an inference-time procedure that rotates hidden representations to suppress components along those vectors. CREST adaptively suppresses unproductive reasoning behaviors, yielding both higher accuracy and lower computational cost. Across diverse reasoning benchmarks and models, CREST improves accuracy by up to 17.5% while reducing token usage by 37.6%, offering a simple and effective pathway to faster, more reliable LLM reasoning.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-28] Korean Canonical Legal Benchmark: Toward Knowledge-Independent Evaluation of <mark class="hl-label green">LLM</mark> s Legal <mark class="hl-label green">Reasoning</mark>  Capabilities</p>
<p>【速读】： 该论文旨在解决当前语言模型在法律推理任务中难以区分其推理能力与领域知识掌握程度的问题。传统评估方法常将两者混杂，导致对模型真实推理能力的误判。解决方案的关键在于构建一个名为韩国规范法律基准（Korean Canonical Legal Benchmark, KCL）的新基准，该基准通过提供问题级别的支持性判例（supporting precedents），实现了对法律推理能力与参数化知识的解耦评估。KCL包含两个子任务：KCL-MCQA（多选题）和KCL-Essay（开放式生成题），其中后者还引入了2,739条实例级评分标准（rubrics）用于自动化评估，从而更精确地衡量模型的法律推理表现。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24572">https://arxiv.org/abs/2512.24572</a><br>
<strong>作者</strong>: Hongseok Oh,Wonseok Hwang,Kyoung-Woon On<br>
<strong>机构</strong>: University of Seoul (首尔大学); LBOX<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce the Korean Canonical Legal Benchmark (KCL), a benchmark designed to assess language models’ legal reasoning capabilities independently of domain-specific knowledge. KCL provides question-level supporting precedents, enabling a more faithful disentanglement of reasoning ability from parameterized knowledge. KCL consists of two components: (1) KCL-MCQA, multiple-choice problems of 283 questions with 1,103 aligned precedents, and (2) KCL-Essay, open-ended generation problems of 169 questions with 550 aligned precedents and 2,739 instance-level rubrics for automated evaluation. Our systematic evaluation of 30+ models shows large remaining gaps, particularly in KCL-Essay, and that reasoning-specialized models consistently outperform their general-purpose counterparts. We release all resources, including the benchmark dataset and evaluation code, at this https URL.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-29] HaluNet: Multi-Granular Uncertainty Modeling for Efficient Hallucination Detection in <mark class="hl-label green">LLM</mark>  Question Answering</p>
<p>【速读】： 该论文旨在解决大语言模型（Large Language Models, LLMs）在问答（Question Answering, QA）任务中频繁产生幻觉（hallucination）的问题，即模型生成事实错误或虚构内容。现有方法通常仅关注单一类型的不确定性信号，忽视了不同来源不确定性之间的互补性，尤其是词元级概率不确定性与内部语义表示所传达的不确定性之间的协同作用。解决方案的关键在于提出一种轻量级可训练的神经框架 HaluNet，其多分支架构通过融合语义嵌入（semantic embeddings）、概率置信度（probabilistic confidence）和分布不确定性（distributional uncertainty），实现跨粒度的词元级不确定性整合，从而在单次前向传播中高效检测幻觉，且在无需外部资源的情况下表现出优越的检测性能和计算效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24562">https://arxiv.org/abs/2512.24562</a><br>
<strong>作者</strong>: Chaodong Tong,Qi Zhang,Jiayang Gao,Lei Jiang,Yanbing Liu,Nannan Sun<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  13 pages, 5 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) excel at question answering (QA) but often generate hallucinations, including factual errors or fabricated content. Detecting hallucinations from internal uncertainty signals is attractive due to its scalability and independence from external resources. Existing methods often aim to accurately capture a single type of uncertainty while overlooking the complementarity among different sources, particularly between token-level probability uncertainty and the uncertainty conveyed by internal semantic representations, which provide complementary views on model reliability. We present \textbfHaluNet, a lightweight and trainable neural framework that integrates multi granular token level uncertainties by combining semantic embeddings with probabilistic confidence and distributional uncertainty. Its multi branch architecture adaptively fuses what the model knows with the uncertainty expressed in its outputs, enabling efficient one pass hallucination detection. Experiments on SQuAD, TriviaQA, and Natural Questions show that HaluNet delivers strong detection performance and favorable computational efficiency, with or without access to context, highlighting its potential for real time hallucination detection in LLM based QA systems.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-30] Safe in the Future Dangerous in the Past: Dissecting Temporal and Linguistic Vulnerabilities in <mark class="hl-label green">LLM</mark> s</p>
<p>【速读】： 该论文旨在解决当前大语言模型（Large Language Models, LLMs）在多语言场景下安全对齐（safety alignment）的假设——即认为英语中的安全机制可零样本迁移至其他语言——是否存在盲区的问题。研究发现，这种假设存在严重风险，因为模型的安全性并非固定属性，而是受语言与时间框架交互影响的动态状态，尤其在低资源语言如豪萨语（Hausa）中表现出复杂干扰机制（Complex Interference）。解决方案的关键在于提出“不变对齐”（Invariant Alignment）这一新范式，强调必须构建跨语言和时间维度稳定的安全机制，而非依赖表面启发式规则，以消除因局部上下文变化导致的安全漏洞（Safety Pockets），从而保障全球南方用户免受特定情境下的有害输出。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24556">https://arxiv.org/abs/2512.24556</a><br>
<strong>作者</strong>: Muhammad Abdullahi Said,Muhammad Sammani Sani<br>
<strong>机构</strong>: African Institute for Mathematical Science (非洲数学科学研究所); University of Vienna (维也纳大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:As Large Language Models (LLMs) integrate into critical global infrastructure, the assumption that safety alignment transfers zero-shot from English to other languages remains a dangerous blind spot. This study presents a systematic audit of three state of the art models (GPT-5.1, Gemini 3 Pro, and Claude 4.5 Opus) using HausaSafety, a novel adversarial dataset grounded in West African threat scenarios (e.g., Yahoo-Yahoo fraud, Dane gun manufacturing). Employing a 2 x 4 factorial design across 1,440 evaluations, we tested the non-linear interaction between language (English vs. Hausa) and temporal framing. Our results challenge the prevailing multilingual safety gap narrative. Instead of a simple degradation in low-resource settings, we identified a mechanism of Complex Interference where safety is determined by the intersection of variables. While models exhibited a Reverse Linguistic with Claude 4.5 Opus proving significantly safer in Hausa (45.0%) than in English (36.7%) due to uncertainty-driven refusal they suffered catastrophic failures in temporal reasoning. We report a profound Temporal Asymmetry, where past-tense framing bypassed defenses (15.6% safe) while future-tense scenarios triggered hyper-conservative refusals (57.2% safe). The magnitude of this volatility is illustrated by a 9.2x disparity between the safest and most vulnerable configurations, proving that safety is not a fixed property but a context-dependent state. We conclude that current models rely on superficial heuristics rather than robust semantic understanding, creating Safety Pockets that leave Global South users exposed to localized harms. We propose Invariant Alignment as a necessary paradigm shift to ensure safety stability across linguistic and temporal shifts.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-31] More Than Bits: Multi-Envelope Double Binary Factorization for Extreme Quantization</p>
<p>【速读】： 该论文针对极端低比特量化（extreme low-bit quantization）下大语言模型（Large Language Models, LLMs）的性能瓶颈问题展开研究，具体而言，现有双二值因子分解（Double Binary Factorization, DBF）方法因缩放参数过于受限——即在分离符号后，所有秩分量共享相同的幅度轮廓（magnitude profile），导致性能饱和。为解决此问题，作者提出多包络双二值因子分解（Multi-envelope DBF, MDBF），其核心创新在于保留共享的一对1-bit符号基底（sign bases），但将单一包络替换为一个秩为 $ l $ 的包络结构；通过在包络组件间共享符号矩阵，MDBF在维持二值载体的同时，将有限的内存预算用于增强幅度表达能力。此外，论文还设计了闭式初始化和交替优化策略以提升训练稳定性与精度。实验表明，在LLaMA与Qwen系列模型上，MDBF在相同每权重比特数条件下显著优于先前二值格式，在保持部署友好推理原语的前提下提升了困惑度（perplexity）和零样本准确率（zero-shot accuracy）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24545">https://arxiv.org/abs/2512.24545</a><br>
<strong>作者</strong>: Yuma Ichikawa,Yoshihiko Fujisawa,Yudai Fujimoto,Akira Sakai,Katsuki Fujisawa<br>
<strong>机构</strong>: Fujitsu Limited(富士通有限公司); RIKEN Center for AIP(理化学研究所人工智能中心); Institute of Science Tokyo(东京科学研究所); Tokai University(东海大学)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
<strong>备注</strong>:  14 pages, 2 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:For extreme low-bit quantization of large language models (LLMs), Double Binary Factorization (DBF) is attractive as it enables efficient inference without sacrificing accuracy. However, the scaling parameters of DBF are too restrictive; after factoring out signs, all rank components share the same magnitude profile, resulting in performance saturation. We propose Multi-envelope DBF (MDBF), which retains a shared pair of 1-bit sign bases but replaces the single envelope with a rank- l  envelope. By sharing sign matrices among envelope components, MDBF effectively maintains a binary carrier and utilizes the limited memory budget for magnitude expressiveness. We also introduce a closed-form initialization and an alternating refinement method to optimize MDBF. Across the LLaMA and Qwen families, MDBF enhances perplexity and zero-shot accuracy over previous binary formats at matched bits per weight while preserving the same deployment-friendly inference primitive.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-32] From Building Blocks to <mark class="hl-label green">Planning</mark> : Multi-Step Spatial <mark class="hl-label green">Reasoning</mark>  in <mark class="hl-label green">LLM</mark> s with Reinforcement Learning</p>
<p>【速读】： 该论文旨在解决大型语言模型（Large Language Models, LLMs）在结构化环境中进行空间推理和多步规划时的局限性，尤其是其在处理空间变换（如旋转、平移、缩放）以及闭合回路策略学习方面的不足。解决方案的关键在于提出一种两阶段方法：第一阶段通过监督微调（Supervised Fine-Tuning）赋予模型基础的空间物理理解能力；第二阶段冻结该物理感知模型，并在其基础上使用轻量级LoRA适配器在GRPO框架内训练策略，以组合这些原子空间变换模块实现多步规划任务。该方法在基于ASCII艺术的强化学习环境中验证有效，显著优于基线模型，且训练收敛更快、更稳定。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24532">https://arxiv.org/abs/2512.24532</a><br>
<strong>作者</strong>: Amir Tahmasbi,Sadegh Majidi,Kazem Taram,Aniket Bera<br>
<strong>机构</strong>: Purdue University (普渡大学)<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Spatial reasoning in large language models (LLMs) has gained increasing attention due to applications in navigation and planning. Despite strong general language capabilities, LLMs still struggle with spatial transformations and multi-step planning in structured environments. We propose a two-stage approach that decomposes spatial reasoning into atomic building blocks and their composition. First, we apply supervised fine-tuning on elementary spatial transformations, such as rotation, translation, and scaling, to equip the model with basic spatial physics. We then freeze this physics-aware model and train lightweight LoRA adapters within the GRPO framework to learn policies that compose these building blocks for multi-step planning in puzzle-based environments, in a closed-loop manner. To support this pipeline, we synthesize an ASCII-art dataset and construct a corresponding ASCII-based reinforcement learning environment. Our method consistently outperforms baselines, including the generic backbone, physics-aware model, and end-to-end RL models, under both Dynamic environments with explicit state updates and Static environments where the model must rely on its internal state across steps. In addition, the proposed approach converges faster and exhibits more stable training compared to end-to-end reinforcement learning from scratch. Finally, we analyze attention patterns to assess whether fine-tuning induces meaningful improvements in spatial understanding.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-33] Pa<mark class="hl-label green">rag</mark> raph Segmentation Revisited: Towards a Standard Task for Structuring Speech</p>
<p>【速读】： 该论文旨在解决自动语音转录文本中缺乏结构化组织的问题，即当前生成的转录文本通常以无结构的词流形式呈现，严重影响可读性和再利用效率。其核心解决方案在于将段落分割（paragraph segmentation）作为语音处理中的关键结构化步骤，并提出三项创新：首先构建了两个面向语音领域的基准数据集TEDPara（人类标注的TED演讲）和YTSegPara（带合成标签的YouTube视频），填补了语音领域段落分割任务缺乏可靠评估资源的空白；其次设计了一种约束解码机制，使大语言模型能够在保持原始转录完整性的前提下插入段落分隔符，从而实现忠实且句级对齐的评估；最后引入轻量级模型MiniSeg，在准确率上达到当前最优，并通过层次扩展实现章节与段落的联合预测，计算开销极低。这些工作共同确立了段落分割在语音处理中的标准化与实用性地位。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24517">https://arxiv.org/abs/2512.24517</a><br>
<strong>作者</strong>: Fabian Retkowski,Alexander Waibel<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Automatic speech transcripts are often delivered as unstructured word streams that impede readability and repurposing. We recast paragraph segmentation as the missing structuring step and fill three gaps at the intersection of speech processing and text segmentation. First, we establish TEDPara (human-annotated TED talks) and YTSegPara (YouTube videos with synthetic labels) as the first benchmarks for the paragraph segmentation task. The benchmarks focus on the underexplored speech domain, where paragraph segmentation has traditionally not been part of post-processing, while also contributing to the wider text segmentation field, which still lacks robust and naturalistic benchmarks. Second, we propose a constrained-decoding formulation that lets large language models insert paragraph breaks while preserving the original transcript, enabling faithful, sentence-aligned evaluation. Third, we show that a compact model (MiniSeg) attains state-of-the-art accuracy and, when extended hierarchically, jointly predicts chapters and paragraphs with minimal computational cost. Together, our resources and methods establish paragraph segmentation as a standardized, practical task in speech processing.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-34] IELTS Writing Revision Platform with Automated Essay Scoring and Adaptive Feedback</p>
<p>【速读】： 该论文旨在解决传统雅思（IELTS）写作备考方法缺乏个性化反馈、难以贴合评分标准的问题。其核心解决方案是构建一个集成自动化作文评分（AES）与针对性反馈的修订平台，通过分离对话引导与写作界面以降低认知负荷并模拟真实考试环境。关键技术在于采用基于DistilBERT的Transformer模型结合回归头进行评分，并在设计基础研究（DBR）迭代中实现自适应反馈机制，最终在统计学上显著提升了考生得分（平均提高0.060分 band，p = 0.011），验证了自动化反馈作为人机协同教学补充的有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24460">https://arxiv.org/abs/2512.24460</a><br>
<strong>作者</strong>: Titas Ramancauskas,Kotryna Ramancauske<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Human-Computer Interaction (cs.HC)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper presents the design, development, and evaluation of a proposed revision platform assisting candidates for the International English Language Testing System (IELTS) writing exam. Traditional IELTS preparation methods lack personalised feedback, catered to the IELTS writing rubric. To address these shortcomings, the platform features an attractive user interface (UI), an Automated Essay Scoring system (AES), and targeted feedback tailored to candidates and the IELTS writing rubric. The platform architecture separates conversational guidance from a dedicated writing interface to reduce cognitive load and simulate exam conditions. Through iterative, Design-Based Research (DBR) cycles, the study progressed from rule-based to transformer-based with a regression head scoring, mounted with adaptive feedback. Early cycles (2-3) revealed fundamental limitations of rule-based approaches: mid-band compression, low accuracy, and negative  R^2  values. DBR Cycle 4 implemented a DistilBERT transformer model with a regression head, yielding substantial improvements with MAE of 0.66 and positive  R^2 . This enabled Cycle 5’s adaptive feedback implementation, which demonstrated statistically significant score improvements (mean +0.060 bands, p = 0.011, Cohen’s d = 0.504), though effectiveness varied by revision strategy. Findings suggest automated feedback functions are most suited as a supplement to human instruction, with conservative surface-level corrections proving more reliable than aggressive structural interventions for IELTS preparation contexts. Challenges remain in assessing higher-band essays, and future work should incorporate longitudinal studies with real IELTS candidates and validation from official examiners.         Subjects:  Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Human-Computer Interaction (cs.HC)  Cite as: arXiv:2512.24460 [<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>]    (or  arXiv:2512.24460v1 [<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24460">https://doi.org/10.48550/arXiv.2512.24460</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-35] Cleaning English Abstracts of Scientific Publications</p>
<p>【速读】： 该论文旨在解决科学文献摘要中包含大量冗余信息（如版权声明、章节标题、作者注释、注册信息及书目元数据等）的问题，这些信息会干扰下游文本分析任务，特别是文档相似性计算和文本嵌入（textual embeddings）的准确性。解决方案的关键在于提出了一种开源且易于集成的语言模型，能够自动识别并移除上述冗余内容，从而在保持摘要语义完整性的同时提升嵌入质量与相似性排序的可靠性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24459">https://arxiv.org/abs/2512.24459</a><br>
<strong>作者</strong>: Michael E. Rose,Nils A. Herrmann,Sebastian Erhardt<br>
<strong>机构</strong>: Max Planck Institute for Innovation and Competition (马克斯·普朗克创新与竞争研究所); Technical University Munich (慕尼黑工业大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  2 tables, 2 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Scientific abstracts are often used as proxies for the content and thematic focus of research publications. However, a significant share of published abstracts contains extraneous information-such as publisher copyright statements, section headings, author notes, registrations, and bibliometric or bibliographic metadata-that can distort downstream analyses, particularly those involving document similarity or textual embeddings. We introduce an open-source, easy-to-integrate language model designed to clean English-language scientific abstracts by automatically identifying and removing such clutter. We demonstrate that our model is both conservative and precise, alters similarity rankings of cleaned abstracts and improves information content of standard-length embeddings.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-36] Comparing Approaches to Automatic Summarization in Less-Resourced Languages</p>
<p>【速读】： 该论文旨在解决低资源语言（less-resourced languages）中自动文本摘要（automatic text summarization）性能不足的问题。其关键解决方案在于系统性比较多种方法，包括大模型（LLM）的零样本提示（zero-shot prompting）、小模型（如mT5）的微调（fine-tuning）及其与三种数据增强技术及多语言迁移学习（multilingual transfer）的结合，并探索基于大型语言模型的翻译流水线方法（LLM translation pipeline approach）。实验表明，经过多语言微调的mT5基线模型在多数指标上优于其他方法，包括零样本LLM表现，同时指出LLM作为评判者在低资源语言上的可靠性可能不足。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24410">https://arxiv.org/abs/2512.24410</a><br>
<strong>作者</strong>: Chester Palen-Michel,Constantine Lignos<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Under review</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Automatic text summarization has achieved high performance in high-resourced languages like English, but comparatively less attention has been given to summarization in less-resourced languages. This work compares a variety of different approaches to summarization from zero-shot prompting of LLMs large and small to fine-tuning smaller models like mT5 with and without three data augmentation approaches and multilingual transfer. We also explore an LLM translation pipeline approach, translating from the source language to English, summarizing and translating back. Evaluating with five different metrics, we find that there is variation across LLMs in their performance across similar parameter sizes, that our multilingual fine-tuned mT5 baseline outperforms most other approaches including zero-shot LLM performance for most metrics, and that LLM as judge may be less reliable on less-resourced languages.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-37] Skim-Aware Contrastive Learning for Efficient Document Representation</p>
<p>【速读】： 该论文旨在解决基于Transformer的模型在长文档（如法律和医学文本）表示上的局限性问题，即现有方法难以有效捕捉全文上下文信息且计算资源消耗大。其解决方案的关键在于提出一种新的自监督对比学习框架，通过随机掩码文档中的某一区域，并利用自然语言推理（Natural Language Inference, NLI）构建对比目标，使被掩码部分与相关段落对齐、与无关段落分离，从而模拟人类“略读-聚焦关键信息”的认知机制，实现更丰富且高效的长文档表征。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24373">https://arxiv.org/abs/2512.24373</a><br>
<strong>作者</strong>: Waheed Ahmed Abro,Zied Bouraoui<br>
<strong>机构</strong>: CDEP - UR 2471, Univ Artois, France; CRIL - CNRS, Univ Artois, France<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Although transformer-based models have shown strong performance in word- and sentence-level tasks, effectively representing long documents, especially in fields like law and medicine, remains difficult. Sparse attention mechanisms can handle longer inputs, but are resource-intensive and often fail to capture full-document context. Hierarchical transformer models offer better efficiency but do not clearly explain how they relate different sections of a document. In contrast, humans often skim texts, focusing on important sections to understand the overall message. Drawing from this human strategy, we introduce a new self-supervised contrastive learning framework that enhances long document representation. Our method randomly masks a section of the document and uses a natural language inference (NLI)-based contrastive objective to align it with relevant parts while distancing it from unrelated ones. This mimics how humans synthesize information, resulting in representations that are both richer and more computationally efficient. Experiments on legal and biomedical texts confirm significant gains in both accuracy and efficiency.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-38] DermaVQA-DAS: Dermatology Assessment Schema (DAS)  Datasets for Closed-Ended Question Answering  Segmentation in Patient-Generated Dermatology Images</p>
<p>【速读】： 该论文旨在解决当前皮肤科图像分析基准数据集普遍缺乏患者自述查询和临床情境信息的问题，从而限制了其在以患者为中心的护理场景中的应用。解决方案的关键在于提出DermaVQA-DAS数据集及其核心组件——皮肤病评估框架（Dermatology Assessment Schema, DAS），该框架由专家设计，系统化地以结构化和标准化方式捕获临床相关的皮肤病变特征，包含36个高层级与27个细粒度的评估问题，并提供中英文多选选项。基于DAS，研究者构建了用于闭合式问答（QA）和皮肤病灶分割的专家标注数据集，并对多种多模态模型进行基准测试，验证了提示工程（prompting strategies）对分割性能的影响，同时展示了在闭合式QA任务中主流大模型（如o3、GPT-4.1）的高准确率表现，为面向患者中心的皮肤科视觉-语言建模提供了可复用的数据资源与评估协议。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24340">https://arxiv.org/abs/2512.24340</a><br>
<strong>作者</strong>: Wen-wai Yim,Yujuan Fu,Asma Ben Abacha,Meliha Yetisgen,Noel Codella,Roberto Andres Novoa,Josep Malvehy<br>
<strong>机构</strong>: Microsoft Health AI (微软健康人工智能); University of Washington (华盛顿大学); Stanford University (斯坦福大学); Hospital Clinic of Barcelona (巴塞罗那诊所医院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advances in dermatological image analysis have been driven by large-scale annotated datasets; however, most existing benchmarks focus on dermatoscopic images and lack patient-authored queries and clinical context, limiting their applicability to patient-centered care. To address this gap, we introduce DermaVQA-DAS, an extension of the DermaVQA dataset that supports two complementary tasks: closed-ended question answering (QA) and dermatological lesion segmentation. Central to this work is the Dermatology Assessment Schema (DAS), a novel expert-developed framework that systematically captures clinically meaningful dermatological features in a structured and standardized form. DAS comprises 36 high-level and 27 fine-grained assessment questions, with multiple-choice options in English and Chinese. Leveraging DAS, we provide expert-annotated datasets for both closed QA and segmentation and benchmark state-of-the-art multimodal models. For segmentation, we evaluate multiple prompting strategies and show that prompt design impacts performance: the default prompt achieves the best results under Mean-of-Max and Mean-of-Mean evaluation aggregation schemes, while an augmented prompt incorporating both patient query title and content yields the highest performance under majority-vote-based microscore evaluation, achieving a Jaccard index of 0.395 and a Dice score of 0.566 with BiomedParse. For closed-ended QA, overall performance is strong across models, with average accuracies ranging from 0.729 to 0.798; o3 achieves the best overall accuracy (0.798), closely followed by GPT-4.1 (0.796), while Gemini-1.5-Pro shows competitive performance within the Gemini family (0.783). We publicly release DermaVQA-DAS, the DAS schema, and evaluation protocols to support and accelerate future research in patient-centered dermatological vision-language modeling (this https URL).<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-39] World model inspired sarcasm <mark class="hl-label green">reasoning</mark>  with large language model <mark class="hl-label green">agents</mark></p>
<p>【速读】： 该论文旨在解决自然语言处理中讽刺理解（sarcasm understanding）的难题，即如何有效捕捉话语表面意义与说话者意图及社会语境之间的不一致。现有方法多依赖单一模型的黑箱预测，难以结构化解释讽刺背后的认知因素，且缺乏对语义评估与规范性预期之间差异的显式建模。解决方案的关键在于提出一种受世界模型启发的讽刺推理框架（World Model inspired SArcasm Reasoning, WM-SAR），将讽刺理解分解为四个可解释的模块：字面意义、上下文、规范性预期和意图，并由专用的大语言模型（LLM）代理分别建模；其中，字面评价与规范性预期间的不一致性被量化为确定性的不一致分数，结合意图分数后，通过轻量级逻辑回归模型整合以推断最终的讽刺概率。该设计既利用了LLM的推理能力，又保持了决策过程的数值可解释性，在多个基准数据集上显著优于现有深度学习和LLM方法。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24329">https://arxiv.org/abs/2512.24329</a><br>
<strong>作者</strong>: Keito Inoshita,Shinnosuke Mizuno<br>
<strong>机构</strong>: University of Tokyo (东京大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Sarcasm understanding is a challenging problem in natural language processing, as it requires capturing the discrepancy between the surface meaning of an utterance and the speaker’s intentions as well as the surrounding social context. Although recent advances in deep learning and Large Language Models (LLMs) have substantially improved performance, most existing approaches still rely on black-box predictions of a single model, making it difficult to structurally explain the cognitive factors underlying sarcasm. Moreover, while sarcasm often emerges as a mismatch between semantic evaluation and normative expectations or intentions, frameworks that explicitly decompose and model these components remain limited. In this work, we reformulate sarcasm understanding as a world model inspired reasoning process and propose World Model inspired SArcasm Reasoning (WM-SAR), which decomposes literal meaning, context, normative expectation, and intention into specialized LLM-based agents. The discrepancy between literal evaluation and normative expectation is explicitly quantified as a deterministic inconsistency score, and together with an intention score, these signals are integrated by a lightweight Logistic Regression model to infer the final sarcasm probability. This design leverages the reasoning capability of LLMs while maintaining an interpretable numerical decision structure. Experiments on representative sarcasm detection benchmarks show that WM-SAR consistently outperforms existing deep learning and LLM-based methods. Ablation studies and case analyses further demonstrate that integrating semantic inconsistency and intention reasoning is essential for effective sarcasm detection, achieving both strong performance and high interpretability.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-40] QianfanHuijin Technical Report: A Novel Multi-Stage Training Paradigm for Finance Industrial <mark class="hl-label green">LLM</mark> s</p>
<p>【速读】： 该论文旨在解决金融领域大语言模型（Large Language Models, LLMs）在工业应用中面临的挑战，即如何超越传统仅依赖知识增强的方法（如BloombergGPT和Baichuan-Finance），进一步提升模型的金融推理能力与代理（agentic）能力，以应对日益复杂的金融服务需求。其解决方案的关键在于提出一种可泛化的多阶段训练范式（multi-stage training paradigm），包括持续预训练（Continual Pre-training, CPT）、金融指令微调（Financial SFT）、金融推理强化学习（Finance Reasoning RL）、金融代理强化学习（Finance Agentic RL）以及面向真实业务场景的一般化强化学习（General RL）。该范式通过逐步细化、由浅入深地优化模型能力，实证表明QianfanHuijin在多个权威金融基准测试中表现优异，且消融实验验证了推理与代理强化学习阶段对相应能力的显著提升，证明该渐进式后训练方法是工业级LLM增强的有效路径。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24314">https://arxiv.org/abs/2512.24314</a><br>
<strong>作者</strong>: Shupeng Li,Weipeng Lu,Linyun Liu,Chen Lin,Shaofei Li,Zhendong Tan,Hanjun Zhong,Yucheng Zeng,Chenghao Zhu,Mengyue Liu,Daxiang Dong,Jianmin Wu,Yunting Xiao,Annan Li,Danyu Liu,Jingnan Zhang,Licen Liu,Dawei Yin,Dou Shen<br>
<strong>机构</strong>: Baidu AI Cloud (百度AI云)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Domain-specific enhancement of Large Language Models (LLMs) within the financial context has long been a focal point of industrial application. While previous models such as BloombergGPT and Baichuan-Finance primarily focused on knowledge enhancement, the deepening complexity of financial services has driven a growing demand for models that possess not only domain knowledge but also robust financial reasoning and agentic capabilities. In this paper, we present QianfanHuijin, a financial domain LLM, and propose a generalizable multi-stage training paradigm for industrial model enhancement. Our approach begins with Continual Pre-training (CPT) on financial corpora to consolidate the knowledge base. This is followed by a fine-grained Post-training pipeline designed with increasing specificity: starting with Financial SFT, progressing to Finance Reasoning RL and Finance Agentic RL, and culminating in General RL aligned with real-world business scenarios. Empirical results demonstrate that QianfanHuijin achieves superior performance across various authoritative financial benchmarks. Furthermore, ablation studies confirm that the targeted Reasoning RL and Agentic RL stages yield significant gains in their respective capabilities. These findings validate our motivation and suggest that this fine-grained, progressive post-training methodology is poised to become a mainstream paradigm for various industrial-enhanced LLMs.         Subjects:  Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)  Cite as: arXiv:2512.24314 [<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>]    (or  arXiv:2512.24314v1 [<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24314">https://doi.org/10.48550/arXiv.2512.24314</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-41] Figure It Out: Improving the Frontier of <mark class="hl-label green">Reasoning</mark>  with Active Visual Thinking</p>
<p>【速读】： 该论文旨在解决复杂推理任务中纯文本模型难以表征全局结构约束的问题，尤其是在涉及隐式空间、几何和结构性关系的场景下。其解决方案的关键在于提出FIGR（Figure-Guided Reasoning），通过端到端强化学习将主动视觉思维引入多轮推理过程：FIGR在问题求解过程中构建视觉表示以显式化中间结构假设，并自适应地调控视觉推理的触发时机与方式，从而增强对文本难以捕捉的全局结构属性的稳定性和连贯性推理能力。实验表明，FIGR在AIME 2025和BeyondAIME等数学推理基准上分别较纯文本链式思维基线提升13.12%和11.00%，验证了图示引导的多模态推理在提升复杂推理稳定性与可靠性方面的有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24297">https://arxiv.org/abs/2512.24297</a><br>
<strong>作者</strong>: Meiqi Chen,Fandong Meng,Jie Zhou<br>
<strong>机构</strong>: WeChat AI, Tencent Inc (微信人工智能，腾讯公司)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Complex reasoning problems often involve implicit spatial, geometric, and structural relationships that are not explicitly encoded in text. While recent reasoning models have achieved strong performance across many domains, purely text-based reasoning struggles to represent global structural constraints in complex settings. In this paper, we introduce FIGR, which integrates active visual thinking into multi-turn reasoning via end-to-end reinforcement learning. FIGR externalizes intermediate structural hypotheses by constructing visual representations during problem solving. By adaptively regulating when and how visual reasoning should be invoked, FIGR enables more stable and coherent reasoning over global structural properties that are difficult to capture from text alone. Experiments on challenging mathematical reasoning benchmarks demonstrate that FIGR outperforms strong text-only chain-of-thought baselines. In particular, FIGR improves the base model by 13.12% on AIME 2025 and 11.00% on BeyondAIME, highlighting the effectiveness of figure-guided multimodal reasoning in enhancing the stability and reliability of complex reasoning.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-42] Automated Analysis of Sustainability Reports: Using <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  for the Extraction and Prediction of EU Taxonomy-Compliant KPIs</p>
<p>【速读】： 该论文旨在解决企业合规欧盟分类法（EU Taxonomy）过程中手动、资源密集型的挑战，特别是如何利用大语言模型（Large Language Models, LLMs）实现自动化。其解决方案的关键在于构建了一个包含190份公司报告的结构化数据集，其中包含经验证的经济活动和定量关键绩效指标（Key Performance Indicators, KPIs），并基于此数据集首次系统评估了LLMs在核心合规工作流中的表现。研究发现，LLMs在定性任务（识别经济活动）上表现中等，而对定量任务（零样本预测财务KPI）则全面失败，同时揭示了简洁元数据优于完整非结构化报告的悖论，以及模型置信度校准不足的问题，最终表明LLMs尚不具备完全自动化能力，但可作为人类专家的辅助工具。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24289">https://arxiv.org/abs/2512.24289</a><br>
<strong>作者</strong>: Jonathan Schmoll,Adam Jatowt<br>
<strong>机构</strong>: University of Innsbruck (因斯布鲁克大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The manual, resource-intensive process of complying with the EU Taxonomy presents a significant challenge for companies. While Large Language Models (LLMs) offer a path to automation, research is hindered by a lack of public benchmark datasets. To address this gap, we introduce a novel, structured dataset from 190 corporate reports, containing ground-truth economic activities and quantitative Key Performance Indicators (KPIs). We use this dataset to conduct the first systematic evaluation of LLMs on the core compliance workflow. Our results reveal a clear performance gap between qualitative and quantitative tasks. LLMs show moderate success in the qualitative task of identifying economic activities, with a multi-step agentic framework modestly enhancing precision. Conversely, the models comprehensively fail at the quantitative task of predicting financial KPIs in a zero-shot setting. We also discover a paradox, where concise metadata often yields superior performance to full, unstructured reports, and find that model confidence scores are poorly calibrated. We conclude that while LLMs are not ready for full automation, they can serve as powerful assistive tools for human experts. Our dataset provides a public benchmark for future research.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-43] Joint Selection for Large-Scale Pre-Training Data via Policy Gradient-based Mask Learning</p>
<p>【速读】： 该论文旨在解决大规模预训练语言模型（Large Language Models, LLMs）在数据选择过程中难以同时优化质量（quality）与多样性（diversity）指标的问题。传统方法通常单独使用其中一类指标，导致长期预训练中质量指标收益递减，或因过度强调多样性而丢失高价值样本，从而限制模型性能提升。解决方案的关键在于提出DATAMASK——一种高效的联合学习框架，将数据选择建模为掩码学习（mask learning）问题，通过策略梯度优化和多种加速技术，在 trillion-scale 数据规模下实现对质量与多样性指标的统一优化，显著降低选择时间达98.9%，并最终在FineWeb-Mask子集上验证了其有效性，使1.5B稠密模型和7B MoE模型分别获得3.2%和1.9%的性能提升。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24265">https://arxiv.org/abs/2512.24265</a><br>
<strong>作者</strong>: Ziqing Fan,Yuqiao Xian,Yan Sun,Li Shen<br>
<strong>机构</strong>: ByteDance(字节跳动)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:A fine-grained data recipe is crucial for pre-training large language models, as it can significantly enhance training efficiency and model performance. One important ingredient in the recipe is to select samples based on scores produced by defined rules, LLM judgment, or statistical information in embeddings, which can be roughly categorized into quality and diversity metrics. Due to the high computational cost when applied to trillion-scale token pre-training datasets such as FineWeb and DCLM, these two or more types of metrics are rarely considered jointly in a single selection process. However, in our empirical study, selecting samples based on quality metrics exhibit severe diminishing returns during long-term pre-training, while selecting on diversity metrics removes too many valuable high-quality samples, both of which limit pre-trained LLMs’ capabilities. Therefore, we introduce DATAMASK, a novel and efficient joint learning framework designed for large-scale pre-training data selection that can simultaneously optimize multiple types of metrics in a unified process, with this study focusing specifically on quality and diversity metrics. DATAMASK approaches the selection process as a mask learning problem, involving iterative sampling of data masks, computation of policy gradients based on predefined objectives with sampled masks, and updating of mask sampling logits. Through policy gradient-based optimization and various acceleration enhancements, it significantly reduces selection time by 98.9% compared to greedy algorithm, enabling our study to explore joint learning within trillion-scale tokens. With DATAMASK, we select a subset of about 10% from the 15 trillion-token FineWeb dataset, termed FineWeb-Mask. Evaluated across 12 diverse tasks, we achieves significant improvements of 3.2% on a 1.5B dense model and 1.9% on a 7B MoE model.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-44] racing the Flow of Knowledge From Science to Technology Using Deep Learning</p>
<p>【速读】： 该论文旨在解决专利与科学文献之间语义相似性建模的问题，以支持跨领域引用预测（如专利-论文引用关系的识别）。其核心挑战在于如何在保持模型对专利文本特有表达方式敏感的同时，有效捕捉其与科学文献之间的语义关联。解决方案的关键是提出Pat-SPECTER模型——基于SPECTER2进行微调（fine-tuned）的专利专用语言表示模型，通过在专利数据上进一步训练，显著提升了对专利-论文引用关系的预测性能。实验表明，该模型在多项任务中优于其他8种主流语言模型，并成功应用于实际场景（如分离专利-论文配对和预测潜在引用），同时验证了美国专利因“诚信义务”（duty of candor）导致引用文献语义相似度较低的假设。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24259">https://arxiv.org/abs/2512.24259</a><br>
<strong>作者</strong>: Michael E. Rose,Mainak Ghosh,Sebastian Erhardt,Cheng Li,Erik Buunk,Dietmar Harhoff<br>
<strong>机构</strong>: Max Planck Institute for Innovation and Competition (马克斯普朗克创新与竞争研究所)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  4 tables, 7 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We develop a language similarity model suitable for working with patents and scientific publications at the same time. In a horse race-style evaluation, we subject eight language (similarity) models to predict credible Patent-Paper Citations. We find that our Pat-SPECTER model performs best, which is the SPECTER2 model fine-tuned on patents. In two real-world scenarios (separating patent-paper-pairs and predicting patent-paper-pairs) we demonstrate the capabilities of the Pat-SPECTER. We finally test the hypothesis that US patents cite papers that are semantically less similar than in other large jurisdictions, which we posit is because of the duty of candor. The model is open for the academic community and practitioners alike.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-45] LAILA: A Large Trait-Based Dataset for Arabic Automated Essay Scoring</p>
<p>【速读】： 该论文旨在解决阿拉伯语自动作文评分（Arabic Automated Essay Scoring, Arabic AES）研究中因缺乏公开可用数据集而导致的进展受限问题。其解决方案的关键在于构建并发布LAILA，这是目前最大的公开阿拉伯语作文评分数据集，包含7,859篇作文，每篇均被标注了整体分数及七个维度（相关性、结构、词汇、风格、发展、语法和标点）的特质分数。该数据集的设计、收集与标注过程详尽描述，并提供了基于先进阿拉伯语与英语模型在特定提示和跨提示设置下的基准性能结果，从而为阿拉伯语自动评分系统的开发提供了关键支持。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24235">https://arxiv.org/abs/2512.24235</a><br>
<strong>作者</strong>: May Bashendy,Walid Massoud,Sohaila Eltanbouly,Salam Albatarni,Marwan Sayed,Abrar Abir,Houda Bouamor,Tamer Elsayed<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Automated Essay Scoring (AES) has gained increasing attention in recent years, yet research on Arabic AES remains limited due to the lack of publicly available datasets. To address this, we introduce LAILA, the largest publicly available Arabic AES dataset to date, comprising 7,859 essays annotated with holistic and trait-specific scores on seven dimensions: relevance, organization, vocabulary, style, development, mechanics, and grammar. We detail the dataset design, collection, and annotations, and provide benchmark results using state-of-the-art Arabic and English models in prompt-specific and cross-prompt settings. LAILA fills a critical need in Arabic AES research, supporting the development of robust scoring systems.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-46] MedKGI: Iterative Differential Diagnosis with Medical Knowledge Graphs and Information-Guided Inquiring</p>
<p>【速读】： 该论文旨在解决当前大型语言模型（Large Language Models, LLMs）在临床诊断场景中面临的三大核心问题：一是由于缺乏对验证知识的强约束而产生医学内容幻觉；二是提问冗余或低效，无法有效推进诊断进程；三是多轮对话中丧失一致性，导致结论矛盾。解决方案的关键在于提出MedKGI框架，其核心创新包括：利用医学知识图谱（Medical Knowledge Graph, KG）对推理过程进行结构化约束，确保符合临床实践中的受控知识体系；基于信息增益选择具有判别性的提问策略以提升诊断效率；并通过OSCE格式的结构化状态表示维持证据链的连贯性与一致性，从而显著提升诊断准确率和对话效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24181">https://arxiv.org/abs/2512.24181</a><br>
<strong>作者</strong>: Qipeng Wang,Rui Sheng,Yafei Li,Huamin Qu,Yushi Sun,Min Zhu<br>
<strong>机构</strong>: Sichuan University (四川大学); HKUST (香港科技大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advancements in Large Language Models (LLMs) have demonstrated significant promise in clinical diagnosis. However, current models struggle to emulate the iterative, diagnostic hypothesis-driven reasoning of real clinical scenarios. Specifically, current LLMs suffer from three critical limitations: (1) generating hallucinated medical content due to weak grounding in verified knowledge, (2) asking redundant or inefficient questions rather than discriminative ones that hinder diagnostic progress, and (3) losing coherence over multi-turn dialogues, leading to contradictory or inconsistent conclusions. To address these challenges, we propose MedKGI, a diagnostic framework grounded in clinical practices. MedKGI integrates a medical knowledge graph (KG) to constrain reasoning to validated medical ontologies, selects questions based on information gain to maximize diagnostic efficiency, and adopts an OSCE-format structured state to maintain consistent evidence tracking across turns. Experiments on clinical benchmarks show that MedKGI outperforms strong LLM baselines in both diagnostic accuracy and inquiry efficiency, improving dialogue efficiency by 30% on average while maintaining state-of-the-art accuracy.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-47] raining Report of TeleChat3-MoE</p>
<p>【速读】： 该论文旨在解决大规模语言模型（Large Language Model, LLM）在超大规模硬件集群上训练时面临的可扩展性、数值准确性保障与性能瓶颈问题。其关键解决方案包括：构建端到端的训练基础设施，实现基于算子级与端到端数值精度验证的方法以确保跨硬件平台和分布式并行策略的一致性；提出一系列性能优化技术，如交错流水线调度、面向长序列训练的注意力感知数据调度、专家并行中的分层重叠通信机制以及基于DVM（Dataflow Virtual Machine）的算子融合；设计了一种融合解析估计与整数线性规划的系统化并行化框架，用于优化多维并行配置；同时通过集群级优化缓解主机和设备瓶颈，从而实现数千设备规模下的近线性扩展和显著吞吐提升，为大模型在异构硬件生态上的开发提供了坚实基础。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24157">https://arxiv.org/abs/2512.24157</a><br>
<strong>作者</strong>: Xinzhang Liu,Chao Wang,Zhihao Yang,Zhuo Jiang,Xuncheng Zhao,Haoran Wang,Lei Li,Dongdong He,Luobin Liu,Kaizhe Yuan,Han Gao,Zihan Wang,Yitong Yao,Sishi Xiong,Wenmin Deng,Haowei He,Kaidong Yu,Yu Zhao,Ruiyu Fang,Yuhao Jiang,Yingyan Li,Xiaohui Hu,Xi Yu,Jingqi Li,Yanwei Liu,Qingli Li,Xinyu Shi,Junhao Niu,Chengnuo Huang,Yao Xiao,Ruiwen Wang,Fengkai Li,Luwen Pu,Kaipeng Jia,Fubei Yao,Yuyao Huang,Xuewei He,Zhuoru Jiang,Ruiting Song,Rui Xue,Qiyi Xie,Jie Zhang,Zilu Huang,Zhaoxi Zhang,Zhilong Lu,Yanhan Zhang,Yin Zhang,Yanlei Xue,Zhu Yuan,Teng Su,Xin Jiang,Shuangyong Song,Yongxiang Li,Xuelong Li<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:TeleChat3-MoE is the latest series of TeleChat large language models, featuring a Mixture-of-Experts (MoE) architecture with parameter counts ranging from 105 billion to over one trillion,trained end-to-end on Ascend NPU cluster. This technical report mainly presents the underlying training infrastructure that enables reliable and efficient scaling to frontier model sizes. We detail systematic methodologies for operator-level and end-to-end numerical accuracy verification, ensuring consistency across hardware platforms and distributed parallelism strategies. Furthermore, we introduce a suite of performance optimizations, including interleaved pipeline scheduling, attention-aware data scheduling for long-sequence training,hierarchical and overlapped communication for expert parallelism, and DVM-based operator fusion. A systematic parallelization framework, leveraging analytical estimation and integer linear programming, is also proposed to optimize multi-dimensional parallelism configurations. Additionally, we present methodological approaches to cluster-level optimizations, addressing host- and device-bound bottlenecks during large-scale training tasks. These infrastructure advancements yield significant throughput improvements and near-linear scaling on clusters comprising thousands of devices, providing a robust foundation for large-scale language model development on hardware ecosystems.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-48] Large Emotional World Model</p>
<p>【速读】： 该论文旨在解决当前世界模型（World Models）在建模人类决策时忽视情感因素的问题，即现有大型语言模型（LLMs）主要关注物理世界的规律性，缺乏对情绪驱动行为的系统性建模。其解决方案的关键在于提出一种大型情感世界模型（Large Emotional World Model, LEWM），通过构建包含情绪因果关系的Emotion-Why-How（EWH）数据集，使模型能够显式地建模情绪状态、视觉观测与行为之间的关联，从而预测未来世界状态及情绪演变，显著提升对情绪驱动社会行为的预测准确性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24149">https://arxiv.org/abs/2512.24149</a><br>
<strong>作者</strong>: Changhao Song,Yazhou Zhang,Hui Gao,Chang Yang,Peng Zhang<br>
<strong>机构</strong>: Tianjin University (天津大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:World Models serve as tools for understanding the current state of the world and predicting its future dynamics, with broad application potential across numerous fields. As a key component of world knowledge, emotion significantly influences human decision-making. While existing Large Language Models (LLMs) have shown preliminary capability in capturing world knowledge, they primarily focus on modeling physical-world regularities and lack systematic exploration of emotional factors. In this paper, we first demonstrate the importance of emotion in understanding the world by showing that removing emotionally relevant information degrades reasoning performance. Inspired by theory of mind, we further propose a Large Emotional World Model (LEWM). Specifically, we construct the Emotion-Why-How (EWH) dataset, which integrates emotion into causal relationships and enables reasoning about why actions occur and how emotions drive future world states. Based on this dataset, LEWM explicitly models emotional states alongside visual observations and actions, allowing the world model to predict both future states and emotional transitions. Experimental results show that LEWM more accurately predicts emotion-driven social behaviors while maintaining comparable performance to general world models on basic tasks.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-49] Activation Steering for Masked Diffusion Language Models</p>
<p>【速读】： 该论文旨在解决生成式 AI（Generative AI）中掩码扩散语言模型（Masked Diffusion Language Models, MDLMs）在推理阶段缺乏有效控制与引导机制的问题。现有方法难以在不模拟去噪轨迹的前提下实现对高阶语义属性的精准调节，限制了其在实际应用中的可控性。解决方案的关键在于提出一种激活导向（activation-steering）框架，通过单次前向传播计算层级引导向量（layer-wise steering vectors），利用对比样本提取方向信息，并在每个反向扩散步骤中施加这些向量，从而实现高效、细粒度的推理时控制，无需模拟完整的去噪过程。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24143">https://arxiv.org/abs/2512.24143</a><br>
<strong>作者</strong>: Adi Shnaidman,Erin Feiglin,Osher Yaari,Efrat Mentel,Amit Levi,Raz Lapid<br>
<strong>机构</strong>: Deepkeep; Technion<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Masked diffusion language models (MDLMs) generate text through an iterative denoising process. They have recently gained attention due to mask-parallel decoding and competitive performance with autoregressive large language models. However, effective mechanisms for inference-time control and steering in MDLMs remain largely unexplored. We present an activation-steering framework for MDLMs that computes layer-wise steering vectors from a single forward pass using contrastive examples, without simulating the denoising trajectory. These directions are applied at every reverse-diffusion step, yielding an efficient inference-time control mechanism. Experiments on LLaDA-8B-Instruct demonstrate reliable modulation of high-level attributes, with ablations examining the effects of steering across transformer sub-modules and token scope (prompt vs.\ response).<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-50] OptRot: Mitigating Weight Outliers via Data-Free Rotations for Post-Training Quantization</p>
<p>【速读】： 该论文旨在解决大型语言模型（Large Language Models, LLMs）中权重和激活值存在异常值（outliers）导致量化困难的问题。现有方法虽尝试通过旋转（rotations）缓解异常值影响，但存在计算成本高或效果有限的局限。论文提出的关键解决方案是设计可融合的旋转学习机制，其核心在于最小化与权重量化误差相关的廉价代理目标函数：主方法OptRot通过最小化旋转后权重元素的四次幂之和来有效抑制异常值；进一步地，OptRot⁺引入激活协方差信息以提升性能。实验表明，OptRot在W4A8设置下优于Hadamard旋转及更昂贵的数据依赖方法（如SpinQuant、OSTQuant），同时改善激活量化表现，但在W4A4设置下性能下降，揭示了权重与激活量化之间的权衡关系。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24124">https://arxiv.org/abs/2512.24124</a><br>
<strong>作者</strong>: Advait Gadhikar,Riccardo Grazzi,James Hensman<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  25 pages, 10 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The presence of outliers in Large Language Models (LLMs) weights and activations makes them difficult to quantize. Recent work has leveraged rotations to mitigate these outliers. In this work, we propose methods that learn fusible rotations by minimizing principled and cheap proxy objectives to the weight quantization error. We primarily focus on GPTQ as the quantization method. Our main method is OptRot, which reduces weight outliers simply by minimizing the element-wise fourth power of the rotated weights. We show that OptRot outperforms both Hadamard rotations and more expensive, data-dependent methods like SpinQuant and OSTQuant for weight quantization. It also improves activation quantization in the W4A8 setting. We also propose a data-dependent method, OptRot ^+ , that further improves performance by incorporating information on the activation covariance. In the W4A4 setting, we see that both OptRot and OptRot ^+  perform worse, highlighting a trade-off between weight and activation quantization.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-51] raining a Huggingface Model on AWS Sagemaker (Without Tears)</p>
<p>【速读】： 该论文试图解决的研究人员在将Hugging Face模型迁移至AWS SageMaker进行训练时所面临的障碍问题，主要包括云平台学习曲线陡峭、本地环境依赖与云端操作不兼容、以及现有文档信息碎片化导致的知识获取困难。解决方案的关键在于通过集中化整理从零开始训练Hugging Face模型所需的全部核心配置、操作流程和最佳实践，形成结构清晰、可复现的指南，从而降低技术门槛，推动科研群体对云计算资源的高效采用。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24098">https://arxiv.org/abs/2512.24098</a><br>
<strong>作者</strong>: Liling Tan<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The development of Large Language Models (LLMs) has primarily been driven by resource-rich research groups and industry partners. Due to the lack of on-premise computing resources required for increasingly complex models, many researchers are turning to cloud services like AWS SageMaker to train Hugging Face models. However, the steep learning curve of cloud platforms often presents a barrier for researchers accustomed to local environments. Existing documentation frequently leaves knowledge gaps, forcing users to seek fragmented information across the web. This demo paper aims to democratize cloud adoption by centralizing the essential information required for researchers to successfully train their first Hugging Face model on AWS SageMaker from scratch.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-52] Factorized Learning for Temporally Grounded Video-Language Models <mark class="hl-label red">DATE</mark> <mark class="hl-label red">ICCV2025</mark></p>
<p>【速读】： 该论文旨在解决当前视频-语言模型（Video-Language Models, VLMs）在事件级感知中难以实现精确时间定位（temporal grounding）的问题，其核心挑战在于现有方法将时间定位与文本回答任务耦合处理，缺乏明确的逻辑结构，导致优化目标次优。解决方案的关键在于提出一种因子化学习框架 D²VLM，通过“先定位后回答并引用证据”的范式，显式解耦两个任务的学习过程，并引入证据标记（evidence tokens）以强化事件级别的视觉语义捕捉，而非仅关注时间戳表示；同时设计了一种新颖的因子化偏好优化（Factorized Preference Optimization, FPO）算法，将概率性时间定位建模显式嵌入优化目标，从而实现对时间定位和文本响应的联合偏好学习，显著提升模型性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24097">https://arxiv.org/abs/2512.24097</a><br>
<strong>作者</strong>: Wenzheng Zeng,Difei Gao,Mike Zheng Shou,Hwee Tou Ng<br>
<strong>机构</strong>: National University of Singapore (新加坡国立大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Multimedia (<a target="_blank" rel="noopener" href="http://cs.MM">cs.MM</a>)<br>
<strong>备注</strong>:  ICCV 2025 paper. This arXiv version updates Figure 1 to include the concurrent work Qwen2.5-VL to ensure consistency with Table 1</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent video-language models have shown great potential for video understanding, but still struggle with accurate temporal grounding for event-level perception. We observe that two main factors in video understanding (i.e., temporal grounding and textual response) form a logical hierarchy: accurate temporal evidence grounding lays the foundation for reliable textual response. However, existing works typically handle these two tasks in a coupled manner without a clear logical structure, leading to sub-optimal objectives. We address this from a factorized learning perspective. We first propose D ^2 VLM, a framework that decouples the learning of these two tasks while also emphasizing their inherent dependency. We adopt a “grounding then answering with evidence referencing” paradigm and introduce evidence tokens for evidence grounding, which emphasize event-level visual semantic capture beyond the focus on timestamp representation in existing works. To further facilitate the learning of these two tasks, we introduce a novel factorized preference optimization (FPO) algorithm. Unlike standard preference optimization, FPO explicitly incorporates probabilistic temporal grounding modeling into the optimization objective, enabling preference learning for both temporal grounding and textual response. We also construct a synthetic dataset to address the lack of suitable datasets for factorized preference learning with explicit temporal grounding. Experiments on various tasks demonstrate the clear advantage of our approach. Our source code is available at this https URL.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-53] HY-MT1.5 Technical Report</p>
<p>【速读】： 该论文旨在解决高精度机器翻译（Machine Translation, MT）模型在参数效率与性能之间难以平衡的问题，尤其是在中英及英外语言对上的表现优化。其解决方案的关键在于构建一个全流程的多阶段训练框架，包括通用预训练与面向翻译的预训练、监督微调、策略内蒸馏（on-policy distillation）以及强化学习（Reinforcement Learning, RL），从而实现模型在有限参数规模下逼近甚至超越超大规模专有模型（如Gemini-3.0-Pro）的性能。特别是HY-MT1.5-1.8B和HY-MT1.5-7B两个模型分别在小参数量和中等参数量级别上实现了卓越的翻译质量与鲁棒性，且支持术语干预、上下文感知翻译和格式保持等高级约束能力，显著提升了实际应用场景中的可用性与灵活性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24092">https://arxiv.org/abs/2512.24092</a><br>
<strong>作者</strong>: Mao Zheng,Zheng Li,Tao Chen,Mingyang Song,Di Wang<br>
<strong>机构</strong>: Tencent Hunyuan Team (腾讯混元团队)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In this report, we introduce our latest translation models, HY-MT1.5-1.8B and HY-MT1.5-7B, a new family of machine translation models developed through a holistic training framework tailored for high-performance translation. Our methodology orchestrates a multi-stage pipeline that integrates general and MT-oriented pre-training, supervised fine-tuning, on-policy distillation, and reinforcement learning. HY-MT1.5-1.8B, the 1.8B-parameter model demonstrates remarkable parameter efficiency, comprehensively outperforming significantly larger open-source baselines (e.g., Tower-Plus-72B, Qwen3-32B) and mainstream commercial APIs (e.g., Microsoft Translator, Doubao Translator) in standard Chinese-foreign and English-foreign tasks. It achieves approximately 90% of the performance of ultra-large proprietary models such as Gemini-3.0-Pro, while marginally trailing Gemini-3.0-Pro on WMT25 and Mandarin-minority language benchmarks, it maintains a substantial lead over other competing models. Furthermore, HY-MT1.5-7B establishes a new state-of-the-art for its size class, achieving 95% of Gemini-3.0-Pro’s performance on Flores-200 and surpassing it on the challenging WMT25 and Mandarin-minority language test sets. Beyond standard translation, the HY-MT1.5 series supports advanced constraints, including terminology intervention, context-aware translation, and format preservation. Extensive empirical evaluations confirm that both models offer highly competitive, robust solutions for general and specialized translation tasks within their respective parameter scales.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-54] Beyond Hallucinations: A Composite Score for Measuring Reliability in Open-Source <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  <mark class="hl-label red">AAAI2026</mark></p>
<p>【速读】： 该论文旨在解决大语言模型（Large Language Models, LLMs）在决策关键领域中可靠性不足的问题，具体表现为模型过度自信、在输入分布变化下性能下降以及缺乏明确的不确定性估计。现有评估方法碎片化，仅关注单一维度。其解决方案的核心是提出综合可靠性评分（Composite Reliability Score, CRS），这是一个统一框架，将校准（calibration）、鲁棒性（robustness）和不确定性量化（uncertainty quantification）整合为一个可解释的单一指标。通过在五个问答（QA）数据集上对十种主流开源LLM进行实验，CRS不仅保持了稳定的模型排名，还揭示了单个指标无法捕捉的隐藏失效模式，表明最可靠的系统需在准确性、鲁棒性和校准不确定性之间取得平衡。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24058">https://arxiv.org/abs/2512.24058</a><br>
<strong>作者</strong>: Rohit Kumar Salla,Manoj Saravanan,Shrikar Reddy Kota<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  5 pages, 4 tables, accepted at AAAI 2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) like LLaMA, Mistral, and Gemma are increasingly used in decision-critical domains such as healthcare, law, and finance, yet their reliability remains uncertain. They often make overconfident errors, degrade under input shifts, and lack clear uncertainty estimates. Existing evaluations are fragmented, addressing only isolated aspects. We introduce the Composite Reliability Score (CRS), a unified framework that integrates calibration, robustness, and uncertainty quantification into a single interpretable metric. Through experiments on ten leading open-source LLMs across five QA datasets, we assess performance under baselines, perturbations, and calibration methods. CRS delivers stable model rankings, uncovers hidden failure modes missed by single metrics, and highlights that the most dependable systems balance accuracy, robustness, and calibrated uncertainty.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-55] AHA: Aligning Large Audio-Language Models for <mark class="hl-label green">Reasoning</mark>  Hallucinations via Counterfactual Hard Negatives</p>
<p>【速读】： 该论文旨在解决大型音频语言模型（Large Audio-Language Models, LALMs）中存在的幻觉问题，即模型生成的文本与输入音频内容缺乏语义一致性。作者通过系统分析发现，此类接地失败可细分为四类：事件遗漏（Event Omission）、错误事件身份识别（False Event Identity）、时间关系错误（Temporal Relation Error）和定量时间错误（Quantitative Temporal Error）。解决方案的关键在于提出AHA（Audio Hallucination Alignment）框架，其核心机制是利用反事实硬负样本挖掘（counterfactual hard negative mining）构建高质量偏好数据集，使模型能够区分严格的声学证据与语言上看似合理但实际虚假的内容；同时引入AHA-Eval诊断基准以精细化评估模型的时间推理能力。实验表明，基于此框架微调后的Qwen-Audio-AHA模型在AHA-Eval上提升13.7%，并在MMAU-Test和MMAR等公开基准上分别取得1.3%和1.6%的显著性能增益，验证了方法的有效性与泛化能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24052">https://arxiv.org/abs/2512.24052</a><br>
<strong>作者</strong>: Yanxi Chen,Wenhui Zhu,Xiwen Chen,Zhipeng Wang,Xin Li,Peijie Qiu,Hao Wang,Xuanzhao Dong,Yujian Xiong,Anderson Schneider,Yuriy Nevmyvaka,Yalin Wang<br>
<strong>机构</strong>: Arizona State University (亚利桑那州立大学); Clemson University (克莱姆森大学); Washington University in St.Louis (圣路易斯华盛顿大学); Rice University (莱斯大学); Morgan Stanley (摩根士丹利)<br>
<strong>类目</strong>: ound (<a target="_blank" rel="noopener" href="http://cs.SD">cs.SD</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Multimedia (<a target="_blank" rel="noopener" href="http://cs.MM">cs.MM</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Although Large Audio-Language Models (LALMs) deliver state-of-the-art (SOTA) performance, they frequently suffer from hallucinations, e.g. generating text not grounded in the audio input. We analyze these grounding failures and identify a distinct taxonomy: Event Omission, False Event Identity, Temporal Relation Error, and Quantitative Temporal Error. To address this, we introduce the AHA (Audio Hallucination Alignment) framework. By leveraging counterfactual hard negative mining, our pipeline constructs a high-quality preference dataset that forces models to distinguish strict acoustic evidence from linguistically plausible fabrications. Additionally, we establish AHA-Eval, a diagnostic benchmark designed to rigorously test these fine-grained temporal reasoning capabilities. We apply this data to align Qwen2.5-Omni. The resulting model, Qwen-Audio-AHA, achieves a 13.7% improvement on AHA-Eval. Crucially, this benefit generalizes beyond our diagnostic set. Our model shows substantial gains on public benchmarks, including 1.3% on MMAU-Test and 1.6% on MMAR, outperforming latest SOTA methods.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-56] Jailbreaking Attacks vs. Content Safety Filters: How Far Are We in the <mark class="hl-label green">LLM</mark>  Safety Arms Race?</p>
<p>【速读】： 该论文旨在解决当前对大型语言模型（Large Language Models, LLMs）安全性的评估过于聚焦于模型本身，而忽视了实际部署中包含的完整推理管道（包括输入和输出过滤阶段）的问题。现有研究高估了越狱攻击（jailbreaking）的成功率，因其未考虑多层安全机制的作用。解决方案的关键在于首次系统性地评估针对LLM安全对齐的越狱攻击在完整推理管道中的有效性，发现几乎所有越狱技术均可被至少一种安全过滤器检测到，从而揭示出当前评估方法的局限性，并强调需进一步优化检测精度（recall与precision的平衡）以提升防护能力与用户体验。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24044">https://arxiv.org/abs/2512.24044</a><br>
<strong>作者</strong>: Yuan Xin,Dingfan Chen,Linyi Yang,Michael Backes,Xiao Zhang<br>
<strong>机构</strong>: CISPA Helmholtz Center for Information Security (德国信息安全中心); Max Planck Institute for Intelligent Systems (马克斯普朗克智能系统研究所); Southern University of Science and Technology (南方科技大学)<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  26 pages,11 tables, 7 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:As large language models (LLMs) are increasingly deployed, ensuring their safe use is paramount. Jailbreaking, adversarial prompts that bypass model alignment to trigger harmful outputs, present significant risks, with existing studies reporting high success rates in evading common LLMs. However, previous evaluations have focused solely on the models, neglecting the full deployment pipeline, which typically incorporates additional safety mechanisms like content moderation filters. To address this gap, we present the first systematic evaluation of jailbreak attacks targeting LLM safety alignment, assessing their success across the full inference pipeline, including both input and output filtering stages. Our findings yield two key insights: first, nearly all evaluated jailbreak techniques can be detected by at least one safety filter, suggesting that prior assessments may have overestimated the practical success of these attacks; second, while safety filters are effective in detection, there remains room to better balance recall and precision to further optimize protection and user experience. We highlight critical gaps and call for further refinement of detection accuracy and usability in LLM safety systems.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-57] CLP: Large Language Model <mark class="hl-label green">Reasoning</mark>  with Implicit Cognition Latent <mark class="hl-label green">Planning</mark></p>
<p>【速读】： 该论文旨在解决大语言模型（Large Language Models, LLMs）在依赖显式文本计划进行推理时所面临的两大挑战：一是模型幻觉导致的计划生成不准确，二是任务特定问题的高多样性使得通用计划难以构建。为应对这些问题，作者提出iCLP框架，其核心创新在于借鉴人类隐式认知（Implicit Cognition, IC）机制，使LLMs能够自适应地生成潜在计划（Latent Plans, LPs），即对有效推理指令的紧凑编码。关键步骤包括：首先从已有的逐步推理轨迹中蒸馏出显式计划；接着通过向量量化自动编码器与码本学习这些计划的离散表示；最后在潜在计划与对应推理步骤的配对数据上微调LLMs，使其在语言空间中推理时能基于潜空间中的隐式规划完成决策。这一方法显著提升了数学推理和代码生成任务中的准确性与效率，并展现出跨领域泛化能力，同时保持了思维链（Chain-of-Thought）推理的可解释性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24014">https://arxiv.org/abs/2512.24014</a><br>
<strong>作者</strong>: Sijia Chen,Di Niu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  9 pages, 6 figures. The source code is publicly available at <a target="_blank" rel="noopener" href="https://github.com/AgenticFinLab/latent-planning">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language models (LLMs), when guided by explicit textual plans, can perform reliable step-by-step reasoning during problem-solving. However, generating accurate and effective textual plans remains challenging due to LLM hallucinations and the high diversity of task-specific questions. To address this, we draw inspiration from human Implicit Cognition (IC), the subconscious process by which decisions are guided by compact, generalized patterns learned from past experiences without requiring explicit verbalization. We propose iCLP, a novel framework that enables LLMs to adaptively generate latent plans (LPs), which are compact encodings of effective reasoning instructions. iCLP first distills explicit plans from existing step-by-step reasoning trajectories. It then learns discrete representations of these plans via a vector-quantized autoencoder coupled with a codebook. Finally, by fine-tuning LLMs on paired latent plans and corresponding reasoning steps, the models learn to perform implicit planning during reasoning. Experimental results on mathematical reasoning and code generation tasks demonstrate that, with iCLP, LLMs can plan in latent space while reasoning in language space. This approach yields significant improvements in both accuracy and efficiency and, crucially, demonstrates strong cross-domain generalization while preserving the interpretability of chain-of-thought reasoning.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-58] WISE: Web Information Satire and Fakeness Evaluation <mark class="hl-label red">WSDM</mark> <mark class="hl-label red">WSDM2026</mark></p>
<p>【速读】： 该论文旨在解决虚假新闻（fake news）与讽刺内容（satire）之间的区分难题，因其语言特征高度重叠但意图迥异，导致传统检测方法难以准确识别。解决方案的关键在于构建并评估WISE（Web Information Satire and Fakeness Evaluation）框架，通过在Fakeddit数据集上对八种轻量级Transformer模型及两种基线模型进行系统性比较，采用多维度指标（如准确率、F1分数、ROC-AUC等）和严格的统计检验（如配对t检验和McNemar检验），验证了轻量模型如MiniLM和DistilBERT在保持高精度的同时显著降低计算资源消耗，从而为资源受限场景下部署高效、可靠的虚假信息检测系统提供了可行路径。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24000">https://arxiv.org/abs/2512.24000</a><br>
<strong>作者</strong>: Gaurab Chhetri,Subasish Das,Tausif Islam Chowdhury<br>
<strong>机构</strong>: Texas State University (德克萨斯州立大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  This is the author’s preprint. Accepted to WEBGRAPH 2026 (co-located with WSDM 2026), Boise, Idaho, USA, Feb 26, 2026. Final version will appear in WSDM 2026 Companion Proceedings. Conf: <a target="_blank" rel="noopener" href="https://wsdm-conference.org/2026/">this https URL</a> Workshop: <a target="_blank" rel="noopener" href="https://aiimlab.org/events/WSDM_2026_WEB_and_GRAPH_2026_Workshop_on_Web_and_Graphs_Responsible_Intelligence_and_Social_Media.html">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Distinguishing fake or untrue news from satire or humor poses a unique challenge due to their overlapping linguistic features and divergent intent. This study develops WISE (Web Information Satire and Fakeness Evaluation) framework which benchmarks eight lightweight transformer models alongside two baseline models on a balanced dataset of 20,000 samples from Fakeddit, annotated as either fake news or satire. Using stratified 5-fold cross-validation, we evaluate models across comprehensive metrics including accuracy, precision, recall, F1-score, ROC-AUC, PR-AUC, MCC, Brier score, and Expected Calibration Error. Our evaluation reveals that MiniLM, a lightweight model, achieves the highest accuracy (87.58%) among all models, while RoBERTa-base achieves the highest ROC-AUC (95.42%) and strong accuracy (87.36%). DistilBERT offers an excellent efficiency-accuracy trade-off with 86.28% accuracy and 93.90% ROC-AUC. Statistical tests confirm significant performance differences between models, with paired t-tests and McNemar tests providing rigorous comparisons. Our findings highlight that lightweight models can match or exceed baseline performance, offering actionable insights for deploying misinformation detection systems in real-world, resource-constrained settings.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-59] Fantastic <mark class="hl-label green">Reasoning</mark>  Behaviors and Where to Find Them: Unsupervised Discovery of the <mark class="hl-label green">Reasoning</mark>  Process</p>
<p>【速读】： 该论文旨在解决大语言模型（Large Language Models, LLMs）在推理过程中内部机制不透明的问题，尤其是现有基于人工定义概念（如“过度思考”或“反思”）的监督式分析方法难以全面捕捉复杂推理行为的局限性。其解决方案的关键在于提出一种无监督框架 RISE（Reasoning behavior Interpretability via Sparse auto-Encoder），通过将思维链（Chain-of-Thought）分解为句子级“步骤”，并在步骤级激活空间上训练稀疏自编码器（Sparse Auto-Encoders, SAEs），从而发现可解释的推理向量（reasoning vectors），即编码不同推理行为的方向。这些向量不仅能够揭示如反思和回溯等已知行为的分离区域，还可通过目标干预实现对特定推理行为的可控增强或抑制，且无需重新训练模型，同时还能识别出超越人类先验的新颖行为模式，如与置信度相关的向量，显著提升了对LLM推理过程的理解与控制能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23988">https://arxiv.org/abs/2512.23988</a><br>
<strong>作者</strong>: Zhenyu Zhang,Shujian Zhang,John Lambert,Wenxuan Zhou,Zhangyang Wang,Mingqing Chen,Andrew Hard,Rajiv Mathews,Lun Wang<br>
<strong>机构</strong>: Google DeepMind(谷歌深度思维); The University of Texas at Austin(德克萨斯大学奥斯汀分校)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Despite the growing reasoning capabilities of recent large language models (LLMs), their internal mechanisms during the reasoning process remain underexplored. Prior approaches often rely on human-defined concepts (e.g., overthinking, reflection) at the word level to analyze reasoning in a supervised manner. However, such methods are limited, as it is infeasible to capture the full spectrum of potential reasoning behaviors, many of which are difficult to define in token space. In this work, we propose an unsupervised framework (namely, RISE: Reasoning behavior Interpretability via Sparse auto-Encoder) for discovering reasoning vectors, which we define as directions in the activation space that encode distinct reasoning behaviors. By segmenting chain-of-thought traces into sentence-level ‘steps’ and training sparse auto-encoders (SAEs) on step-level activations, we uncover disentangled features corresponding to interpretable behaviors such as reflection and backtracking. Visualization and clustering analyses show that these behaviors occupy separable regions in the decoder column space. Moreover, targeted interventions on SAE-derived vectors can controllably amplify or suppress specific reasoning behaviors, altering inference trajectories without retraining. Beyond behavior-specific disentanglement, SAEs capture structural properties such as response length, revealing clusters of long versus short reasoning traces. More interestingly, SAEs enable the discovery of novel behaviors beyond human supervision. We demonstrate the ability to control response confidence by identifying confidence-related vectors in the SAE decoder space. These findings underscore the potential of unsupervised latent discovery for both interpreting and controllably steering reasoning in LLMs.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-60] CEC-Zero: Zero-Supervision Character Error Correction with Self-Generated Rewards <mark class="hl-label red">AAAI’26</mark></p>
<p>【速读】： 该论文旨在解决大规模中文拼写纠错（Chinese Spelling Correction, CSC）中现有大语言模型（Large Language Models, LLMs）和监督方法在面对新类型错误时鲁棒性不足、且严重依赖昂贵人工标注的问题。其解决方案的关键在于提出一种零监督强化学习框架 CEC-Zero，通过让 LLM 自主纠正自身错误来实现无需标签的训练：首先从干净文本合成带错输入，然后基于语义相似性和候选纠错结果的一致性计算簇共识奖励（cluster-consensus rewards），并利用近端策略优化（Proximal Policy Optimization, PPO）更新策略。该方法在9个基准上相比监督基线提升10–13 F₁ 分点，优于强监督微调模型5–8 F₁ 分点，同时具备无偏奖励和收敛性的理论保障，为鲁棒、可扩展的CSC提供了全新的无标签范式。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23971">https://arxiv.org/abs/2512.23971</a><br>
<strong>作者</strong>: Zhiming Lin,Kai Zhao,Sophie Zhang,Peilai Yu,Canran Xiao<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  AAAI’26 poster</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large-scale Chinese spelling correction (CSC) remains critical for real-world text processing, yet existing LLMs and supervised methods lack robustness to novel errors and rely on costly annotations. We introduce CEC-Zero, a zero-supervision reinforcement learning framework that addresses this by enabling LLMs to correct their own mistakes. CEC-Zero synthesizes errorful inputs from clean text, computes cluster-consensus rewards via semantic similarity and candidate agreement, and optimizes the policy with PPO. It outperforms supervised baselines by 10–13 F _1  points and strong LLM fine-tunes by 5–8 points across 9 benchmarks, with theoretical guarantees of unbiased rewards and convergence. CEC-Zero establishes a label-free paradigm for robust, scalable CSC, unlocking LLM potential in noisy text pipelines.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-61] Efficient Context Scaling with LongCat ZigZag Attention</p>
<p>【速读】： 该论文旨在解决长文本处理中因全连接注意力机制（full attention）导致的计算开销过大问题，尤其是在长上下文场景下模型推理效率低下的挑战。解决方案的关键在于提出一种稀疏注意力机制——LongCat ZigZag Attention (LoZA)，它能够在有限计算预算下将现有全注意力模型高效转换为稀疏版本，从而在预填充（prefill）密集型和解码（decode）密集型任务中均实现显著加速。通过在训练中期引入LoZA，作者构建了可处理高达100万token的长上下文基础模型LongCat-Flash-Exp，有效支持长期推理与长周期智能体（agentic）能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23966">https://arxiv.org/abs/2512.23966</a><br>
<strong>作者</strong>: Chen Zhang,Yang Bai,Jiahuan Li,Anchun Gui,Keheng Wang,Feifan Liu,Guanyu Wu,Yuwei Jiang,Defei Bu,Li Wei,Haihang Jing,Hongyin Tang,Xin Chen,Xiangzhou Huang,Fengcun Li,Rongxiang Weng,Yulei Qian,Yifan Lu,Yerui Sun,Jingang Wang,Yuchen Xie,Xunliang Cai<br>
<strong>机构</strong>: Meituan(美团)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  10 pages, 3 figures, 3 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce LongCat ZigZag Attention (LoZA), which is a sparse attention scheme designed to transform any existing full-attention models into sparse versions with rather limited compute budget. In long-context scenarios, LoZA can achieve significant speed-ups both for prefill-intensive (e.g., retrieval-augmented generation) and decode-intensive (e.g., tool-integrated reasoning) cases. Specifically, by applying LoZA to LongCat-Flash during mid-training, we serve LongCat-Flash-Exp as a long-context foundation model that can swiftly process up to 1 million tokens, enabling efficient long-term reasoning and long-horizon agentic capabilities.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-62] Improving Multi-step <mark class="hl-label green">RAG</mark>  with Hypergraph-based Memory for Long-Context Complex Relational Modeling</p>
<p>【速读】： 该论文旨在解决多步检索增强生成（multi-step retrieval-augmented generation, RAG）系统中因记忆模块设计静态化而导致的推理碎片化与全局理解能力弱的问题。现有记忆机制仅作为被动存储，无法有效捕捉原始事实间的高阶关联，从而限制了复杂推理和知识演化的表征能力。解决方案的关键在于提出HGMem——一种基于超图（hypergraph）的记忆机制，将记忆建模为具有超边结构的动态表达形式，使记忆单元之间能够逐步形成高阶交互关系，从而构建围绕核心问题的整合性、情境化知识结构，显著提升后续步骤中的深层推理能力和全局语义理解能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23959">https://arxiv.org/abs/2512.23959</a><br>
<strong>作者</strong>: Chulun Zhou,Chunkang Zhang,Guoxin Yu,Fandong Meng,Jie Zhou,Wai Lam,Mo Yu<br>
<strong>机构</strong>: The Chinese University of Hong Kong (香港中文大学); WeChat AI (微信人工智能)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  21 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multi-step retrieval-augmented generation (RAG) has become a widely adopted strategy for enhancing large language models (LLMs) on tasks that demand global comprehension and intensive reasoning. Many RAG systems incorporate a working memory module to consolidate retrieved information. However, existing memory designs function primarily as passive storage that accumulates isolated facts for the purpose of condensing the lengthy inputs and generating new sub-queries through deduction. This static nature overlooks the crucial high-order correlations among primitive facts, the compositions of which can often provide stronger guidance for subsequent steps. Therefore, their representational strength and impact on multi-step reasoning and knowledge evolution are limited, resulting in fragmented reasoning and weak global sense-making capacity in extended contexts. We introduce HGMem, a hypergraph-based memory mechanism that extends the concept of memory beyond simple storage into a dynamic, expressive structure for complex reasoning and global understanding. In our approach, memory is represented as a hypergraph whose hyperedges correspond to distinct memory units, enabling the progressive formation of higher-order interactions within memory. This mechanism connects facts and thoughts around the focal problem, evolving into an integrated and situated knowledge structure that provides strong propositions for deeper reasoning in subsequent steps. We evaluate HGMem on several challenging datasets designed for global sense-making. Extensive experiments and in-depth analyses show that our method consistently improves multi-step RAG and substantially outperforms strong baseline systems across diverse tasks.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-63] Disentangling Learning from Judgment: Representation Learning for Open Response Analytics</p>
<p>【速读】： 该论文旨在解决自动化评分系统中教师评分倾向（rater tendencies）与学生作答内容信号（content signals）混淆的问题，从而导致评分结果难以解释和验证。其关键解决方案是提出一种以分析为导向的框架，将教师历史作为动态先验（dynamic priors），结合句嵌入（sentence embeddings）并采用中心化（centering）和残差化（residualization）方法来消除提示（prompt）和教师效应的混杂影响，最终通过时序验证的线性模型量化各信号贡献，并利用投影表面模型可视化评分分歧。此方法显著提升了评分准确性（AUC~0.815），同时使教师评分行为可审计、可解释，有助于揭示学生真实理解与表面表述之间的差异。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23941">https://arxiv.org/abs/2512.23941</a><br>
<strong>作者</strong>: Conrad Borchers,Manit Patel,Seiyon M. Lee,Anthony F. Botelho<br>
<strong>机构</strong>: Carnegie Mellon University (卡内基梅隆大学); University of Florida (佛罗里达大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>)<br>
<strong>备注</strong>:  Short research paper accepted at Learning Analytics and Knowledge (LAK '26)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Open-ended responses are central to learning, yet automated scoring often conflates what students wrote with how teachers grade. We present an analytics-first framework that separates content signals from rater tendencies, making judgments visible and auditable via analytics. Using de-identified ASSISTments mathematics responses, we model teacher histories as dynamic priors and derive text representations from sentence embeddings, incorporating centering and residualization to mitigate prompt and teacher confounds. Temporally-validated linear models quantify the contributions of each signal, and a projection surfaces model disagreements for qualitative inspection. Results show that teacher priors heavily influence grade predictions; the strongest results arise when priors are combined with content embeddings (AUC~0.815), while content-only models remain above chance but substantially weaker (AUC~0.626). Adjusting for rater effects sharpens the residual content representation, retaining more informative embedding dimensions and revealing cases where semantic evidence supports understanding as opposed to surface-level differences in how students respond. The contribution presents a practical pipeline that transforms embeddings from mere features into learning analytics for reflection, enabling teachers and researchers to examine where grading practices align (or conflict) with evidence of student reasoning and learning.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-64] Probing the Limits of Compressive Memory: A Study of Infini-Attention in Small-Scale Pretraining</p>
<p>【速读】： 该论文旨在解决小语言模型（Small Language Models, SLMs）在资源受限场景下难以有效利用有限数据和计算能力的问题，同时提升其长文本上下文处理能力。解决方案的关键在于引入Infini-attention机制，该机制通过构建压缩记忆来保留历史信息，同时维持局部注意力结构，从而在参数受限的情况下增强模型的长上下文外推能力。实验表明，尽管多次压缩会导致检索准确率下降，但Infini-attention仍显著优于基线模型，在16,384 token上下文中实现最高达31%的准确率提升，验证了其作为架构级记忆机制对SLMs长程依赖建模的有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23862">https://arxiv.org/abs/2512.23862</a><br>
<strong>作者</strong>: Ruizhe Huang,Kexuan Zhang,Yihao Fang,Baifeng Yu<br>
<strong>机构</strong>: Huawei Technologies Canada Co., Ltd (华为技术加拿大有限公司)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This study investigates small-scale pretraining for Small Language Models (SLMs) to enable efficient use of limited data and compute, improve accessibility in low-resource settings and reduce costs. To enhance long-context extrapolation in compact models, we focus on Infini-attention, which builds a compressed memory from past segments while preserving local attention. In our work, we conduct an empirical study using 300M-parameter LLaMA models pretrained with Infini-attention. The model demonstrates training stability and outperforms the baseline in long-context retrieval. We identify the balance factor as a key part of the model performance, and we found that retrieval accuracy drops with repeated memory compressions over long sequences. Even so, Infini-attention still effectively compensates for the SLM’s limited parameters. Particularly, despite performance degradation at a 16,384-token context, the Infini-attention model achieves up to 31% higher accuracy than the baseline. Our findings suggest that achieving robust long-context capability in SLMs benefits from architectural memory like Infini-attention.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-65] rellis: Learning to Compress Key-Value Memory in Attention Models</p>
<p>【速读】： 该论文旨在解决Transformer模型在处理长序列时面临的二次计算复杂度以及不断增长的键值（Key-Value, KV）缓存问题。解决方案的关键在于提出一种名为Trellis的新架构，其核心创新是引入了一个固定大小的记忆体和一个两阶段递归压缩机制，能够在测试时动态地将新的键值信息压缩存储至该记忆体中；该机制通过在线梯度下降与遗忘门（forget gate）相结合的方式，实现压缩记忆的递归更新，从而在保持重要上下文信息的同时控制内存占用，显著提升长序列场景下的性能表现。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23852">https://arxiv.org/abs/2512.23852</a><br>
<strong>作者</strong>: Mahdi Karami,Ali Behrouz,Praneeth Kacham,Vahab Mirrokni<br>
<strong>机构</strong>: Google Research(谷歌研究)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  In Second Conference on Language Modeling (COLM) (2025)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Transformers, while powerful, suffer from quadratic computational complexity and the ever-growing Key-Value (KV) cache of the attention mechanism. This paper introduces Trellis, a novel Transformer architecture with bounded memory that learns how to compress its key-value memory dynamically at test time. Trellis replaces the standard KV cache with a fixed-size memory and train a two-pass recurrent compression mechanism to store new keys and values into memory. To achieve this, it leverages an online gradient descent procedure with a forget gate, enabling the compressed memory to be updated recursively while learning to retain important contextual information from incoming tokens at test time. Extensive experiments on language modeling, common-sense reasoning, recall-intensive tasks, and time series show that the proposed architecture outperforms strong baselines. Notably, its performance gains increase as the sequence length grows, highlighting its potential for long-context applications.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-66] he Drill-Down and Fabricate Test (DDFT): A Protocol for Measuring Epistemic Robustness in Language Models</p>
<p>【速读】： 该论文旨在解决当前语言模型评估体系的局限性问题，即现有静态基准（如MMLU和TruthfulQA）仅衡量模型在理想条件下的知识掌握程度，而无法反映其在信息退化或对抗攻击等现实压力下维持事实准确性（factual accuracy）的能力。为应对这一挑战，作者提出了一种名为“钻取与伪造测试”（Drill-Down and Fabricate Test, DDFT）的新评估协议，其关键在于通过渐进式语义压缩（progressive semantic compression）和对抗性伪造（adversarial fabrication）来量化模型的<strong>认知鲁棒性</strong>（epistemic robustness）。解决方案的核心创新是构建一个双系统认知模型：一个生成流畅文本的语义系统（Semantic System）与一个验证事实准确性的认知验证器（Epistemic Verifier），并通过大规模实证分析发现，模型的错误检测能力（error detection capability）是决定整体鲁棒性的关键瓶颈（rho=-0.817, p=0.007），而非参数量或架构类型，从而揭示了提升可靠性需依赖训练方法和验证机制的革新。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23850">https://arxiv.org/abs/2512.23850</a><br>
<strong>作者</strong>: Rahul Baxi<br>
<strong>机构</strong>: Independent Researcher(独立研究员)<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  Currently under review at TMLR</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Current language model evaluations measure what models know under ideal conditions but not how robustly they know it under realistic stress. Static benchmarks like MMLU and TruthfulQA cannot distinguish a model that lacks knowledge from one whose verification mechanisms collapse when information degrades or adversaries probe for weaknesses. We introduce the Drill-Down and Fabricate Test (DDFT), a protocol that measures epistemic robustness: a model’s ability to maintain factual accuracy under progressive semantic compression and adversarial fabrication. We propose a two-system cognitive model comprising a Semantic System that generates fluent text and an Epistemic Verifier that validates factual accuracy. Our findings, based on evaluating 9 frontier models across 8 knowledge domains at 5 compression levels (1,800 turn-level evaluations), reveal that epistemic robustness is orthogonal to conventional design paradigms. Neither parameter count (r=0.083, p=0.832) nor architectural type (r=0.153, p=0.695) significantly predicts robustness, suggesting it emerges from training methodology and verification mechanisms distinct from current approaches. Error detection capability strongly predicts overall robustness (rho=-0.817, p=0.007), indicating this is the critical bottleneck. We find that flagship models exhibit brittleness despite their scale, while smaller models can achieve robust performance, challenging assumptions about the relationship between model size and reliability. The DDFT framework provides both theoretical foundation and practical tools for assessing epistemic robustness before deployment in critical applications.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-67] Integrating Domain Knowledge for Financial QA: A Multi-Retriever <mark class="hl-label green">RAG</mark>  Approach with <mark class="hl-label green">LLM</mark> s</p>
<p>【速读】： 该论文旨在解决金融数值推理问答（Financial Numerical Reasoning Question Answering, QA）任务中因缺乏领域知识而导致的错误问题。尽管大型语言模型（Large Language Models, LLMs）取得进展，金融类数值问题仍具挑战性，因其依赖特定金融领域知识和复杂的多步数值推理能力。解决方案的关键在于构建一个基于多检索器的检索增强生成系统（multi-retriever Retrieval Augmented Generators, RAG），该系统同时检索外部金融领域知识与内部问题上下文，并结合最新LLM进行推理。实验表明，使用SecBERT编码器进行领域特异性训练显著提升了神经符号模型性能，超越了FinQA论文中的最优基线；同时，最佳提示驱动的LLM生成器实现了当前最优（SOTA）性能，较基线提升7%，但仍低于人类专家水平，验证了小模型在少量示例下外源知识收益与幻觉损失之间的权衡关系，而大模型则更倾向于从外部事实中获益。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23848">https://arxiv.org/abs/2512.23848</a><br>
<strong>作者</strong>: Yukun Zhang,Stefan Elbl Droguett,Samyak Jain<br>
<strong>机构</strong>: Stanford University (斯坦福大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Computational Engineering, Finance, and Science (cs.CE); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This research project addresses the errors of financial numerical reasoning Question Answering (QA) tasks due to the lack of domain knowledge in finance. Despite recent advances in Large Language Models (LLMs), financial numerical questions remain challenging because they require specific domain knowledge in finance and complex multi-step numeric reasoning. We implement a multi-retriever Retrieval Augmented Generators (RAG) system to retrieve both external domain knowledge and internal question contexts, and utilize the latest LLM to tackle these tasks. Through comprehensive ablation experiments and error analysis, we find that domain-specific training with the SecBERT encoder significantly contributes to our best neural symbolic model surpassing the FinQA paper’s top model, which serves as our baseline. This suggests the potential superior performance of domain-specific training. Furthermore, our best prompt-based LLM generator achieves the state-of-the-art (SOTA) performance with significant improvement (7%), yet it is still below the human expert performance. This study highlights the trade-off between hallucinations loss and external knowledge gains in smaller models and few-shot examples. For larger models, the gains from external facts typically outweigh the hallucination loss. Finally, our findings confirm the enhanced numerical reasoning capabilities of the latest LLM, optimized for few-shot learning.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-68] Adversarial Lens: Exploiting Attention Layers to Generate Adversarial Examples for Evaluation</p>
<p>【速读】： 该论文旨在解决如何在大型语言模型（Large Language Models, LLMs）的评估管道中引入有效且语义一致的对抗样本，以更真实地测试其鲁棒性。传统方法如基于提示（prompt-based）或梯度（gradient-based）的攻击往往难以保证扰动与模型内部生成逻辑的一致性。本文的关键解决方案是利用中间注意力层（intermediate attention layers）中模型对token的预测分布直接生成对抗样本——这些分布代表了模型在生成过程中的阶段性假设，因此所生成的扰动不仅语义上接近原始输入，还能保持与模型自身推理路径的一致性，从而为评估系统提供更具说服力的压力测试手段。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23837">https://arxiv.org/abs/2512.23837</a><br>
<strong>作者</strong>: Kaustubh Dhole<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advances in mechanistic interpretability suggest that intermediate attention layers encode token-level hypotheses that are iteratively refined toward the final output. In this work, we exploit this property to generate adversarial examples directly from attention-layer token distributions. Unlike prompt-based or gradient-based attacks, our approach leverages model-internal token predictions, producing perturbations that are both plausible and internally consistent with the model’s own generation process. We evaluate whether tokens extracted from intermediate layers can serve as effective adversarial perturbations for downstream evaluation tasks. We conduct experiments on argument quality assessment using the ArgQuality dataset, with LLaMA-3.1-Instruct-8B serving as both the generator and evaluator. Our results show that attention-based adversarial examples lead to measurable drops in evaluation performance while remaining semantically similar to the original inputs. However, we also observe that substitutions drawn from certain layers and token positions can introduce grammatical degradation, limiting their practical effectiveness. Overall, our findings highlight both the promise and current limitations of using intermediate-layer representations as a principled source of adversarial examples for stress-testing LLM-based evaluation pipelines.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-69] Retrieval Augmented Question Answering: When Should <mark class="hl-label green">LLM</mark> s Admit Ignorance?</p>
<p>【速读】： 该论文旨在解决大语言模型（Large Language Models, LLMs）在检索增强生成（Retrieval-Augmented Generation, RAG）中因扩展上下文窗口（expanded context windows）引入过多无关信息而导致生成性能下降的问题。其核心解决方案是设计一种自适应提示策略（adaptive prompting strategy），通过将检索到的信息分块并逐块顺序输入LLM进行推理，从而在保留关键知识的同时减少冗余信息干扰；该策略通过调节分块大小实现相关性与无关信息量之间的权衡，实验证明其在保持与标准提示相当性能的前提下显著降低token消耗。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23836">https://arxiv.org/abs/2512.23836</a><br>
<strong>作者</strong>: Dingmin Wang,Ji Ma,Shankar Kumar<br>
<strong>机构</strong>: Google Research (谷歌研究); University of Oxford (牛津大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The success of expanded context windows in Large Language Models (LLMs) has driven increased use of broader context in retrieval-augmented generation. We investigate the use of LLMs for retrieval augmented question answering. While longer contexts make it easier to incorporate targeted knowledge, they introduce more irrelevant information that hinders the model’s generation process and degrades its performance. To address the issue, we design an adaptive prompting strategy which involves splitting the retrieved information into smaller chunks and sequentially prompting a LLM to answer the question using each chunk. Adjusting the chunk size allows a trade-off between incorporating relevant information and reducing irrelevant information. Experimental results on three open-domain question answering datasets demonstrate that the adaptive strategy matches the performance of standard prompting while using fewer tokens. Our analysis reveals that when encountering insufficient information, the LLM often generates incorrect answers instead of declining to respond, which constitutes a major source of error. This finding highlights the need for further research into enhancing LLMs’ ability to effectively decline requests when faced with inadequate information.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-70] Explaining News Bias Detection: A Comparative SHAP Analysis of Transformer Model Decision Mechanisms</p>
<p>【速读】： 该论文旨在解决新闻文本中偏见检测模型决策过程不透明、错误机制不清的问题，尤其关注不同模型架构如何通过语言特征识别偏见并导致误判。其解决方案的关键在于采用基于SHAP（Shapley Additive Explanations）的可解释性分析方法，对两个基于Transformer的偏见检测模型——一个在BABE数据集上微调的专用偏见检测器与一个领域自适应预训练RoBERTa模型——进行词级归因比较，揭示二者在正确与错误预测中对评价性语言的处理差异。研究发现，专用偏见检测器更易将中立内容误判为偏见，因其归因强度与预测准确性不一致；而领域适应模型则表现出更符合预测结果的归因模式，显著减少63%的假阳性，且错误主要源于话语层面的模糊性而非明确偏见线索，凸显了模型结构和训练策略对可靠性和新闻场景适用性的关键影响。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23835">https://arxiv.org/abs/2512.23835</a><br>
<strong>作者</strong>: Himel Ghosh<br>
<strong>机构</strong>: Technical University of Munich (慕尼黑工业大学); Sapienza University of Rome (罗马大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Human-Computer Interaction (cs.HC)<br>
<strong>备注</strong>:  10 pages, 8 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Automated bias detection in news text is heavily used to support journalistic analysis and media accountability, yet little is known about how bias detection models arrive at their decisions or why they fail. In this work, we present a comparative interpretability study of two transformer-based bias detection models: a bias detector fine-tuned on the BABE dataset and a domain-adapted pre-trained RoBERTa model fine-tuned on the BABE dataset, using SHAP-based explanations. We analyze word-level attributions across correct and incorrect predictions to characterize how different model architectures operationalize linguistic bias. Our results show that although both models attend to similar categories of evaluative language, they differ substantially in how these signals are integrated into predictions. The bias detector model assigns stronger internal evidence to false positives than to true positives, indicating a misalignment between attribution strength and prediction correctness and contributing to systematic over-flagging of neutral journalistic content. In contrast, the domain-adaptive model exhibits attribution patterns that better align with prediction outcomes and produces 63% fewer false positives. We further demonstrate that model errors arise from distinct linguistic mechanisms, with false positives driven by discourse-level ambiguity rather than explicit bias cues. These findings highlight the importance of interpretability-aware evaluation for bias detection systems and suggest that architectural and training choices critically affect both model reliability and deployment suitability in journalistic contexts.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-71] StressRoBERTa: Cross-Condition Transfer Learning from Depression Anxiety and PTSD to Stress Detection</p>
<p>【速读】： 该论文旨在解决如何通过自然语言处理技术自动检测英文推文中的自我报告慢性应激（chronic stress）问题，尤其关注利用跨疾病迁移学习提升模型性能。其解决方案的关键在于提出 StressRoBERTa 模型，该模型基于 RoBERTa 架构，通过在临床相关疾病（如抑郁、焦虑、创伤后应激障碍 PTSD）语料库 Stress-SMHD 上进行持续训练（continual training），从而获得更优的语义表征能力；随后在 SMM4H 2022 Task 8 数据集上微调，最终实现 82% 的 F1 分数，显著优于基线模型及共享任务最佳系统（79% F1），验证了从高共病率的精神健康障碍中迁移知识对提升慢性应激识别效果的有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23813">https://arxiv.org/abs/2512.23813</a><br>
<strong>作者</strong>: Amal Alqahtani,Efsun Kayi,Mona Diab<br>
<strong>机构</strong>: The George Washington University (乔治·华盛顿大学); King Saud University (国王萨德大学); Johns Hopkins University Applied Physics Laboratory (约翰霍普金斯大学应用物理实验室); Carnegie Mellon University (卡内基梅隆大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The prevalence of chronic stress represents a significant public health concern, with social media platforms like Twitter serving as important venues for individuals to share their experiences. This paper introduces StressRoBERTa, a cross-condition transfer learning approach for automatic detection of self-reported chronic stress in English tweets. The investigation examines whether continual training on clinically related conditions (depression, anxiety, PTSD), disorders with high comorbidity with chronic stress, improves stress detection compared to general language models and broad mental health models. RoBERTa is continually trained on the Stress-SMHD corpus (108M words from users with self-reported diagnoses of depression, anxiety, and PTSD) and fine-tuned on the SMM4H 2022 Task 8 dataset. StressRoBERTa achieves 82% F1-score, outperforming the best shared task system (79% F1) by 3 percentage points. The results demonstrate that focused cross-condition transfer from stress-related disorders (+1% F1 over vanilla RoBERTa) provides stronger representations than general mental health training. Evaluation on Dreaddit (81% F1) further demonstrates transfer from clinical mental health contexts to situational stress discussions.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-72] MiMo-Audio: Audio Language Models are Few-Shot Learners</p>
<p>【速读】： 该论文旨在解决现有音频语言模型依赖任务特定微调（task-specific fine-tuning）导致泛化能力不足的问题，即模型难以像人类一样仅通过少量示例或简单指令即可适应新音频任务。其解决方案的关键在于采用大规模预训练范式——通过将MiMo-Audio的预训练数据扩展至超过一亿小时，使模型在无需微调的情况下涌现出少样本学习（few-shot learning）能力，并结合系统化的指令微调（instruction tuning）与思维机制（thinking mechanisms）提升音频理解与生成性能。这一方法使MiMo-Audio-7B-Base在开源模型中达到语音智能和音频理解基准上的最先进水平（SOTA），并成功泛化至训练数据中未包含的任务，如语音转换、风格迁移和语音编辑等。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23808">https://arxiv.org/abs/2512.23808</a><br>
<strong>作者</strong>: Xiaomi LLM-Core Team:Dong Zhang,Gang Wang,Jinlong Xue,Kai Fang,Liang Zhao,Rui Ma,Shuhuai Ren,Shuo Liu,Tao Guo,Weiji Zhuang,Xin Zhang,Xingchen Song,Yihan Yan,Yongzhe He,Cici,Bowen Shen,Chengxuan Zhu,Chong Ma,Chun Chen,Heyu Chen,Jiawei Li,Lei Li,Menghang Zhu,Peidian Li,Qiying Wang,Sirui Deng,Weimin Xiong,Wenshan Huang,Wenyu Yang,Yilin Jiang,Yixin Yang,Yuanyuan Tian,Yue Ma,Yue Yu,Zihan Zhang,Zihao Yue,Bangjun Xiao,Bingquan Xia,Bofei Gao,Bowen Ye,Can Cai,Chang Liu,Chenhong He,Chunan Li,Dawei Zhu,Duo Zhang,Fengyuan Shi,Guoan Wang,Hailin Zhang,Hanglong Lv,Hanyu Li,Hao Tian,Heng Qu,Hongshen Xu,Houbin Zhang,Huaqiu Liu,Jiangshan Duo,Jianguang Zuo,Jianyu Wei,Jiebao Xiao,Jinhao Dong,Jun Shi,Junhao Hu,Kainan Bao,Kang Zhou,Linghao Zhang,Meng Chen,Nuo Chen,Peng Zhang,Qianli Chen,Qiantong Wang,Rang Li,Shaohui Liu,Shengfan Wang,Shicheng Li,Shihua Yu,Shijie Cao,Shimao Chen,Shuhao Gu,Weikun Wang,Wenhan Ma,Xiangwei Deng,Xing Yong,Xing Zhang,Xu Wang,Yifan Song,Yihao Zhao,Yingbo Zhao,Yizhao Gao,Yu Cheng,Yu Tu,Yudong Wang,Zhaojun Huang,Zhengju Tang,Zhenru Lin,Zhichao Song,Zhipeng Xu,Zhixian Zheng,Zihan Jiang<br>
<strong>机构</strong>: Xiaomi(小米)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Sound (<a target="_blank" rel="noopener" href="http://cs.SD">cs.SD</a>); Audio and Speech Processing (<a target="_blank" rel="noopener" href="http://eess.AS">eess.AS</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Existing audio language models typically rely on task-specific fine-tuning to accomplish particular audio tasks. In contrast, humans are able to generalize to new audio tasks with only a few examples or simple instructions. GPT-3 has shown that scaling next-token prediction pretraining enables strong generalization capabilities in text, and we believe this paradigm is equally applicable to the audio domain. By scaling MiMo-Audio’s pretraining data to over one hundred million of hours, we observe the emergence of few-shot learning capabilities across a diverse set of audio tasks. We develop a systematic evaluation of these capabilities and find that MiMo-Audio-7B-Base achieves SOTA performance on both speech intelligence and audio understanding benchmarks among open-source models. Beyond standard metrics, MiMo-Audio-7B-Base generalizes to tasks absent from its training data, such as voice conversion, style transfer, and speech editing. MiMo-Audio-7B-Base also demonstrates powerful speech continuation capabilities, capable of generating highly realistic talk shows, recitations, livestreaming and debates. At the post-training stage, we curate a diverse instruction-tuning corpus and introduce thinking mechanisms into both audio understanding and generation. MiMo-Audio-7B-Instruct achieves open-source SOTA on audio understanding benchmarks (MMSU, MMAU, MMAR, MMAU-Pro), spoken dialogue benchmarks (Big Bench Audio, MultiChallenge Audio) and instruct-TTS evaluations, approaching or surpassing closed-source models. Model checkpoints and full evaluation suite are available at this https URL.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-73] Entropy-Aware Speculative Decoding Toward Improved <mark class="hl-label green">LLM</mark>  <mark class="hl-label green">Reasoning</mark></p>
<p>【速读】： 该论文旨在解决传统推测解码（Speculative Decoding, SD）方法中因草稿模型（draft model）与目标大语言模型（LLM）过度对齐而导致性能受限的问题，即SD的加速效果无法超越目标模型本身的性能上限。解决方案的关键在于提出一种无需训练的增强方法——熵感知推测解码（Entropy-Aware Speculative Decoding, EASD），其核心机制是在每步解码时引入基于采样分布熵的动态惩罚策略：当草稿模型和目标模型均表现出高熵且top-N预测存在显著重叠时，该候选token被拒绝并由目标模型重新采样，从而有效防止低置信度错误传播。此机制使EASD具备超越目标模型固有性能的潜力，并在多个推理基准测试中验证了其优越性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23765">https://arxiv.org/abs/2512.23765</a><br>
<strong>作者</strong>: Tiancheng Su,Meicong Zhang,Guoxiu He<br>
<strong>机构</strong>: East China Normal University (华东师范大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Speculative decoding (SD) accelerates large language model (LLM) reasoning by using a small draft model to generate candidate tokens, which the target LLM either accepts directly or regenerates upon rejection. However, excessive alignment between the draft and target models constrains SD to the performance of the target LLM. To address this limitation, we propose Entropy-Aware Speculative Decoding (EASD), a training-free enhancement. Building on standard SD, EASD incorporates a dynamic entropy-based penalty. At each decoding step, we employ the entropy of the sampling distribution to quantify model uncertainty. When both models exhibit high entropy with substantial overlap among their top-N predictions, the corresponding token is rejected and re-sampled by the target LLM. This penalty prevents low-confidence errors from propagating. By incorporating draft-model verification, EASD enables the possibility of surpassing the target model’s inherent performance. Experiments across multiple reasoning benchmarks demonstrate that EASD consistently outperforms existing SD methods and, in most cases, surpasses the target LLM itself. We further prove that the efficiency of EASD is comparable to that of SD. The code can be found in the Supplementary Materials.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-74] State-of-the-art Small Language Coder Model: Mify-Coder</p>
<p>【速读】： 该论文旨在解决当前大型语言模型（Large Language Model, LLM）在代码生成与智能体驱动工作流中存在计算资源消耗高、效率低且难以部署于通用硬件环境的问题。其核心解决方案在于通过“计算最优”训练策略，在仅使用2.5B参数的Mify-Coder模型上，融合高质量人工标注数据与代理设计的合成数据，并结合基于大模型的质量过滤机制提升数据密度，从而实现与更大规模模型相当甚至更优的准确性、安全性与效率。关键创新点在于：1）采用受控的数据混合与采样动态优化策略；2）利用企业级评估数据迭代优化提示工程；3）通过量化技术使模型可在标准桌面环境下部署，无需专用硬件支持。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23747">https://arxiv.org/abs/2512.23747</a><br>
<strong>作者</strong>: Abhinav Parmar,Abhisek Panigrahi,Abhishek Kumar Dwivedi,Abhishek Bhattacharya,Adarsh Ramachandra,Aditya Choudhary,Aditya Garg,Aditya Raj,Alankrit Bhatt,Alpesh Yadav,Anant Vishnu,Ananthu Pillai,Ankush Kumar,Aryan Patnaik,Aswatha Narayanan S,Avanish Raj Singh,Bhavya Shree Gadda,Brijesh Pankajbhai Kachhadiya,Buggala Jahnavi,Chidurala Nithin Krishna,Chintan Shah,Chunduru Akshaya,Debarshi Banerjee,Debrup Dey,Deepa R.,Deepika B G,Faiz ur Rahman,Gagan Gayari,Gudhi Jagadeesh Kumar Naidu,Gursimar Singh,Harshal Tyagi,Harshini K,James Mani Vathalloor,Jayarama Nettar,Jayashree Gajjam,Joe Walter Sugil George,Kamalakara Sri Krishna Tadepalli,Kamalkumar Rathinasamy,Karan Chaurasia,Karthikeyan S,Kashish Arora,Kaushal Desai,Khushboo Buwade,Kiran Manjrekar,Malikireddy Venkata Sai Likhitha,Manjunath A,Mitali Mahavir Bedmutha,Mohammed Rafee Tarafdar,Nikhil Tiwari,Nikitha K Gigi,Pavan Ravikumar,Pendyala Swarnanjali,Piyush Anand,Prakash Chandrasekar,Prasanna Bhalchandra Gawade,Prasanth Sivan,Preeti Khurana,Priyanshi Babbar,Rajab Ali Mondal,Rajesh Kumar Vissapragada,Rajeshwari Ganesan,Rajeswari Koppisetti,Ramjee R.,Ramkumar Thiruppathisamy,Rani G. S.,S Reka,Samarth Gupta,Sandeep Reddy Kothakota,Sarathy K,Sathyanarayana Sampath Kumar,Saurabh Kumar,Shashank Khasare,Shenbaga Devi Venkatesh Kumar,Shiva Rama Krishna Parvatham,Shoeb Shaikh,Shrishanmathi A,Shubham Pathak,Sree Samhita Koppaka,Sreenivasa Raghavan K S,Sreeram Venkatasubramanian,Suprabha Desai Bojja,Swetha R,Syed Ahmed,Chinmai Harshitha Thota,Tushar Yadav,Veeravelly Kusumitha,V V S S Prasanth Patnaik,Vidya Sri Sesetti,Vijayakeerthi K,Vikram Raj Bakshi,Vinay K K,Vinoth Kumar Loganathan,Vipin Tiwari,Vivek Kumar Shrivastav,V Venkata Sri Datta Charan,Wasim Akhtar Khan<br>
<strong>机构</strong>: Infosys AI Research (Infosys人工智能研究中心)<br>
<strong>类目</strong>: oftware Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present Mify-Coder, a 2.5B-parameter code model trained on 4.2T tokens using a compute-optimal strategy built on the Mify-2.5B foundation model. Mify-Coder achieves comparable accuracy and safety while significantly outperforming much larger baseline models on standard coding and function-calling benchmarks, demonstrating that compact models can match frontier-grade models in code generation and agent-driven workflows. Our training pipeline combines high-quality curated sources with synthetic data generated through agentically designed prompts, refined iteratively using enterprise-grade evaluation datasets. LLM-based quality filtering further enhances data density, enabling frugal yet effective training. Through disciplined exploration of CPT-SFT objectives, data mixtures, and sampling dynamics, we deliver frontier-grade code intelligence within a single continuous training trajectory. Empirical evidence shows that principled data and compute discipline allow smaller models to achieve competitive accuracy, efficiency, and safety compliance. Quantized variants of Mify-Coder enable deployment on standard desktop environments without requiring specialized hardware.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-75] Break Out the Silverware – Semantic Understanding of Stored Household Items</p>
<p>【速读】： 该论文旨在解决服务机器人在家庭环境中执行“找物品”任务时面临的常识推理难题，即如何根据视觉输入和场景理解推断出日常物品的隐藏存储位置（如抽屉、橱柜或衣柜），这要求机器人具备超越单纯视觉识别的语义与空间认知能力。解决方案的关键在于提出了一种名为NOAM（Non-visible Object Allocation Model）的混合代理架构，其核心是将结构化场景理解与大语言模型（Large Language Model, LLM）推理相结合：首先通过视觉模型提取可见容器及空间上下文信息并转化为自然语言描述，再由LLM（如GPT-4）基于这些描述进行隐式存储位置的推理，从而实现对不可见物品存储位置的准确预测。此方法显著提升了预测准确性并接近人类水平，为部署具有认知能力的服务机器人提供了可模块化集成的技术路径。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23739">https://arxiv.org/abs/2512.23739</a><br>
<strong>作者</strong>: Michaela Levi-Richter,Reuth Mirsky,Oren Glickman<br>
<strong>机构</strong>: Tufts University (塔夫茨大学); Bar-Ilan University (巴伊兰大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
<strong>备注</strong>:  Poster presented at the Israeli Seminar on Computational Linguistics 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:``Bring me a plate.‘’ For domestic service robots, this simple command reveals a complex challenge: inferring where everyday items are stored, often out of sight in drawers, cabinets, or closets. Despite advances in vision and manipulation, robots still lack the commonsense reasoning needed to complete this task. We introduce the Stored Household Item Challenge, a benchmark task for evaluating service robots’ cognitive capabilities: given a household scene and a queried item, predict its most likely storage location. Our benchmark includes two datasets: (1) a real-world evaluation set of 100 item-image pairs with human-annotated ground truth from participants’ kitchens, and (2) a development set of 6,500 item-image pairs annotated with storage polygons over public kitchen images. These datasets support realistic modeling of household organization and enable comparative evaluation across agent architectures. To begin tackling this challenge, we introduce NOAM (Non-visible Object Allocation Model), a hybrid agent pipeline that combines structured scene understanding with large language model inference. NOAM converts visual input into natural language descriptions of spatial context and visible containers, then prompts a language model (e.g., GPT-4) to infer the most likely hidden storage location. This integrated vision-language agent exhibits emergent commonsense reasoning and is designed for modular deployment within broader robotic systems. We evaluate NOAM against baselines including random selection, vision-language pipelines (Grounding-DINO + SAM), leading multimodal models (e.g., Gemini, GPT-4o, Kosmos-2, LLaMA, Qwen), and human performance. NOAM significantly improves prediction accuracy and approaches human-level results, highlighting best practices for deploying cognitively capable agents in domestic environments.          Comments: Poster presented at the Israeli Seminar on Computational Linguistics 2025   Subjects:  Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)  Cite as: arXiv:2512.23739 [<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>]    (or  arXiv:2512.23739v1 [<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.23739">https://doi.org/10.48550/arXiv.2512.23739</a>   Focus to learn more                      arXiv-issued DOI via DataCite        Submission history From: Reuth Mirsky [view email]       [v1]         Thu, 25 Dec 2025 15:21:49 UTC (4,504 KB)<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-76] When in Doubt Deliberate: Confidence-Based Routing to Expert Debate for Sexism Detection</p>
<p>【速读】： 该论文旨在解决在线性别歧视内容（sexist content）检测中因数据稀缺、标签噪声和概念模糊性导致的模型不稳定与误判问题，尤其针对传统方法难以识别隐晦、语境依赖性强的歧视性表达。其解决方案的关键在于提出一个两阶段框架：第一阶段通过类平衡焦点损失（class-balanced focal loss）、类别感知批处理（class-aware batching）和事后阈值校准（post-hoc threshold calibration）缓解标签不平衡与噪声监督；第二阶段引入动态路由机制，在推理时将高置信度样本直接分类，并将不确定样本交由新型“协作专家判断”（Collaborative Expert Judgment, CEJ）模块处理，该模块调用多个角色化代理（personas）进行推理并由裁判模型整合共识，从而有效应对概念模糊或边界案例。此设计显著提升了对隐蔽性别歧视内容的识别能力，在多个基准测试中达到当前最优性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23732">https://arxiv.org/abs/2512.23732</a><br>
<strong>作者</strong>: Anwar Alajmi,Gabriele Pergola<br>
<strong>机构</strong>: University of Warwick (华威大学); Public Authority of Applied Education and Training (科威特应用教育和培训公共机构)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Sexist content online increasingly appears in subtle, context-dependent forms that evade traditional detection methods. Its interpretation often depends on overlapping linguistic, psychological, legal, and cultural dimensions, which produce mixed and sometimes contradictory signals, even in annotated datasets. These inconsistencies, combined with label scarcity and class imbalance, result in unstable decision boundaries and cause fine-tuned models to overlook subtler, underrepresented forms of harm. Together, these limitations point to the need for a design that explicitly addresses the combined effects of (i) underrepresentation, (ii) noise, and (iii) conceptual ambiguity in both data and model predictions. To address these challenges, we propose a two-stage framework that unifies (i) targeted training procedures to adapt supervision to scarce and noisy data with (ii) selective, reasoning-based inference to handle ambiguous or borderline cases. Our training setup applies class-balanced focal loss, class-aware batching, and post-hoc threshold calibration to mitigate label imbalance and noisy supervision. At inference time, a dynamic routing mechanism classifies high-confidence cases directly and escalates uncertain instances to a novel \textitCollaborative Expert Judgment (CEJ) module, which prompts multiple personas and consolidates their reasoning through a judge model. Our approach achieves state-of-the-art results across several benchmarks, with a +2.72% improvement in F1 on the EXIST 2025 Task 1.1, and a gains of +4.48% and +1.30% on the EDOS Tasks A and B, respectively.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-77] Emergent World Beliefs: Exploring Transformers in Stochastic Games <mark class="hl-label red">NEURIPS2025</mark></p>
<p>【速读】： 该论文旨在解决大型语言模型（Large Language Models, LLMs）在不完全信息环境中的世界建模能力问题，特别是针对部分可观测马尔可夫决策过程（Partially Observable Markov Decision Process, POMDP）场景下的表征学习机制。其解决方案的关键在于：通过在扑克牌局历史（Poker Hand History, PHH）数据上预训练一个类GPT的模型，并对其内部激活进行非线性探测（nonlinear probes），发现模型能够自发学习到确定性结构（如牌型等级）和随机性特征（如胜率equity），且这些表征与理论上的信念状态（belief states）高度相关，表明LLMs可在无显式指导的情况下构建对德州扑克这一随机环境的内在表示。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23722">https://arxiv.org/abs/2512.23722</a><br>
<strong>作者</strong>: Adam Kamel,Tanish Rastogi,Michael Ma,Kailash Ranganathan,Kevin Zhu<br>
<strong>机构</strong>: University of Waterloo (滑铁卢大学); Independent Researcher; University of California, Berkeley (加州大学伯克利分校); Algoverse AI Research<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  Accepted at NeurIPS 2025 Mechanistic Interpretability Workshop</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Transformer-based large language models (LLMs) have demonstrated strong reasoning abilities across diverse fields, from solving programming challenges to competing in strategy-intensive games such as chess. Prior work has shown that LLMs can develop emergent world models in games of perfect information, where internal representations correspond to latent states of the environment. In this paper, we extend this line of investigation to domains of incomplete information, focusing on poker as a canonical partially observable Markov decision process (POMDP). We pretrain a GPT-style model on Poker Hand History (PHH) data and probe its internal activations. Our results demonstrate that the model learns both deterministic structure, such as hand ranks, and stochastic features, such as equity, without explicit instruction. Furthermore, by using primarily nonlinear probes, we demonstrated that these representations are decodeable and correlate with theoretical belief states, suggesting that LLMs are learning their own representation of the stochastic environment of Texas Hold’em Poker.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-78] HarmTransform: Transforming Explicit Harmful Queries into Stealthy via Multi-<mark class="hl-label green">Agent</mark>  Debate</p>
<p>【速读】： 该论文旨在解决当前大语言模型（Large Language Models, LLMs）安全对齐训练数据中对隐蔽性有害查询（covert harmful queries）覆盖不足的问题。现有方法主要针对显式危险内容进行防护，而忽视了用户通过隐晦改写（covert rephrasing）伪装恶意意图的行为，从而在安全机制上形成盲区。解决方案的关键在于提出 HarmTransform——一个基于多智能体辩论（multi-agent debate）的框架，通过多个代理之间迭代式批判与优化，系统性地将原始有害查询转化为更具隐蔽性的形式，同时保持其核心恶意目标不变。该框架生成的高质量、低检测率的转化样本可显著提升未来 LLM 安全对齐训练的数据多样性与有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23717">https://arxiv.org/abs/2512.23717</a><br>
<strong>作者</strong>: Shenzhe Zhu<br>
<strong>机构</strong>: University of Toronto (多伦多大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language models (LLMs) are equipped with safety mechanisms to detect and block harmful queries, yet current alignment approaches primarily focus on overtly dangerous content and overlook more subtle threats. However, users can often disguise harmful intent through covert rephrasing that preserves malicious objectives while appearing benign, which creates a significant gap in existing safety training data. To address this limitation, we introduce HarmTransform, a multi-agent debate framework for systematically transforming harmful queries into stealthier forms while preserving their underlying harmful intent. Our framework leverages iterative critique and refinement among multiple agents to generate high-quality, covert harmful query transformations that can be used to improve future LLM safety alignment. Experiments demonstrate that HarmTransform significantly outperforms standard baselines in producing effective query transformations. At the same time, our analysis reveals that debate acts as a double-edged sword: while it can sharpen transformations and improve stealth, it may also introduce topic shifts and unnecessary complexity. These insights highlight both the promise and the limitations of multi-agent debate for generating comprehensive safety training data.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-79] Noise-Driven Persona Formation in Reflexive Neural Language Generation <mark class="hl-label red">MICRO</mark> <mark class="hl-label red">STOC</mark></p>
<p>【速读】： 该论文旨在解决大语言模型（Large Language Models, LLMs）中噪声驱动的人格特征（persona）涌现机制难以量化与重现的问题。其解决方案的关键在于提出了一种名为 Luca-Noise Reflex Protocol (LN-RP) 的计算框架，通过在初始生成状态中注入随机噪声种子，系统性地观察152个生成周期内语言行为的非线性转变，并识别出三种具有不同熵特征的稳定人格模式。该方法不仅证实了外部噪声源可可靠诱导反射式生成动力学的相变，还通过定量评估验证了人格保留的一致性和各模式间的显著差异（p &lt; 0.01），为研究LLM中的反射生成、涌现行为及长程语言连贯性提供了可复现的实验路径。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23716">https://arxiv.org/abs/2512.23716</a><br>
<strong>作者</strong>: Toshiyuki Shigemura<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  324 pages, 9 figures (Figure 7 intentionally skipped), with Appendices A-I. This manuscript presents a computational framework for noise-driven persona formation in neural language generation, analyzing 152 generation cycles using GPT-5.1 with stochastic noise seeds generated by Microsoft Copilot. Primary category: <a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper introduces the Luca-Noise Reflex Protocol (LN-RP), a computational framework for analyzing noise-driven persona emergence in large language models. By injecting stochastic noise seeds into the initial generation state, we observe nonlinear transitions in linguistic behavior across 152 generation cycles. Our results reveal three stable persona modes with distinct entropy signatures, and demonstrate that external noise sources can reliably induce phase transitions in reflexive generation dynamics. Quantitative evaluation confirms consistent persona retention and significant differences across modes (p  0.01). The protocol provides a reproducible method for studying reflexive generation, emergent behavior, and longrange linguistic coherence in LLMs.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-80] PharmaShip: An Entity-Centric Reading-Order-Supervised Benchmark for Chinese Pharmaceutical Shipping Documents</p>
<p>【速读】： 该论文旨在解决医药领域文档理解中因光学字符识别（OCR）噪声和模板异质性导致的预训练文本布局模型性能下降问题。其解决方案的关键在于构建了一个真实世界中文药品运输单据数据集PharmaShip，涵盖序列实体识别（SER）、关系抽取（RE）和阅读顺序预测（ROP）三项互补任务，并采用以实体为中心的评估协议以最小化不同模型架构带来的干扰。实验表明，像素信息与显式几何结构提供互补的归纳偏置，但单独使用均不足；引入面向阅读顺序的正则化可显著提升SER和实体链接（EL）性能，且更稳定的长距离位置覆盖能改善页尾预测并减少截断伪影。该工作为医药领域安全关键场景下的文档理解提供了可控、可复现的基准，并强调了序列感知约束作为结构建模的通用归纳偏置的重要性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23714">https://arxiv.org/abs/2512.23714</a><br>
<strong>作者</strong>: Tingwei Xie,Tianyi Zhou,Yonghong Song<br>
<strong>机构</strong>: Xi’an Jiaotong University (西安交通大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  5 pages, 4 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present PharmaShip, a real-world Chinese dataset of scanned pharmaceutical shipping documents designed to stress-test pre-trained text-layout models under noisy OCR and heterogeneous templates. PharmaShip covers three complementary tasks-sequence entity recognition (SER), relation extraction (RE), and reading order prediction (ROP)-and adopts an entity-centric evaluation protocol to minimize confounds across architectures. We benchmark five representative baselines spanning pixel-aware and geometry-aware families (LiLT, LayoutLMv3-base, GeoLayoutLM and their available RORE-enhanced variants), and standardize preprocessing, splits, and optimization. Experiments show that pixels and explicit geometry provide complementary inductive biases, yet neither alone is sufficient: injecting reading-order-oriented regularization consistently improves SER and EL and yields the most robust configuration, while longer positional coverage stabilizes late-page predictions and reduces truncation artifacts. ROP is accurate at the word level but challenging at the segment level, reflecting boundary ambiguity and long-range crossings. PharmaShip thus establishes a controlled, reproducible benchmark for safety-critical document understanding in the pharmaceutical domain and highlights sequence-aware constraints as a transferable bias for structure modeling. We release the dataset at this https URL.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-81] PyBangla at BLP-2025 Task 2: Enhancing Bangla-to-Python Code Generation with Iterative Self-Correction and Multilingual <mark class="hl-label green">Agents</mark></p>
<p>【速读】： 该论文旨在解决低资源语言（如孟加拉语）到代码（Python）的自然语言编程（NL2Code）问题，即如何在缺乏大量标注数据和专用模型的情况下实现高质量的代码生成。传统方法依赖于特定任务的微调，难以适配资源稀缺的语言场景。其解决方案的关键在于提出一种基于代理（agent-based）的框架 BanglaCodeAct，该框架利用多代理提示（multi-agent prompting）与迭代自我修正机制，在开放源码多语言大语言模型（LLM）中构建“思考-代码-观察”（Thought-Code-Observation）循环，从而动态生成、测试并优化代码，无需任务特异性微调。实验表明，Qwen3-8B 搭配 BanglaCodeAct 在 mHumanEval 数据集上达到 94.0%（开发集）和 71.6%（盲测集）的 pass@1 准确率，显著提升了低资源语言下的代码生成性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23713">https://arxiv.org/abs/2512.23713</a><br>
<strong>作者</strong>: Jahidul Islam,Md Ataullha,Saiful Azad<br>
<strong>机构</strong>: Green University of Bangladesh (格林大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  6 Pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:LLMs excel at code generation from English prompts, but this progress has not extended to low-resource languages. We address Bangla-to-Python code generation by introducing BanglaCodeAct, an agent-based framework that leverages multi-agent prompting and iterative self-correction. Unlike prior approaches relying on task-specific fine-tuning, BanglaCodeAct employs an open-source multilingual LLM within a Thought-Code-Observation loop, enabling dynamic generation, testing, and refinement of code from Bangla instructions. We benchmark several small-parameter open-source LLMs and evaluate their effectiveness on the mHumanEval dataset for Bangla NL2Code. Our results show that Qwen3-8B, when deployed with BanglaCodeAct, achieves the best performance, with pass@1 accuracy of 94.0% on the development set and 71.6% on the blind test set. These results establish a new benchmark for Bangla-to-Python translation and highlight the potential of agent-based reasoning for reliable code generation in low-resource languages. Experimental scripts are publicly available at this http URL.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-82] STED and Consistency Scoring: A Framework for Evaluating <mark class="hl-label green">LLM</mark>  Structured Output Reliability</p>
<p>【速读】： 该论文旨在解决大型语言模型（Large Language Models, LLMs）在结构化数据生成任务中输出一致性不足的问题，这对生产环境中的可靠性至关重要。解决方案的关键在于提出一个综合评估与改进框架，其中核心创新是引入STED（Semantic Tree Edit Distance）——一种能够平衡语义灵活性与结构严格性的新型相似性度量指标，并结合一致性评分机制，通过多次生成结果的STED聚合来量化输出可靠性。实验表明，STED在语义等价情况下保持高相似度（0.86–0.90），而在结构不一致时得分接近0，显著优于TED、BERTScore和DeepDiff等现有方法，从而为模型选择、提示迭代优化及不一致性根源诊断提供了理论基础与实用工具。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23712">https://arxiv.org/abs/2512.23712</a><br>
<strong>作者</strong>: Guanghui Wang,Jinze Yu,Xing Zhang,Dayuan Jiang,Yin Song,Tomal Deb,Xuefeng Liu,Peiyang He<br>
<strong>机构</strong>: AWS Generative AI Innovation Center (AWS 生成式人工智能创新中心); AWS WWSO SA Field Initiatives (AWS WWSO SA 现场倡议)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) are increasingly deployed for structured data generation, yet output consistency remains critical for production applications. We introduce a comprehensive framework for evaluating and improving consistency in LLM-generated structured outputs. Our approach combines: (1) STED (Semantic Tree Edit Distance), a novel similarity metric balancing semantic flexibility with structural strictness when comparing JSON outputs, and (2) a consistency scoring framework aggregating multiple STED measurements across repeated generations to quantify reliability. Through systematic experiments on synthetic datasets with controlled schema, expression, and semantic variations, we demonstrate STED achieves superior performance ( 0.86-0.90  similarity for semantic equivalents,  0.0  for structural breaks) compared to existing metrics including TED, BERTScore, and DeepDiff. Applying our framework to benchmark six LLMs reveals significant variations: Claude-3.7-Sonnet demonstrates exceptional consistency, maintaining near-perfect structural reliability even at high temperatures ( T=0.9 ), while models like Claude-3-Haiku and Nova-Pro exhibit substantial degradation requiring careful tuning. Our framework enables practical applications including targeted model selection for structured tasks, iterative prompt refinement for reproducible results, and diagnostic analysis to identify inconsistency root causes. This work provides theoretical foundations and practical tools for ensuring reliable structured output generation in LLM-based production systems.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-83] CAT: A Metric-Driven Framework for Analyzing the Consistency-Accuracy Relation of <mark class="hl-label green">LLM</mark> s under Controlled Input Variations</p>
<p>【速读】： 该论文旨在解决当前大型语言模型（Large Language Models, LLMs）评估中对准确性和响应一致性（response consistency）之间相互关系缺乏系统性分析的问题。现有评估方法通常独立关注准确性或一致性，但在高风险实际应用场景中，两者协同作用对模型可靠性至关重要。解决方案的关键在于提出一种名为 \textscCAT 的框架，其核心是 Consistency-Accuracy Relation (CAR) 曲线，用于可视化在不同一致性要求下模型准确性的变化趋势，并引入 Consistency-Oriented Robustness Estimate (CORE) 指数，通过整合 CAR 曲线的面积和形状来量化准确率与一致性的权衡关系。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23711">https://arxiv.org/abs/2512.23711</a><br>
<strong>作者</strong>: Paulo Cavalin,Cassia Sanctos,Marcelo Grave,Claudio Pinhanez,Yago Primerano<br>
<strong>机构</strong>: IBM Research Brazil(IBM研究巴西)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce \textscCAT, a framework designed to evaluate and visualize the \emphinterplay of \emphaccuracy and \emphresponse consistency of Large Language Models (LLMs) under controllable input variations, using multiple-choice (MC) benchmarks as a case study. Current evaluation practices primarily focus on model capabilities such as accuracy or benchmark scores and, more recently, measuring consistency is being considered an essential property for deploying LLMs in high-stake, real-world applications. We argue in this paper that although both dimensions should still be evaluated independently, their inter-dependency also need to be considered for a more nuanced evaluation of LLMs. At the core of \textscCAT are the \emphConsistency-Accuracy Relation (CAR) curves, which visualize how model accuracy varies with increasing consistency requirements, as defined by the \emphMinimum-Consistency Accuracy (MCA) metric. We further propose the \emphConsistency-Oriented Robustness Estimate (CORE) index, a global metric that combines the area and shape of the CAR curve to quantify the trade-off between accuracy and consistency. We present a practical demonstration of our framework across a diverse set of generalist and domain-specific LLMs, evaluated on multiple MC benchmarks. We also outline how \textscCAT can be extended beyond MC tasks to support long-form, open-ended evaluations through adaptable scoring functions.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-84] Enriching Historical Records: An OCR and AI-Driven Approach for Database Integration</p>
<p>【速读】： 该论文旨在解决如何设计一个自动化处理流程，将历史文献图像中的数据与现有高质量数据库记录进行统一 harmonize（协调一致）的问题。其核心挑战在于处理历史文档中布局多样性、术语差异以及低质量光学字符识别（OCR）带来的数据提取难题。解决方案的关键在于整合OCR技术、基于大语言模型（LLM）的数据解释与约束解码机制，以及高效的记录链接算法：OCR实现了1.08%的字符错误率（CER）和5.06%的词错误率（WER），结合生成式AI对OCR文本进行结构化JSON提取后准确率达到63%（标注后提升至65%），表明生成式AI能有效校正OCR性能不足；进一步通过记录链接算法实现94%（标注数据）和81%（OCR原始数据）的匹配准确率，从而构建出可扩展、自动化的数字人文处理管道。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23710">https://arxiv.org/abs/2512.23710</a><br>
<strong>作者</strong>: Zahra Abedi,Richard M.K. van Dijk,Gijs Wijnholds,Tessa Verhoef<br>
<strong>机构</strong>: Leiden Institute of Advanced Computer Science, Leiden University (莱顿大学高级计算机科学研究所)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This research digitizes and analyzes the Leidse hoogleraren en lectoren 1575-1815 books written between 1983 and 1985, which contain biographic data about professors and curators of Leiden University. It addresses the central question: how can we design an automated pipeline that integrates OCR, LLM-based interpretation, and database linking to harmonize data from historical document images with existing high-quality database records? We applied OCR techniques, generative AI decoding constraints that structure data extraction, and database linkage methods to process typewritten historical records into a digital format. OCR achieved a Character Error Rate (CER) of 1.08 percent and a Word Error Rate (WER) of 5.06 percent, while JSON extraction from OCR text achieved an average accuracy of 63 percent and, based on annotated OCR, 65 percent. This indicates that generative AI somewhat corrects low OCR performance. Our record linkage algorithm linked annotated JSON files with 94% accuracy and OCR-derived JSON files with 81%. This study contributes to digital humanities research by offering an automated pipeline for interpreting digitized historical documents, addressing challenges like layout variability and terminology differences, and exploring the applicability and strength of an advanced generative AI model.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-85] <mark class="hl-label green">Large</mark> <mark class="hl-label green">language</mark> <mark class="hl-label green">models</mark>  and the entropy of English</p>
<p>【速读】： 该论文旨在解决语言模型中长距离结构（long-ranged structure）的识别与建模问题，即揭示英语文本在远距离字符间是否存在显著依赖关系及其统计特性。其解决方案的关键在于利用大语言模型（Large Language Models, LLMs）对来自多种来源的英文文本进行分析，通过计算条件熵或码长（code length）随上下文长度 $ N \sim 10^4 $ 字符的增长趋势，发现码长仍持续下降，表明存在跨数百甚至数千字符的直接依赖或相互作用；同时，独立于模型的数据分析进一步验证了这些远距离字符间的微弱但显著的相关性，并揭示出随着上下文长度增加，模型对越来越多字符的预测趋于确定性。这一发现为构建基于统计物理的语言模型提供了重要约束条件。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24969">https://arxiv.org/abs/2512.24969</a><br>
<strong>作者</strong>: Colin Scheibner,Lindsay M. Smith,William Bialek<br>
<strong>机构</strong>: Princeton University (普林斯顿大学); The CUNY Graduate Center (纽约市立大学研究生院)<br>
<strong>类目</strong>: atistical Mechanics (cond-mat.stat-mech); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Biological Physics (physics.bio-ph); Neurons and Cognition (<a target="_blank" rel="noopener" href="http://q-bio.NC">q-bio.NC</a>)<br>
<strong>备注</strong>:  8 pages, 6 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We use large language models (LLMs) to uncover long-ranged structure in English texts from a variety of sources. The conditional entropy or code length in many cases continues to decrease with context length at least to  N\sim 10^4  characters, implying that there are direct dependencies or interactions across these distances. A corollary is that there are small but significant correlations between characters at these separations, as we show from the data independent of models. The distribution of code lengths reveals an emergent certainty about an increasing fraction of characters at large  N . Over the course of model training, we observe different dynamics at long and short context lengths, suggesting that long-ranged structure is learned only gradually. Our results constrain efforts to build statistical physics models of LLMs or language itself.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-86] Quantum Visual Word Sense Disambiguation: Unraveling Ambiguities Through Quantum Inference Model</p>
<p>【速读】： 该论文旨在解决视觉词义消歧（Visual Word Sense Disambiguation, VWS) 中因语义不确定性导致的歧义词候选图像混淆问题，特别是传统基于经典概率的方法在处理来自不同来源的释义（gloss）时易引入语义偏差，从而影响消歧准确性的问题。其解决方案的关键在于引入量子推理模型（Quantum Inference Model for Unsupervised VWS, Q-VWSD），通过将目标词的多个释义编码为量子叠加态（superposition state），利用量子叠加与干涉特性缓解语义偏差；进一步形式化表明该方法是经典概率方法的量子推广，并设计了可在经典计算机上高效运行的启发式版本，实验证明其能更有效地利用大语言模型提供的非专业化释义，显著优于现有先进方法。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24687">https://arxiv.org/abs/2512.24687</a><br>
<strong>作者</strong>: Wenbo Qiao,Peng Zhang,Qinghua Hu<br>
<strong>机构</strong>: Tianjin University (天津大学)<br>
<strong>类目</strong>: Quantum Physics (quant-ph); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Visual word sense disambiguation focuses on polysemous words, where candidate images can be easily confused. Traditional methods use classical probability to calculate the likelihood of an image matching each gloss of the target word, summing these to form a posterior probability. However, due to the challenge of semantic uncertainty, glosses from different sources inevitably carry semantic biases, which can lead to biased disambiguation results. Inspired by quantum superposition in modeling uncertainty, this paper proposes a Quantum Inference Model for Unsupervised Visual Word Sense Disambiguation (Q-VWSD). It encodes multiple glosses of the target word into a superposition state to mitigate semantic biases. Then, the quantum circuit is executed, and the results are observed. By formalizing our method, we find that Q-VWSD is a quantum generalization of the method based on classical probability. Building on this, we further designed a heuristic version of Q-VWSD that can run more efficiently on classical computing. The experiments demonstrate that our method outperforms state-of-the-art classical methods, particularly by effectively leveraging non-specialized glosses from large language models, which further enhances performance. Our approach showcases the potential of quantum machine learning in practical applications and provides a case for leveraging quantum modeling advantages on classical computers while quantum hardware remains immature.<br>
zh</p>
</div></div>
<h3 id="计算机视觉">计算机视觉</h3>
<div class="note purple no-icon flat"><p>[CV-0] SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time</p>
<p>【速读】：该论文旨在解决视频生成过程中空间（camera viewpoint）与时间（motion sequence）难以解耦的问题，从而实现对生成视频中视角和运动的独立控制。传统视频扩散模型通常将时空信息混合建模，导致无法灵活调整相机轨迹或动态内容。其解决方案的关键在于提出了一种新颖的动画时间嵌入机制（animation time-embedding），在扩散过程中显式编码时间维度以实现对输出视频运动序列的精确控制；同时设计了基于时序扭曲（temporal warping）的训练策略，利用现有多视角数据模拟连续的时间变化，从而无需专门标注的时空变化配对数据即可学习有效的时空解耦表示。此外，论文还构建了首个全覆盖空间-时间轨迹合成数据集CamxTime，并引入改进的相机条件机制，显著提升了空间与时间双重控制的精度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25075">https://arxiv.org/abs/2512.25075</a><br>
<strong>作者</strong>: Zhening Huang,Hyeonho Jeong,Xuelin Chen,Yulia Gryaditskaya,Tuanfeng Y. Wang,Joan Lasenby,Chun-Hao Huang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://zheninghuang.github.io/Space-Time-Pilot/">this https URL</a> Code: <a target="_blank" rel="noopener" href="https://github.com/ZheningHuang/spacetimepilot">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present SpaceTimePilot, a video diffusion model that disentangles space and time for controllable generative rendering. Given a monocular video, SpaceTimePilot can independently alter the camera viewpoint and the motion sequence within the generative process, re-rendering the scene for continuous and arbitrary exploration across space and time. To achieve this, we introduce an effective animation time-embedding mechanism in the diffusion process, allowing explicit control of the output video’s motion sequence with respect to that of the source video. As no datasets provide paired videos of the same dynamic scene with continuous temporal variations, we propose a simple yet effective temporal-warping training scheme that repurposes existing multi-view datasets to mimic temporal differences. This strategy effectively supervises the model to learn temporal control and achieve robust space-time disentanglement. To further enhance the precision of dual control, we introduce two additional components: an improved camera-conditioning mechanism that allows altering the camera from the first frame, and CamxTime, the first synthetic space-and-time full-coverage rendering dataset that provides fully free space-time video trajectories within a scene. Joint training on the temporal-warping scheme and the CamxTime dataset yields more precise temporal control. We evaluate SpaceTimePilot on both real-world and synthetic data, demonstrating clear space-time disentanglement and strong results compared to prior work. Project page: this https URL Code: this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-1] GaMO: Geometry-aware Multi-view Diffusion Outpainting for Sparse-View 3D Reconstruction</p>
<p>【速读】：该论文旨在解决稀疏视角下三维场景重建质量下降的问题，即当输入视图数量有限时，现有方法难以生成高质量且几何一致的场景表示。其解决方案的关键在于提出GaMO（Geometry-aware Multi-view Outpainter）框架，通过多视角外推（multi-view outpainting）而非传统的新视角生成方式，从已有相机位姿出发扩展视野范围，从而在不引入额外训练的情况下保持几何一致性并提升场景覆盖度。该方法利用零样本的多视角条件与几何感知去噪策略，在保证重建精度的同时实现显著加速（相较当前最优扩散模型提速25倍，处理时间低于10分钟）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25073">https://arxiv.org/abs/2512.25073</a><br>
<strong>作者</strong>: Yi-Chuan Huang,Hao-Jen Chien,Chin-Yang Lin,Ying-Huan Chen,Yu-Lun Liu<br>
<strong>机构</strong>: National Yang Ming Chiao Tung University (国立阳明交通大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://yichuanh.github.io/GaMO/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advances in 3D reconstruction have achieved remarkable progress in high-quality scene capture from dense multi-view imagery, yet struggle when input views are limited. Various approaches, including regularization techniques, semantic priors, and geometric constraints, have been implemented to address this challenge. Latest diffusion-based methods have demonstrated substantial improvements by generating novel views from new camera poses to augment training data, surpassing earlier regularization and prior-based techniques. Despite this progress, we identify three critical limitations in these state-of-the-art approaches: inadequate coverage beyond known view peripheries, geometric inconsistencies across generated views, and computationally expensive pipelines. We introduce GaMO (Geometry-aware Multi-view Outpainter), a framework that reformulates sparse-view reconstruction through multi-view outpainting. Instead of generating new viewpoints, GaMO expands the field of view from existing camera poses, which inherently preserves geometric consistency while providing broader scene coverage. Our approach employs multi-view conditioning and geometry-aware denoising strategies in a zero-shot manner without training. Extensive experiments on Replica and ScanNet++ demonstrate state-of-the-art reconstruction quality across 3, 6, and 9 input views, outperforming prior methods in PSNR and LPIPS, while achieving a  25\times  speedup over SOTA diffusion-based methods with processing time under 10 minutes. Project page: this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-2] Edit3r: Instant 3D Scene Editing from Sparse Unposed Images</p>
<p>【速读】：该论文旨在解决从未对齐、视图不一致的指令编辑图像中直接重建与编辑3D场景的问题，传统方法通常依赖于每场景优化，导致效率低下且难以实现快速渲染。其解决方案的关键在于提出一个前馈式框架Edit3r，通过两项核心技术实现无需优化即可生成语义对齐且具有高3D一致性的编辑结果：一是基于SAM2（Segment Anything Model 2）的着色策略，用于生成跨视角一致的监督信号；二是不对称输入策略，将重着色参考视图与原始辅助视图配对，促使网络融合并对齐不同视角的信息。此设计使模型在推理阶段能够有效处理由2D编辑工具（如InstructPix2Pix）生成的图像，即使训练中未接触此类编辑内容，仍能实现高质量3D编辑。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25071">https://arxiv.org/abs/2512.25071</a><br>
<strong>作者</strong>: Jiageng Liu,Weijie Lyu,Xueting Li,Yejie Guo,Ming-Hsuan Yang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://edit3r.github.io/edit3r/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present Edit3r, a feed-forward framework that reconstructs and edits 3D scenes in a single pass from unposed, view-inconsistent, instruction-edited images. Unlike prior methods requiring per-scene optimization, Edit3r directly predicts instruction-aligned 3D edits, enabling fast and photorealistic rendering without optimization or pose estimation. A key challenge in training such a model lies in the absence of multi-view consistent edited images for supervision. We address this with (i) a SAM2-based recoloring strategy that generates reliable, cross-view-consistent supervision, and (ii) an asymmetric input strategy that pairs a recolored reference view with raw auxiliary views, encouraging the network to fuse and align disparate observations. At inference, our model effectively handles images edited by 2D methods such as InstructPix2Pix, despite not being exposed to such edits during training. For large-scale quantitative evaluation, we introduce DL3DV-Edit-Bench, a benchmark built on the DL3DV test split, featuring 20 diverse scenes, 4 edit types and 100 edits in total. Comprehensive quantitative and qualitative results show that Edit3r achieves superior semantic alignment and enhanced 3D consistency compared to recent baselines, while operating at significantly higher inference speed, making it promising for real-time 3D editing applications.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-3] FineTec: Fine-Grained Action Recognition Under Temporal Corruption via Skeleton Decomposition and Sequence Completion <mark class="hl-label red">AAAI2026</mark></p>
<p>【速读】：该论文旨在解决在存在时间损坏（temporal corruption）的情况下，从受损的骨架序列中准确识别细粒度动作（fine-grained action recognition）的问题。现实场景中，基于在线姿态估计的骨架数据常伴有大量缺失，导致难以恢复细微的运动线索，从而影响动作区分能力。其解决方案的关键在于提出一个统一框架 FineTec：首先通过上下文感知的补全机制与多样化的时序掩码恢复基础骨架序列；随后利用基于运动方差的空间分解模块将骨架划分为动态和静态子区域，并生成两个增强骨架序列；再结合物理驱动的拉格朗日动力学估计关节加速度，最终将位置与加速度特征融合后输入图卷积网络（GCN）进行动作识别。该方法有效提升了在严重时间损坏下的鲁棒性与泛化能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25067">https://arxiv.org/abs/2512.25067</a><br>
<strong>作者</strong>: Dian Shao,Mingfei Shi,Like Liu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Accepted by AAAI 2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recognizing fine-grained actions from temporally corrupted skeleton sequences remains a significant challenge, particularly in real-world scenarios where online pose estimation often yields substantial missing data. Existing methods often struggle to accurately recover temporal dynamics and fine-grained spatial structures, resulting in the loss of subtle motion cues crucial for distinguishing similar actions. To address this, we propose FineTec, a unified framework for Fine-grained action recognition under Temporal Corruption. FineTec first restores a base skeleton sequence from corrupted input using context-aware completion with diverse temporal masking. Next, a skeleton-based spatial decomposition module partitions the skeleton into five semantic regions, further divides them into dynamic and static subgroups based on motion variance, and generates two augmented skeleton sequences via targeted perturbation. These, along with the base sequence, are then processed by a physics-driven estimation module, which utilizes Lagrangian dynamics to estimate joint accelerations. Finally, both the fused skeleton position sequence and the fused acceleration sequence are jointly fed into a GCN-based action recognition head. Extensive experiments on both coarse-grained (NTU-60, NTU-120) and fine-grained (Gym99, Gym288) benchmarks show that FineTec significantly outperforms previous methods under various levels of temporal corruption. Specifically, FineTec achieves top-1 accuracies of 89.1% and 78.1% on the challenging Gym99-severe and Gym288-severe settings, respectively, demonstrating its robustness and generalizability. Code and datasets could be found at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-4] From Inpainting to Editing: A Self-Bootstrapping Framework for Context-Rich Visual Dubbing</p>
<p>【速读】：该论文旨在解决音频驱动的视频配音（audio-driven visual dubbing）任务中因缺乏理想训练数据而导致的同步精度低、视觉伪影和身份漂移等问题。现有方法依赖掩码引导的图像修复范式，迫使模型在缺失内容补全与唇部同步之间权衡，难以实现高质量输出。其解决方案的关键在于提出一种自 bootstrapping 框架，将原本病态的图像修复问题重构为一个良定的视频到视频编辑问题：首先利用扩散 Transformer（Diffusion Transformer, DiT）生成理想训练样本——即为每个真实视频合成唇部动作改变但其他视觉条件一致的“同伴视频”，形成对齐的视频对；随后基于这些完整且对齐的视频对端到端训练一个 DiT-based 音频驱动编辑器，使其专注于精确的音频驱动唇部修改，同时借助完整的帧级视觉上下文（包括身份线索、场景交互和连续时空动态）实现高保真度的唇音同步与鲁棒性表现。此外，引入时间步自适应多阶段学习策略以解耦扩散过程中不同时间步的冲突编辑目标，从而提升训练稳定性与性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25066">https://arxiv.org/abs/2512.25066</a><br>
<strong>作者</strong>: Xu He,Haoxian Zhang,Hejia Chen,Changyuan Zheng,Liyang Chen,Songlin Tang,Jiehui Huang,Xiaoqiang Liu,Pengfei Wan,Zhiyong Wu<br>
<strong>机构</strong>: Tsinghua University (清华大学); Kling Team, Kuaishou Technology (快手科技); Beihang University (北京航空航天大学); Hong Kong University of Science and Technology (香港科技大学); The Chinese University of Hong Kong (香港中文大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project Page <a target="_blank" rel="noopener" href="https://hjrphoebus.github.io/X-Dub">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Audio-driven visual dubbing aims to synchronize a video’s lip movements with new speech, but is fundamentally challenged by the lack of ideal training data: paired videos where only a subject’s lip movements differ while all other visual conditions are identical. Existing methods circumvent this with a mask-based inpainting paradigm, where an incomplete visual conditioning forces models to simultaneously hallucinate missing content and sync lips, leading to visual artifacts, identity drift, and poor synchronization. In this work, we propose a novel self-bootstrapping framework that reframes visual dubbing from an ill-posed inpainting task into a well-conditioned video-to-video editing problem. Our approach employs a Diffusion Transformer, first as a data generator, to synthesize ideal training data: a lip-altered companion video for each real sample, forming visually aligned video pairs. A DiT-based audio-driven editor is then trained on these pairs end-to-end, leveraging the complete and aligned input video frames to focus solely on precise, audio-driven lip modifications. This complete, frame-aligned input conditioning forms a rich visual context for the editor, providing it with complete identity cues, scene interactions, and continuous spatiotemporal dynamics. Leveraging this rich context fundamentally enables our method to achieve highly accurate lip sync, faithful identity preservation, and exceptional robustness against challenging in-the-wild scenarios. We further introduce a timestep-adaptive multi-phase learning strategy as a necessary component to disentangle conflicting editing objectives across diffusion timesteps, thereby facilitating stable training and yielding enhanced lip synchronization and visual fidelity. Additionally, we propose ContextDubBench, a comprehensive benchmark dataset for robust evaluation in diverse and challenging practical application scenarios.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-5] Generative Classifiers Avoid Shortcut Solutions <mark class="hl-label red">ICLR2025</mark></p>
<p>【速读】：该论文旨在解决判别式分类方法在分布变化（distribution shift）下性能显著下降的问题，其根本原因在于模型过度依赖与标签存在虚假相关性的特征（spurious correlations），而这些特征在训练数据中成立但在测试数据中失效。解决方案的关键在于采用生成式分类器（generative classifiers），这类方法通过建模所有特征（包括核心特征和虚假特征）的类条件分布，而非仅关注虚假相关特征，从而避免了对不稳健特征的过拟合。论文进一步表明，基于扩散模型（diffusion-based）和自回归（autoregressive）的生成式分类器在多个图像和文本分布偏移基准上达到最优性能，并在医学影像、卫星图像等真实场景中有效降低虚假相关性的影响，同时通过高斯简化模型分析揭示了生成式分类器的归纳偏置及其在何种数据特性下优于判别式方法。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25034">https://arxiv.org/abs/2512.25034</a><br>
<strong>作者</strong>: Alexander C. Li,Ananya Kumar,Deepak Pathak<br>
<strong>机构</strong>: Carnegie Mellon University (卡内基梅隆大学); Stanford University (斯坦福大学)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Neural and Evolutionary Computing (<a target="_blank" rel="noopener" href="http://cs.NE">cs.NE</a>)<br>
<strong>备注</strong>:  ICLR 2025. Code: <a target="_blank" rel="noopener" href="https://github.com/alexlioralexli/generative-classifiers">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Discriminative approaches to classification often learn shortcuts that hold in-distribution but fail even under minor distribution shift. This failure mode stems from an overreliance on features that are spuriously correlated with the label. We show that generative classifiers, which use class-conditional generative models, can avoid this issue by modeling all features, both core and spurious, instead of mainly spurious ones. These generative classifiers are simple to train, avoiding the need for specialized augmentations, strong regularization, extra hyperparameters, or knowledge of the specific spurious correlations to avoid. We find that diffusion-based and autoregressive generative classifiers achieve state-of-the-art performance on five standard image and text distribution shift benchmarks and reduce the impact of spurious correlations in realistic applications, such as medical or satellite datasets. Finally, we carefully analyze a Gaussian toy setting to understand the inductive biases of generative classifiers, as well as the data properties that determine when generative classifiers outperform discriminative ones.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-6] FoundationSLAM: Unleashing the Power of Depth Foundation Models for End-to-End Dense Visual SLAM</p>
<p>【速读】：该论文旨在解决基于光流（optical flow）的单目稠密SLAM系统中缺乏几何一致性的问题，从而实现更准确和鲁棒的跟踪与建图。其关键解决方案在于通过引入基础深度模型（foundation depth models）的引导，将光流估计与几何推理相融合：首先设计了一个混合光流网络（Hybrid Flow Network），生成具有几何感知能力的对应关系，以确保跨关键帧的一致性深度和位姿推断；其次提出双向一致的束调整层（Bi-Consistent Bundle Adjustment Layer），在多视角约束下联合优化关键帧位姿与深度以增强全局一致性；最后引入可靠性感知精化机制（Reliability-Aware Refinement），通过区分可靠与不确定区域动态调整光流更新过程，形成匹配与优化之间的闭环反馈。该方法在多个挑战性数据集上实现了优于现有方法的轨迹精度和稠密重建质量，并在18 FPS下实时运行，展现出良好的泛化能力和实用性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25008">https://arxiv.org/abs/2512.25008</a><br>
<strong>作者</strong>: Yuchen Wu,Jiahe Li,Fabio Tosi,Matteo Poggi,Jin Zheng,Xiao Bai<br>
<strong>机构</strong>: Beihang University (北京航空航天大学); Stanford University (斯坦福大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present FoundationSLAM, a learning-based monocular dense SLAM system that addresses the absence of geometric consistency in previous flow-based approaches for accurate and robust tracking and mapping. Our core idea is to bridge flow estimation with geometric reasoning by leveraging the guidance from foundation depth models. To this end, we first develop a Hybrid Flow Network that produces geometry-aware correspondences, enabling consistent depth and pose inference across diverse keyframes. To enforce global consistency, we propose a Bi-Consistent Bundle Adjustment Layer that jointly optimizes keyframe pose and depth under multi-view constraints. Furthermore, we introduce a Reliability-Aware Refinement mechanism that dynamically adapts the flow update process by distinguishing between reliable and uncertain regions, forming a closed feedback loop between matching and optimization. Extensive experiments demonstrate that FoundationSLAM achieves superior trajectory accuracy and dense reconstruction quality across multiple challenging datasets, while running in real-time at 18 FPS, demonstrating strong generalization to various scenarios and practical applicability of our method.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-7] Bi-C2R: Bidirectional Continual Compatible Representation for Re-indexing Free Lifelong Person Re-identification</p>
<p>【速读】：该论文旨在解决终身行人重识别（Lifelong person Re-IDentification, L-ReID）中因历史画廊图像无法频繁重新索引（re-indexing）而导致的特征不兼容问题，尤其是在数据隐私限制和大规模画廊图像带来的高重索引成本背景下，更新后的查询特征与旧模型提取的画廊特征之间存在不一致性，严重损害重识别性能。为应对这一挑战，作者提出了一种无需重索引的终身行人重识别任务（Re-index Free Lifelong person Re-IDentification, RFL-ReID），其核心解决方案是设计了一个双向连续兼容表示框架（Bidirectional Continuous Compatible Representation, Bi-C2R），通过持续更新旧模型提取的画廊特征，使新旧模型输出的特征在语义空间中保持兼容性，从而实现高效且稳定的终身学习。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25000">https://arxiv.org/abs/2512.25000</a><br>
<strong>作者</strong>: Zhenyu Cui,Jiahuan Zhou,Yuxin Peng<br>
<strong>机构</strong>: Peking University (北京大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Lifelong person Re-IDentification (L-ReID) exploits sequentially collected data to continuously train and update a ReID model, focusing on the overall performance of all data. Its main challenge is to avoid the catastrophic forgetting problem of old knowledge while training on new data. Existing L-ReID methods typically re-extract new features for all historical gallery images for inference after each update, known as “re-indexing”. However, historical gallery data typically suffers from direct saving due to the data privacy issue and the high re-indexing costs for large-scale gallery images. As a result, it inevitably leads to incompatible retrieval between query features extracted by the updated model and gallery features extracted by those before the update, greatly impairing the re-identification performance. To tackle the above issue, this paper focuses on a new task called Re-index Free Lifelong person Re-IDentification (RFL-ReID), which requires performing lifelong person re-identification without re-indexing historical gallery images. Therefore, RFL-ReID is more challenging than L-ReID, requiring continuous learning and balancing new and old knowledge in diverse streaming data, and making the features output by the new and old models compatible with each other. To this end, we propose a Bidirectional Continuous Compatible Representation (Bi-C2R) framework to continuously update the gallery features extracted by the old model to perform efficient L-ReID in a compatible manner. We verify our proposed Bi-C2R method through theoretical analysis and extensive experiments on multiple benchmarks, which demonstrate that the proposed method can achieve leading performance on both the introduced RFL-ReID task and the traditional L-ReID task.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-8] PhysTalk: Language-driven Real-time Physics in 3D Gaussian Scenes</p>
<p>【速读】：该论文旨在解决现有视觉模拟系统中缺乏物理真实性与高效语言交互接口的问题，传统方法通常依赖缓慢的离线优化流程，难以实现实时、可交互的4D动画生成。其解决方案的关键在于提出PhysTalk框架，该框架以3D高斯溅射（3D Gaussian Splatting, 3DGS）场景为输入，利用大语言模型（Large Language Model, LLM）将用户文本提示直接转化为可执行代码，通过轻量级代理和粒子动力学实时修改3DGS参数，从而在不进行耗时网格提取的前提下，首次实现3DGS与物理引擎的直接耦合，支持多材质对象的碰撞感知、基于物理的交互式动画控制，且无需训练、计算开销低，显著提升了4D动画的实时性与可访问性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24986">https://arxiv.org/abs/2512.24986</a><br>
<strong>作者</strong>: Luca Collorone,Mert Kiray,Indro Spinelli,Fabio Galasso,Benjamin Busam<br>
<strong>机构</strong>: Sapienza University of Rome (罗马大学); Technical University of Munich (慕尼黑工业大学); Munich Center for Machine Learning (MCML) (慕尼黑机器学习中心)<br>
<strong>类目</strong>: Graphics (<a target="_blank" rel="noopener" href="http://cs.GR">cs.GR</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Realistic visual simulations are omnipresent, yet their creation requires computing time, rendering, and expert animation knowledge. Open-vocabulary visual effects generation from text inputs emerges as a promising solution that can unlock immense creative potential. However, current pipelines lack both physical realism and effective language interfaces, requiring slow offline optimization. In contrast, PhysTalk takes a 3D Gaussian Splatting (3DGS) scene as input and translates arbitrary user prompts into real time, physics based, interactive 4D animations. A large language model (LLM) generates executable code that directly modifies 3DGS parameters through lightweight proxies and particle dynamics. Notably, PhysTalk is the first framework to couple 3DGS directly with a physics simulator without relying on time consuming mesh extraction. While remaining open vocabulary, this design enables interactive 3D Gaussian animation via collision aware, physics based manipulation of arbitrary, multi material objects. Finally, PhysTalk is train-free and computationally lightweight: this makes 4D animation broadly accessible and shifts these workflows from a “render and wait” paradigm toward an interactive dialogue with a modern, physics-informed pipeline.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-9] DarkEQA: Benchmarking Vision-Language Models for Embodied Question Answering in Low-Light Indoor Environments</p>
<p>【速读】：该论文旨在解决当前视觉语言模型（Vision Language Models, VLMs）在低光照条件下感知能力不足的问题，尤其是在夜间或黑暗环境中执行任务时的鲁棒性缺失。现有评估基准多基于理想光照条件，未能充分反映真实场景中因光照不足导致的视觉退化问题，从而限制了VLM在全天候（24/7）机器人应用中的可靠性。解决方案的关键在于提出DarkEQA——一个开源基准测试平台，用于评估与环境问答（EQA）相关的感知原语在多层级低光条件下的表现。其核心创新在于物理保真度：通过在线性RAW空间中模拟光照衰减和传感器噪声，并采用ISP（Image Signal Processing）启发的渲染流程，精确建模真实世界的低光退化过程，从而实现可归因的鲁棒性分析。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24985">https://arxiv.org/abs/2512.24985</a><br>
<strong>作者</strong>: Yohan Park,Hyunwoo Ha,Wonjun Jo,Tae-Hyun Oh<br>
<strong>机构</strong>: Korea Advanced Institute of Science and Technology (KAIST) (韩国科学技术院); Pohang University of Science and Technology (POSTECH) (浦项科技大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
<strong>备注</strong>:  Submitted to IEEE Robotics and Automation Letters (RA-L)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Vision Language Models (VLMs) are increasingly adopted as central reasoning modules for embodied agents. Existing benchmarks evaluate their capabilities under ideal, well-lit conditions, yet robust 24/7 operation demands performance under a wide range of visual degradations, including low-light conditions at night or in dark environments–a core necessity that has been largely overlooked. To address this underexplored challenge, we present DarkEQA, an open-source benchmark for evaluating EQA-relevant perceptual primitives under multi-level low-light conditions. DarkEQA isolates the perception bottleneck by evaluating question answering from egocentric observations under controlled degradations, enabling attributable robustness analysis. A key design feature of DarkEQA is its physical fidelity: visual degradations are modeled in linear RAW space, simulating physics-based illumination drop and sensor noise followed by an ISP-inspired rendering pipeline. We demonstrate the utility of DarkEQA by evaluating a wide range of state-of-the-art VLMs and Low-Light Image Enhancement (LLIE) models. Our analysis systematically reveals VLMs’ limitations when operating under these challenging visual conditions. Our code and benchmark dataset will be released upon acceptance.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-10] Evaluating the Impact of Compression Techniques on the Robustness of CNNs under Natural Corruptions <mark class="hl-label red">ICML</mark></p>
<p>【速读】：该论文旨在解决深度学习模型压缩与鲁棒性之间的权衡问题，特别是在资源受限设备上部署计算机视觉系统时，压缩技术可能损害模型在自然退化（natural corruption）环境下的鲁棒性。解决方案的关键在于系统性评估量化（quantization）、剪枝（pruning）和权重量化聚类（weight clustering）三种压缩技术单独及组合应用对ResNet-50、VGG-19和MobileNetV2等卷积神经网络在CIFAR-10-C和CIFAR-100-C数据集上的影响，通过多目标评估方法识别出在准确率、压缩比和鲁棒性之间取得最优平衡的配置，发现特定组合策略不仅能保持甚至提升鲁棒性，尤其适用于复杂架构模型。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24971">https://arxiv.org/abs/2512.24971</a><br>
<strong>作者</strong>: Itallo Patrick Castro Alves Da Silva,Emanuel Adler Medeiros Pereira,Erick de Andrade Barboza,Baldoino Fonseca dos Santos Neto,Marcio de Medeiros Ribeiro<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Accepted for publication at the 2025 International Conference on Machine Learning and Applications (ICMLA). IEEE Catalog Number: CFP25592-ART</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Compressed deep learning models are crucial for deploying computer vision systems on resource-constrained devices. However, model compression may affect robustness, especially under natural corruption. Therefore, it is important to consider robustness evaluation while validating computer vision systems. This paper presents a comprehensive evaluation of compression techniques - quantization, pruning, and weight clustering applied individually and in combination to convolutional neural networks (ResNet-50, VGG-19, and MobileNetV2). Using the CIFAR-10-C and CIFAR 100-C datasets, we analyze the trade-offs between robustness, accuracy, and compression ratio. Our results show that certain compression strategies not only preserve but can also improve robustness, particularly on networks with more complex architectures. Utilizing multiobjective assessment, we determine the best configurations, showing that customized technique combinations produce beneficial multi-objective results. This study provides insights into selecting compression methods for robust and efficient deployment of models in corrupted real-world environments.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-11] ShowUI-π: Flow-based Generative Models as GUI Dexterous Hands</p>
<p>【速读】：该论文旨在解决现有图形用户界面（GUI）智能体在执行复杂交互操作（如拖拽进度条等连续动作）时的局限性问题，当前方法多依赖离散点击预测（x,y），难以实现自由形式、闭环反馈的轨迹控制。其关键解决方案是提出ShowUI-π，一个基于流模型（flow-based model）的生成式GUI操控代理，核心创新包括：(i) 统一离散点击与连续拖拽动作的建模框架，支持多模态交互适应；(ii) 基于流模型的动作生成机制，通过轻量级动作专家从连续视觉观测中预测微小光标调整，保障拖拽轨迹的平滑性和稳定性；(iii) 构建包含20K拖拽轨迹的训练数据集和ScreenDrag基准测试平台，提供在线与离线相结合的评估协议，验证了该方法在低参数量（450M）下显著优于现有主流模型（如Gemini-2.5-CUA，得分22.18 vs. ShowUI-π的26.98）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24965">https://arxiv.org/abs/2512.24965</a><br>
<strong>作者</strong>: Siyuan Hu,Kevin Qinghong Lin,Mike Zheng Shou<br>
<strong>机构</strong>: National University of Singapore (新加坡国立大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Human-Computer Interaction (cs.HC)<br>
<strong>备注</strong>:  17 pages, 15 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Building intelligent agents capable of dexterous manipulation is essential for achieving human-like automation in both robotics and digital environments. However, existing GUI agents rely on discrete click predictions (x,y), which prohibits free-form, closed-loop trajectories (e.g. dragging a progress bar) that require continuous, on-the-fly perception and adjustment. In this work, we develop ShowUI- \pi , the first flow-based generative model as GUI dexterous hand, featuring the following designs: (i) Unified Discrete-Continuous Actions, integrating discrete clicks and continuous drags within a shared model, enabling flexible adaptation across diverse interaction modes; (ii) Flow-based Action Generation for drag modeling, which predicts incremental cursor adjustments from continuous visual observations via a lightweight action expert, ensuring smooth and stable trajectories; (iii) Drag Training data and Benchmark, where we manually collect and synthesize 20K drag trajectories across five domains (e.g. PowerPoint, Adobe Premiere Pro), and introduce ScreenDrag, a benchmark with comprehensive online and offline evaluation protocols for assessing GUI agents’ drag capabilities. Our experiments show that proprietary GUI agents still struggle on ScreenDrag (e.g. Operator scores 13.27, and the best Gemini-2.5-CUA reaches 22.18). In contrast, ShowUI- \pi  achieves 26.98 with only 450M parameters, underscoring both the difficulty of the task and the effectiveness of our approach. We hope this work advances GUI agents toward human-like dexterous control in digital world. The code is available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-12] VIPER: Process-aware Evaluation for Generative Video <mark class="hl-label green">Reasoning</mark></p>
<p>【速读】：该论文旨在解决当前生成式视频推理（Generative Video Reasoning, GVR）评估中因依赖单帧评估而导致的“结果作弊”（outcome-hacking）问题，即模型可能通过错误的中间推理过程得出正确结论，从而误导性能评价。解决方案的关键在于提出一种<strong>过程感知的评估范式</strong>，其核心是引入VIPER基准测试平台（涵盖16项跨时间、结构、符号、空间、物理和规划等推理任务）以及新的量化指标——<strong>过程-结果一致性（Process-outcome Consistency, POC@r）</strong>，该指标利用视觉语言模型作为评判者（VLM-as-Judge），结合分层评分标准，同时评估中间步骤的有效性和最终结果的正确性，从而更真实地衡量模型的视觉推理能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24952">https://arxiv.org/abs/2512.24952</a><br>
<strong>作者</strong>: Yifan Li,Yukai Gu,Yingqian Min,Zikang Liu,Yifan Du,Kun Zhou,Min Yang,Wayne Xin Zhao,Minghui Qiu<br>
<strong>机构</strong>: Gaoling School of Artificial Intelligence, Renmin University of China (中国人民大学高瓴人工智能学院); School of Information, Renmin University of China (中国人民大学信息学院); Beijing Key Laboratory of Research on Large Models and Intelligent Governance (北京市大模型与智能治理重点实验室); ByteDance(字节跳动)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Work in progress</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent breakthroughs in video generation have demonstrated an emerging capability termed Chain-of-Frames (CoF) reasoning, where models resolve complex tasks through the generation of continuous frames. While these models show promise for Generative Video Reasoning (GVR), existing evaluation frameworks often rely on single-frame assessments, which can lead to outcome-hacking, where a model reaches a correct conclusion through an erroneous process. To address this, we propose a process-aware evaluation paradigm. We introduce VIPER, a comprehensive benchmark spanning 16 tasks across temporal, structural, symbolic, spatial, physics, and planning reasoning. Furthermore, we propose Process-outcome Consistency (POC@r), a new metric that utilizes VLM-as-Judge with a hierarchical rubric to evaluate both the validity of the intermediate steps and the final result. Our experiments reveal that state-of-the-art video models achieve only about 20% POC@1.0 and exhibit a significant outcome-hacking. We further explore the impact of test-time scaling and sampling robustness, highlighting a substantial gap between current video generation and true generalized visual reasoning. Our benchmark will be publicly released.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-13] ProDM: Synthetic Reality-driven Property-aware Progressive Diffusion Model for Coronary Calcium Motion Correction in Non-gated Chest CT</p>
<p>【速读】：该论文旨在解决非门控胸部CT（non-gated chest CT）在冠状动脉钙化（Coronary Artery Calcium, CAC）定量评估中因心脏和呼吸运动伪影导致的准确性下降问题。当前，虽然门控心脏CT能有效减少运动伪影，但其应用受限于设备要求和医保覆盖不足；而广泛可用的非门控CT虽具潜力，却因严重伪影影响CAC评分精度。论文提出的解决方案是ProDM（Property-aware Progressive Correction Diffusion Model），其关键创新在于：（1）构建钙化运动模拟数据引擎，从门控CT直接合成多样化运动轨迹下的非门控图像，实现无需配对数据的监督训练；（2）引入属性感知学习策略，通过可微分的钙化一致性损失（calcium consistency loss）融入钙化特异性先验知识，保障病灶结构完整性；（3）设计渐进式校正机制，在扩散过程中逐步降低伪影，提升稳定性与钙化保真度。实验表明，ProDM显著优于多个基线方法，在真实患者数据上提升了CAC评分准确性和风险分层性能，并通过放射科医生盲评验证了其临床可用性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24948">https://arxiv.org/abs/2512.24948</a><br>
<strong>作者</strong>: Xinran Gong,Gorkem Durak,Halil Ertugrul Aktas,Vedat Cicek,Jinkui Hao,Ulas Bagci,Nilay S. Shah,Bo Zhou<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  21 pages, 8 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Coronary artery calcium (CAC) scoring from chest CT is a well-established tool to stratify and refine clinical cardiovascular disease risk estimation. CAC quantification relies on the accurate delineation of calcified lesions, but is oftentimes affected by artifacts introduced by cardiac and respiratory motion. ECG-gated cardiac CTs substantially reduce motion artifacts, but their use in population screening and routine imaging remains limited due to gating requirements and lack of insurance coverage. Although identification of incidental CAC from non-gated chest CT is increasingly considered for it offers an accessible and widely available alternative, this modality is limited by more severe motion artifacts. We present ProDM (Property-aware Progressive Correction Diffusion Model), a generative diffusion framework that restores motion-free calcified lesions from non-gated CTs. ProDM introduces three key components: (1) a CAC motion simulation data engine that synthesizes realistic non-gated acquisitions with diverse motion trajectories directly from cardiac-gated CTs, enabling supervised training without paired data; (2) a property-aware learning strategy incorporating calcium-specific priors through a differentiable calcium consistency loss to preserve lesion integrity; and (3) a progressive correction scheme that reduces artifacts gradually across diffusion steps to enhance stability and calcium fidelity. Experiments on real patient datasets show that ProDM significantly improves CAC scoring accuracy, spatial lesion fidelity, and risk stratification performance compared with several baselines. A reader study on real non-gated scans further confirms that ProDM suppresses motion artifacts and improves clinical usability. These findings highlight the potential of progressive, property-aware frameworks for reliable CAC quantification from routine chest CT imaging.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-14] HaineiFRDM: Explore Diffusion to Restore Defects in Fast-Movement Films</p>
<p>【速读】：该论文旨在解决当前开源电影修复方法在修复效果上落后于商业方案的问题，主要瓶颈在于使用低质量合成数据训练以及采用噪声较大的光流估计。其核心解决方案是提出HaineiFRDM（Film Restoration Diffusion Model），利用扩散模型强大的内容理解能力提升修复质量；关键技术包括：1）基于图像块（patch-wise）的训练与推理策略，使单张24GB显存GPU即可处理高分辨率影片；2）设计位置感知的全局提示（position-aware Global Prompt）与帧融合机制，增强跨帧一致性；3）引入全局-局部频域模块以重建不同块间的纹理一致性；4）首次采用低分辨率预修复结果作为全局残差，有效缓解分块带来的块状伪影（blocky artifacts）。这些创新共同提升了修复精度和视觉自然度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24946">https://arxiv.org/abs/2512.24946</a><br>
<strong>作者</strong>: Rongji Xun,Junjie Yuan,Zhongjie Wang<br>
<strong>机构</strong>: Tongji University (同济大学); Shanghai Film Restoration Laboratory (上海电影修复实验室)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Multimedia (<a target="_blank" rel="noopener" href="http://cs.MM">cs.MM</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Existing open-source film restoration methods show limited performance compared to commercial methods due to training with low-quality synthetic data and employing noisy optical flows. In addition, high-resolution films have not been explored by the open-source this http URL propose HaineiFRDM(Film Restoration Diffusion Model), a film restoration framework, to explore diffusion model’s powerful content-understanding ability to help human expert better restore indistinguishable film this http URL, we employ a patch-wise training and testing strategy to make restoring high-resolution films on one 24GB-VRAMR GPU possible and design a position-aware Global Prompt and Frame Fusion this http URL, we introduce a global-local frequency module to reconstruct consistent textures among different patches. Besides, we firstly restore a low-resolution result and use it as global residual to mitigate blocky artifacts caused by patching this http URL, we construct a film restoration dataset that contains restored real-degraded films and realistic synthetic this http URL experimental results conclusively demonstrate the superiority of our model in defect restoration ability over existing open-source methods. Code and the dataset will be released.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-15] Semi-Supervised Diversity-Aware Domain Adaptation for 3D Object detection</p>
<p>【速读】：该论文旨在解决3D目标检测模型在跨域场景下性能下降的问题，即训练于某一地域（如美国）的激光雷达（LiDAR）感知模型在部署至其他地域（如亚洲或欧洲）时出现显著性能衰减的现象。解决方案的关键在于提出一种基于神经元激活模式的新型LiDAR域适应方法，其核心思想是：仅需标注少量具有代表性和多样性的目标域样本，并通过精准选择这些样本以重构模型的激活空间分布，即可实现接近最优的域适应效果。该方法不仅显著降低了标注成本，还结合受持续学习启发的后训练策略，有效防止模型权重从原始源域模型发生漂移，从而在保持源域性能的同时提升目标域表现。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24922">https://arxiv.org/abs/2512.24922</a><br>
<strong>作者</strong>: Bartłomiej Olber,Jakub Winter,Paweł Wawrzyński,Andrii Gamalii,Daniel Górniak,Marcin Łojek,Robert Nowak,Krystian Radlak<br>
<strong>机构</strong>: Warsaw University of Technology (华沙理工大学); Institute of Computer Science, Polish Academy of Sciences (波兰科学院计算机科学研究所)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:3D object detectors are fundamental components of perception systems in autonomous vehicles. While these detectors achieve remarkable performance on standard autonomous driving benchmarks, they often struggle to generalize across different domains - for instance, a model trained in the U.S. may perform poorly in regions like Asia or Europe. This paper presents a novel lidar domain adaptation method based on neuron activation patterns, demonstrating that state-of-the-art performance can be achieved by annotating only a small, representative, and diverse subset of samples from the target domain if they are correctly selected. The proposed approach requires very small annotation budget and, when combined with post-training techniques inspired by continual learning prevent weight drift from the original model. Empirical evaluation shows that the proposed domain adaptation approach outperforms both linear probing and state-of-the-art domain adaptation techniques.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-16] FinMMDocR: Benchmarking Financial Multimodal <mark class="hl-label green">Reasoning</mark>  with Scenario Awareness Document Understanding and Multi-Step Computation <mark class="hl-label red">AAAI-26</mark></p>
<p>【速读】：该论文旨在解决当前多模态大语言模型（Multimodal Large Language Models, MLLMs）在真实金融场景下进行数值推理能力不足的问题。现有基准测试在金融场景意识、文档理解深度及多步计算复杂性方面存在明显局限，难以评估模型在专业金融任务中的实际表现。解决方案的关键在于构建FinMMDocR这一新型双语多模态基准，其核心创新包括：(1) 引入57.9%包含12类隐式金融场景（如投资组合管理）的问题，强化模型对领域假设的理解与推理能力；(2) 提供涵盖9类金融文档（如公司研究报告）的837份中英文长文档（平均50.8页），显著提升文档广度与细节丰富度；(3) 设计平均需11步推理（含5.3步信息提取和5.7步计算）的任务，并要求65.0%的问题跨页整合证据（平均2.4页），从而系统性挑战模型的复杂多模态推理能力。实验表明，最优MLLM仅达58.0%准确率，且不同检索增强生成（Retrieval-Augmented Generation, RAG）方法性能差异显著，凸显了该基准对推动MLLM在现实金融场景中推理能力进步的重要价值。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24903">https://arxiv.org/abs/2512.24903</a><br>
<strong>作者</strong>: Zichen Tang,Haihong E,Rongjin Li,Jiacheng Liu,Linwei Jia,Zhuodi Hao,Zhongjun Yang,Yuanze Li,Haolin Tian,Xinyi Hu,Peizhi Zhao,Yuan Liu,Zhengyu Wang,Xianghe Wang,Yiling Huang,Xueyuan Lin,Ruofei Bai,Zijian Xie,Qian Huang,Ruining Cao,Haocheng Gao<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Computational Engineering, Finance, and Science (cs.CE)<br>
<strong>备注</strong>:  Accepted by AAAI-26 Main Track</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce FinMMDocR, a novel bilingual multimodal benchmark for evaluating multimodal large language models (MLLMs) on real-world financial numerical reasoning. Compared to existing benchmarks, our work delivers three major advancements. (1) Scenario Awareness: 57.9% of 1,200 expert-annotated problems incorporate 12 types of implicit financial scenarios (e.g., Portfolio Management), challenging models to perform expert-level reasoning based on assumptions; (2) Document Understanding: 837 Chinese/English documents spanning 9 types (e.g., Company Research) average 50.8 pages with rich visual elements, significantly surpassing existing benchmarks in both breadth and depth of financial documents; (3) Multi-Step Computation: Problems demand 11-step reasoning on average (5.3 extraction + 5.7 calculation steps), with 65.0% requiring cross-page evidence (2.4 pages average). The best-performing MLLM achieves only 58.0% accuracy, and different retrieval-augmented generation (RAG) methods show significant performance variations on this task. We expect FinMMDocR to drive improvements in MLLMs and reasoning-enhanced methods on complex multimodal reasoning tasks in real-world scenarios.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-17] OFL-SAM2: Prompt SAM2 with Online Few-shot Learner for Efficient Medical Image Segmentation</p>
<p>【速读】：该论文旨在解决将Segment Anything Model 2 (SAM2)应用于医学图像分割（Medical Image Segmentation, MIS）任务时面临的两大挑战：一是需要大量标注数据进行微调，二是依赖高质量的人工提示（prompt），这两者均耗时且需医学专家参与。解决方案的关键在于提出OFL-SAM2框架，其核心思想是利用少量标注样本训练一个轻量级映射网络（mapping network），该网络能够捕捉医学知识并将通用图像特征转换为目标特征，从而为每一帧提供额外的判别性目标表示，实现无需人工提示的标签高效分割。该映射网络支持推理阶段的在线参数更新，显著提升模型在测试序列上的泛化能力。技术上，OFL-SAM2包含两个关键组件：(1) 在线少样本学习器，用于基于有限数据训练映射网络生成目标特征；(2) 自适应融合模块，动态整合目标特征与冻结SAM2生成的记忆注意力特征，从而获得准确且鲁棒的目标表示。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24861">https://arxiv.org/abs/2512.24861</a><br>
<strong>作者</strong>: Meng Lan,Lefei Zhang,Xiaomeng Li<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The Segment Anything Model 2 (SAM2) has demonstrated remarkable promptable visual segmentation capabilities in video data, showing potential for extension to medical image segmentation (MIS) tasks involving 3D volumes and temporally correlated 2D image sequences. However, adapting SAM2 to MIS presents several challenges, including the need for extensive annotated medical data for fine-tuning and high-quality manual prompts, which are both labor-intensive and require intervention from medical experts. To address these challenges, we introduce OFL-SAM2, a prompt-free SAM2 framework for label-efficient MIS. Our core idea is to leverage limited annotated samples to train a lightweight mapping network that captures medical knowledge and transforms generic image features into target features, thereby providing additional discriminative target representations for each frame and eliminating the need for manual prompts. Crucially, the mapping network supports online parameter update during inference, enhancing the model’s generalization across test sequences. Technically, we introduce two key components: (1) an online few-shot learner that trains the mapping network to generate target features using limited data, and (2) an adaptive fusion module that dynamically integrates the target features with the memory-attention features generated by frozen SAM2, leading to accurate and robust target representation. Extensive experiments on three diverse MIS datasets demonstrate that OFL-SAM2 achieves state-of-the-art performance with limited training data.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-18] VLN-MME: Diagnosing M<mark class="hl-label green">LLM</mark> s as Language-guided Visual Navigation <mark class="hl-label green">agents</mark></p>
<p>【速读】：该论文旨在解决多模态大语言模型（Multimodal Large Language Models, MLLMs）在具身导航任务中作为零样本代理（zero-shot agents）时性能不足的问题，特别是其在多轮对话、空间推理和序列动作预测方面的局限性。解决方案的关键在于提出一个统一且可扩展的评估框架——VLN-MME，该框架通过将传统导航数据集标准化为统一基准，简化了实验设计并支持模块化比较与组件级消融分析。这一框架揭示了增强基线代理的链式思维（Chain-of-Thought, CoT）推理和自我反思反而导致性能下降，表明MLLMs在具身导航场景中存在上下文感知能力差、3D空间推理保真度低的问题，从而为MLLM后训练优化为具身代理提供了重要指导。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24851">https://arxiv.org/abs/2512.24851</a><br>
<strong>作者</strong>: Xunyi Zhao,Gengze Zhou,Qi Wu<br>
<strong>机构</strong>: Adelaide University (阿德莱德大学); Australian Institute of Machine Learning (澳大利亚机器学习研究所)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multimodal Large Language Models (MLLMs) have demonstrated remarkable capabilities across a wide range of vision-language tasks. However, their performance as embodied agents, which requires multi-round dialogue spatial reasoning and sequential action prediction, needs further exploration. Our work investigates this potential in the context of Vision-and-Language Navigation (VLN) by introducing a unified and extensible evaluation framework to probe MLLMs as zero-shot agents by bridging traditional navigation datasets into a standardized benchmark, named VLN-MME. We simplify the evaluation with a highly modular and accessible design. This flexibility streamlines experiments, enabling structured comparisons and component-level ablations across diverse MLLM architectures, agent designs, and navigation tasks. Crucially, enabled by our framework, we observe that enhancing our baseline agent with Chain-of-Thought (CoT) reasoning and self-reflection leads to an unexpected performance decrease. This suggests MLLMs exhibit poor context awareness in embodied navigation tasks; although they can follow instructions and structure their output, their 3D spatial reasoning fidelity is low. VLN-MME lays the groundwork for systematic evaluation of general-purpose MLLMs in embodied navigation settings and reveals limitations in their sequential decision-making capabilities. We believe these findings offer crucial guidance for MLLM post-training as embodied agents.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-19] CropTrack: A Tracking with Re-Identification Framework for Precision Agriculture</p>
<p>【速读】：该论文旨在解决农业环境中多目标跟踪（Multiple-object tracking, MOT）中因目标外观高度相似、频繁遮挡及光照突变导致的轨迹混淆与身份维持困难问题。现有方法主要依赖运动信息进行关联，在强遮挡场景下难以保持目标身份一致性；而直接引入外观信息又因作物间视觉相似性高而效果不佳。其解决方案的关键在于提出CropTrack框架，通过三方面创新实现：(1) 基于重排序增强的外观关联机制提升特征区分度；(2) 引入基于外观冲突消解的一对多关联策略以应对复杂遮挡；(3) 采用指数移动平均原型特征库动态更新外观表征，从而显著改善外观驱动的关联准确性与稳定性。实验表明，该方法在公开农业MOT数据集上实现了更高的识别F1分数和关联准确率，同时大幅减少身份切换次数。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24838">https://arxiv.org/abs/2512.24838</a><br>
<strong>作者</strong>: Md Ahmed Al Muzaddid,Jordan A. James,William J. Beksi<br>
<strong>机构</strong>: The University of Texas at Arlington (德克萨斯大学阿灵顿分校)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
<strong>备注</strong>:  8 pages, 5 figures, and 3 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multiple-object tracking (MOT) in agricultural environments presents major challenges due to repetitive patterns, similar object appearances, sudden illumination changes, and frequent occlusions. Contemporary trackers in this domain rely on the motion of objects rather than appearance for association. Nevertheless, they struggle to maintain object identities when targets undergo frequent and strong occlusions. The high similarity of object appearances makes integrating appearance-based association nontrivial for agricultural scenarios. To solve this problem we propose CropTrack, a novel MOT framework based on the combination of appearance and motion information. CropTrack integrates a reranking-enhanced appearance association, a one-to-many association with appearance-based conflict resolution strategy, and an exponential moving average prototype feature bank to improve appearance-based association. Evaluated on publicly available agricultural MOT datasets, CropTrack demonstrates consistent identity preservation, outperforming traditional motion-based tracking methods. Compared to the state of the art, CropTrack achieves significant gains in identification F1 and association accuracy scores with a lower number of identity switches.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-20] Video and Language Alignment in 2D Systems for 3D Multi-object Scenes with Multi-Information Derivative-Free Control</p>
<p>【速读】：该论文旨在解决跨模态系统在从二维（2D）视觉输入迁移到三维（3D）场景处理时所面临的维数鸿沟问题，尤其是在存在物体遮挡和特征区分困难的情况下。其核心挑战在于如何让原本在2D数据上训练的跨模态模型（如视觉-语言模型）在线适应3D环境中的动态变化，而无需重新预训练或微调。解决方案的关键在于引入一种基于无导数优化（derivative-free optimisation）的后悔最小化（regret minimisation）方法，以改进多变量互信息（multivariate mutual information）估计，并通过价值导向的优化机制直接利用视觉-语言模型的噪声输出来控制场景内相机（in-scene camera），从而实现对3D场景中对象遮挡和特征差异的自适应学习。该方法使现有跨模态系统能够在不依赖额外训练的前提下，在多目标3D场景中提升任务性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24826">https://arxiv.org/abs/2512.24826</a><br>
<strong>作者</strong>: Jason Armitage,Rico Sennnrich<br>
<strong>机构</strong>: University of Zurich (苏黎世大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Cross-modal systems trained on 2D visual inputs are presented with a dimensional shift when processing 3D scenes. An in-scene camera bridges the dimensionality gap but requires learning a control module. We introduce a new method that improves multivariate mutual information estimates by regret minimisation with derivative-free optimisation. Our algorithm enables off-the-shelf cross-modal systems trained on 2D visual inputs to adapt online to object occlusions and differentiate features. The pairing of expressive measures and value-based optimisation assists control of an in-scene camera to learn directly from the noisy outputs of vision-language models. The resulting pipeline improves performance in cross-modal tasks on multi-object 3D scenes without resorting to pretraining or finetuning.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-21] Nonlinear Noise2Noise for Efficient Monte Carlo Denoiser Training</p>
<p>【速读】：该论文旨在解决Noise2Noise方法在处理高动态范围（HDR）图像时因非线性变换（如色调映射函数）引入偏差的问题。传统Noise2Noise训练要求输入和目标图像均含噪声，但无法兼容常见的非线性预处理操作，因为这些操作会改变目标图像的期望值，从而导致模型学习到有偏的结果。解决方案的关键在于提出一个理论框架，用于分析特定非线性函数对训练偏差的影响，并识别出一类具有最小偏差的非线性变换组合——即通过精心设计的损失函数与色调映射函数的配对，可在压缩动态范围的同时显著降低偏差，使得原本依赖干净参考图像的蒙特卡洛渲染去噪器仅用噪声数据即可实现接近原性能的效果。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24794">https://arxiv.org/abs/2512.24794</a><br>
<strong>作者</strong>: Andrew Tinits,Stephen Mann<br>
<strong>机构</strong>: University of Waterloo (滑铁卢大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Graphics (<a target="_blank" rel="noopener" href="http://cs.GR">cs.GR</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  15 pages, 7 figures, 2 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The Noise2Noise method allows for training machine learning-based denoisers with pairs of input and target images where both the input and target can be noisy. This removes the need for training with clean target images, which can be difficult to obtain. However, Noise2Noise training has a major limitation: nonlinear functions applied to the noisy targets will skew the results. This bias occurs because the nonlinearity makes the expected value of the noisy targets different from the clean target image. Since nonlinear functions are common in image processing, avoiding them limits the types of preprocessing that can be performed on the noisy targets. Our main insight is that certain nonlinear functions can be applied to the noisy targets without adding significant bias to the results. We develop a theoretical framework for analyzing the effects of these nonlinearities, and describe a class of nonlinear functions with minimal bias. We demonstrate our method on the denoising of high dynamic range (HDR) images produced by Monte Carlo rendering. Noise2Noise training can have trouble with HDR images, where the training process is overwhelmed by outliers and performs poorly. We consider a commonly used method of addressing these training issues: applying a nonlinear tone mapping function to the model output and target images to reduce their dynamic range. This method was previously thought to be incompatible with Noise2Noise training because of the nonlinearities involved. We show that certain combinations of loss functions and tone mapping functions can reduce the effect of outliers while introducing minimal bias. We apply our method to an existing machine learning-based Monte Carlo denoiser, where the original implementation was trained with high-sample count reference images. Our results approach those of the original implementation, but are produced using only noisy training data.          Comments: 15 pages, 7 figures, 2 tables   Subjects:  Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Graphics (<a target="_blank" rel="noopener" href="http://cs.GR">cs.GR</a>); Machine Learning (cs.LG)   ACMclasses: I.4.3; I.3.7; I.5.1   Cite as: arXiv:2512.24794 [<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>]    (or  arXiv:2512.24794v1 [<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24794">https://doi.org/10.48550/arXiv.2512.24794</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)     Journalreference: SIGGRAPH Asia 2025 Conference Papers, Article 49, 1-11    Related DOI:            <a target="_blank" rel="noopener" href="https://doi.org/10.1145/3757377.3763931">https://doi.org/10.1145/3757377.3763931</a>     Focus to learn more                     DOI(s) linking to related resources<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-22] Projection-based Adversarial Attack using Physics-in-the-Loop Optimization for Monocular Depth Estimation</p>
<p>【速读】：该论文旨在解决深度神经网络（Deep Neural Networks, DNNs）在单目深度估计（Monocular Depth Estimation, MDE）任务中对对抗攻击的脆弱性问题，这种脆弱性可能导致模型输出错误的深度信息，从而影响实际应用中的可靠性。解决方案的关键在于提出一种基于投影的对抗攻击方法，该方法通过将扰动光投射到目标物体上，结合物理在回路（Physics-in-the-Loop, PITL）优化策略——即在真实环境中评估候选扰动以考虑设备特性和环境干扰——并采用分布式协方差矩阵自适应进化策略（Distributed Covariance Matrix Adaptation Evolution Strategy）进行高效搜索，最终成功生成导致深度误估的对抗样本，使目标场景中的部分物体消失。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24792">https://arxiv.org/abs/2512.24792</a><br>
<strong>作者</strong>: Takeru Kusakabe,Yudai Hirose,Mashiho Mukaida,Satoshi Ono<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG); Neural and Evolutionary Computing (<a target="_blank" rel="noopener" href="http://cs.NE">cs.NE</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Deep neural networks (DNNs) remain vulnerable to adversarial attacks that cause misclassification when specific perturbations are added to input images. This vulnerability also threatens the reliability of DNN-based monocular depth estimation (MDE) models, making robustness enhancement a critical need in practical applications. To validate the vulnerability of DNN-based MDE models, this study proposes a projection-based adversarial attack method that projects perturbation light onto a target object. The proposed method employs physics-in-the-loop (PITL) optimization – evaluating candidate solutions in actual environments to account for device specifications and disturbances – and utilizes a distributed covariance matrix adaptation evolution strategy. Experiments confirmed that the proposed method successfully created adversarial examples that lead to depth misestimations, resulting in parts of objects disappearing from the target scene.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-23] Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow</p>
<p>【速读】：该论文旨在解决如何将预训练的生成式视频模型（generative video models）中的人类引导运动转化为机器人系统所需的低级控制指令这一挑战，从而实现对开放世界中多样化物体（包括刚性、铰接式、可变形和颗粒状物体）的零样本操作。其解决方案的关键在于引入Dream2Flow框架，通过3D物体光流（3D object flow）作为中间表征，将视频生成与机器人控制相连接：首先从生成视频中重建3D物体运动轨迹，并将其建模为物体轨迹跟踪问题；进而通过分离状态变化与执行器动作，克服了“具身鸿沟”（embodiment gap），使预训练视频模型能够直接指导机器人完成未见过的任务，无需任务特定示范，最终借助轨迹优化或强化学习将3D光流转化为可执行的底层控制命令。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24766">https://arxiv.org/abs/2512.24766</a><br>
<strong>作者</strong>: Karthik Dharmarajan,Wenlong Huang,Jiajun Wu,Li Fei-Fei,Ruohan Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project website: <a target="_blank" rel="noopener" href="https://dream2flow.github.io/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Generative video modeling has emerged as a compelling tool to zero-shot reason about plausible physical interactions for open-world manipulation. Yet, it remains a challenge to translate such human-led motions into the low-level actions demanded by robotic systems. We observe that given an initial image and task instruction, these models excel at synthesizing sensible object motions. Thus, we introduce Dream2Flow, a framework that bridges video generation and robotic control through 3D object flow as an intermediate representation. Our method reconstructs 3D object motions from generated videos and formulates manipulation as object trajectory tracking. By separating the state changes from the actuators that realize those changes, Dream2Flow overcomes the embodiment gap and enables zero-shot guidance from pre-trained video models to manipulate objects of diverse categories-including rigid, articulated, deformable, and granular. Through trajectory optimization or reinforcement learning, Dream2Flow converts reconstructed 3D object flow into executable low-level commands without task-specific demonstrations. Simulation and real-world experiments highlight 3D object flow as a general and scalable interface for adapting video generation models to open-world robotic manipulation. Videos and visualizations are available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-24] UniC-Lift: Unified 3D Instance Segmentation via Contrastive Learning <mark class="hl-label red">AAAI2026</mark></p>
<p>【速读】：该论文旨在解决3D Gaussian Splatting (3DGS) 和神经辐射场（Neural Radiance Fields, NeRF）在多视角图像中进行实例/语义分割时，因2D视角间实例标签不一致导致的3D预测质量下降问题。现有方法通常采用两阶段策略，依赖对比学习与超参数敏感的聚类或预处理标签以提升一致性，但存在训练效率低和性能受限的问题。其解决方案的关键在于提出一个统一框架，将标签一致性建模与3D分割优化融合：通过引入可学习的特征嵌入（feature embedding）对高斯原语进行分割表示，并设计一种新颖的“Embedding-to-Label”解码机制，实现端到端优化；同时为改善物体边界处的伪影问题，提出在边界区域硬挖掘样本，且通过在光栅化后的特征嵌入上添加线性层再计算三元组损失（triplet loss），显著提升了训练稳定性与分割精度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24763">https://arxiv.org/abs/2512.24763</a><br>
<strong>作者</strong>: Ankit Dhiman,Srinath R,Jaswanth Reddy,Lokesh R Boregowda,Venkatesh Babu Radhakrishnan<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Accepted to AAAI 2026. Project Page: <a target="_blank" rel="noopener" href="https://unic-lift.github.io/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:3D Gaussian Splatting (3DGS) and Neural Radiance Fields (NeRF) have advanced novel-view synthesis. Recent methods extend multi-view 2D segmentation to 3D, enabling instance/semantic segmentation for better scene understanding. A key challenge is the inconsistency of 2D instance labels across views, leading to poor 3D predictions. Existing methods use a two-stage approach in which some rely on contrastive learning with hyperparameter-sensitive clustering, while others preprocess labels for consistency. We propose a unified framework that merges these steps, reducing training time and improving performance by introducing a learnable feature embedding for segmentation in Gaussian primitives. This embedding is then efficiently decoded into instance labels through a novel “Embedding-to-Label” process, effectively integrating the optimization. While this unified framework offers substantial benefits, we observed artifacts at the object boundaries. To address the object boundary issues, we propose hard-mining samples along these boundaries. However, directly applying hard mining to the feature embeddings proved unstable. Therefore, we apply a linear layer to the rasterized feature embeddings before calculating the triplet loss, which stabilizes training and significantly improves performance. Our method outperforms baselines qualitatively and quantitatively on the ScanNet, Replica3D, and Messy-Rooms datasets.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-25] Splatwizard: A Benchmark Toolkit for 3D Gaussian Splatting Compression</p>
<p>【速读】：该论文旨在解决当前基于3D高斯溅射（3D Gaussian Splatting, 3DGS）的压缩模型缺乏标准化、全面评估工具的问题。现有基准测试往往无法充分衡量不同方法在渲染速度、率失真权衡、内存效率和几何精度等方面的综合性能，限制了算法比较与改进。解决方案的关键在于提出Splatwizard——一个专为3DGS压缩模型设计的统一基准测试工具包，其核心包括：支持快速实现新压缩模型的易用框架、集成先进方法的自动化流水线，以及对图像质量指标、重建网格的切比雪夫距离（Chamfer distance）、渲染帧率和计算资源消耗等关键性能指标的自动量化评估。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24742">https://arxiv.org/abs/2512.24742</a><br>
<strong>作者</strong>: Xiang Liu,Yimin Zhou,Jinxiang Wang,Yujun Huang,Shuzhao Xie,Shiyu Qin,Mingyao Hong,Jiawei Li,Yaowei Wang,Zhi Wang,Shu-Tao Xia,Bin Chen<br>
<strong>机构</strong>: Tsinghua University (清华大学); Harbin Institute of Technology, Shenzhen (哈尔滨工业大学深圳校区); Pengcheng Laboratory (鹏城实验室); Huawei Technologies Ltd (华为技术有限公司)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The recent advent of 3D Gaussian Splatting (3DGS) has marked a significant breakthrough in real-time novel view synthesis. However, the rapid proliferation of 3DGS-based algorithms has created a pressing need for standardized and comprehensive evaluation tools, especially for compression task. Existing benchmarks often lack the specific metrics necessary to holistically assess the unique characteristics of different methods, such as rendering speed, rate distortion trade-offs memory efficiency, and geometric accuracy. To address this gap, we introduce Splatwizard, a unified benchmark toolkit designed specifically for benchmarking 3DGS compression models. Splatwizard provides an easy-to-use framework to implement new 3DGS compression model and utilize state-of-the-art techniques proposed by previous work. Besides, an integrated pipeline that automates the calculation of key performance indicators, including image-based quality metrics, chamfer distance of reconstruct mesh, rendering frame rates, and computational resource consumption is included in the framework as well. Code is available at this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-26] EchoFoley: Event-Centric Hierarchical Control for Video Grounded Creative Sound Generation</p>
<p>【速读】：该论文针对视频-文本到音频（Video-Text-to-Audio, VT2A）任务中存在的三大局限性展开研究：一是视觉与文本条件之间的不平衡导致视觉主导；二是缺乏对细粒度可控生成的明确定义；三是现有数据集依赖简短类别标签，导致指令理解与执行能力弱。为解决这些问题，论文提出EchoFoley新任务，通过符号化表示声音事件（sounding events），明确指定声音在视频中的时间、内容及方式，从而实现事件级别的局部控制和层次化的语义控制。其核心解决方案是构建了大规模专家标注的数据集EchoFoley-6k（包含6000个视频-指令-标注三元组），并设计了以声音事件为中心的代理生成框架EchoVidia，采用慢-快思维策略提升可控性和感知质量，实验表明该方法在可控性上优于现有VT2A模型40.7%，感知质量提升12.5%。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24731">https://arxiv.org/abs/2512.24731</a><br>
<strong>作者</strong>: Bingxuan Li,Yiming Cui,Yicheng He,Yiwei Wang,Shu Zhang,Longyin Wen,Yulei Niu<br>
<strong>机构</strong>: ByteDance Intelligent Creation (字节跳动智能创作); University of Illinois Urbana-Champaign (伊利诺伊大学厄巴纳-香槟分校); University of California, Merced (加州大学默塞德分校); University of California, Los Angeles (加州大学洛杉矶分校)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Sound effects build an essential layer of multimodal storytelling, shaping the emotional atmosphere and the narrative semantics of videos. Despite recent advancement in video-text-to-audio (VT2A), the current formulation faces three key limitations: First, an imbalance between visual and textual conditioning that leads to visual dominance; Second, the absence of a concrete definition for fine-grained controllable generation; Third, weak instruction understanding and following, as existing datasets rely on brief categorical tags. To address these limitations, we introduce EchoFoley, a new task designed for video-grounded sound generation with both event level local control and hierarchical semantic control. Our symbolic representation for sounding events specifies when, what, and how each sound is produced within a video or instruction, enabling fine-grained controls like sound generation, insertion, and editing. To support this task, we construct EchoFoley-6k, a large-scale, expert-curated benchmark containing over 6,000 video-instruction-annotation triplets. Building upon this foundation, we propose EchoVidia a sounding-event-centric agentic generation framework with slow-fast thinking strategy. Experiments show that EchoVidia surpasses recent VT2A models by 40.7% in controllability and 12.5% in perceptual quality.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-27] FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation</p>
<p>【速读】：该论文旨在解决生成式视频模型在推理过程中因模型容量（model capacity）分配不合理导致的效率与质量难以平衡的问题。研究表明，模型容量对不同时间步的影响存在显著差异：在早期和晚期阶段至关重要，而在中间阶段则影响较小。解决方案的关键在于提出一种阶段感知的多模型采样策略 FlowBlending，其核心是根据时间步的敏感性动态选择模型容量——在容量敏感阶段使用大模型以保障质量，在中间阶段使用小模型以提升效率。此外，作者引入了基于速度-发散分析（velocity-divergence analysis）的简单判据来识别容量敏感区域，并验证该方法可在不牺牲视觉保真度、时序连贯性和语义一致性前提下，实现高达 1.65 倍的推理加速和 57.35% 的浮点运算量（FLOPs）减少，且兼容现有加速技术，进一步提升性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24724">https://arxiv.org/abs/2512.24724</a><br>
<strong>作者</strong>: Jibin Song,Mingi Kwon,Jaeseok Jeong,Youngjung Uh<br>
<strong>机构</strong>: Yonsei University (延世大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://jibin86.github.io/flowblending_project_page">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In this work, we show that the impact of model capacity varies across timesteps: it is crucial for the early and late stages but largely negligible during the intermediate stage. Accordingly, we propose FlowBlending, a stage-aware multi-model sampling strategy that employs a large model and a small model at capacity-sensitive stages and intermediate stages, respectively. We further introduce simple criteria to choose stage boundaries and provide a velocity-divergence analysis as an effective proxy for identifying capacity-sensitive regions. Across LTX-Video (2B/13B) and WAN 2.1 (1.3B/14B), FlowBlending achieves up to 1.65x faster inference with 57.35% fewer FLOPs, while maintaining the visual fidelity, temporal coherence, and semantic alignment of the large models. FlowBlending is also compatible with existing sampling-acceleration techniques, enabling up to 2x additional speedup. Project page is available at: this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-28] Evolving Not Training: Zero-Shot <mark class="hl-label green">Reasoning</mark>  Segmentation via Evolutionary Prompting</p>
<p>【速读】：该论文旨在解决推理分割（Reasoning Segmentation）任务中现有方法的局限性，特别是监督微调（Supervised Fine-Tuning, SFT）易导致灾难性遗忘和领域依赖、强化学习（Reinforcement Learning, RL）训练不稳定且对预定义奖励函数过度敏感，以及当前无训练（training-free）方法受限于静态推理范式——即单次“生成-分割”链缺乏推理深度与自我修正能力的问题。解决方案的关键在于提出EVOL-SAM3，一种零样本框架，将推理分割重构为一个推理时的进化搜索过程，通过“生成-评估-演化”循环迭代优化提示（prompt）假设群体；其核心创新包括：视觉竞技场（Visual Arena）实现无需参考的成对锦标赛评估以衡量提示适应度，语义变异算子（Semantic Mutation operator）注入多样性并纠正语义错误，以及异质竞技场模块（Heterogeneous Arena module）融合几何先验与语义推理以增强最终选择的鲁棒性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24702">https://arxiv.org/abs/2512.24702</a><br>
<strong>作者</strong>: Kai Ye,Xiaotong You,Jianghang Lin,Jiayi Ji,Pingyang Dai,Liujuan Cao<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Reasoning Segmentation requires models to interpret complex, context-dependent linguistic queries to achieve pixel-level localization. Current dominant approaches rely heavily on Supervised Fine-Tuning (SFT) or Reinforcement Learning (RL). However, SFT suffers from catastrophic forgetting and domain dependency, while RL is often hindered by training instability and rigid reliance on predefined reward functions. Although recent training-free methods circumvent these training burdens, they are fundamentally limited by a static inference paradigm. These methods typically rely on a single-pass “generate-then-segment” chain, which suffers from insufficient reasoning depth and lacks the capability to self-correct linguistic hallucinations or spatial misinterpretations. In this paper, we challenge these limitations and propose EVOL-SAM3, a novel zero-shot framework that reformulates reasoning segmentation as an inference-time evolutionary search process. Instead of relying on a fixed prompt, EVOL-SAM3 maintains a population of prompt hypotheses and iteratively refines them through a “Generate-Evaluate-Evolve” loop. We introduce a Visual Arena to assess prompt fitness via reference-free pairwise tournaments, and a Semantic Mutation operator to inject diversity and correct semantic errors. Furthermore, a Heterogeneous Arena module integrates geometric priors with semantic reasoning to ensure robust final selection. Extensive experiments demonstrate that EVOL-SAM3 not only substantially outperforms static baselines but also significantly surpasses fully supervised state-of-the-art methods on the challenging ReasonSeg benchmark in a zero-shot setting. The code is available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-29] Renormalization Group Guided Tensor Network Structure Search <mark class="hl-label red">AAAI2026</mark></p>
<p>【速读】：该论文旨在解决张量网络结构搜索（Tensor Network Structure Search, TN-SS）中面临的三大挑战：单一尺度优化难以捕捉多尺度结构、离散搜索空间阻碍结构的平滑演化，以及结构与参数优化分离导致计算效率低下。为应对这些问题，作者提出了一种受物理重整化群（Renormalization Group, RG）启发的框架——RGTN（Renormalization Group guided Tensor Network search）。其核心创新在于引入可学习边门（learnable edge gates）实现优化阶段的拓扑调整，并基于物理量如节点张力（node tension）和边信息流（edge information flow）生成智能结构提案；通过从低复杂度粗尺度逐步细化到精细尺度，RGTN在保持紧凑结构的同时，借助尺度诱导扰动有效跳出局部最优，从而显著提升计算效率与结构适应性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24663">https://arxiv.org/abs/2512.24663</a><br>
<strong>作者</strong>: Maolin Wang,Bowen Yu,Sheng Zhang,Linjie Mi,Wanyu Wang,Yiqi Wang,Pengyue Jia,Xuetao Wei,Zenglin Xu,Ruocheng Guo,Xiangyu Zhao<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Accepted to AAAI 2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Tensor network structure search (TN-SS) aims to automatically discover optimal network topologies and rank configurations for efficient tensor decomposition in high-dimensional data representation. Despite recent advances, existing TN-SS methods face significant limitations in computational tractability, structure adaptivity, and optimization robustness across diverse tensor characteristics. They struggle with three key challenges: single-scale optimization missing multi-scale structures, discrete search spaces hindering smooth structure evolution, and separated structure-parameter optimization causing computational inefficiency. We propose RGTN (Renormalization Group guided Tensor Network search), a physics-inspired framework transforming TN-SS via multi-scale renormalization group flows. Unlike fixed-scale discrete search methods, RGTN uses dynamic scale-transformation for continuous structure evolution across resolutions. Its core innovation includes learnable edge gates for optimization-stage topology modification and intelligent proposals based on physical quantities like node tension measuring local stress and edge information flow quantifying connectivity importance. Starting from low-complexity coarse scales and refining to finer ones, RGTN finds compact structures while escaping local minima via scale-induced perturbations. Extensive experiments on light field data, high-order synthetic tensors, and video completion tasks show RGTN achieves state-of-the-art compression ratios and runs 4-600 \times  faster than existing methods, validating the effectiveness of our physics-inspired approach.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-30] From Sequential to Spatial: Reordering Autoregression for Efficient Visual Generation</p>
<p>【速读】：该论文旨在解决传统自回归（autoregressive）视觉生成模型在推理阶段因逐token解码而导致的效率低下问题。其核心解决方案是提出RadAR框架，关键创新在于引入基于径向拓扑（radial topology）的并行化生成机制：以一个初始token为中心，将其余token按空间距离分层为多个同心环，生成过程按环逐层进行，同一环内token可并行预测，从而显著提升并行度；同时设计嵌套注意力机制（nested attention mechanism），在前向传播中动态修正不一致预测，缓解误差累积与模型坍塌风险，兼顾生成效率与质量。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24639">https://arxiv.org/abs/2512.24639</a><br>
<strong>作者</strong>: Siyang Wang,Hanting Li,Wei Li,Jie Hu,Xinghao Chen,Feng Zhao<br>
<strong>机构</strong>: University of Science and Technology of China (中国科学技术大学); Huawei Noah’s Ark Lab (华为诺亚方舟实验室)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Inspired by the remarkable success of autoregressive models in language modeling, this paradigm has been widely adopted in visual generation. However, the sequential token-by-token decoding mechanism inherent in traditional autoregressive models leads to low inference this http URL this paper, we propose RadAR, an efficient and parallelizable framework designed to accelerate autoregressive visual generation while preserving its representational capacity. Our approach is motivated by the observation that visual tokens exhibit strong local dependencies and spatial correlations with their neighbors–a property not fully exploited in standard raster-scan decoding orders. Specifically, we organize the generation process around a radial topology: an initial token is selected as the starting point, and all other tokens are systematically grouped into multiple concentric rings according to their spatial distances from this center. Generation then proceeds in a ring-wise manner, from inner to outer regions, enabling the parallel prediction of all tokens within the same ring. This design not only preserves the structural locality and spatial coherence of visual scenes but also substantially increases parallelization. Furthermore, to address the risk of inconsistent predictions arising from simultaneous token generation with limited context, we introduce a nested attention mechanism. This mechanism dynamically refines implausible outputs during the forward pass, thereby mitigating error accumulation and preventing model collapse. By integrating radial parallel prediction with dynamic output correction, RadAR significantly improves generation efficiency.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-31] FireRescue: A UAV-Based Dataset and Enhanced YOLO Model for Object Detection in Fire Rescue Scenes</p>
<p>【速读】：该论文旨在解决消防救援场景下目标检测的两个核心问题：一是现有研究多集中于山地或森林等环境，忽视了城市救援场景的复杂性和高频性；二是现有检测系统类别单一，缺乏对指挥决策关键目标（如消防车、消防员）的全面覆盖。解决方案的关键在于构建了一个名为“FireRescue”的新数据集，涵盖城市、山地、森林和水域等多种救援场景，包含8类关键目标共15,980张图像和32,000个边界框，并提出改进的FRS-YOLO模型。该模型通过引入即插即用的多维协同增强注意力模块，提升易混淆类别（如消防车与普通车辆）的判别能力，同时集成动态特征采样器强化高响应前景特征，从而缓解烟雾遮挡和背景干扰导致的小目标漏检问题。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24622">https://arxiv.org/abs/2512.24622</a><br>
<strong>作者</strong>: Qingyu Xu,Runtong Zhang,Zihuan Qiu,Fanman Meng<br>
<strong>机构</strong>: UESTC(电子科技大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Object detection in fire rescue scenarios is importance for command and decision-making in firefighting operations. However, existing research still suffers from two main limitations. First, current work predominantly focuses on environments such as mountainous or forest areas, while paying insufficient attention to urban rescue scenes, which are more frequent and structurally complex. Second, existing detection systems include a limited number of classes, such as flames and smoke, and lack a comprehensive system covering key targets crucial for command decisions, such as fire trucks and firefighters. To address the above issues, this paper first constructs a new dataset named “FireRescue” for rescue command, which covers multiple rescue scenarios, including urban, mountainous, forest, and water areas, and contains eight key categories such as fire trucks and firefighters, with a total of 15,980 images and 32,000 bounding boxes. Secondly, to tackle the problems of inter-class confusion and missed detection of small targets caused by chaotic scenes, diverse targets, and long-distance shooting, this paper proposes an improved model named FRS-YOLO. On the one hand, the model introduces a plug-and-play multidi-mensional collaborative enhancement attention module, which enhances the discriminative representation of easily confused categories (e.g., fire trucks vs. ordinary trucks) through cross-dimensional feature interaction. On the other hand, it integrates a dynamic feature sampler to strengthen high-response foreground features, thereby mitigating the effects of smoke occlusion and background interference. Experimental results demonstrate that object detection in fire rescue scenarios is highly challenging, and the proposed method effectively improves the detection performance of YOLO series models in this context.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-32] LLHA-Net: A Hierarchical Attention Network for Two-View Correspondence Learning</p>
<p>【速读】：该论文旨在解决计算机视觉中特征点匹配任务因大量异常值（outliers）导致的匹配精度与鲁棒性下降的问题，尤其是在异常值比例较高时如何有效提取高质量信息并降低负样本带来的误差。其解决方案的关键在于提出一种名为“逐层分层注意力网络”（Layer-by-Layer Hierarchical Attention Network）的新方法，通过引入阶段融合（stage fusion）、分层特征提取（hierarchical extraction）以及注意力机制（attention mechanism），增强网络对特征点语义信息的表征能力；具体包括：设计逐层通道融合模块以保留各阶段特征语义并实现整体融合，构建分层注意力模块以自适应地捕获全局感知与结构语义信息，并提出两种特征提取与集成架构以提升网络的适应性。实验表明，该方法在YFCC100M和SUN3D两个公开数据集上均优于多个前沿技术，在去噪与相机位姿估计方面表现优异。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24620">https://arxiv.org/abs/2512.24620</a><br>
<strong>作者</strong>: Shuyuan Lin,Yu Guo,Xiao Chen,Yanjie Liang,Guobao Xiao,Feiran Huang<br>
<strong>机构</strong>: Jinan University (暨南大学); Guangzhou City University of Technology (广州城市理工学院); Peng Cheng Laboratory (鹏城实验室); Tongji University (同济大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Establishing the correct correspondence of feature points is a fundamental task in computer vision. However, the presence of numerous outliers among the feature points can significantly affect the matching results, reducing the accuracy and robustness of the process. Furthermore, a challenge arises when dealing with a large proportion of outliers: how to ensure the extraction of high-quality information while reducing errors caused by negative samples. To address these issues, in this paper, we propose a novel method called Layer-by-Layer Hierarchical Attention Network, which enhances the precision of feature point matching in computer vision by addressing the issue of outliers. Our method incorporates stage fusion, hierarchical extraction, and an attention mechanism to improve the network’s representation capability by emphasizing the rich semantic information of feature points. Specifically, we introduce a layer-by-layer channel fusion module, which preserves the feature semantic information from each stage and achieves overall fusion, thereby enhancing the representation capability of the feature points. Additionally, we design a hierarchical attention module that adaptively captures and fuses global perception and structural semantic information using an attention mechanism. Finally, we propose two architectures to extract and integrate features, thereby improving the adaptability of our network. We conduct experiments on two public datasets, namely YFCC100M and SUN3D, and the results demonstrate that our proposed method outperforms several state-of-the-art techniques in both outlier removal and camera pose estimation. Source code is available at this http URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-33] MoniRefer: A Real-world Large-scale Multi-modal Dataset based on Roadside Infrastructure for 3D Visual Grounding</p>
<p>【速读】：该论文旨在解决户外监控场景下3D视觉定位（3D visual grounding）任务缺乏高质量多模态数据支持的问题，尤其针对路侧基础设施系统如何理解自然语言并精确定位复杂交通环境中的目标物体这一关键挑战。现有方法主要聚焦于室内或车辆自身视角的室外驾驶场景，而忽视了由路侧传感器采集的、面向宏观交通管理的多视角点云与文本配对数据的稀缺性。解决方案的关键在于：首先构建了首个真实世界大规模多模态数据集MoniRefer，包含约13.6万条对象及41.1万条自然语言描述，覆盖多个复杂交叉路口，并通过人工验证确保语义与3D标注的准确性；其次提出端到端的Moni3DVG方法，融合图像提供的丰富外观信息与点云中的几何及光学特征，实现跨模态特征学习与精准3D目标定位，实验表明该方法在新基准上具有显著优越性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24605">https://arxiv.org/abs/2512.24605</a><br>
<strong>作者</strong>: Panquan Yang,Junfei Huang,Zongzhangbao Yin,Yingsong Hu,Anni Xu,Xinyi Luo,Xueqi Sun,Hai Wu,Sheng Ao,Zhaoxing Zhu,Chenglu Wen,Cheng Wang<br>
<strong>机构</strong>: Xiamen University (厦门大学); Pengcheng Laboratory (鹏城实验室)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  14 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:3D visual grounding aims to localize the object in 3D point cloud scenes that semantically corresponds to given natural language sentences. It is very critical for roadside infrastructure system to interpret natural languages and localize relevant target objects in complex traffic environments. However, most existing datasets and approaches for 3D visual grounding focus on the indoor and outdoor driving scenes, outdoor monitoring scenarios remain unexplored due to scarcity of paired point cloud-text data captured by roadside infrastructure sensors. In this paper, we introduce a novel task of 3D Visual Grounding for Outdoor Monitoring Scenarios, which enables infrastructure-level understanding of traffic scenes beyond the ego-vehicle perspective. To support this task, we construct MoniRefer, the first real-world large-scale multi-modal dataset for roadside-level 3D visual grounding. The dataset consists of about 136,018 objects with 411,128 natural language expressions collected from multiple complex traffic intersections in the real-world environments. To ensure the quality and accuracy of the dataset, we manually verified all linguistic descriptions and 3D labels for objects. Additionally, we also propose a new end-to-end method, named Moni3DVG, which utilizes the rich appearance information provided by images and geometry and optical information from point cloud for multi-modal feature learning and 3D object localization. Extensive experiments and ablation studies on the proposed benchmarks demonstrate the superiority and effectiveness of our method. Our dataset and code will be released.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-34] Collaborative Low-Rank Adaptation for Pre-Trained Vision Transformers</p>
<p>【速读】：该论文旨在解决现有低秩适配（Low-rank Adaptation, LoRA）方法在微调预训练视觉Transformer时难以兼顾学习性能与参数效率的问题。当前方法要么牺牲微调效果，要么引入过多可训练参数，无法实现最优平衡。其解决方案的关键在于提出协同低秩适配（Collaborative Low-rank Adaptation, CLoRA），该方法包含两个核心组件：基空间共享（base-space sharing）和样本无关多样性增强（sample-agnostic diversity enhancement, SADE）。其中，基空间共享使所有低秩模块（Low-rank Modules, LRMs）共享一组降维/升维投影空间，从而在保持参数效率的同时提升学习能力；SADE通过正则化不同低秩矩阵之间的相似性，抑制冗余表示，促进多样化特征学习，最终在图像和点云任务上实现了更优的性能-效率权衡，且在点云分析中所需的GFLOPs最少。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24603">https://arxiv.org/abs/2512.24603</a><br>
<strong>作者</strong>: Zheng Liu,Jinchao Zhu,Gao Huang<br>
<strong>机构</strong>: University of Science and Technology Beijing (北京科技大学); Beijing Engineering Research Center of Industrial Spectrum Imaging (工业光谱成像北京市工程研究中心); Nankai University (南开大学); Tsinghua University (清华大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  13 tables, 3 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Low-rank adaptation (LoRA) has achieved remarkable success in fine-tuning pre-trained vision transformers for various downstream tasks. Existing studies mainly focus on exploring more parameter-efficient strategies or more effective representation learning schemes. However, these methods either sacrifice fine-tuning performance or introduce excessive trainable parameters, failing to strike a balance between learning performance and parameter efficiency. To address this problem, we propose a novel tuning method named collaborative low-rank adaptation (CLoRA) in this paper. CLoRA consists of base-space sharing and sample-agnostic diversity enhancement (SADE) components. To maintain parameter efficiency while expanding the learning capacity of low-rank modules (LRMs), base-space sharing allows all LRMs to share a set of down/up-projection spaces. In CLoRA, the low-rank matrices obtained from the shared spaces collaboratively construct each LRM. Since the representations extracted by these matrices may contain redundant information, SADE is employed to regularize the similarities among them to encourage diverse representations in the training process. We conduct extensive experiments on widely used image and point cloud datasets to evaluate the performance of CLoRA. Experimental results demonstrate that CLoRA strikes a better balance between learning performance and parameter efficiency, while requiring the fewest GFLOPs for point cloud analysis, compared with the state-of-the-art methods.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-35] 3D Semantic Segmentation for Post-Disaster Assessment</p>
<p>【速读】：该论文旨在解决现有深度学习模型在灾后环境中进行3D语义分割（3D semantic segmentation）时缺乏专用数据集的问题。其关键解决方案是构建一个针对灾后场景的3D点云数据集，该数据集基于无人机（UAV）拍摄的飓风Ian（2022）受灾区域影像，利用结构光重建（Structure-from-Motion, SfM）与多视角立体视觉（Multi-View Stereo, MVS）技术生成高质量3D点云，并在此基础上评估了当前最先进的3D语义分割模型（如Fast Point Transformer、Point Transformer v3和OA-CNNs），揭示了现有方法在灾后环境中的显著局限性，从而强调了开发专门用于灾后场景理解的3D分割技术和基准数据集的紧迫性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24593">https://arxiv.org/abs/2512.24593</a><br>
<strong>作者</strong>: Nhut Le,Maryam Rahnemoonfar<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  Accepted by the 2025 IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2025)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The increasing frequency of natural disasters poses severe threats to human lives and leads to substantial economic losses. While 3D semantic segmentation is crucial for post-disaster assessment, existing deep learning models lack datasets specifically designed for post-disaster environments. To address this gap, we constructed a specialized 3D dataset using unmanned aerial vehicles (UAVs)-captured aerial footage of Hurricane Ian (2022) over affected areas, employing Structure-from-Motion (SfM) and Multi-View Stereo (MVS) techniques to reconstruct 3D point clouds. We evaluated the state-of-the-art (SOTA) 3D semantic segmentation models, Fast Point Transformer (FPT), Point Transformer v3 (PTv3), and OA-CNNs on this dataset, exposing significant limitations in existing methods for disaster-stricken regions. These findings underscore the urgent need for advancements in 3D segmentation techniques and the development of specialized 3D benchmark datasets to improve post-disaster scene understanding and response.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-36] SliceLens: Fine-Grained and Grounded Error Slice Discovery for Multi-Instance Vision Tasks</p>
<p>【速读】：该论文旨在解决计算机视觉模型在具有连贯视觉模式的子集（即误差切片，error slices）上系统性失效的问题，尤其针对多实例任务（如目标检测、分割和姿态估计）中现有切片发现方法适用性不足、难以捕捉复杂视觉关系导致的角落案例（corner cases）以及当前基准测试缺乏真实错误标注等问题。其解决方案的关键在于提出SliceLens框架，该框架基于假设驱动的方法，利用大语言模型（LLM）与视觉语言模型（VLM）进行 grounded visual reasoning，自动生成并验证多样化的失败假设，从而可靠地识别出细粒度且可解释的误差切片；同时引入FeSD（Fine-grained Slice Discovery）基准，首次为实例级视觉任务设计了专家标注并精炼的地面真实切片，精确对齐局部错误区域，显著提升了误差切片发现的准确性与实用性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24592">https://arxiv.org/abs/2512.24592</a><br>
<strong>作者</strong>: Wei Zhang,Chaoqun Wang,Zixuan Guan,Sam Kao,Pengfei Zhao,Peng Wu,Sifeng He<br>
<strong>机构</strong>: Apple(苹果)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Systematic failures of computer vision models on subsets with coherent visual patterns, known as error slices, pose a critical challenge for robust model evaluation. Existing slice discovery methods are primarily developed for image classification, limiting their applicability to multi-instance tasks such as detection, segmentation, and pose estimation. In real-world scenarios, error slices often arise from corner cases involving complex visual relationships, where existing instance-level approaches lacking fine-grained reasoning struggle to yield meaningful insights. Moreover, current benchmarks are typically tailored to specific algorithms or biased toward image classification, with artificial ground truth that fails to reflect real model failures. To address these limitations, we propose SliceLens, a hypothesis-driven framework that leverages LLMs and VLMs to generate and verify diverse failure hypotheses through grounded visual reasoning, enabling reliable identification of fine-grained and interpretable error slices. We further introduce FeSD (Fine-grained Slice Discovery), the first benchmark specifically designed for evaluating fine-grained error slice discovery across instance-level vision tasks, featuring expert-annotated and carefully refined ground-truth slices with precise grounding to local error regions. Extensive experiments on both existing benchmarks and FeSD demonstrate that SliceLens achieves state-of-the-art performance, improving Precision@10 by 0.42 (0.73 vs. 0.31) on FeSD, and identifies interpretable slices that facilitate actionable model improvements, as validated through model repair experiments.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-37] Improving Few-Shot Change Detection Visual Question Answering via Decision-Ambiguity-guided Reinforcement Fine-Tuning</p>
<p>【速读】：该论文旨在解决变化检测视觉问答（CDVQA）中因决策模糊性（Decision-Ambiguity）导致的模型性能瓶颈问题，即模型对正确答案与强干扰项（distractors）赋予相近置信度，从而影响判别能力和鲁棒性。解决方案的关键在于提出一种基于决策模糊性的强化微调框架（DARFT），其核心机制包括：首先利用预训练的监督微调（SFT）模型挖掘出决策模糊样本（DAS），随后在这些样本子集上采用组内相对策略优化（group-relative policy optimization），通过多样本解码和组内相对优势信号，有效抑制强干扰项并增强决策边界，且无需额外标注监督。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24591">https://arxiv.org/abs/2512.24591</a><br>
<strong>作者</strong>: Fuyu Dong,Ke Li,Di Wang,Nan Luo,Yiming Zhang,Kaiyu Li,Jianfei Yang,Quan Wang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Change detection visual question answering (CDVQA) requires answering text queries by reasoning about semantic changes in bi-temporal remote sensing images. A straightforward approach is to boost CDVQA performance with generic vision-language models via supervised fine-tuning (SFT). Despite recent progress, we observe that a significant portion of failures do not stem from clearly incorrect predictions, but from decision ambiguity, where the model assigns similar confidence to the correct answer and strong distractors. To formalize this challenge, we define Decision-Ambiguous Samples (DAS) as instances with a small probability margin between the ground-truth answer and the most competitive alternative. We argue that explicitly optimizing DAS is crucial for improving the discriminability and robustness of CDVQA models. To this end, we propose DARFT, a Decision-Ambiguity-guided Reinforcement Fine-Tuning framework that first mines DAS using an SFT-trained reference policy and then applies group-relative policy optimization on the mined subset. By leveraging multi-sample decoding and intra-group relative advantages, DARFT suppresses strong distractors and sharpens decision boundaries without additional supervision. Extensive experiments demonstrate consistent gains over SFT baselines, particularly under few-shot settings.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-38] RGBT-Ground Benchmark: Visual Grounding Beyond RGB in Complex Real-World Scenarios</p>
<p>【速读】：该论文旨在解决现有视觉定位（Visual Grounding, VG）基准数据集普遍基于清洁环境（如COCO）构建、缺乏复杂真实场景多样性的问题，从而无法有效评估模型在光照变化、天气条件等实际挑战下的鲁棒性和泛化能力。其解决方案的关键在于提出首个面向复杂现实场景的大规模多模态视觉定位基准RGBT-Ground，该基准包含空间对齐的RGB与热红外（Thermal Infrared, TIR）图像对、高质量指代表达、目标边界框及细粒度场景/环境/对象层级标注；同时设计了一个统一的视觉定位框架，支持单模态（RGB或TIR）与多模态（RGB-TIR）输入，并进一步提出RGBT-VGNet作为融合互补视觉模态的简单而有效的基线方法，显著提升了夜间和远距离等极端条件下的定位性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24561">https://arxiv.org/abs/2512.24561</a><br>
<strong>作者</strong>: Tianyi Zhao,Jiawen Xi,Linhui Xiao,Junnan Li,Xue Yang,Maoxun Yuan,Xingxing Wei<br>
<strong>机构</strong>: Beihang University (北京航空航天大学); Pengcheng Laboratory (鹏城实验室); Shanghai Jiao Tong University (上海交通大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  27pages, 9figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Visual Grounding (VG) aims to localize specific objects in an image according to natural language expressions, serving as a fundamental task in vision-language understanding. However, existing VG benchmarks are mostly derived from datasets collected under clean environments, such as COCO, where scene diversity is limited. Consequently, they fail to reflect the complexity of real-world conditions, such as changes in illumination, weather, etc., that are critical to evaluating model robustness and generalization in safety-critical applications. To address these limitations, we present RGBT-Ground, the first large-scale visual grounding benchmark built for complex real-world scenarios. It consists of spatially aligned RGB and Thermal infrared (TIR) image pairs with high-quality referring expressions, corresponding object bounding boxes, and fine-grained annotations at the scene, environment, and object levels. This benchmark enables comprehensive evaluation and facilitates the study of robust grounding under diverse and challenging conditions. Furthermore, we establish a unified visual grounding framework that supports both uni-modal (RGB or TIR) and multi-modal (RGB-TIR) visual inputs. Based on it, we propose RGBT-VGNet, a simple yet effective baseline for fusing complementary visual modalities to achieve robust grounding. We conduct extensive adaptations to the existing methods on RGBT-Ground. Experimental results show that our proposed RGBT-VGNet significantly outperforms these adapted methods, particularly in nighttime and long-distance scenarios. All resources will be publicly released to promote future research on robust visual grounding in complex real-world environments.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-39] OCP-LS: An Efficient Algorithm for Visual Localization</p>
<p>【速读】：该论文旨在解决深度学习中大规模优化问题的挑战，特别是传统优化算法在收敛速度、训练稳定性和抗噪声干扰能力方面的不足。其解决方案的关键在于提出一种新颖的二阶优化算法，通过引入OCP（Optimal Control-based Preconditioning）方法并合理近似海森矩阵（Hessian matrix）的对角元素，从而在保持高定位精度的同时显著提升优化效率与鲁棒性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24552">https://arxiv.org/abs/2512.24552</a><br>
<strong>作者</strong>: Jindi Zhong,Hongxia Wang,Huanshui Zhang<br>
<strong>机构</strong>: Shandong University of Science and Technology (山东科技大学); Shandong University (山东大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Optimization and Control (math.OC)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper proposes a novel second-order optimization algorithm. It aims to address large-scale optimization problems in deep learning because it incorporates the OCP method and appropriately approximating the diagonal elements of the Hessian matrix. Extensive experiments on multiple standard visual localization benchmarks demonstrate the significant superiority of the proposed method. Compared with conventional optimiza tion algorithms, our framework achieves competitive localization accuracy while exhibiting faster convergence, enhanced training stability, and improved robustness to noise interference.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-40] PhyGDPO: Physics-Aware Groupwise Direct Preference Optimization for Physically Consistent Text-to-Video Generation</p>
<p>【速读】：该论文旨在解决当前文本到视频（Text-to-Video, T2V）生成方法在遵循物理规律方面表现不足的问题，尤其在复杂真实场景中难以建模丰富的物理交互与现象。现有方法依赖图形渲染或提示扩展，难以泛化至非模拟环境，且缺乏高质量物理增强数据。其解决方案的关键在于提出两个核心组件：一是Physics-Augmented video data construction Pipeline（PhyAugPipe），利用具备思维链推理能力的视觉语言模型（Vision-Language Model, VLM）自动构建大规模物理增强训练数据集PhyVidGen-135K；二是Physics-aware Groupwise Direct Preference Optimization（PhyGDPO）框架，基于群体式Plackett-Luce概率模型捕捉整体偏好，并引入Physics-Guided Rewarding（PGR）机制通过VLM提取物理奖励引导优化过程，同时设计LoRA-Switch Reference（LoRA-SR）策略实现高效训练。实验表明，该方法在PhyGenBench和VideoPhy2基准上显著优于当前开源最优方案。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24551">https://arxiv.org/abs/2512.24551</a><br>
<strong>作者</strong>: Yuanhao Cai,Kunpeng Li,Menglin Jia,Jialiang Wang,Junzhe Sun,Feng Liang,Weifeng Chen,Felix Juefei-Xu,Chu Wang,Ali Thabet,Xiaoliang Dai,Xuan Ju,Alan Yuille,Ji Hou<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advances in text-to-video (T2V) generation have achieved good visual quality, yet synthesizing videos that faithfully follow physical laws remains an open challenge. Existing methods mainly based on graphics or prompt extension struggle to generalize beyond simple simulated environments or learn implicit physical reasoning. The scarcity of training data with rich physics interactions and phenomena is also a problem. In this paper, we first introduce a Physics-Augmented video data construction Pipeline, PhyAugPipe, that leverages a vision-language model (VLM) with chain-of-thought reasoning to collect a large-scale training dataset, PhyVidGen-135K. Then we formulate a principled Physics-aware Groupwise Direct Preference Optimization, PhyGDPO, framework that builds upon the groupwise Plackett-Luce probabilistic model to capture holistic preferences beyond pairwise comparisons. In PhyGDPO, we design a Physics-Guided Rewarding (PGR) scheme that embeds VLM-based physics rewards to steer optimization toward physical consistency. We also propose a LoRA-Switch Reference (LoRA-SR) scheme that eliminates memory-heavy reference duplication for efficient training. Experiments show that our method significantly outperforms state-of-the-art open-source methods on PhyGenBench and VideoPhy2. Please check our project page at this https URL for more video results. Our code, models, and data will be released at this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-41] Hierarchical Vector-Quantized Latents for Perceptual Low-Resolution Video Compression</p>
<p>【速读】：该论文旨在解决视频流量激增背景下，传统视频编码器（如H.264和HEVC）在支持机器学习任务时存在的局限性问题。这些编码器主要面向像素域重建，缺乏对深度学习流水线友好的潜在表示（latent representations）原生支持，从而限制了其在生成式AI (Generative AI) 和边缘计算场景中的应用。解决方案的关键在于提出一种多尺度向量量化变分自编码器（Multi-Scale Vector Quantized Variational Autoencoder, MS-VQ-VAE），该模型通过引入基于3D残差卷积的两级层次化潜在结构，实现对低分辨率视频（64×64）的紧凑且高保真潜在表征，同时具备轻量化设计（约18.5M参数），适合部署于资源受限的边缘设备。此外，结合预训练VGG16网络提取的感知损失函数，显著提升了重建视频的主观质量，在UCF101数据集上达到25.96 dB PSNR和0.8375 SSIM，优于单尺度基线模型（提升1.41 dB PSNR和0.0248 SSIM）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24547">https://arxiv.org/abs/2512.24547</a><br>
<strong>作者</strong>: Manikanta Kotthapalli,Banafsheh Rekabdar<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  11 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The exponential growth of video traffic has placed increasing demands on bandwidth and storage infrastructure, particularly for content delivery networks (CDNs) and edge devices. While traditional video codecs like H.264 and HEVC achieve high compression ratios, they are designed primarily for pixel-domain reconstruction and lack native support for machine learning-centric latent representations, limiting their integration into deep learning pipelines. In this work, we present a Multi-Scale Vector Quantized Variational Autoencoder (MS-VQ-VAE) designed to generate compact, high-fidelity latent representations of low-resolution video, suitable for efficient storage, transmission, and client-side decoding. Our architecture extends the VQ-VAE-2 framework to a spatiotemporal setting, introducing a two-level hierarchical latent structure built with 3D residual convolutions. The model is lightweight (approximately 18.5M parameters) and optimized for 64x64 resolution video clips, making it appropriate for deployment on edge devices with constrained compute and memory resources. To improve perceptual reconstruction quality, we incorporate a perceptual loss derived from a pre-trained VGG16 network. Trained on the UCF101 dataset using 2-second video clips (32 frames at 16 FPS), on the test set we achieve 25.96 dB PSNR and 0.8375 SSIM. On validation, our model improves over the single-scale baseline by 1.41 dB PSNR and 0.0248 SSIM. The proposed framework is well-suited for scalable video compression in bandwidth-sensitive scenarios, including real-time streaming, mobile video analytics, and CDN-level storage optimization.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-42] Using <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  To Translate Machine Results To Human Results</p>
<p>【速读】：该论文旨在解决医学影像分析中结构化检测结果与临床叙事报告之间存在“语义鸿沟”的问题，即当前基于计算机视觉（Computer Vision, CV）的模型虽能精准识别异常区域并输出分类标签和边界框，但无法自动生成符合放射科医生书写习惯的自然语言诊断报告。解决方案的关键在于构建一个端到端的多模态流水线：首先利用YOLOv5和YOLOv8目标检测模型对胸部X光图像进行异常定位与分类，提取结构化发现；随后将这些结构化输出作为输入传递给大语言模型（Large Language Model, LLM），由其生成具有临床意义的自然语言描述和总结。实验表明，该方法在语义层面与人工报告高度一致，且GPT-4在清晰度方面表现优异，但在文本流畅性上仍有改进空间，说明系统已具备较高的临床准确性，但生成文本的风格仍可进一步优化以贴近专业放射科医师的写作特征。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24518">https://arxiv.org/abs/2512.24518</a><br>
<strong>作者</strong>: Trishna Niraula,Jonathan Stubblefield<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  11 pages, 7 figures, 3 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Artificial intelligence (AI) has transformed medical imaging, with computer vision (CV) systems achieving state-of-the-art performance in classification and detection tasks. However, these systems typically output structured predictions, leaving radiologists responsible for translating results into full narrative reports. Recent advances in large language models (LLMs), such as GPT-4, offer new opportunities to bridge this gap by generating diagnostic narratives from structured findings. This study introduces a pipeline that integrates YOLOv5 and YOLOv8 for anomaly detection in chest X-ray images with a large language model (LLM) to generate natural-language radiology reports. The YOLO models produce bounding-box predictions and class labels, which are then passed to the LLM to generate descriptive findings and clinical summaries. YOLOv5 and YOLOv8 are compared in terms of detection accuracy, inference latency, and the quality of generated text, as measured by cosine similarity to ground-truth reports. Results show strong semantic similarity between AI and human reports, while human evaluation reveals GPT-4 excels in clarity (4.88/5) but exhibits lower scores for natural writing flow (2.81/5), indicating that current systems achieve clinical accuracy but remain stylistically distinguishable from radiologist-authored text.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-43] raining-Free Color-Aware Adversarial Diffusion Sanitization for Diffusion Stegomalware Defense at Security Gateways</p>
<p>【速读】：该论文旨在解决生成式 AI（Generative AI）驱动的扩散模型隐写术（diffusion steganography）所带来的安全威胁，特别是针对无需微调或辅助解码器即可嵌入高容量信息的隐蔽通信技术，这类技术可被用于命令与控制（C2）、载荷部署及数据外泄等恶意场景。其解决方案的关键在于提出一种无需训练的防御机制——对抗性扩散净化（Adversarial Diffusion Sanitization, ADS），该机制利用预训练去噪器作为扩散解码器的可微分代理，并引入颜色感知的四元数耦合更新规则，在严格失真限制下有效降低伪影，从而在不检测隐藏内容的前提下中和潜在恶意载荷，显著削弱解码成功率至接近零，同时保持最小的感知影响，实现优于传统内容变换方法的安全-效用权衡。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24499">https://arxiv.org/abs/2512.24499</a><br>
<strong>作者</strong>: Vladimir Frants,Sos Agaian<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The rapid expansion of generative AI has normalized large-scale synthetic media creation, enabling new forms of covert communication. Recent generative steganography methods, particularly those based on diffusion models, can embed high-capacity payloads without fine-tuning or auxiliary decoders, creating significant challenges for detection and remediation. Coverless diffusion-based techniques are difficult to counter because they generate image carriers directly from secret data, enabling attackers to deliver stegomalware for command-and-control, payload staging, and data exfiltration while bypassing detectors that rely on cover-stego discrepancies. This work introduces Adversarial Diffusion Sanitization (ADS), a training-free defense for security gateways that neutralizes hidden payloads rather than detecting them. ADS employs an off-the-shelf pretrained denoiser as a differentiable proxy for diffusion-based decoders and incorporates a color-aware, quaternion-coupled update rule to reduce artifacts under strict distortion limits. Under a practical threat model and in evaluation against the state-of-the-art diffusion steganography method Pulsar, ADS drives decoder success rates to near zero with minimal perceptual impact. Results demonstrate that ADS provides a favorable security-utility trade-off compared to standard content transformations, offering an effective mitigation strategy against diffusion-driven steganography.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-44] F2IDiff: Real-world Image Super-resolution using Feature to Image Diffusion Foundation Model</p>
<p>【速读】：该论文旨在解决生成式 AI（Generative AI）在单图像超分辨率（Single Image Super-Resolution, SISR）任务中因强生成能力导致的幻觉问题，尤其是在消费级智能手机摄影场景下，低分辨率（LR）图像质量较高，对生成内容的保真度要求更高。传统基于文本到图像扩散模型（Text-to-Image Diffusion, T2IDiff）的SISR方法虽能提升图像质量，但其高层语义文本特征难以准确描述小尺度细节，且模型设计针对低分辨率图像（约1MP），而现代手机摄像头输出的LR图像通常达到12MP以上，导致局部区域无法被有效建模。为此，论文提出一种基于更低层级特征条件引导的SISR网络，即特征到图像扩散（Feature-to-Image Diffusion, F2IDiff）基础模型（Foundation Model），采用DINOv2提取的视觉特征作为条件输入，以实现更严格、更丰富的局部结构约束，从而在保持图像真实性的同时提升超分性能。解决方案的关键在于使用更具空间敏感性的底层视觉特征（如DINOv2特征）替代高层文本特征，以增强对小尺度细节的刻画能力并减少不必要的幻觉。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24473">https://arxiv.org/abs/2512.24473</a><br>
<strong>作者</strong>: Devendra K. Jangid,Ripon K. Saha,Dilshan Godaliyadda,Jing Li,Seok-Jun Lee,Hamid R. Sheikh<br>
<strong>机构</strong>: MPI Lab, Samsung Research America (三星美国研究院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Image and Video Processing (eess.IV)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:With the advent of Generative AI, Single Image Super-Resolution (SISR) quality has seen substantial improvement, as the strong priors learned by Text-2-Image Diffusion (T2IDiff) Foundation Models (FM) can bridge the gap between High-Resolution (HR) and Low-Resolution (LR) images. However, flagship smartphone cameras have been slow to adopt generative models because strong generation can lead to undesirable hallucinations. For substantially degraded LR images, as seen in academia, strong generation is required and hallucinations are more tolerable because of the wide gap between LR and HR images. In contrast, in consumer photography, the LR image has substantially higher fidelity, requiring only minimal hallucination-free generation. We hypothesize that generation in SISR is controlled by the stringency and richness of the FM’s conditioning feature. First, text features are high level features, which often cannot describe subtle textures in an image. Additionally, Smartphone LR images are at least  12MP , whereas SISR networks built on T2IDiff FM are designed to perform inference on much smaller images ( 1MP ). As a result, SISR inference has to be performed on small patches, which often cannot be accurately described by text feature. To address these shortcomings, we introduce an SISR network built on a FM with lower-level feature conditioning, specifically DINOv2 features, which we call a Feature-to-Image Diffusion (F2IDiff) Foundation Model (FM). Lower level features provide stricter conditioning while being rich descriptors of even small patches.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-45] Spectral and Spatial Graph Learning for Multispectral Solar Image Compression</p>
<p>【速读】：该论文旨在解决空间任务中多光谱太阳图像的高保真压缩难题，即在有限带宽条件下如何有效保留精细的光谱与空间细节。解决方案的关键在于提出一种面向太阳观测的可学习图像压缩框架，其核心由两个互补模块构成：一是<strong>跨波段窗口图嵌入（Inter-Spectral Windowed Graph Embedding, iSWGE）</strong>，通过将不同光谱通道建模为带有学习边特征的图节点，显式捕捉波段间的复杂关系；二是<strong>窗口化空间图注意力与卷积注意力块（Windowed Spatial Graph Attention and Convolutional Block Attention, WSGA-C）</strong>，结合稀疏图注意力机制与卷积注意力机制，降低空间冗余并增强细尺度结构的保留能力。实验表明，该方法在SDOML数据集上六个极紫外（EUV）通道下相较强基线模型实现了20.15%的均值光谱信息散度（MSID）下降、最高1.09%的峰值信噪比（PSNR）提升及1.62%的对数变换MS-SSIM增益，实现了在相近比特率下的更清晰且光谱忠实的重建效果。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24463">https://arxiv.org/abs/2512.24463</a><br>
<strong>作者</strong>: Prasiddha Siwakoti,Atefeh Khoshkhahtinat,Piyush M. Mehta,Barbara J. Thompson,Michael S. F. Kirk,Daniel da Silva<br>
<strong>机构</strong>: West Virginia University (西弗吉尼亚大学); NASA Goddard Space Flight Center (美国国家航空航天局戈达德太空飞行中心)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  8 pages, 6 figures 1 table. Code available at <a target="_blank" rel="noopener" href="https://github.com/agyat4/sgraph">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:High-fidelity compression of multispectral solar imagery remains challenging for space missions, where limited bandwidth must be balanced against preserving fine spectral and spatial details. We present a learned image compression framework tailored to solar observations, leveraging two complementary modules: (1) the Inter-Spectral Windowed Graph Embedding (iSWGE), which explicitly models inter-band relationships by representing spectral channels as graph nodes with learned edge features; and (2) the Windowed Spatial Graph Attention and Convolutional Block Attention (WSGA-C), which combines sparse graph attention with convolutional attention to reduce spatial redundancy and emphasize fine-scale structures. Evaluations on the SDOML dataset across six extreme ultraviolet (EUV) channels show that our approach achieves a 20.15%reduction in Mean Spectral Information Divergence (MSID), up to 1.09% PSNR improvement, and a 1.62% log transformed MS-SSIM gain over strong learned baselines, delivering sharper and spectrally faithful reconstructions at comparable bits-per-pixel rates. The code is publicly available at this https URL .<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-46] Exploring Compositionality in Vision Transformers using Wavelet Representations</p>
<p>【速读】：该论文旨在解决视觉 Transformer (Vision Transformer, ViT) 编码器在表征空间中是否具备组合性（compositionality）的问题，即其学习到的特征表示是否能够通过低级基元（primitives）的组合来重构原始图像表示。解决方案的关键在于引入离散小波变换（Discrete Wavelet Transform, DWT）作为获取输入依赖性基元的工具，并构建一个类比于语言模型中组合性测量框架的评估体系，从而在 ViT 的潜在空间中验证基元的可组合性。实验表明，单层 DWT 分解所得的基元能够近似地在编码器表示空间中实现组合，揭示了 ViT 在信息结构化过程中对局部与全局特征进行层次化组合的机制。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24438">https://arxiv.org/abs/2512.24438</a><br>
<strong>作者</strong>: Akshad Shyam Purushottamdas,Pranav K Nayak,Divya Mehul Rajparia,Deekshith Patel,Yashmitha Gogineni,Konda Reddy Mopuri,Sumohana S. Channappayya<br>
<strong>机构</strong>: IIT Hyderabad (印度理工学院海得拉巴分校)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  9 pages, 6 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:While insights into the workings of the transformer model have largely emerged by analysing their behaviour on language tasks, this work investigates the representations learnt by the Vision Transformer (ViT) encoder through the lens of compositionality. We introduce a framework, analogous to prior work on measuring compositionality in representation learning, to test for compositionality in the ViT encoder. Crucial to drawing this analogy is the Discrete Wavelet Transform (DWT), which is a simple yet effective tool for obtaining input-dependent primitives in the vision setting. By examining the ability of composed representations to reproduce original image representations, we empirically test the extent to which compositionality is respected in the representation space. Our findings show that primitives from a one-level DWT decomposition produce encoder representations that approximately compose in latent space, offering a new perspective on how ViTs structure information.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-47] AI-Driven Evaluation of Surgical Skill via Action Recognition</p>
<p>【速读】：该论文旨在解决传统外科技能评估方法依赖专家主观评判、存在评分者间差异且耗时费力的问题，尤其在低收入和中等收入国家难以实现规模化应用。其解决方案的关键在于提出一种基于人工智能的自动化评估框架，核心创新包括：采用改进的TimeSformer视频Transformer架构（引入分层时间注意力与加权空间注意力机制）实现手术视频中动作的精准识别，并结合YOLO-based目标检测与跟踪技术提取精细的器械运动特征，从而从五个维度对显微吻合术技能进行量化评价，实验表明该系统在帧级动作分割上达到93.62%的准确率（经后处理），并能以76%的平均分类准确率复现专家评估结果，展现出客观、一致且可解释的评估潜力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24411">https://arxiv.org/abs/2512.24411</a><br>
<strong>作者</strong>: Yan Meng,Daniel A. Donoho,Marcelle Altshuler,Omar Arnaout<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The development of effective training and evaluation strategies is critical. Conventional methods for assessing surgical proficiency typically rely on expert supervision, either through onsite observation or retrospective analysis of recorded procedures. However, these approaches are inherently subjective, susceptible to inter-rater variability, and require substantial time and effort from expert surgeons. These demands are often impractical in low- and middle-income countries, thereby limiting the scalability and consistency of such methods across training programs. To address these limitations, we propose a novel AI-driven framework for the automated assessment of microanastomosis performance. The system integrates a video transformer architecture based on TimeSformer, improved with hierarchical temporal attention and weighted spatial attention mechanisms, to achieve accurate action recognition within surgical videos. Fine-grained motion features are then extracted using a YOLO-based object detection and tracking method, allowing for detailed analysis of instrument kinematics. Performance is evaluated along five aspects of microanastomosis skill, including overall action execution, motion quality during procedure-critical actions, and general instrument handling. Experimental validation using a dataset of 58 expert-annotated videos demonstrates the effectiveness of the system, achieving 87.7% frame-level accuracy in action segmentation that increased to 93.62% with post-processing, and an average classification accuracy of 76% in replicating expert assessments across all skill aspects. These findings highlight the system’s potential to provide objective, consistent, and interpretable feedback, thereby enabling more standardized, data-driven training and evaluation in surgical education.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-48] DyStream: Streaming Dyadic Talking Heads Generation via Flow Matching-based Autoregressive Model</p>
<p>【速读】：该论文旨在解决生成式对话头像视频（Talking Head Video）时的超低延迟问题，现有基于分块的方法需要完整的非因果上下文窗口，导致显著延迟，无法实现真实交互中所需的即时非语言反馈。解决方案的关键在于提出一种基于流匹配（Flow Matching）的自回归模型 DyStream，其核心设计包括：(1) 采用适合流式处理的自回归框架并引入流匹配头以进行概率建模；(2) 提出一种带有前瞻模块（lookahead module）的因果编码器，在保持低延迟的同时融入短时未来上下文（如60 ms），从而提升视频质量。实验表明，该方法每帧生成时间仅为34 ms，系统总延迟低于100 ms，并在HDTF数据集上实现了领先的唇同步质量（离线和在线LipSync Confidence得分分别为8.13和7.61）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24408">https://arxiv.org/abs/2512.24408</a><br>
<strong>作者</strong>: Bohong Chen,Haiyang Liu<br>
<strong>机构</strong>: Zhejiang University (浙江大学); The University of Tokyo (东京大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project Page: <a target="_blank" rel="noopener" href="https://robinwitch.github.io/DyStream-Page">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Generating realistic, dyadic talking head video requires ultra-low latency. Existing chunk-based methods require full non-causal context windows, introducing significant delays. This high latency critically prevents the immediate, non-verbal feedback required for a realistic listener. To address this, we present DyStream, a flow matching-based autoregressive model that could generate video in real-time from both speaker and listener audio. Our method contains two key designs: (1) we adopt a stream-friendly autoregressive framework with flow-matching heads for probabilistic modeling, and (2) We propose a causal encoder enhanced by a lookahead module to incorporate short future context (e.g., 60 ms) to improve quality while maintaining low latency. Our analysis shows this simple-and-effective method significantly surpass alternative causal strategies, including distillation and generative encoder. Extensive experiments show that DyStream could generate video within 34 ms per frame, guaranteeing the entire system latency remains under 100 ms. Besides, it achieves state-of-the-art lip-sync quality, with offline and online LipSync Confidence scores of 8.13 and 7.61 on HDTF, respectively. The model, weights and codes are available.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-49] Lifting Vision: Ground to Aerial Localization with <mark class="hl-label green">Reasoning</mark>  Guided <mark class="hl-label green">Planning</mark></p>
<p>【速读】：该论文旨在解决当前视觉导航与地理定位任务中依赖文本信息进行推理所导致的空间理解能力不足的问题，尤其在空间推理和跨视角一致性方面存在局限。其解决方案的关键在于提出一种基于视觉推理的范式——Geo-Consistent Visual Planning，并设计了名为ViReLoc（Visual Reasoning for Localization）的框架，该框架完全基于视觉表征进行路径规划与定位，通过强化学习目标优化逐步推理过程，同时引入对比学习和自适应特征交互机制以对齐不同视角下的视觉特征并减少视点差异，从而提升空间推理准确性和跨视角检索性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24404">https://arxiv.org/abs/2512.24404</a><br>
<strong>作者</strong>: Soham Pahari,M. Srinivas<br>
<strong>机构</strong>: UPES (University of Petroleum and Energy Studies); NIT Warangal (National Institute of Technology Warangal)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multimodal intelligence development recently show strong progress in visual understanding and high level reasoning. Though, most reasoning system still reply on textual information as the main medium for inference. This limit their effectiveness in spatial tasks such as visual navigation and geo-localization. This work discuss about the potential scope of this field and eventually propose an idea visual reasoning paradigm Geo-Consistent Visual Planning, our introduced framework called Visual Reasoning for Localization, or ViReLoc, which performs planning and localization using only visual representations. The proposed framework learns spatial dependencies and geometric relations that text based reasoning often suffer to understand. By encoding step by step inference in the visual domain and optimizing with reinforcement based objectives, ViReLoc plans routes between two given ground images. The system also integrates contrastive learning and adaptive feature interaction to align cross view perspectives and reduce viewpoint differences. Experiments across diverse navigation and localization scenarios show consistent improvements in spatial reasoning accuracy and cross view retrieval performance. These results establish visual reasoning as a strong complementary approach for navigation and localization, and show that such tasks can be performed without real time global positioning system data, leading to more secure navigation solutions.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-50] RedunCut: Measurement-Driven Sampling and Accuracy Performance Modeling for Low-Cost Live Video Analytics</p>
<p>【速读】：该论文旨在解决大规模摄像头网络中实时视频分析（Live Video Analytics, LVA）因现代视觉模型推理成本过高而导致的计算资源浪费问题。现有动态模型尺寸选择（Dynamic Model Size Selection, DMSS）方法虽能通过内容感知的方式降低开销，但其在多样化工作负载下表现不佳，尤其在移动视频和低精度目标场景中失效，根源在于采样策略效率低下以及每段视频的精度预测不准确。解决方案的关键在于提出RedunCut系统：一是引入基于测量驱动的规划器，量化采样的成本-收益权衡以优化采样决策；二是构建轻量级、数据驱动的性能模型，提升精度预测准确性。实验表明，RedunCut在多种视频类型与模型架构下可实现14%-62%的计算成本削减，同时保持对历史数据有限性和概念漂移的鲁棒性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24386">https://arxiv.org/abs/2512.24386</a><br>
<strong>作者</strong>: Gur-Eyal Sela,Kumar Krishna Agrawal,Bharathan Balaji,Joseph Gonzalez,Ion Stoica<br>
<strong>机构</strong>: UC Berkeley (加州大学伯克利分校); Amazon (亚马逊)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Distributed, Parallel, and Cluster Computing (cs.DC)<br>
<strong>备注</strong>:  21 pages, 23 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Live video analytics (LVA) runs continuously across massive camera fleets, but inference cost with modern vision models remains high. To address this, dynamic model size selection (DMSS) is an attractive approach: it is content-aware but treats models as black boxes, and could potentially reduce cost by up to 10x without model retraining or modification. Without ground truth labels at runtime, we observe that DMSS methods use two stages per segment: (i) sampling a few models to calculate prediction statistics (e.g., confidences), then (ii) selection of the model size from those statistics. Prior systems fail to generalize to diverse workloads, particularly to mobile videos and lower accuracy targets. We identify that the failure modes stem from inefficient sampling whose cost exceeds its benefit, and inaccurate per-segment accuracy prediction. In this work, we present RedunCut, a new DMSS system that addresses both: It uses a measurement-driven planner that estimates the cost-benefit tradeoff of sampling, and a lightweight, data-driven performance model to improve accuracy prediction. Across road-vehicle, drone, and surveillance videos and multiple model families and tasks, RedunCut reduces compute cost by 14-62% at fixed accuracy and remains robust to limited historical data and to drift.          Comments: 21 pages, 23 figures   Subjects:  Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Distributed, Parallel, and Cluster Computing (cs.DC)  Cite as: arXiv:2512.24386 [<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>]    (or  arXiv:2512.24386v1 [<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24386">https://doi.org/10.48550/arXiv.2512.24386</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-51] Forging Spatial Intelligence: A Roadmap of Multi-Modal Data Pre-Training for Autonomous Systems</p>
<p>【速读】：该论文旨在解决多模态传感器数据（如摄像头与激光雷达）在自主系统（如自动驾驶车辆和无人机）中融合以构建真正空间智能（Spatial Intelligence）的问题。当前基础模型在单模态场景下表现优异，但跨模态整合仍面临挑战。解决方案的关键在于提出一个统一的预训练范式分类体系，涵盖从单模态基线到复杂联合框架，从而学习用于3D目标检测和语义占用预测等高级任务的全局表征；同时探索文本输入与占用表示的融合，以支持开放世界感知与规划，并识别计算效率和模型可扩展性等瓶颈，为通用多模态基础模型的发展提供路线图。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24385">https://arxiv.org/abs/2512.24385</a><br>
<strong>作者</strong>: Song Wang,Lingdong Kong,Xiaolu Liu,Hao Shi,Wentong Li,Jianke Zhu,Steven C. H. Hoi<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
<strong>备注</strong>:  Preprint; 38 pages, 7 figures, 9 tables; GitHub at <a target="_blank" rel="noopener" href="https://github.com/worldbench/awesome-spatial-intelligence">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The rapid advancement of autonomous systems, including self-driving vehicles and drones, has intensified the need to forge true Spatial Intelligence from multi-modal onboard sensor data. While foundation models excel in single-modal contexts, integrating their capabilities across diverse sensors like cameras and LiDAR to create a unified understanding remains a formidable challenge. This paper presents a comprehensive framework for multi-modal pre-training, identifying the core set of techniques driving progress toward this goal. We dissect the interplay between foundational sensor characteristics and learning strategies, evaluating the role of platform-specific datasets in enabling these advancements. Our central contribution is the formulation of a unified taxonomy for pre-training paradigms: ranging from single-modality baselines to sophisticated unified frameworks that learn holistic representations for advanced tasks like 3D object detection and semantic occupancy prediction. Furthermore, we investigate the integration of textual inputs and occupancy representations to facilitate open-world perception and planning. Finally, we identify critical bottlenecks, such as computational efficiency and model scalability, and propose a roadmap toward general-purpose multi-modal foundation models capable of achieving robust Spatial Intelligence for real-world deployment.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-52] Geometric Multi-Session Map Merging with Learned Local Descriptors</p>
<p>【速读】：该论文旨在解决大规模环境下多时段点云地图合并（multi-session map merging）中的关键挑战，即如何在不同采集会话中准确对齐具有重叠区域的地图，从而实现长时间、大范围自主作业的全局一致性。其解决方案的核心在于提出了一种基于学习的局部描述符框架GMLD，该框架通过关键点感知编码器（keypoint-aware encoder）和平面几何变换器（plane-based geometric transformer）联合提取具有判别性的特征，用于回环检测（loop closure detection）与相对位姿估计（relative pose estimation）。此外，在因子图优化阶段引入跨会话扫描匹配代价因子，进一步提升整体地图的全局一致性，实验表明该方法在多个公开及自采数据集上均表现出低误差、高鲁棒性的地图融合性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24384">https://arxiv.org/abs/2512.24384</a><br>
<strong>作者</strong>: Yanlong Ma,Nakul S. Joshi,Christa S. Robison,Philip R. Osteen,Brett T. Lopez<br>
<strong>机构</strong>: University of California, Los Angeles (加州大学洛杉矶分校); DEVCOM Army Research Laboratory (陆军研究实验室)<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multi-session map merging is crucial for extended autonomous operations in large-scale environments. In this paper, we present GMLD, a learning-based local descriptor framework for large-scale multi-session point cloud map merging that systematically aligns maps collected across different sessions with overlapping regions. The proposed framework employs a keypoint-aware encoder and a plane-based geometric transformer to extract discriminative features for loop closure detection and relative pose estimation. To further improve global consistency, we include inter-session scan matching cost factors in the factor-graph optimization stage. We evaluate our framework on the public datasets, as well as self-collected data from diverse environments. The results show accurate and robust map merging with low error, and the learned features deliver strong performance in both loop closure detection and relative pose estimation.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-53] he Mechanics of CNN Filtering with Rectification</p>
<p>【速读】：该论文旨在解决卷积神经网络（Convolutional Neural Networks, CNNs）中卷积滤波器的机械性质理解问题，特别是如何从物理能量-动量关系的角度解释其信息传播机制。解决方案的关键在于提出“基础信息力学”（elementary information mechanics）模型，将卷积核分解为正交的偶函数分量和奇函数分量：偶分量对应于各向同性扩散且保持质心不变，类比于静止或势能；奇分量则导致质心定向位移，类比于动能。通过离散余弦变换（Discrete Cosine Transform, DCT）在频域分析表明，小尺寸卷积核（如3×3像素）的信息传播主要由低频基底（DC项与梯度项∇）主导，从而揭示了通用CNN中的信息处理过程与相对论物理中能量-动量关系之间的首次明确联系。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24338">https://arxiv.org/abs/2512.24338</a><br>
<strong>作者</strong>: Liam Frija-Altrac,Matthew Toews<br>
<strong>机构</strong>: École de Technologie Supérieure (École de Technologie Supérieure)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper proposes elementary information mechanics as a new model for understanding the mechanical properties of convolutional filtering with rectification, inspired by physical theories of special relativity and quantum mechanics. We consider kernels decomposed into orthogonal even and odd components. Even components cause image content to diffuse isotropically while preserving the center of mass, analogously to rest or potential energy with zero net momentum. Odd kernels cause directional displacement of the center of mass, analogously to kinetic energy with non-zero momentum. The speed of information displacement is linearly related to the ratio of odd vs total kernel energy. Even-Odd properties are analyzed in the spectral domain via the discrete cosine transform (DCT), where the structure of small convolutional filters (e.g.  3 \times 3  pixels) is dominated by low-frequency bases, specifically the DC  \Sigma  and gradient components  \nabla , which define the fundamental modes of information propagation. To our knowledge, this is the first work demonstrating the link between information processing in generic CNNs and the energy-momentum relation, a cornerstone of modern relativistic physics.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-54] Spatial-aware Vision Language Model for Autonomous Driving</p>
<p>【速读】：该论文旨在解决当前视觉-语言模型（Vision-Language Models, VLMs）在端到端自动驾驶中因依赖二维图像线索进行复杂场景理解与决策而导致的可靠性与安全性瓶颈问题，特别是其在度量空间推理和几何推断方面的不足。解决方案的关键在于提出LVLDrive框架，通过引入LiDAR点云作为额外模态来增强VLM的三维度量空间理解能力；其中，核心创新是设计了一种渐进式融合Q-Former（Gradual Fusion Q-Former），以逐步注入LiDAR特征，从而有效缓解异构3D数据对预训练VLM造成的灾难性干扰，保障模型原有知识体系的稳定性与完整性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24331">https://arxiv.org/abs/2512.24331</a><br>
<strong>作者</strong>: Weijie Wei,Zhipeng Luo,Ling Feng,Venice Erin Liong<br>
<strong>机构</strong>: Motional; University of Amsterdam (阿姆斯特丹大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:While Vision-Language Models (VLMs) show significant promise for end-to-end autonomous driving by leveraging the common sense embedded in language models, their reliance on 2D image cues for complex scene understanding and decision-making presents a critical bottleneck for safety and reliability. Current image-based methods struggle with accurate metric spatial reasoning and geometric inference, leading to unreliable driving policies. To bridge this gap, we propose LVLDrive (LiDAR-Vision-Language), a novel framework specifically designed to upgrade existing VLMs with robust 3D metric spatial understanding for autonomous driving by incoperating LiDAR point cloud as an extra input modality. A key challenge lies in mitigating the catastrophic disturbance introduced by disparate 3D data to the pre-trained VLMs. To this end, we introduce a Gradual Fusion Q-Former that incrementally injects LiDAR features, ensuring the stability and preservation of the VLM’s existing knowledge base. Furthermore, we develop a spatial-aware question-answering (SA-QA) dataset to explicitly teach the model advanced 3D perception and reasoning capabilities. Extensive experiments on driving benchmarks demonstrate that LVLDrive achieves superior performance compared to vision-only counterparts across scene understanding, metric spatial perception, and reliable driving decision-making. Our work highlights the necessity of explicit 3D metric data for building trustworthy VLM-based autonomous systems.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-55] SenseNova-MARS: Empowering Multimodal <mark class="hl-label green">Agent</mark> ic <mark class="hl-label green">Reasoning</mark>  and Search via Reinforcement Learning</p>
<p>【速读】：该论文旨在解决视觉语言模型（Vision-Language Models, VLMs）在复杂视觉任务中缺乏动态工具调用与连续推理能力的问题，尤其在知识密集型和视觉复杂的场景下，现有方法难以实现视觉推理与外部工具（如图像搜索、文本搜索、图像裁剪）的无缝交织。其解决方案的关键在于提出SenseNova-MARS框架，该框架通过强化学习（Reinforcement Learning, RL）实现多模态代理式推理与搜索的协同优化，核心创新包括：1）引入Batch-Normalized Group Sequence Policy Optimization（BN-GSPO）算法以提升训练稳定性并增强工具调用与推理效率；2）构建首个面向高分辨率图像的搜索驱动型基准HR-MMSearch，用于系统评估VLMs在精细视觉理解任务中的表现。实验证明，SenseNova-MARS-8B在多个开源基准上达到领先性能，显著优于部分闭源模型。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24330">https://arxiv.org/abs/2512.24330</a><br>
<strong>作者</strong>: Yong Xien Chng,Tao Hu,Wenwen Tong,Xueheng Li,Jiandong Chen,Haojia Yu,Jiefan Lu,Hewei Guo,Hanming Deng,Chengjun Xie,Gao Huang,Dahua Lin,Lewei Lu<br>
<strong>机构</strong>: SenseTime Research (商汤科技); Tsinghua University (清华大学); University of Science and Technology of China (中国科学技术大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:While Vision-Language Models (VLMs) can solve complex tasks through agentic reasoning, their capabilities remain largely constrained to text-oriented chain-of-thought or isolated tool invocation. They fail to exhibit the human-like proficiency required to seamlessly interleave dynamic tool manipulation with continuous reasoning, particularly in knowledge-intensive and visually complex scenarios that demand coordinated external tools such as search and image cropping. In this work, we introduce SenseNova-MARS, a novel Multimodal Agentic Reasoning and Search framework that empowers VLMs with interleaved visual reasoning and tool-use capabilities via reinforcement learning (RL). Specifically, SenseNova-MARS dynamically integrates the image search, text search, and image crop tools to tackle fine-grained and knowledge-intensive visual understanding challenges. In the RL stage, we propose the Batch-Normalized Group Sequence Policy Optimization (BN-GSPO) algorithm to improve the training stability and advance the model’s ability to invoke tools and reason effectively. To comprehensively evaluate the agentic VLMs on complex visual tasks, we introduce the HR-MMSearch benchmark, the first search-oriented benchmark composed of high-resolution images with knowledge-intensive and search-driven questions. Experiments demonstrate that SenseNova-MARS achieves state-of-the-art performance on open-source search and fine-grained image understanding benchmarks. Specifically, on search-oriented benchmarks, SenseNova-MARS-8B scores 67.84 on MMSearch and 41.64 on HR-MMSearch, surpassing proprietary models such as Gemini-3-Flash and GPT-5. SenseNova-MARS represents a promising step toward agentic VLMs by providing effective and robust tool-use capabilities. To facilitate further research in this field, we will release all code, models, and datasets.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-56] Robust Egocentric Referring Video Object Segmentation via Dual-Modal Causal Intervention <mark class="hl-label red">NEURIPS2025</mark></p>
<p>【速读】：该论文旨在解决第一人称视角视频中指代表达对象分割（Ego-RVOS）任务的鲁棒性问题，其核心挑战源于egocentric视频固有的模糊性以及训练数据中存在的偏差，导致现有方法容易学习到虚假相关性，如数据集中物体与动作配对的偏倚，以及第一人称视角下快速运动和频繁遮挡等视觉混淆因素。解决方案的关键在于提出一种可插拔的因果框架CERES，通过双模态因果干预机制实现：一方面采用后门调整（backdoor adjustment）原则消除语言表征偏差；另一方面利用前门调整（front-door adjustment）概念，结合语义视觉特征与几何深度信息，在因果原理指导下构建更抗第一人称视角失真的表示，从而显著提升模型性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24323">https://arxiv.org/abs/2512.24323</a><br>
<strong>作者</strong>: Haijing Liu,Zhiyuan Song,Hefeng Wu,Tao Pu,Keze Wang,Liang Lin<br>
<strong>机构</strong>: Sun Yat-sen University (中山大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  NeurIPS 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Egocentric Referring Video Object Segmentation (Ego-RVOS) aims to segment the specific object actively involved in a human action, as described by a language query, within first-person videos. This task is critical for understanding egocentric human behavior. However, achieving such segmentation robustly is challenging due to ambiguities inherent in egocentric videos and biases present in training data. Consequently, existing methods often struggle, learning spurious correlations from skewed object-action pairings in datasets and fundamental visual confounding factors of the egocentric perspective, such as rapid motion and frequent occlusions. To address these limitations, we introduce Causal Ego-REferring Segmentation (CERES), a plug-in causal framework that adapts strong, pre-trained RVOS backbones to the egocentric domain. CERES implements dual-modal causal intervention: applying backdoor adjustment principles to counteract language representation biases learned from dataset statistics, and leveraging front-door adjustment concepts to address visual confounding by intelligently integrating semantic visual features with geometric depth information guided by causal principles, creating representations more robust to egocentric distortions. Extensive experiments demonstrate that CERES achieves state-of-the-art performance on Ego-RVOS benchmarks, highlighting the potential of applying causal reasoning to build more reliable models for broader egocentric video understanding.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-57] UniAct: Unified Motion Generation and Action Streaming for Humanoid Robots</p>
<p>【速读】：该论文旨在解决人形机器人在执行多样化多模态指令（如语言、音乐和轨迹）时，难以实现高阶感知与全身动作实时协同的问题。现有方法往往无法有效将异构输入转化为稳定、低延迟的控制行为，导致泛化能力受限。解决方案的关键在于提出UniAct框架，其通过两阶段设计实现：首先利用微调后的多模态大语言模型（Multimodal Large Language Model, MLLM）对多模态指令进行语义理解；其次采用因果流式处理管道（causal streaming pipeline），结合矢量量化（Vector Quantization, VQ）构建共享离散码本（FSQ），统一不同模态输入并约束运动空间至物理合理流形（physically grounded manifold），从而实现亚500毫秒延迟下的高效动作生成。此方法显著提升了零样本跟踪不完美参考动作的成功率（提升19%），并在20小时的人形动作基准数据集UniMoCap上验证了跨场景鲁棒性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24321">https://arxiv.org/abs/2512.24321</a><br>
<strong>作者</strong>: Nan Jiang,Zimo He,Wanhe Yu,Lexi Pang,Yunhao Li,Hongjie Li,Jieming Cui,Yuhan Li,Yizhou Wang,Yixin Zhu,Siyuan Huang<br>
<strong>机构</strong>: Peking University (北京大学); Beijing Institute for General Artificial Intelligence (BIGAI) (北京通用人工智能研究院); School of Psychological and Cognitive Sciences, Peking University (北京大学心理与认知科学学院); School of Computer Science, Peking University (北京大学计算机学院); Yuanpei College, Peking University (北京大学元培学院); School of Foreign Languages, Peking University (北京大学外国语学院); School of EECS, Peking University (北京大学电子工程与计算机科学学院); Huazhong University of Science and Technology (华中科技大学); State Key Lab of General AI (通用人工智能国家重点实验室); Nat’l Eng. Research Center of Visual Technology (国家视觉技术工程研究中心); Beijing Key Laboratory of Behavior and Mental Health, Peking University (北京大学行为与心理健康北京市重点实验室); Embodied Intelligence Lab, PKU-Wuhan Institute for Artificial Intelligence (北京大学-武汉人工智能 embodied intelligence 实验室)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://jnnan.github.io/uniact/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:A long-standing objective in humanoid robotics is the realization of versatile agents capable of following diverse multimodal instructions with human-level flexibility. Despite advances in humanoid control, bridging high-level multimodal perception with whole-body execution remains a significant bottleneck. Existing methods often struggle to translate heterogeneous instructions – such as language, music, and trajectories – into stable, real-time actions. Here we show that UniAct, a two-stage framework integrating a fine-tuned MLLM with a causal streaming pipeline, enables humanoid robots to execute multimodal instructions with sub-500 ms latency. By unifying inputs through a shared discrete codebook via FSQ, UniAct ensures cross-modal alignment while constraining motions to a physically grounded manifold. This approach yields a 19% improvement in the success rate of zero-shot tracking of imperfect reference motions. We validate UniAct on UniMoCap, our 20-hour humanoid motion benchmark, demonstrating robust generalization across diverse real-world scenarios. Our results mark a critical step toward responsive, general-purpose humanoid assistants capable of seamless interaction through unified perception and control.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-58] Virtual-Eyes: Quantitative Validation of a Lung CT Quality-Control Pipeline for Foundation-Model Cancer Risk Prediction</p>
<p>【速读】：该论文旨在解决低剂量计算机断层扫描（Low-Dose CT, LDCT）肺部癌症筛查中深度学习流程缺乏量化鲁棒性预处理的问题。解决方案的关键在于提出并验证了Virtual-Eyes，一个临床驱动的16位CT质量控制流水线，其核心包括强制512×512像素分辨率、剔除短序列或非诊断性序列，并通过Hounsfield单位滤波和双侧肺覆盖评分提取连续肺部区域，同时保留原始16位数据网格。该方法显著提升了通用型基础模型（如RAD-DINO和Merlin）在切片级与患者级任务中的性能与校准度，而对专用模型（如Sybil和ResNet-18）则可能因上下文依赖性和捷径学习导致性能下降，表明解剖目标导向的质量控制可稳定并增强通用模型工作流，但可能破坏针对原始临床环境训练的专用模型。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24294">https://arxiv.org/abs/2512.24294</a><br>
<strong>作者</strong>: Md. Enamul Hoq,Linda Larson-Prior,Fred Prior<br>
<strong>机构</strong>: University of Arkansas for Medical Sciences (阿肯色大学医学科学学院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  23 pages, and Under Review-MIDL-2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Robust preprocessing is rarely quantified in deep-learning pipelines for low-dose CT (LDCT) lung cancer screening. We develop and validate Virtual-Eyes, a clinically motivated 16-bit CT quality-control pipeline, and measure its differential impact on generalist foundation models versus specialist models. Virtual-Eyes enforces strict 512x512 in-plane resolution, rejects short or non-diagnostic series, and extracts a contiguous lung block using Hounsfield-unit filtering and bilateral lung-coverage scoring while preserving the native 16-bit grid. Using 765 NLST patients (182 cancer, 583 non-cancer), we compute slice-level embeddings from RAD-DINO and Merlin with frozen encoders and train leakage-free patient-level MLP heads; we also evaluate Sybil and a 2D ResNet-18 baseline under Raw versus Virtual-Eyes inputs without backbone retraining. Virtual-Eyes improves RAD-DINO slice-level AUC from 0.576 to 0.610 and patient-level AUC from 0.646 to 0.683 (mean pooling) and from 0.619 to 0.735 (max pooling), with improved calibration (Brier score 0.188 to 0.112). In contrast, Sybil and ResNet-18 degrade under Virtual-Eyes (Sybil AUC 0.886 to 0.837; ResNet-18 AUC 0.571 to 0.596) with evidence of context dependence and shortcut learning, and Merlin shows limited transferability (AUC approximately 0.507 to 0.567) regardless of preprocessing. These results demonstrate that anatomically targeted QC can stabilize and improve generalist foundation-model workflows but may disrupt specialist models adapted to raw clinical context.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-59] One-shot synthesis of rare gastrointestinal lesions improves diagnostic accuracy and clinical training</p>
<p>【速读】：该论文旨在解决罕见胃肠道病变在常规内镜检查中出现频率低的问题，这一现象限制了人工智能（AI）模型的可靠训练以及新手临床医生的教育。其解决方案的关键在于提出了一种名为EndoRare的一次性、无需重新训练的生成式框架，该框架能够从单一参考图像中合成多样且高保真的病变实例；通过语言引导的概念解耦机制，将诊断性病变特征与非诊断属性分离，将前者编码为可学习的原型嵌入（prototype embedding），同时变化后者以保证多样性，从而实现高效的数据增强和临床实用性提升。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24278">https://arxiv.org/abs/2512.24278</a><br>
<strong>作者</strong>: Jia Yu,Yan Zhu,Peiyao Fu,Tianyi Chen,Zhihua Wang,Fei Wu,Quanlin Li,Pinghong Zhou,Shuo Wang,Xian Yang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Rare gastrointestinal lesions are infrequently encountered in routine endoscopy, restricting the data available for developing reliable artificial intelligence (AI) models and training novice clinicians. Here we present EndoRare, a one-shot, retraining-free generative framework that synthesizes diverse, high-fidelity lesion exemplars from a single reference image. By leveraging language-guided concept disentanglement, EndoRare separates pathognomonic lesion features from non-diagnostic attributes, encoding the former into a learnable prototype embedding while varying the latter to ensure diversity. We validated the framework across four rare pathologies (calcifying fibrous tumor, juvenile polyposis syndrome, familial adenomatous polyposis, and Peutz-Jeghers syndrome). Synthetic images were judged clinically plausible by experts and, when used for data augmentation, significantly enhanced downstream AI classifiers, improving the true positive rate at low false-positive rates. Crucially, a blinded reader study demonstrated that novice endoscopists exposed to EndoRare-generated cases achieved a 0.400 increase in recall and a 0.267 increase in precision. These results establish a practical, data-efficient pathway to bridge the rare-disease gap in both computer-aided diagnostics and clinical education.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-60] LiftProj: Space Lifting and Projection-Based Panorama Stitching</p>
<p>【速读】：该论文旨在解决传统图像拼接技术在处理具有显著视差和复杂遮挡的三维场景时出现的几何失真、鬼影效应及结构弯曲等问题，尤其是在多视角累积和360°闭环拼接场景中表现不佳。其解决方案的关键在于提出一种空间提升的全景拼接框架（spatially lifted panoramic stitching framework），首先将每张输入图像提升为统一坐标系下的密集三维点云表示，并通过置信度加权实现跨视角全局融合；随后在三维空间中建立统一投影中心并采用等距圆柱投影映射至单个全景流形，从而生成几何一致的360°全景布局；最后在画布域内进行孔洞填充以恢复由视角切换引发的未知区域纹理与语义连续性。该方法实现了从二维变形（warping）到三维一致性（3D consistency）的范式转变，具备良好的模块扩展性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24276">https://arxiv.org/abs/2512.24276</a><br>
<strong>作者</strong>: Yuan Jia,Ruimin Wu,Rui Song,Jiaojiao Li,Bin Song<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Multimedia (<a target="_blank" rel="noopener" href="http://cs.MM">cs.MM</a>)<br>
<strong>备注</strong>:  16 pages, 10 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Traditional image stitching techniques have predominantly utilized two-dimensional homography transformations and mesh warping to achieve alignment on a planar surface. While effective for scenes that are approximately coplanar or exhibit minimal parallax, these approaches often result in ghosting, structural bending, and stretching distortions in non-overlapping regions when applied to real three-dimensional scenes characterized by multiple depth layers and occlusions. Such challenges are exacerbated in multi-view accumulations and 360° closed-loop stitching scenarios. In response, this study introduces a spatially lifted panoramic stitching framework that initially elevates each input image into a dense three-dimensional point representation within a unified coordinate system, facilitating global cross-view fusion augmented by confidence metrics. Subsequently, a unified projection center is established in three-dimensional space, and an equidistant cylindrical projection is employed to map the fused data onto a single panoramic manifold, thereby producing a geometrically consistent 360° panoramic layout. Finally, hole filling is conducted within the canvas domain to address unknown regions revealed by viewpoint transitions, restoring continuous texture and semantic coherence. This framework reconceptualizes stitching from a two-dimensional warping paradigm to a three-dimensional consistency paradigm and is designed to flexibly incorporate various three-dimensional lifting and completion modules. Experimental evaluations demonstrate that the proposed method substantially mitigates geometric distortions and ghosting artifacts in scenarios involving significant parallax and complex occlusions, yielding panoramic results that are more natural and consistent.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-61] aming Hallucinations: Boosting M<mark class="hl-label green">LLM</mark> s Video Understanding via Counterfactual Video Generation</p>
<p>【速读】：该论文旨在解决多模态大语言模型（Multimodal Large Language Models, MLLMs）在视频理解任务中因过度依赖语言先验而导致的视觉未接地幻觉（visual ungrounded hallucinations）问题，尤其是在处理违背常识的反事实视频时更为显著。这一局限性源于文本与视频数据之间的内在不平衡，且由于收集和标注反事实数据成本高昂，传统方法难以有效缓解。解决方案的关键在于提出DualityForge框架，该框架利用可控扩散视频编辑技术将真实视频转化为反事实场景，并通过嵌入结构化上下文信息于视频编辑与问答生成过程中，自动构建高质量的视频-问答对用于对比训练；同时设计了Duality-Normalized Advantage Training（DNA-Train）策略，采用两阶段SFT-强化学习（RL）训练机制，在RL阶段引入成对ℓ₁优势归一化，从而实现更稳定高效的策略优化。实验表明，该方法在DualityVidQA测试集上相较Qwen2.5-VL-7B基线模型减少幻觉达24.0%，并在多个基准测试中均取得显著提升，验证了其泛化能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24271">https://arxiv.org/abs/2512.24271</a><br>
<strong>作者</strong>: Zhe Huang,Hao Wen,Aiming Hao,Bingze Song,Meiqi Wu,Jiahong Wu,Xiangxiang Chu,Sheng Lu,Haoqian Wang<br>
<strong>机构</strong>: Tsinghua University (清华大学); Beihang University (北京航空航天大学); AMAP, Alibaba Group (高德地图，阿里巴巴集团)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  18 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multimodal Large Language Models (MLLMs) have made remarkable progress in video understanding. However, they suffer from a critical vulnerability: an over-reliance on language priors, which can lead to visual ungrounded hallucinations, especially when processing counterfactual videos that defy common sense. This limitation, stemming from the intrinsic data imbalance between text and video, is challenging to address due to the substantial cost of collecting and annotating counterfactual data. To address this, we introduce DualityForge, a novel counterfactual data synthesis framework that employs controllable, diffusion-based video editing to transform real-world videos into counterfactual scenarios. By embedding structured contextual information into the video editing and QA generation processes, the framework automatically produces high-quality QA pairs together with original-edited video pairs for contrastive training. Based on this, we build DualityVidQA, a large-scale video dataset designed to reduce MLLM hallucinations. In addition, to fully exploit the contrastive nature of our paired data, we propose Duality-Normalized Advantage Training (DNA-Train), a two-stage SFT-RL training regime where the RL phase applies pair-wise  \ell_1  advantage normalization, thereby enabling a more stable and efficient policy optimization. Experiments on DualityVidQA-Test demonstrate that our method substantially reduces model hallucinations on counterfactual videos, yielding a relative improvement of 24.0% over the Qwen2.5-VL-7B baseline. Moreover, our approach achieves significant gains across both hallucination and general-purpose benchmarks, indicating strong generalization capability. We will open-source our dataset and code.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-62] Physically-Grounded Manifold Projection with Foundation Priors for Metal Artifact Reduction in Dental CBCT</p>
<p>【速读】：该论文旨在解决牙科锥形束计算机断层扫描（Dental CBCT）中金属伪影严重遮挡解剖结构、影响诊断准确性的问题。现有基于深度学习的金属伪影去除（MAR）方法存在局限：监督方法因“回归均值”效应导致光谱模糊，无监督方法则可能引发结构幻觉；而扩散模型虽能提升图像真实性，但依赖缓慢的随机迭代采样，难以满足临床时效性需求。解决方案的关键在于提出物理引导的流形投影（Physically-Grounded Manifold Projection, PGMP）框架：首先通过解剖自适应物理仿真（Anatomically-Adaptive Physics Simulation, AAPS）生成高保真训练对，弥合合成数据与真实场景之间的差距；其次设计DMP-Former模型，将恢复任务重构为确定性流形投影，实现单次前向传播即可完成去伪影，避免随机采样；最后引入语义结构对齐（Semantic-Structural Alignment, SSA）模块，利用医学基础模型（MedDINOv3）先验约束输出的临床合理性。该方案在合成及多中心临床数据上均显著优于现有方法，在效率和诊断可靠性方面树立新基准。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24260">https://arxiv.org/abs/2512.24260</a><br>
<strong>作者</strong>: Zhi Li,Yaqi Wang,Bingtao Ma,Yifan Zhang,Huiyu Zhou,Shuai Wang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  This manuscript has been submitted to Medical Image Analysis for peer review</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Metal artifacts in Dental CBCT severely obscure anatomical structures, hindering diagnosis. Current deep learning for Metal Artifact Reduction (MAR) faces limitations: supervised methods suffer from spectral blurring due to “regression-to-the-mean”, while unsupervised ones risk structural hallucinations. Denoising Diffusion Models (DDPMs) offer realism but rely on slow, stochastic iterative sampling, unsuitable for clinical use. To resolve this, we propose the Physically-Grounded Manifold Projection (PGMP) framework. First, our Anatomically-Adaptive Physics Simulation (AAPS) pipeline synthesizes high-fidelity training pairs via Monte Carlo spectral modeling and patient-specific digital twins, bridging the synthetic-to-real gap. Second, our DMP-Former adapts the Direct x-Prediction paradigm, reformulating restoration as a deterministic manifold projection to recover clean anatomy in a single forward pass, eliminating stochastic sampling. Finally, a Semantic-Structural Alignment (SSA) module anchors the solution using priors from medical foundation models (MedDINOv3), ensuring clinical plausibility. Experiments on synthetic and multi-center clinical datasets show PGMP outperforms state-of-the-art methods on unseen anatomy, setting new benchmarks in efficiency and diagnostic reliability. Code and data: this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-63] MambaSeg: Harnessing Mamba for Accurate and Efficient Image-Event Semantic Segmentation <mark class="hl-label red">AAAI2026</mark></p>
<p>【速读】：该论文旨在解决现有RGB与事件（event）数据融合方法在语义分割任务中存在计算复杂度高、忽视事件流时间动态特性的问题。针对这些问题，作者提出MambaSeg框架，其关键创新在于采用并行的Mamba编码器分别高效建模RGB图像和事件流，并引入双维度交互模块（Dual-Dimensional Interaction Module, DDIM），包含跨空间交互模块（Cross-Spatial Interaction Module, CSIM）和跨时间交互模块（Cross-Temporal Interaction Module, CTIM），实现多模态数据在空间与时间维度上的细粒度融合，从而提升跨模态对齐精度、降低歧义性，并充分利用RGB与事件数据的互补优势。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24243">https://arxiv.org/abs/2512.24243</a><br>
<strong>作者</strong>: Fuqiang Gu,Yuanke Li,Xianlei Long,Kangping Ji,Chao Chen,Qingyi Gu,Zhenliang Ni<br>
<strong>机构</strong>: 1. University of Science and Technology of China (中国科学技术大学); 2. Huawei Cloud (华为云); 3. Alibaba Group (阿里巴巴集团)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Accepted by AAAI 2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Semantic segmentation is a fundamental task in computer vision with wide-ranging applications, including autonomous driving and robotics. While RGB-based methods have achieved strong performance with CNNs and Transformers, their effectiveness degrades under fast motion, low-light, or high dynamic range conditions due to limitations of frame cameras. Event cameras offer complementary advantages such as high temporal resolution and low latency, yet lack color and texture, making them insufficient on their own. To address this, recent research has explored multimodal fusion of RGB and event data; however, many existing approaches are computationally expensive and focus primarily on spatial fusion, neglecting the temporal dynamics inherent in event streams. In this work, we propose MambaSeg, a novel dual-branch semantic segmentation framework that employs parallel Mamba encoders to efficiently model RGB images and event streams. To reduce cross-modal ambiguity, we introduce the Dual-Dimensional Interaction Module (DDIM), comprising a Cross-Spatial Interaction Module (CSIM) and a Cross-Temporal Interaction Module (CTIM), which jointly perform fine-grained fusion along both spatial and temporal dimensions. This design improves cross-modal alignment, reduces ambiguity, and leverages the complementary properties of each modality. Extensive experiments on the DDD17 and DSEC datasets demonstrate that MambaSeg achieves state-of-the-art segmentation performance while significantly reducing computational cost, showcasing its promise for efficient, scalable, and robust multimodal perception.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-64] MotivNet: Evolving Meta-Sapiens into an Emotionally Intelligent Foundation Model</p>
<p>【速读】：该论文旨在解决当前面部情绪识别（Facial Emotion Recognition, FER）模型在真实场景中泛化能力弱的问题，即在多样数据集上测试时性能显著下降，限制了FER在实际应用中的可靠性。解决方案的关键在于提出MotivNet，一个基于Meta-Sapiens（一种通过大规模掩码自编码器预训练获得的通用人类视觉基础模型）构建的可泛化FER模型。MotivNet无需跨域训练即可在多个数据集上实现竞争性表现，其有效性通过基准性能、模型相似性和数据相似性三个标准验证，从而证明FER可以作为Sapiens的有效下游任务，推动其在真实环境中的应用。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24231">https://arxiv.org/abs/2512.24231</a><br>
<strong>作者</strong>: Rahul Medicharla,Alper Yilmaz<br>
<strong>机构</strong>: The Ohio State University (俄亥俄州立大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  6 pages, 4 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In this paper, we introduce MotivNet, a generalizable facial emotion recognition model for robust real-world application. Current state-of-the-art FER models tend to have weak generalization when tested on diverse data, leading to deteriorated performance in the real world and hindering FER as a research domain. Though researchers have proposed complex architectures to address this generalization issue, they require training cross-domain to obtain generalizable results, which is inherently contradictory for real-world application. Our model, MotivNet, achieves competitive performance across datasets without cross-domain training by using Meta-Sapiens as a backbone. Sapiens is a human vision foundational model with state-of-the-art generalization in the real world through large-scale pretraining of a Masked Autoencoder. We propose MotivNet as an additional downstream task for Sapiens and define three criteria to evaluate MotivNet’s viability as a Sapiens task: benchmark performance, model similarity, and data similarity. Throughout this paper, we describe the components of MotivNet, our training approach, and our results showing MotivNet is generalizable across domains. We demonstrate that MotivNet can be benchmarked against existing SOTA models and meets the listed criteria, validating MotivNet as a Sapiens downstream task, and making FER more incentivizing for in-the-wild application. The code is available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-65] Mi<mark class="hl-label green">rag</mark> e: One-Step Video Diffusion for Photorealistic and Coherent Asset Editing in Driving Scenes</p>
<p>【速读】：该论文旨在解决视觉主导的自动驾驶系统在数据增强中面临的挑战，即如何在保持高视觉保真度（visual fidelity）和时间一致性（temporal coherence）的前提下实现高质量的视频对象编辑。现有方法往往难以兼顾这两者，导致生成结果出现模糊或帧间不一致的问题。解决方案的关键在于提出一种单步视频扩散模型 Mirage，其核心创新包括：首先，利用文本到视频的扩散先验确保跨帧的时间一致性；其次，通过将预训练2D编码器提取的时序无关潜在变量注入3D解码器，恢复空间细节并维持因果结构；最后，引入两阶段数据对齐策略（粗粒度3D对齐与细粒度2D优化），缓解因不同优化目标导致的对象高斯分布偏移问题，从而提升姿态对齐精度并提供更清晰的监督信号。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24227">https://arxiv.org/abs/2512.24227</a><br>
<strong>作者</strong>: Shuyun Wang,Haiyang Sun,Bing Wang,Hangjun Ye,Xin Yu<br>
<strong>机构</strong>: The University of Queensland (昆士兰大学); Xiaomi EV (小米电动汽车)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Vision-centric autonomous driving systems rely on diverse and scalable training data to achieve robust performance. While video object editing offers a promising path for data augmentation, existing methods often struggle to maintain both high visual fidelity and temporal coherence. In this work, we propose \textbfMirage, a one-step video diffusion model for photorealistic and coherent asset editing in driving scenes. Mirage builds upon a text-to-video diffusion prior to ensure temporal consistency across frames. However, 3D causal variational autoencoders often suffer from degraded spatial fidelity due to compression, and directly passing 3D encoder features to decoder layers breaks temporal causality. To address this, we inject temporally agnostic latents from a pretrained 2D encoder into the 3D decoder to restore detail while preserving causal structures. Furthermore, because scene objects and inserted assets are optimized under different objectives, their Gaussians exhibit a distribution mismatch that leads to pose misalignment. To mitigate this, we introduce a two-stage data alignment strategy combining coarse 3D alignment and fine 2D refinement, thereby improving alignment and providing cleaner supervision. Extensive experiments demonstrate that Mirage achieves high realism and temporal consistency across diverse editing scenarios. Beyond asset editing, Mirage can also generalize to other video-to-video translation tasks, serving as a reliable baseline for future research. Our code is available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-66] ARM: A Learnable Plug-and-Play Module for CLIP-based Open-vocabulary Semantic Segmentation</p>
<p>【速读】：该论文旨在解决开放词汇语义分割（Open-vocabulary Semantic Segmentation, OVSS）中因CLIP模型缺乏像素级细节而导致的性能瓶颈问题。现有无需训练的方法要么依赖昂贵的外部基础模型（如SAM、DINO）引入先验信息，要么采用静态手工启发式策略处理CLIP内部特征，存在计算成本高或效果不佳的缺陷。其解决方案的关键在于提出一种轻量且可学习的注意力增强模块（Attention Refinement Module, ARM），该模块通过语义引导的交叉注意力机制，自适应融合层次化特征：利用深层特征（K, V）选择并优化浅层特征（Q），再经由自注意力机制进一步精炼，实现对CLIP内部潜力的有效挖掘与提升。ARM采用“训练一次、随处使用”的范式，在通用数据集（如COCO-Stuff）上训练后即可作为即插即用的后处理模块，显著提升多种无需训练框架的性能，同时保持极低的推理开销。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24224">https://arxiv.org/abs/2512.24224</a><br>
<strong>作者</strong>: Ziquan Liu,Zhewei Zhu,Xuyang Shi<br>
<strong>机构</strong>: Southwest University of Science and Technology (西南科技大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  10 pages, 4 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Open-vocabulary semantic segmentation (OVSS) is fundamentally hampered by the coarse, image-level representations of CLIP, which lack precise pixel-level details. Existing training-free methods attempt to resolve this by either importing priors from costly external foundation models (e.g., SAM, DINO) or by applying static, hand-crafted heuristics to CLIP’s internal features. These approaches are either computationally expensive or sub-optimal. We propose the Attention Refinement Module (ARM), a lightweight, learnable module that effectively unlocks and refines CLIP’s internal potential. Unlike static-fusion methods, ARM learns to adaptively fuse hierarchical features. It employs a semantically-guided cross-attention block, using robust deep features (K, V) to select and refine detail-rich shallow features (Q), followed by a self-attention block. The key innovation lies in a ``train once, use anywhere&quot; paradigm. Trained once on a general-purpose dataset (e.g., COCO-Stuff), ARM acts as a universal plug-and-play post-processor for diverse training-free frameworks. Extensive experiments show that ARM consistently boosts baseline performance on multiple benchmarks with negligible inference overhead, establishing an efficient and effective paradigm for training-free OVSS.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-67] Medical Image Classification on Imbalanced Data Using ProGAN and SMA-Optimized ResNet: Application to COVID-19</p>
<p>【速读】：该论文旨在解决医学图像分类中因样本类别严重不均衡（class imbalance）导致的模型性能下降问题，尤其是在疫情背景下，如新冠肺炎（COVID-19）影像数据中阳性病例远少于阴性病例，使得传统深度学习方法难以准确识别少数类。其解决方案的关键在于提出一种渐进式生成对抗网络（progressive generative adversarial network, PGAN），用于生成高质量的合成医学图像以补充真实数据，并采用加权融合策略将合成数据与真实数据结合后输入深度网络分类器；同时引入多目标元启发式群体优化算法自动调优分类器超参数，从而显著提升在大规模不平衡胸部X光图像数据集上的分类精度，实现4类和2类不平衡分类任务分别达到95.5%和98.5%的准确率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24214">https://arxiv.org/abs/2512.24214</a><br>
<strong>作者</strong>: Sina Jahromi,Farshid Hajati,Alireza Rezaee,Javaher Nourian<br>
<strong>机构</strong>: University of Tehran (德黑兰大学); University of New England (纽英格兰大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The challenge of imbalanced data is prominent in medical image classification. This challenge arises when there is a significant disparity in the number of images belonging to a particular class, such as the presence or absence of a specific disease, as compared to the number of images belonging to other classes. This issue is especially notable during pandemics, which may result in an even more significant imbalance in the dataset. Researchers have employed various approaches in recent years to detect COVID-19 infected individuals accurately and quickly, with artificial intelligence and machine learning algorithms at the forefront. However, the lack of sufficient and balanced data remains a significant obstacle to these methods. This study addresses the challenge by proposing a progressive generative adversarial network to generate synthetic data to supplement the real ones. The proposed method suggests a weighted approach to combine synthetic data with real ones before inputting it into a deep network classifier. A multi-objective meta-heuristic population-based optimization algorithm is employed to optimize the hyper-parameters of the classifier. The proposed model exhibits superior cross-validated metrics compared to existing methods when applied to a large and imbalanced chest X-ray image dataset of COVID-19. The proposed model achieves 95.5% and 98.5% accuracy for 4-class and 2-class imbalanced classification problems, respectively. The successful experimental outcomes demonstrate the effectiveness of the proposed model in classifying medical images using imbalanced data during pandemics.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-68] RANGER: A Monocular Zero-Shot Semantic Navigation Framework through Contextual Adaptation</p>
<p>【速读】：该论文旨在解决当前零样本开放词汇语义导航（zero-shot open-vocabulary semantic navigation）方法在实际应用中的两大瓶颈：一是对模拟器提供的精确深度和位姿信息的高度依赖，限制了其在真实场景中的部署；二是缺乏上下文学习（in-context learning, ICL）能力，难以通过短时视频快速适应新环境。解决方案的关键在于提出RANGER框架，该框架仅依赖单目相机输入，利用强大的3D基础模型实现无需深度与位姿信息的语义导航，并通过关键帧驱动的3D重建、语义点云生成、视觉-语言模型（vision-language model, VLM）引导的探索价值评估以及自适应航点选择等模块，实现了高效的零样本导航与强ICL适应性，能够在不修改架构或微调的情况下，仅通过观察一段新环境的短视频即显著提升任务效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24212">https://arxiv.org/abs/2512.24212</a><br>
<strong>作者</strong>: Ming-Ming Yu,Yi Chen,Börje F. Karlsson,Wenjun Wu<br>
<strong>机构</strong>: Beihang University (北京航空航天大学); Beijing Academy of Artificial Intelligence (北京人工智能研究院); Institute of Automation, Chinese Academy of Sciences (中国科学院自动化研究所); Hangzhou International Innovation Institute, Beihang University (杭州国际创新研究院，北京航空航天大学)<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Efficiently finding targets in complex environments is fundamental to real-world embodied applications. While recent advances in multimodal foundation models have enabled zero-shot object goal navigation, allowing robots to search for arbitrary objects without fine-tuning, existing methods face two key limitations: (1) heavy reliance on precise depth and pose information provided by simulators, which restricts applicability in real-world scenarios; and (2) lack of in-context learning (ICL) capability, making it difficult to quickly adapt to new environments, as in leveraging short videos. To address these challenges, we propose RANGER, a novel zero-shot, open-vocabulary semantic navigation framework that operates using only a monocular camera. Leveraging powerful 3D foundation models, RANGER eliminates the dependency on depth and pose while exhibiting strong ICL capability. By simply observing a short video of a new environment, the system can also significantly improve task efficiency without requiring architectural modifications or fine-tuning. The framework integrates several key components: keyframe-based 3D reconstruction, semantic point cloud generation, vision-language model (VLM)-driven exploration value estimation, high-level adaptive waypoint selection, and low-level action execution. Experiments on the HM3D benchmark and real-world environments demonstrate that RANGER achieves competitive performance in terms of navigation success rate and exploration efficiency, while showing superior ICL adaptability, with no previous 3D mapping of the environment required.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-69] CorGi: Contribution-Guided Block-Wise Interval Caching for Training-Free Acceleration of Diffusion Transformers</p>
<p>【速读】：该论文旨在解决扩散 Transformer (Diffusion Transformer, DiT) 在图像生成任务中因迭代去噪过程与高容量模型导致的推理成本过高的问题。其核心挑战在于，DiT 的去噪过程中存在大量跨步骤的冗余计算。解决方案的关键在于提出 CorGi（Contribution-Guided Block-Wise Interval Caching）框架，该框架无需训练即可通过识别并缓存低贡献度的 Transformer 块输出，在每个间隔内重用这些块以减少冗余计算，同时保持生成质量；进一步地，针对文本到图像任务，CorGi+ 引入基于每层交叉注意力图的显著性 token 识别机制，并采用局部注意力更新策略，保护关键对象细节，从而在不牺牲生成质量的前提下实现最高达 2.0 倍的加速效果。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24195">https://arxiv.org/abs/2512.24195</a><br>
<strong>作者</strong>: Yonglak Son,Suhyeok Kim,Seungryong Kim,Young Geun Kim<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  16 pages, 20 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Diffusion transformer (DiT) achieves remarkable performance in visual generation, but its iterative denoising process combined with larger capacity leads to a high inference cost. Recent works have demonstrated that the iterative denoising process of DiT models involves substantial redundant computation across steps. To effectively reduce the redundant computation in DiT, we propose CorGi (Contribution-Guided Block-Wise Interval Caching), training-free DiT inference acceleration framework that selectively reuses the outputs of transformer blocks in DiT across denoising steps. CorGi caches low-contribution blocks and reuses them in later steps within each interval to reduce redundant computation while preserving generation quality. For text-to-image tasks, we further propose CorGi+, which leverages per-block cross-attention maps to identify salient tokens and applies partial attention updates to protect important object details. Evaluation on the state-of-the-art DiT models demonstrates that CorGi and CorGi+ achieve up to 2.0x speedup on average, while preserving high generation quality.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-70] PointRAFT: 3D deep learning for high-throughput prediction of potato tuber weight from partial point clouds</p>
<p>【速读】：该论文旨在解决在农业收获过程中，利用RGB-D相机获取的不完整点云数据（由于自遮挡导致）对马铃薯（potato）重量估计存在系统性低估的问题。传统方法需先重建完整三维几何结构，但效率低且易受遮挡影响。其解决方案的关键在于提出PointRAFT——一种高通量点云回归网络，直接从部分点云中预测连续的3D形状属性（如马铃薯重量），无需显式重建完整几何体；其核心创新是引入“对象高度嵌入”（object height embedding），将马铃薯高度作为额外几何线索融入模型，显著提升了在实际作业条件下的重量预测精度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24193">https://arxiv.org/abs/2512.24193</a><br>
<strong>作者</strong>: Pieter M. Blok,Haozhou Wang,Hyun Kwon Suh,Peicheng Wang,James Burridge,Wei Guo<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  14 pages, 7 figures, 3 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Potato yield is a key indicator for optimizing cultivation practices in agriculture. Potato yield can be estimated on harvesters using RGB-D cameras, which capture three-dimensional (3D) information of individual tubers moving along the conveyor belt. However, point clouds reconstructed from RGB-D images are incomplete due to self-occlusion, leading to systematic underestimation of tuber weight. To address this, we introduce PointRAFT, a high-throughput point cloud regression network that directly predicts continuous 3D shape properties, such as tuber weight, from partial point clouds. Rather than reconstructing full 3D geometry, PointRAFT infers target values directly from raw 3D data. Its key architectural novelty is an object height embedding that incorporates tuber height as an additional geometric cue, improving weight prediction under practical harvesting conditions. PointRAFT was trained and evaluated on 26,688 partial point clouds collected from 859 potato tubers across four cultivars and three growing seasons on an operational harvester in Japan. On a test set of 5,254 point clouds from 172 tubers, PointRAFT achieved a mean absolute error of 12.0 g and a root mean squared error of 17.2 g, substantially outperforming a linear regression baseline and a standard PointNet++ regression network. With an average inference time of 6.3 ms per point cloud, PointRAFT supports processing rates of up to 150 tubers per second, meeting the high-throughput requirements of commercial potato harvesters. Beyond potato weight estimation, PointRAFT provides a versatile regression network applicable to a wide range of 3D phenotyping and robotic perception tasks. The code, network weights, and a subset of the dataset are publicly available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-71] Guiding a Diffusion Transformer with the Internal Dynamics of Itself</p>
<p>【速读】：该论文旨在解决扩散模型在生成高质量图像时面临的低概率区域覆盖不足问题，以及传统引导策略（如无分类器引导，Classifier Free Guidance, CFG）导致样本过简化或失真的缺陷。其核心解决方案是提出一种简单而有效的内部引导机制（Internal Guidance, IG），该方法在训练过程中引入中间层的辅助监督信号，并在采样阶段通过外推中间层与深层输出来提升生成质量。实验表明，IG显著提升了训练效率和生成效果，在ImageNet 256×256数据集上，结合CFG后，LightningDiT-XL/1+IG达到当前最优FID值1.19。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24176">https://arxiv.org/abs/2512.24176</a><br>
<strong>作者</strong>: Xingyu Zhou,Qifan Li,Xiaobin Hu,Hai Chen,Shuhang Gu<br>
<strong>机构</strong>: University of Electronic Science and Technology of China (电子科技大学); National University of Singapore (新加坡国立大学); Sun Yat-sen University (中山大学); North China Institute of Computer Systems Engineering (华北计算机系统工程研究所)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  Project Page: <a target="_blank" rel="noopener" href="https://zhouxingyu13.github.io/Internal-Guidance/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The diffusion model presents a powerful ability to capture the entire (conditional) data distribution. However, due to the lack of sufficient training and data to learn to cover low-probability areas, the model will be penalized for failing to generate high-quality images corresponding to these areas. To achieve better generation quality, guidance strategies such as classifier free guidance (CFG) can guide the samples to the high-probability areas during the sampling stage. However, the standard CFG often leads to over-simplified or distorted samples. On the other hand, the alternative line of guiding diffusion model with its bad version is limited by carefully designed degradation strategies, extra training and additional sampling steps. In this paper, we proposed a simple yet effective strategy Internal Guidance (IG), which introduces an auxiliary supervision on the intermediate layer during training process and extrapolates the intermediate and deep layer’s outputs to obtain generative results during sampling process. This simple strategy yields significant improvements in both training efficiency and generation quality on various baselines. On ImageNet 256x256, SiT-XL/2+IG achieves FID=5.31 and FID=1.75 at 80 and 800 epochs. More impressively, LightningDiT-XL/1+IG achieves FID=1.34 which achieves a large margin between all of these methods. Combined with CFG, LightningDiT-XL/1+IG achieves the current state-of-the-art FID of 1.19.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-72] Deep Global Clustering for Hyperspectral Image Segmentation: Concepts Applications and Open Challenges</p>
<p>【速读】：该论文旨在解决高光谱成像（Hyperspectral Imaging, HSI）分析中因数据量庞大导致的计算瓶颈问题，特别是针对域特定应用（如近距农业监测）中预训练基础模型迁移性能不佳的问题。解决方案的关键在于提出 Deep Global Clustering (DGC) 框架，其核心创新是通过局部补丁观测学习全局聚类结构，无需预训练即可实现内存高效的HSI分割；该框架利用重叠区域强制一致性约束，在消费级硬件上训练时间少于30分钟且内存占用恒定，从而在叶部病害数据集上实现了背景-组织分离（平均IoU 0.925）和可导航语义粒度的无监督疾病检测。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24172">https://arxiv.org/abs/2512.24172</a><br>
<strong>作者</strong>: Yu-Tang Chang,Pin-Wei Chen,Shih-Fang Chen<br>
<strong>机构</strong>: National Taiwan University (国立台湾大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  10 pages, 4 figures. Technical report extending ACPA 2025 conference paper. Code and data available at <a target="_blank" rel="noopener" href="https://github.com/b05611038/HSI_global_clustering">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Hyperspectral imaging (HSI) analysis faces computational bottlenecks due to massive data volumes that exceed available memory. While foundation models pre-trained on large remote sensing datasets show promise, their learned representations often fail to transfer to domain-specific applications like close-range agricultural monitoring where spectral signatures, spatial scales, and semantic targets differ fundamentally. This report presents Deep Global Clustering (DGC), a conceptual framework for memory-efficient HSI segmentation that learns global clustering structure from local patch observations without pre-training. DGC operates on small patches with overlapping regions to enforce consistency, enabling training in under 30 minutes on consumer hardware while maintaining constant memory usage. On a leaf disease dataset, DGC achieves background-tissue separation (mean IoU 0.925) and demonstrates unsupervised disease detection through navigable semantic granularity. However, the framework suffers from optimization instability rooted in multi-objective loss balancing: meaningful representations emerge rapidly but degrade due to cluster over-merging in feature space. We position this work as intellectual scaffolding - the design philosophy has merit, but stable implementation requires principled approaches to dynamic loss balancing. Code and data are available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-73] DiffThinker: Towards Generative Multimodal <mark class="hl-label green">Reasoning</mark>  with Diffusion Models</p>
<p>【速读】：该论文旨在解决当前多模态大语言模型（Multimodal Large Language Models, MLLMs）在复杂长程、视觉主导任务中因推理过程以文本为中心而导致性能不佳的问题。其解决方案的关键在于提出一种全新的生成式多模态推理范式（Generative Multimodal Reasoning paradigm），并设计了基于扩散模型（diffusion-based）的推理框架 DiffThinker。该框架将多模态推理重新建模为原生的图像到图像生成任务，从而在视觉主导任务中实现了更高的逻辑一致性和空间精度，同时展现出效率高、可控性强、天然并行性好和协作能力强等核心特性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24165">https://arxiv.org/abs/2512.24165</a><br>
<strong>作者</strong>: Zefeng He,Xiaoye Qu,Yafu Li,Tong Zhu,Siyuan Huang,Yu Cheng<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://diffthinker-project.github.io">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:While recent Multimodal Large Language Models (MLLMs) have attained significant strides in multimodal reasoning, their reasoning processes remain predominantly text-centric, leading to suboptimal performance in complex long-horizon, vision-centric tasks. In this paper, we establish a novel Generative Multimodal Reasoning paradigm and introduce DiffThinker, a diffusion-based reasoning framework. Conceptually, DiffThinker reformulates multimodal reasoning as a native generative image-to-image task, achieving superior logical consistency and spatial precision in vision-centric tasks. We perform a systematic comparison between DiffThinker and MLLMs, providing the first in-depth investigation into the intrinsic characteristics of this paradigm, revealing four core properties: efficiency, controllability, native parallelism, and collaboration. Extensive experiments across four domains (sequential planning, combinatorial optimization, constraint satisfaction, and spatial configuration) demonstrate that DiffThinker significantly outperforms leading closed source models including GPT-5 (+314.2%) and Gemini-3-Flash (+111.6%), as well as the fine-tuned Qwen3-VL-32B baseline (+39.0%), highlighting generative multimodal reasoning as a promising approach for vision-centric reasoning.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-74] Bayesian Self-Distillation for Image Classification</p>
<p>【速读】：该论文旨在解决深度神经网络在分类任务中使用硬标签（hard targets）训练时导致的过自信问题，这会限制模型的校准性（calibration）、泛化能力和鲁棒性。现有自蒸馏（self-distillation）方法虽试图利用模型自身预测中的类别间和样本特定信息来缓解此问题，但仍依赖硬标签，效果受限。其解决方案的关键在于提出贝叶斯自蒸馏（Bayesian Self-Distillation, BSD），通过贝叶斯推理从模型自身的预测中构建样本特定的目标分布，从而在初始化后完全摆脱对硬标签的依赖。BSD在多个架构和数据集上均实现更高测试准确率（如ResNet-50在CIFAR-100上提升+1.4%）和显著更低的期望校准误差（ECE降低40%），并增强对数据扰动、噪声标签等场景的鲁棒性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24162">https://arxiv.org/abs/2512.24162</a><br>
<strong>作者</strong>: Anton Adelöw,Matteo Gamba,Atsuto Maki<br>
<strong>机构</strong>: KTH Royal Institute of Technology (皇家理工学院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  17 pages, 17 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Supervised training of deep neural networks for classification typically relies on hard targets, which promote overconfidence and can limit calibration, generalization, and robustness. Self-distillation methods aim to mitigate this by leveraging inter-class and sample-specific information present in the model’s own predictions, but often remain dependent on hard targets, reducing their effectiveness. With this in mind, we propose Bayesian Self-Distillation (BSD), a principled method for constructing sample-specific target distributions via Bayesian inference using the model’s own predictions. Unlike existing approaches, BSD does not rely on hard targets after initialization. BSD consistently yields higher test accuracy (e.g. +1.4% for ResNet-50 on CIFAR-100) and significantly lower Expected Calibration Error (ECE) (-40% ResNet-50, CIFAR-100) than existing architecture-preserving self-distillation methods for a range of deep architectures and datasets. Additional benefits include improved robustness against data corruptions, perturbations, and label noise. When combined with a contrastive loss, BSD achieves state-of-the-art robustness under label noise for single-stage, single-network methods.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-75] owards Open-Vocabulary Industrial Defect Understanding with a Large-Scale Multimodal Dataset</p>
<p>【速读】：该论文旨在解决工业制造领域中多模态缺陷检测与理解的难题，即如何利用大规模、高质量的图文对数据来训练通用且高效的视觉-语言基础模型，以支持分类、分割、检索、图像描述生成及缺陷生成等多种下游任务。其解决方案的关键在于构建了首个百万级工业多模态缺陷数据集IMDD-1M（Industrial Multimodal Defect Dataset），包含100万对齐的高分辨率图像-文本样本，覆盖60余种材料类别和400余种缺陷类型，并配有专家标注的细粒度文本描述；在此基础上，从头训练了一个基于扩散机制的视觉-语言基础模型，该模型可通过轻量级微调在仅需不足5%目标任务数据的情况下达到与专用专家模型相当的性能，从而实现数据高效、领域自适应且知识驱动的制造智能系统。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24160">https://arxiv.org/abs/2512.24160</a><br>
<strong>作者</strong>: TsaiChing Ni,ZhenQi Chen,YuanFu Yang<br>
<strong>机构</strong>: National Yang Ming Chiao Tung University (国立阳明交通大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present IMDD-1M, the first large-scale Industrial Multimodal Defect Dataset comprising 1,000,000 aligned image-text pairs, designed to advance multimodal learning for manufacturing and quality inspection. IMDD-1M contains high-resolution real-world defects spanning over 60 material categories and more than 400 defect types, each accompanied by expert-verified annotations and fine-grained textual descriptions detailing defect location, severity, and contextual attributes. This dataset enables a wide spectrum of applications, including classification, segmentation, retrieval, captioning, and generative modeling. Building upon IMDD-1M, we train a diffusion-based vision-language foundation model from scratch, specifically tailored for industrial scenarios. The model serves as a generalizable foundation that can be efficiently adapted to specialized domains through lightweight fine-tuning. With less than 5% of the task-specific data required by dedicated expert models, it achieves comparable performance, highlighting the potential of data-efficient foundation model adaptation for industrial inspection and generation, paving the way for scalable, domain-adaptive, and knowledge-grounded manufacturing intelligence.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-76] aming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning</p>
<p>【速读】：该论文旨在解决文本到图像扩散模型在通过人类反馈强化学习（Reinforcement Learning from Human Feedback, RLHF）对齐过程中出现的偏好模式崩溃（Preference Mode Collapse, PMC）问题，即模型过度优化导致生成结果趋于单一、缺乏多样性（如图像风格趋同或过度曝光）。解决方案的关键在于提出一种名为方向解耦对齐（Directional Decoupling Alignment, D²-Align）的新框架：该方法首先在奖励模型的嵌入空间中学习一个方向性修正向量，同时冻结奖励模型本身；随后将此修正应用于训练过程中的奖励信号，从而有效缓解因奖励模型固有偏倚引发的过拟合现象，维持生成多样性的同时提升与人类偏好的对齐质量。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24146">https://arxiv.org/abs/2512.24146</a><br>
<strong>作者</strong>: Chubin Chen,Sujie Hu,Jiashu Zhu,Meiqi Wu,Jintao Chen,Yanxun Li,Nisha Huang,Chengyu Fang,Jiahong Wu,Xiangxiang Chu,Xiu Li<br>
<strong>机构</strong>: Tsinghua University (清华大学); AMAP, Alibaba Group (阿里巴巴集团)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent studies have demonstrated significant progress in aligning text-to-image diffusion models with human preference via Reinforcement Learning from Human Feedback. However, while existing methods achieve high scores on automated reward metrics, they often lead to Preference Mode Collapse (PMC)-a specific form of reward hacking where models converge on narrow, high-scoring outputs (e.g., images with monolithic styles or pervasive overexposure), severely degrading generative diversity. In this work, we introduce and quantify this phenomenon, proposing DivGenBench, a novel benchmark designed to measure the extent of PMC. We posit that this collapse is driven by over-optimization along the reward model’s inherent biases. Building on this analysis, we propose Directional Decoupling Alignment (D ^2 -Align), a novel framework that mitigates PMC by directionally correcting the reward signal. Specifically, our method first learns a directional correction within the reward model’s embedding space while keeping the model frozen. This correction is then applied to the reward signal during the optimization process, preventing the model from collapsing into specific modes and thereby maintaining diversity. Our comprehensive evaluation, combining qualitative analysis with quantitative metrics for both quality and diversity, reveals that D ^2 -Align achieves superior alignment with human preference.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-77] GARDO: Reinforcing Diffusion Models without Reward Hacking</p>
<p>【速读】：该论文旨在解决扩散模型在在线强化学习（Online Reinforcement Learning, RL）微调过程中因代理奖励（proxy reward）与真实目标不一致而导致的奖励欺骗（reward hacking）问题，以及由此引发的图像质量下降和生成多样性崩溃（mode collapse）。传统方法通过引入对参考策略的正则化来抑制奖励欺骗，但此类方法会牺牲样本效率并阻碍对高奖励新区域的有效探索，因为参考策略通常为次优。论文提出了一种名为Gated and Adaptive Regularization with Diversity-aware Optimization (GARDO)的通用框架，其核心创新在于：<strong>选择性地对高不确定性样本施加正则化惩罚，而非全局应用；通过周期性更新参考模型以匹配在线策略的能力，实现自适应正则化；并通过放大高质量且高多样性的样本奖励，增强模式覆盖而不破坏优化稳定性</strong>。这一机制在保持样本效率的同时提升了探索能力，并有效缓解了奖励欺骗和模式坍缩问题。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24138">https://arxiv.org/abs/2512.24138</a><br>
<strong>作者</strong>: Haoran He,Yuxiao Ye,Jie Liu,Jiajun Liang,Zhiyong Wang,Ziyang Yuan,Xintao Wang,Hangyu Mao,Pengfei Wan,Ling Pan<br>
<strong>机构</strong>: Hong Kong University of Science and Technology (香港科技大学); Kuaishou Technology (快手科技); CUHK MMLab (香港中文大学多媒体实验室); The University of Edinburgh (爱丁堡大学)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  17 pages. Project: <a target="_blank" rel="noopener" href="https://tinnerhrhe.github.io/gardo_project">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Fine-tuning diffusion models via online reinforcement learning (RL) has shown great potential for enhancing text-to-image alignment. However, since precisely specifying a ground-truth objective for visual tasks remains challenging, the models are often optimized using a proxy reward that only partially captures the true goal. This mismatch often leads to reward hacking, where proxy scores increase while real image quality deteriorates and generation diversity collapses. While common solutions add regularization against the reference policy to prevent reward hacking, they compromise sample efficiency and impede the exploration of novel, high-reward regions, as the reference policy is usually sub-optimal. To address the competing demands of sample efficiency, effective exploration, and mitigation of reward hacking, we propose Gated and Adaptive Regularization with Diversity-aware Optimization (GARDO), a versatile framework compatible with various RL algorithms. Our key insight is that regularization need not be applied universally; instead, it is highly effective to selectively penalize a subset of samples that exhibit high uncertainty. To address the exploration challenge, GARDO introduces an adaptive regularization mechanism wherein the reference model is periodically updated to match the capabilities of the online policy, ensuring a relevant regularization target. To address the mode collapse issue in RL, GARDO amplifies the rewards for high-quality samples that also exhibit high diversity, encouraging mode coverage without destabilizing the optimization process. Extensive experiments across diverse proxy rewards and hold-out unseen metrics consistently show that GARDO mitigates reward hacking and enhances generation diversity without sacrificing sample efficiency or exploration, highlighting its effectiveness and robustness.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-78] Enhancing <mark class="hl-label green">LLM</mark> -Based Neural Network Generation: Few-Shot Prompting and Efficient Validation for Automated Architecture Design</p>
<p>【速读】：该论文旨在解决计算机视觉领域中自动化神经网络架构设计的挑战，尤其是在任务多样性与计算资源受限条件下，如何高效生成高质量且多样化的网络结构。其核心问题在于传统神经架构搜索（Neural Architecture Search, NAS）方法计算成本高，而大型语言模型（Large Language Models, LLMs）虽具潜力但缺乏针对视觉任务的系统性提示工程（prompt engineering）与验证策略。解决方案的关键在于：一是提出少样本架构提示（Few-Shot Architecture Prompting, FSAP），通过系统评估不同数量的支持样例（n=1至6），发现使用3个示例可在架构多样性与上下文聚焦之间取得最优平衡；二是引入空白字符归一化哈希验证（Whitespace-Normalized Hash Validation），一种轻量级去重方法（耗时&lt;1ms），相比AST解析提速100倍，有效避免重复架构训练，提升搜索效率。两项贡献共同构建了面向计算机视觉的LLM驱动架构搜索新范式，为资源有限的研究者提供了可落地的自动化设计工具。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24120">https://arxiv.org/abs/2512.24120</a><br>
<strong>作者</strong>: Chandini Vysyaraju,Raghuvir Duvvuri,Avi Goyal,Dmitry Ignatov,Radu Timofte<br>
<strong>机构</strong>: University of Würzburg (维尔茨堡大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Automated neural network architecture design remains a significant challenge in computer vision. Task diversity and computational constraints require both effective architectures and efficient search methods. Large Language Models (LLMs) present a promising alternative to computationally intensive Neural Architecture Search (NAS), but their application to architecture generation in computer vision has not been systematically studied, particularly regarding prompt engineering and validation strategies. Building on the task-agnostic NNGPT/LEMUR framework, this work introduces and validates two key contributions for computer vision. First, we present Few-Shot Architecture Prompting (FSAP), the first systematic study of the number of supporting examples (n = 1, 2, 3, 4, 5, 6) for LLM-based architecture generation. We find that using n = 3 examples best balances architectural diversity and context focus for vision tasks. Second, we introduce Whitespace-Normalized Hash Validation, a lightweight deduplication method (less than 1 ms) that provides a 100x speedup over AST parsing and prevents redundant training of duplicate computer vision architectures. In large-scale experiments across seven computer vision benchmarks (MNIST, CIFAR-10, CIFAR-100, CelebA, ImageNette, SVHN, Places365), we generated 1,900 unique architectures. We also introduce a dataset-balanced evaluation methodology to address the challenge of comparing architectures across heterogeneous vision tasks. These contributions provide actionable guidelines for LLM-based architecture search in computer vision and establish rigorous evaluation practices, making automated design more accessible to researchers with limited computational resources.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-79] GeoBench: Rethinking Multimodal Geometric Problem-Solving via Hierarchical Evaluation</p>
<p>【速读】：该论文旨在解决当前视觉-语言模型（Vision-Language Models, VLMs）在几何推理能力评估中存在的三大问题：测试数据可能因源自教科书基准而发生污染、过度关注最终答案而忽视推理过程、诊断粒度不足。为应对这些挑战，作者提出了GeoBench——一个分层基准，包含四个几何问题求解层次：视觉感知（Visual Perception）、目标导向规划（Goal-Oriented Planning）、严格定理应用（Rigorous Theorem Application）和自我反思回溯（Self-Reflective Backtracking）。解决方案的关键在于通过TrustGeoGen生成的六个形式化验证任务，系统性地评估从属性提取到逻辑错误修正的多种能力，并揭示了子目标分解与无关前提过滤对最终求解准确率的关键影响，同时指出Chain-of-Thought提示在某些任务中反而会降低性能，从而为几何推理系统的开发提供了可操作的指导。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24119">https://arxiv.org/abs/2512.24119</a><br>
<strong>作者</strong>: Yuan Feng,Yue Yang,Xiaohan He,Jiatong Zhao,Jianlong Chen,Zijun Chen,Daocheng Fu,Qi Liu,Renqiu Xia,Bo Zhang,Junchi Yan<br>
<strong>机构</strong>: Shanghai Jiao Tong University (上海交通大学); Shanghai Artificial Intelligence Laboratory (上海人工智能实验室); Fudan University (复旦大学); The Chinese University of Hong Kong, Shenzhen (香港中文大学（深圳)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Geometric problem solving constitutes a critical branch of mathematical reasoning, requiring precise analysis of shapes and spatial relationships. Current evaluations of geometric reasoning in vision-language models (VLMs) face limitations, including the risk of test data contamination from textbook-based benchmarks, overemphasis on final answers over reasoning processes, and insufficient diagnostic granularity. To address these issues, we present GeoBench, a hierarchical benchmark featuring four reasoning levels in geometric problem-solving: Visual Perception, Goal-Oriented Planning, Rigorous Theorem Application, and Self-Reflective Backtracking. Through six formally verified tasks generated via TrustGeoGen, we systematically assess capabilities ranging from attribute extraction to logical error correction. Experiments reveal that while reasoning models like OpenAI-o3 outperform general MLLMs, performance declines significantly with increasing task complexity. Key findings demonstrate that sub-goal decomposition and irrelevant premise filtering critically influence final problem-solving accuracy, whereas Chain-of-Thought prompting unexpectedly degrades performance in some tasks. These findings establish GeoBench as a comprehensive benchmark while offering actionable guidelines for developing geometric problem-solving systems.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-80] Guided Diffusion-based Generation of Adversarial Objects for Real-World Monocular Depth Estimation Attacks</p>
<p>【速读】：该论文旨在解决单目深度估计（Monocular Depth Estimation, MDE）在自动驾驶系统中易受对抗攻击的问题，此类攻击可能导致深度估计错误并传播至下游决策模块，进而危及交通安全性。现有物理攻击方法主要依赖纹理贴图，存在放置约束严格、现实感不足等问题，限制了其在复杂驾驶环境中的有效性。解决方案的关键在于提出一种无需训练的生成式对抗攻击框架，通过扩散模型（diffusion-based conditional generation）生成与场景一致的自然对抗物体；该框架结合显著区域选择模块（Salient Region Selection）和雅可比向量积引导机制（Jacobian Vector Product Guidance），精准定位对MDE影响最大的区域，并利用预训练扩散模型的梯度方向指导对抗扰动生成，从而实现高隐蔽性、强物理可部署性的深度误导攻击。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24111">https://arxiv.org/abs/2512.24111</a><br>
<strong>作者</strong>: Yongtao Chen,Yanbo Wang,Wentao Zhao,Guole Shen,Tianchen Deng,Jingchuan Wang<br>
<strong>机构</strong>: Shanghai Jiao Tong University (上海交通大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Monocular Depth Estimation (MDE) serves as a core perception module in autonomous driving systems, but it remains highly susceptible to adversarial attacks. Errors in depth estimation may propagate through downstream decision making and influence overall traffic safety. Existing physical attacks primarily rely on texture-based patches, which impose strict placement constraints and exhibit limited realism, thereby reducing their effectiveness in complex driving environments. To overcome these limitations, this work introduces a training-free generative adversarial attack framework that generates naturalistic, scene-consistent adversarial objects via a diffusion-based conditional generation process. The framework incorporates a Salient Region Selection module that identifies regions most influential to MDE and a Jacobian Vector Product Guidance mechanism that steers adversarial gradients toward update directions supported by the pre-trained diffusion model. This formulation enables the generation of physically plausible adversarial objects capable of inducing substantial adversarial depth shifts. Extensive digital and physical experiments demonstrate that our method significantly outperforms existing attacks in effectiveness, stealthiness, and physical deployability, underscoring its strong practical implications for autonomous driving safety assessment.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-81] hink Before You Move: Latent Motion <mark class="hl-label green">Reasoning</mark>  for Text-to-Motion Generation</p>
<p>【速读】：该论文旨在解决文本到动作生成（Text-to-Motion, T2M）中因语义-运动阻抗不匹配（Semantic-Kinematic Impedance Mismatch）导致的难题，即如何在单次映射中将语义密集、离散的语言意图准确地转化为运动高频、连续的动作数据。其解决方案的关键在于引入一种基于认知科学中分层运动控制启发的<strong>潜空间系统2推理（Latent System 2 Reasoning）</strong>，核心创新是提出<strong>双粒度编码器（Dual-Granularity Tokenizer）</strong>，将运动分解为两个独立流形：用于规划全局拓扑结构的压缩语义潜变量（Reasoning Latent）和用于保持物理保真度的高频执行潜变量（Execution Latent）。通过强制模型先进行自回归推理（规划粗略轨迹），再执行动作（生成帧），有效弥合了语言与物理之间的不可言说性鸿沟（ineffability gap），从而显著提升语义对齐性和物理合理性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24100">https://arxiv.org/abs/2512.24100</a><br>
<strong>作者</strong>: Yijie Qian,Juncheng Wang,Yuxiang Feng,Chao Xu,Wang Lu,Yang Liu,Baigui Sun,Yiqiang Chen,Yong Liu,Shujun Wang<br>
<strong>机构</strong>: Zhejiang University (浙江大学); Hong Kong Polytechnic University (香港理工大学); IROOTECH TECHNOLOGY; Wolf 1069 b Lab (Wolf 1069 b 实验室); Sany Group (三一集团); King’s College London (伦敦国王学院); Institute of Computing Technology, Chinese Academy of Sciences (中国科学院计算技术研究所)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  project page: <a target="_blank" rel="noopener" href="https://chenhaoqcdyq.github.io/LMR/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Current state-of-the-art paradigms predominantly treat Text-to-Motion (T2M) generation as a direct translation problem, mapping symbolic language directly to continuous poses. While effective for simple actions, this System 1 approach faces a fundamental theoretical bottleneck we identify as the Semantic-Kinematic Impedance Mismatch: the inherent difficulty of grounding semantically dense, discrete linguistic intent into kinematically dense, high-frequency motion data in a single shot. In this paper, we argue that the solution lies in an architectural shift towards Latent System 2 Reasoning. Drawing inspiration from Hierarchical Motor Control in cognitive science, we propose Latent Motion Reasoning (LMR) that reformulates generation as a two-stage Think-then-Act decision process. Central to LMR is a novel Dual-Granularity Tokenizer that disentangles motion into two distinct manifolds: a compressed, semantically rich Reasoning Latent for planning global topology, and a high-frequency Execution Latent for preserving physical fidelity. By forcing the model to autoregressively reason (plan the coarse trajectory) before it moves (instantiates the frames), we effectively bridge the ineffability gap between language and physics. We demonstrate LMR’s versatility by implementing it for two representative baselines: T2M-GPT (discrete) and MotionStreamer (continuous). Extensive experiments show that LMR yields non-trivial improvements in both semantic alignment and physical plausibility, validating that the optimal substrate for motion planning is not natural language, but a learned, motion-aligned concept space. Codes and demos can be found in \hyperlinkthis https URLthis https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-82] RainFusion2.0: Temporal-Spatial Awareness and Hardware-Efficient Block-wise Sparse Attention</p>
<p>【速读】：该论文旨在解决生成式 AI (Generative AI) 中扩散 Transformer (Diffusion Transformer, DiT) 模型因注意力机制导致的极高计算开销问题，以及现有稀疏注意力方法在硬件通用性不足和预测稀疏模式带来额外开销方面的局限性。解决方案的关键在于提出 RainFusion2.0，其核心创新包括：(1) 利用块级均值作为代表性 token 进行稀疏掩码预测，降低预测开销；(2) 实现时空感知的 token 重排策略以增强稀疏结构的有效性；(3) 引入首帧 sink 机制专门优化视频生成场景下的注意力分布。该方案在保持视频质量的前提下实现了高达 80% 的稀疏度，并带来 1.5~1.8 倍的端到端加速，且具备跨多种硬件平台的良好泛化能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24086">https://arxiv.org/abs/2512.24086</a><br>
<strong>作者</strong>: Aiyue Chen,Yaofu Liu,Junjian Huang,Guang Lian,Yiwu Yao,Wangli Lan,Jing Lin,Zhixin Ma,Tingting Zhou,Harry Yang<br>
<strong>机构</strong>: Huawei Technologies Co., Ltd (华为技术有限公司); The Hong Kong University of Science and Technology (香港科技大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In video and image generation tasks, Diffusion Transformer (DiT) models incur extremely high computational costs due to attention mechanisms, which limits their practical applications. Furthermore, with hardware advancements, a wide range of devices besides graphics processing unit (GPU), such as application-specific integrated circuit (ASIC), have been increasingly adopted for model inference. Sparse attention, which leverages the inherent sparsity of attention by skipping computations for insignificant tokens, is an effective approach to mitigate computational costs. However, existing sparse attention methods have two critical limitations: the overhead of sparse pattern prediction and the lack of hardware generality, as most of these methods are designed for GPU. To address these challenges, this study proposes RainFusion2.0, which aims to develop an online adaptive, hardware-efficient, and low-overhead sparse attention mechanism to accelerate both video and image generative models, with robust performance across diverse hardware platforms. Key technical insights include: (1) leveraging block-wise mean values as representative tokens for sparse mask prediction; (2) implementing spatiotemporal-aware token permutation; and (3) introducing a first-frame sink mechanism specifically designed for video generation scenarios. Experimental results demonstrate that RainFusion2.0 can achieve 80% sparsity while achieving an end-to-end speedup of 1.5~1.8x without compromising video quality. Moreover, RainFusion2.0 demonstrates effectiveness across various generative models and validates its generalization across diverse hardware platforms.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-83] Balanced Hierarchical Contrastive Learning with Decoupled Queries for Fine-grained Object Detection in Remote Sensing Images</p>
<p>【速读】：该论文旨在解决细粒度遥感图像检测中，如何有效利用标签层次结构提升模型性能的问题。具体而言，现有方法在应用监督对比学习时忽略了两个关键挑战：一是标签层级间数据分布不均导致高频类别主导学习过程，二是类别语义关系的学习干扰了类无关的目标定位能力。解决方案的关键在于提出一种平衡的分层对比损失（balanced hierarchical contrastive loss）与解耦学习策略（decoupled learning strategy）。前者通过引入可学习的类别原型（class prototypes）并均衡每个层级中不同类别的梯度贡献，确保每批训练样本中各层级类别对损失计算的等权重参与；后者则将检测变压器（DETR）中的对象查询（object queries）分离为分类和定位两组，实现任务特异性特征提取与优化，从而在三个具有层次标注的细粒度遥感数据集上显著优于当前最优方法。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24074">https://arxiv.org/abs/2512.24074</a><br>
<strong>作者</strong>: Jingzhou Chen,Dexin Chen,Fengchao Xiong,Yuntao Qian,Liang Xiao<br>
<strong>机构</strong>: Nanjing University of Science and Technology (南京理工大学); Zhejiang University (浙江大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Fine-grained remote sensing datasets often use hierarchical label structures to differentiate objects in a coarse-to-fine manner, with each object annotated across multiple levels. However, embedding this semantic hierarchy into the representation learning space to improve fine-grained detection performance remains challenging. Previous studies have applied supervised contrastive learning at different hierarchical levels to group objects under the same parent class while distinguishing sibling subcategories. Nevertheless, they overlook two critical issues: (1) imbalanced data distribution across the label hierarchy causes high-frequency classes to dominate the learning process, and (2) learning semantic relationships among categories interferes with class-agnostic localization. To address these issues, we propose a balanced hierarchical contrastive loss combined with a decoupled learning strategy within the detection transformer (DETR) framework. The proposed loss introduces learnable class prototypes and equilibrates gradients contributed by different classes at each hierarchical level, ensuring that each hierarchical class contributes equally to the loss computation in every mini-batch. The decoupled strategy separates DETR’s object queries into classification and localization sets, enabling task-specific feature extraction and optimization. Experiments on three fine-grained datasets with hierarchical annotations demonstrate that our method outperforms state-of-the-art approaches.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-84] Pathology Context Recalibration Network for Ocular Disease Recognition</p>
<p>【速读】：该论文旨在解决深度神经网络（DNN）在眼科疾病自动识别中忽视临床病理上下文信息和专家经验先验的问题，从而限制了模型性能提升与决策可解释性。解决方案的关键在于提出两个核心模块：一是病理重校准模块（Pathology Recalibration Module, PRM），通过像素级上下文压缩算子与病理分布集中算子相结合，挖掘病理上下文先验；二是专家先验引导适配器（Expert Prior Guidance Adapter, EPGA），充分挖掘专家经验先验以突出显著的像素级特征区域。此外，引入集成损失（Integrated Loss, IL）综合考虑样本级损失分布与标签频率的影响，进一步提升模型性能。整体架构PCRNet结合PRM、EPGA与IL，在多个眼科疾病数据集上实现了优于现有基于注意力机制网络和先进损失方法的识别效果。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24066">https://arxiv.org/abs/2512.24066</a><br>
<strong>作者</strong>: Zunjie Xiao,Xiaoqing Zhang,Risa Higashita,Jiang Liu<br>
<strong>机构</strong>: Southern University of Science and Technology (南方科技大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  The article has been accepted for publication at Machine Intelligence Research (MIR)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Pathology context and expert experience play significant roles in clinical ocular disease diagnosis. Although deep neural networks (DNNs) have good ocular disease recognition results, they often ignore exploring the clinical pathology context and expert experience priors to improve ocular disease recognition performance and decision-making interpretability. To this end, we first develop a novel Pathology Recalibration Module (PRM) to leverage the potential of pathology context prior via the combination of the well-designed pixel-wise context compression operator and pathology distribution concentration operator; then this paper applies a novel expert prior Guidance Adapter (EPGA) to further highlight significant pixel-wise representation regions by fully mining the expert experience prior. By incorporating PRM and EPGA into the modern DNN, the PCRNet is constructed for automated ocular disease recognition. Additionally, we introduce an Integrated Loss (IL) to boost the ocular disease recognition performance of PCRNet by considering the effects of sample-wise loss distributions and training label frequencies. The extensive experiments on three ocular disease datasets demonstrate the superiority of PCRNet with IL over state-of-the-art attention-based networks and advanced loss methods. Further visualization analysis explains the inherent behavior of PRM and EPGA that affects the decision-making process of DNNs.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-85] Neighbor-aware Instance Refining with Noisy Labels for Cross-Modal Retrieval <mark class="hl-label red">AAAI-26</mark></p>
<p>【速读】：该论文旨在解决跨模态检索（Cross-Modal Retrieval, CMR）中因标注数据存在噪声而导致模型性能下降的问题。现有方法虽尝试通过鲁棒学习范式、标签校准策略和实例选择机制提升抗噪能力，但难以同时兼顾模型性能上限、校准可靠性与数据利用率。其解决方案的关键在于提出一种新颖的鲁棒跨模态学习框架——Neighbor-aware Instance Refining with Noisy Labels (NIRNL)，核心创新包括：1）Cross-modal Margin Preserving (CMP) 用于保持正负样本对间的相对距离以增强区分度；2）Neighbor-aware Instance Refining (NIR) 基于跨模态邻域一致性识别纯净子集、困难子集与噪声子集，并针对不同子集设计定制化优化策略，从而在最大化利用全部数据的同时抑制误差传播，显著提升模型在高噪声率下的鲁棒性与性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24064">https://arxiv.org/abs/2512.24064</a><br>
<strong>作者</strong>: Yizhi Liu,Ruitao Pu,Shilin Xu,Yingke Chen,Quan-Hui Liu,Yuan Sun<br>
<strong>机构</strong>: 1. University of Science and Technology of China (中国科学技术大学); 2. Institute of Artificial Intelligence, University of Science and Technology of China (中国科学技术大学人工智能研究院); 3. Alibaba Cloud (阿里巴巴云); 4. Tencent AI Lab (腾讯人工智能实验室)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Multimedia (<a target="_blank" rel="noopener" href="http://cs.MM">cs.MM</a>)<br>
<strong>备注</strong>:  9 pages, 4 figures, and AAAI-26 conference</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In recent years, Cross-Modal Retrieval (CMR) has made significant progress in the field of multi-modal analysis. However, since it is time-consuming and labor-intensive to collect large-scale and well-annotated data, the annotation of multi-modal data inevitably contains some noise. This will degrade the retrieval performance of the model. To tackle the problem, numerous robust CMR methods have been developed, including robust learning paradigms, label calibration strategies, and instance selection mechanisms. Unfortunately, they often fail to simultaneously satisfy model performance ceilings, calibration reliability, and data utilization rate. To overcome the limitations, we propose a novel robust cross-modal learning framework, namely Neighbor-aware Instance Refining with Noisy Labels (NIRNL). Specifically, we first propose Cross-modal Margin Preserving (CMP) to adjust the relative distance between positive and negative pairs, thereby enhancing the discrimination between sample pairs. Then, we propose Neighbor-aware Instance Refining (NIR) to identify pure subset, hard subset, and noisy subset through cross-modal neighborhood consensus. Afterward, we construct different tailored optimization strategies for this fine-grained partitioning, thereby maximizing the utilization of all available data while mitigating error propagation. Extensive experiments on three benchmark datasets demonstrate that NIRNL achieves state-of-the-art performance, exhibiting remarkable robustness, especially under high noise rates.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-86] Reinforced Diffusion: Learning to Push the Limits of Anisotropic Diffusion for Image Denoising</p>
<p>【速读】：该论文旨在解决传统各向异性扩散（Anisotropic Diffusion）图像去噪方法在复杂图像结构下适应性不足的问题，这类方法依赖显式的扩散算子，难以有效处理多样化的图像细节。其解决方案的关键在于提出一种基于强化学习的可训练各向异性扩散框架，通过深度Q-learning学习不同迭代步骤中扩散动作的顺序，从而构建出具有强结构自适应性的随机各向异性扩散过程，显著提升了去噪性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24035">https://arxiv.org/abs/2512.24035</a><br>
<strong>作者</strong>: Xinran Qin,Yuhui Quan,Ruotao Xu,Hui Ji<br>
<strong>机构</strong>: South China University of Technology (华南理工大学); National University of Singapore (新加坡国立大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Image denoising is an important problem in low-level vision and serves as a critical module for many image recovery tasks. Anisotropic diffusion is a wide family of image denoising approaches with promising performance. However, traditional anisotropic diffusion approaches use explicit diffusion operators which are not well adapted to complex image structures. As a result, their performance is limited compared to recent learning-based approaches. In this work, we describe a trainable anisotropic diffusion framework based on reinforcement learning. By modeling the denoising process as a series of naive diffusion actions with order learned by deep Q-learning, we propose an effective diffusion-based image denoiser. The diffusion actions selected by deep Q-learning at different iterations indeed composite a stochastic anisotropic diffusion process with strong adaptivity to different image structures, which enjoys improvement over the traditional ones. The proposed denoiser is applied to removing three types of often-seen noise. The experiments show that it outperforms existing diffusion-based methods and competes with the representative deep CNN-based methods.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-87] PipeFlow: Pipelined Processing and Motion-Aware Frame Selection for Long-Form Video Editing</p>
<p>【速读】：该论文旨在解决长视频编辑中因联合编辑与去噪扩散隐式模型（Denoising Diffusion Implicit Models, DDIM）反演在长序列上导致的计算成本呈指数级增长的问题。解决方案的关键在于提出一种可扩展的流水线化视频编辑方法 PipeFlow，其核心创新包括：基于结构相似性指数（Structural Similarity Index Measure, SSIM）和光流（Optical Flow）分析识别低运动帧并跳过编辑；设计一种基于可用 GPU 内存的流水线任务调度算法，将视频分段并行执行 DDIM 反演与联合编辑；利用神经网络插值技术平滑分段边界帧并补全跳过的帧。该方法通过分段处理实现编辑时间与视频长度的线性增长，从而突破传统方法在长视频场景下的计算瓶颈，理论上支持无限长度视频的高效编辑。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24026">https://arxiv.org/abs/2512.24026</a><br>
<strong>作者</strong>: Mustafa Munir,Md Mostafijur Rahman,Kartikeya Bhardwaj,Paul Whatmough,Radu Marculescu<br>
<strong>机构</strong>: The University of Texas at Austin (德克萨斯大学奥斯汀分校); Qualcomm AI Research (高通人工智能研究中心)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Long-form video editing poses unique challenges due to the exponential increase in the computational cost from joint editing and Denoising Diffusion Implicit Models (DDIM) inversion across extended sequences. To address these limitations, we propose PipeFlow, a scalable, pipelined video editing method that introduces three key innovations: First, based on a motion analysis using Structural Similarity Index Measure (SSIM) and Optical Flow, we identify and propose to skip editing of frames with low motion. Second, we propose a pipelined task scheduling algorithm that splits a video into multiple segments and performs DDIM inversion and joint editing in parallel based on available GPU memory. Lastly, we leverage a neural network-based interpolation technique to smooth out the border frames between segments and interpolate the previously skipped frames. Our method uniquely scales to longer videos by dividing them into smaller segments, allowing PipeFlow’s editing time to increase linearly with video length. In principle, this enables editing of infinitely long videos without the growing per-frame computational overhead encountered by other methods. PipeFlow achieves up to a 9.6X speedup compared to TokenFlow and a 31.7X speedup over Diffusion Motion Transfer (DMT).<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-88] RS<mark class="hl-label green">Agent</mark> : Learning to <mark class="hl-label green">Reason</mark>  and Act for Text-Guided Segmentation via Multi-Turn Tool Invocations</p>
<p>【速读】：该论文旨在解决文本引导的目标分割（text-guided object segmentation）中因单次推理导致的定位错误难以修正的问题，即现有方法通常将分割任务视为一次性空间定位（one-shot grounding），缺乏对初始误判进行验证、重新聚焦和迭代优化的能力。其解决方案的关键在于提出RSAgent——一个基于多轮工具调用（multi-turn tool invocations）的代理型多模态大语言模型（agentic Multimodal Large Language Model, MLLM），通过在推理与动作之间交替执行（interleaving reasoning and action），结合视觉反馈（visual feedback）和历史观测信息动态修正空间假设，实现目标重定位与掩码迭代精化。该方法显著提升了分割的鲁棒性和准确性，在ReasonSeg和RefCOCOg等基准上均达到当前最优性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24023">https://arxiv.org/abs/2512.24023</a><br>
<strong>作者</strong>: Xingqi He,Yujie Zhang,Shuyong Gao,Wenjie Li,Lingyi Hong,Mingxi Chen,Kaixun Jiang,Jiyuan Fu,Wenqiang Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Text-guided object segmentation requires both cross-modal reasoning and pixel grounding abilities. Most recent methods treat text-guided segmentation as one-shot grounding, where the model predicts pixel prompts in a single forward pass to drive an external segmentor, which limits verification, refocusing and refinement when initial localization is wrong. To address this limitation, we propose RSAgent, an agentic Multimodal Large Language Model (MLLM) which interleaves reasoning and action for segmentation via multi-turn tool invocations. RSAgent queries a segmentation toolbox, observes visual feedback, and revises its spatial hypothesis using historical observations to re-localize targets and iteratively refine masks. We further build a data pipeline to synthesize multi-turn reasoning segmentation trajectories, and train RSAgent with a two-stage framework: cold-start supervised fine-tuning followed by agentic reinforcement learning with fine-grained, task-specific rewards. Extensive experiments show that RSAgent achieves a zero-shot performance of 66.5% gIoU on ReasonSeg test, improving over Seg-Zero-7B by 9%, and reaches 81.5% cIoU on RefCOCOg, demonstrating state-of-the-art performance on both in-domain and out-of-domain benchmarks.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-89] FUSE-RSVLM: Feature Fusion Vision-Language Model for Remote Sensing</p>
<p>【速读】：该论文旨在解决大型视觉语言模型（Vision-Language Models, VLMs）在遥感（Remote Sensing, RS）领域应用时面临的两大核心挑战：一是难以提取细粒度的视觉特征，二是深度语言处理过程中出现的视觉遗忘问题。为应对这些问题，作者提出了一种多特征融合遥感视觉-语言模型（Multi-Feature Fusion Remote Sensing Vision-Language Model, MF-RSVLM），其关键创新在于引入了多尺度视觉表征学习机制与循环视觉特征注入策略——前者通过融合全局上下文与局部细节提升对遥感场景中微小和复杂结构的捕捉能力，后者则确保语言生成过程始终锚定于视觉证据，有效缓解视觉遗忘现象，从而显著提升遥感图像分类、图像描述生成及视觉问答等任务的性能表现。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24022">https://arxiv.org/abs/2512.24022</a><br>
<strong>作者</strong>: Yunkai Dang,Donghao Wang,Jiacheng Yang,Yifan Jiang,Meiyi Zhu,Yuekun Yang,Cong Wang,Qi Fan,Wenbin Li,Yang Gao<br>
<strong>机构</strong>: Nanjing University (南京大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large vision-language models (VLMs) exhibit strong performance across various tasks. However, these VLMs encounter significant challenges when applied to the remote sensing domain due to the inherent differences between remote sensing images and natural images. Existing remote sensing VLMs often fail to extract fine-grained visual features and suffer from visual forgetting during deep language processing. To address this, we introduce MF-RSVLM, a Multi-Feature Fusion Remote Sensing Vision–Language Model that effectively extracts and fuses visual features for RS understanding. MF-RSVLM learns multi-scale visual representations and combines global context with local details, improving the capture of small and complex structures in RS scenes. A recurrent visual feature injection scheme ensures the language model remains grounded in visual evidence and reduces visual forgetting during generation. Extensive experiments on diverse RS benchmarks show that MF-RSVLM achieves state-of-the-art or highly competitive performance across remote sensing classification, image captioning, and VQA tasks. Our code is publicly available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-90] Structure-Guided Allocation of 2D Gaussians for Image Representation and Compression</p>
<p>【速读】：该论文旨在解决基于2D Gaussian Splatting (2DGS) 的图像表示方法在低码率下率失真（Rate-Distortion, RD）效率不足的问题，其根源在于现有管线对图像结构缺乏感知，导致表示能力与参数精度分配不合理。解决方案的关键在于提出一种结构引导的分配原则，通过三个核心机制实现：(1) 基于自然图像空间结构先验进行结构引导初始化，生成局部化且语义合理的2D高斯分布；(2) 在量化感知微调中引入自适应位宽量化策略，对复杂区域的小尺度高斯赋予更高精度，从而优化RD性能并减少冗余；(3) 引入几何一致性正则项，使高斯椭球方向与局部梯度方向对齐，以更好保留结构细节。该方案在保持超过1000 FPS解码速度的同时显著提升了2DGS的表示能力和RD效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24018">https://arxiv.org/abs/2512.24018</a><br>
<strong>作者</strong>: Huanxiong Liang,Yunuo Chen,Yicheng Pan,Sixian Wang,Jincheng Dai,Guo Lu,Wenjun Zhang<br>
<strong>机构</strong>: Shanghai Jiao Tong University (上海交通大学); Beijing University of Posts and Telecommunications (北京邮电大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advances in 2D Gaussian Splatting (2DGS) have demonstrated its potential as a compact image representation with millisecond-level decoding. However, existing 2DGS-based pipelines allocate representation capacity and parameter precision largely oblivious to image structure, limiting their rate-distortion (RD) efficiency at low bitrates. To address this, we propose a structure-guided allocation principle for 2DGS, which explicitly couples image structure with both representation capacity and quantization precision, while preserving native decoding speed. First, we introduce a structure-guided initialization that assigns 2D Gaussians according to spatial structural priors inherent in natural images, yielding a localized and semantically meaningful distribution. Second, during quantization-aware fine-tuning, we propose adaptive bitwidth quantization of covariance parameters, which grants higher precision to small-scale Gaussians in complex regions and lower precision elsewhere, enabling RD-aware optimization, thereby reducing redundancy without degrading edge quality. Third, we impose a geometry-consistent regularization that aligns Gaussian orientations with local gradient directions to better preserve structural details. Extensive experiments demonstrate that our approach substantially improves both the representational power and the RD performance of 2DGS while maintaining over 1000 FPS decoding. Compared with the baseline GSImage, we reduce BD-rate by 43.44% on Kodak and 29.91% on DIV2K.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-91] FitControler: Toward Fit-Aware Virtual Try-On</p>
<p>【速读】：该论文旨在解决虚拟试衣（Virtual Try-On, VTON）中长期被忽视的关键问题——服装合身度（fit），即服装与人体的贴合程度，这是影响整体风格协调性的核心因素。现有方法多聚焦于服装细节的逼真渲染，却未充分考虑合身度对视觉风格的整体塑造作用。解决方案的关键在于提出FitControler，一个可学习的插件模块，能够无缝集成至主流VTON模型中实现定制化合身控制。其核心技术包括：1）设计了一个<strong>适合感知的布局生成器</strong>（fit-aware layout generator），基于精心处理的与服装无关的表征重新绘制人体-服装布局；2）引入<strong>多尺度合身注入器</strong>（multi-scale fit injector），将布局线索传递给VTON模型以驱动布局引导的试衣生成。实验表明，该方法在多个VTON模型上均能实现精确的合身控制，并构建了包含13,000对不同合身度的人体-服装样本的数据集Fit4Men，同时提出了两个合身一致性评估指标用于量化生成质量。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24016">https://arxiv.org/abs/2512.24016</a><br>
<strong>作者</strong>: Lu Yang,Yicheng Liu,Yanan Li,Xiang Bai,Hao Lu<br>
<strong>机构</strong>: Huazhong University of Science and Technology (华中科技大学); Wuhan Institute of Technology (武汉工程大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Realistic virtual try-on (VTON) concerns not only faithful rendering of garment details but also coordination of the style. Prior art typically pursues the former, but neglects a key factor that shapes the holistic style – garment fit. Garment fit delineates how a garment aligns with the body of a wearer and is a fundamental element in fashion design. In this work, we introduce fit-aware VTON and present FitControler, a learnable plug-in that can seamlessly integrate into modern VTON models to enable customized fit control. To achieve this, we highlight two challenges: i) how to delineate layouts of different fits and ii) how to render the garment that matches the layout. FitControler first features a fit-aware layout generator to redraw the body-garment layout conditioned on a set of delicately processed garment-agnostic representations, and a multi-scale fit injector is then used to deliver layout cues to enable layout-driven VTON. In particular, we build a fit-aware VTON dataset termed Fit4Men, including 13,000 body-garment pairs of different fits, covering both tops and bottoms, and featuring varying camera distances and body poses. Two fit consistency metrics are also introduced to assess the fitness of generations. Extensive experiments show that FitControler can work with various VTON models and achieve accurate fit control. Code and data will be released.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-92] On Exact Editing of Flow-Based Diffusion Models</p>
<p>【速读】：该论文旨在解决流形空间中基于流的扩散编辑（flow-based diffusion editing）方法在潜在轨迹演化过程中因速度误差累积导致的语义不一致性和结构保真度下降问题。其核心解决方案是提出条件速度修正（Conditioned Velocity Correction, CVC）框架，通过引入双视角速度转换机制，将潜在演化显式分解为两个分支：保持结构一致性的分支（与源分布轨迹对齐）和受语义引导的分支（可控地向目标分布偏移）。进一步地，CVC利用经验贝叶斯推断（Empirical Bayes Inference）与Tweedie校正（Tweedie correction）对条件速度场进行后验一致性更新，从而量化并补偿潜在空间中的绝对速度误差，确保长期轨迹稳定性与真实流形的一致性，实现高保真重建与平滑局部语义转换。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24015">https://arxiv.org/abs/2512.24015</a><br>
<strong>作者</strong>: Zixiang Li,Yue Song,Jianing Peng,Ting Liu,Jun Huang,Xiaochao Qu,Luoqi Liu,Wei Wang,Yao Zhao,Yunchao Wei<br>
<strong>机构</strong>: Beijing Jiaotong University (北京交通大学); Visual Intelligence +X International Cooperation Joint Laboratory of MOE (教育部视觉智能+x国际合作联合实验室); Meitu Inc (美图公司); Tsinghua University (清华大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent methods in flow-based diffusion editing have enabled direct transformations between source and target image distribution without explicit inversion. However, the latent trajectories in these methods often exhibit accumulated velocity errors, leading to semantic inconsistency and loss of structural fidelity. We propose Conditioned Velocity Correction (CVC), a principled framework that reformulates flow-based editing as a distribution transformation problem driven by a known source prior. CVC rethinks the role of velocity in inter-distribution transformation by introducing a dual-perspective velocity conversion mechanism. This mechanism explicitly decomposes the latent evolution into two components: a structure-preserving branch that remains consistent with the source trajectory, and a semantically-guided branch that drives a controlled deviation toward the target distribution. The conditional velocity field exhibits an absolute velocity error relative to the true underlying distribution trajectory, which inherently introduces potential instability and trajectory drift in the latent space. To address this quantifiable deviation and maintain fidelity to the true flow, we apply a posterior-consistent update to the resulting conditional velocity field. This update is derived from Empirical Bayes Inference and Tweedie correction, which ensures a mathematically grounded error compensation over time. Our method yields stable and interpretable latent dynamics, achieving faithful reconstruction alongside smooth local semantic conversion. Comprehensive experiments demonstrate that CVC consistently achieves superior fidelity, better semantic alignment, and more reliable editing behavior across diverse tasks.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-93] Bridging the Perception-Cognition Gap:Re-engineering SAM2 with Hilbert-Mamba for Robust VLM-based Medical Diagnosis</p>
<p>【速读】：该论文旨在解决视觉语言模型（Visual Language Models, VLMs）在处理复杂三维（3D）多模态医学图像时面临的两大挑战：一是如何有效融合互补信息，二是如何避免遗漏细微但关键的病理特征。其解决方案的核心在于提出一种两阶段融合框架——Hilbert-VLM，其中的关键创新包括：1）对Segment Anything Model 2（SAM2）架构进行系统性重构，将希尔伯特空间填充曲线（Hilbert space-filling curves）嵌入Mamba状态空间模型（SSM）的扫描机制中，以最大化保留3D数据的空间局部性；2）引入新型希尔伯特-Mamba交叉注意力机制（Hilbert-Mamba Cross-Attention, HMCA）与尺度感知解码器，增强细粒度特征捕捉能力；3）设计提示增强模块，将分割掩膜及其文本属性统一为信息密集型提示，从而提升VLM推理精度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24013">https://arxiv.org/abs/2512.24013</a><br>
<strong>作者</strong>: Hao Wu,Hui Li,Yiyun Su<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent studies suggest that Visual Language Models (VLMs) hold great potential for tasks such as automated medical diagnosis. However, processing complex three-dimensional (3D) multimodal medical images poses significant challenges - specifically, the effective integration of complementary information and the occasional oversight of subtle yet critical pathological features. To address these issues, we present a novel two-stage fusion framework termed Hilbert-VLM. This framework leverages the HilbertMed-SAM module for precise lesion segmentation, with the generated multimodal enhanced prompts then guiding the VLM toward accurate disease classification. Our key innovation lies in the systematic redesign of the Segment Anything Model 2 (SAM2) architecture: we incorporate Hilbert space-filling curves into the scanning mechanism of the Mamba State Space Model (SSM) to maximize the preservation of spatial locality in 3D data, a property critical for medical image analysis. We also introduce a novel Hilbert-Mamba Cross-Attention (HMCA) mechanism and a scale-aware decoder to capture fine-grained details. Meanwhile, the prompt enhancement module unifies segmentation masks and their corresponding textual attributes into an information-dense prompt to support VLM inference. Extensive experiments were conducted to validate the effectiveness of the Hilbert-VLM model. On the BraTS2021 segmentation benchmark, it achieves a Dice score of 82.35 percent, with a diagnostic classification accuracy (ACC) of 78.85 percent. These results demonstrate that the proposed model offers substantial potential to improve the accuracy and reliability of medical VLM-based analysis.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-94] Improved 3D Gaussian Splatting of Unknown Spacecraft Structure Using Space Environment Illumination Knowledge</p>
<p>【速读】：该论文旨在解决在空间交会与近距离操作（Rendezvous and Proximity Operations, RPO）过程中，如何从动态光照条件下的图像序列中恢复未知目标航天器的几何结构并保证后续相机位姿估计的精度问题。传统3D高斯溅射（3D Gaussian Splatting, 3DGS）模型训练依赖静态场景假设，难以适应太空环境中快速变化的光照条件，导致渲染图像的光度准确性下降，进而影响位姿估计性能。解决方案的关键在于将服务航天器估算并持续维护的太阳位置先验知识引入3DGS训练流程，以提升模型在复杂光照下对全局阴影和自遮挡的建模能力，从而增强渲染图像的光度保真度，保障下游位姿估计任务的可靠性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23998">https://arxiv.org/abs/2512.23998</a><br>
<strong>作者</strong>: Tae Ha Park,Simone D’Amico<br>
<strong>机构</strong>: Nara Space Technology Inc.(Nara空间技术公司); Stanford University (斯坦福大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Presented at 2025 IEEE International Conference on Space Robotics (iSpaRo)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This work presents a novel pipeline to recover the 3D structure of an unknown target spacecraft from a sequence of images captured during Rendezvous and Proximity Operations (RPO) in space. The target’s geometry and appearance are represented as a 3D Gaussian Splatting (3DGS) model. However, learning 3DGS requires static scenes, an assumption in contrast to dynamic lighting conditions encountered in spaceborne imagery. The trained 3DGS model can also be used for camera pose estimation through photometric optimization. Therefore, in addition to recovering a geometrically accurate 3DGS model, the photometric accuracy of the rendered images is imperative to downstream pose estimation tasks during the RPO process. This work proposes to incorporate the prior knowledge of the Sun’s position, estimated and maintained by the servicer spacecraft, into the training pipeline for improved photometric quality of 3DGS rasterization. Experimental studies demonstrate the effectiveness of the proposed solution, as 3DGS models trained on a sequence of images learn to adapt to rapidly changing illumination conditions in space and reflect global shadowing and self-occlusion.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-95] Bridging Structure and Appearance: Topological Features for Robust Self-Supervised Segmentation</p>
<p>【速读】：该论文旨在解决自监督语义分割方法在面对外观歧义（appearance ambiguities）时性能下降的问题，其根本原因在于模型过度依赖不稳定的外观特征（如阴影、反光和局部纹理）。解决方案的关键在于提出GASeg框架，通过引入可微分盒计数（Differentiable Box-Counting, DBC）模块，从几何特征和外观特征两个并行流中量化多尺度拓扑统计信息，并结合拓扑增强（Topological Augmentation, TopoAug）策略模拟真实世界的外观歧义，以及多目标损失函数（GALoss）显式地强制几何与外观特征之间的跨模态对齐，从而提升模型对稳定结构表征的学习能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23997">https://arxiv.org/abs/2512.23997</a><br>
<strong>作者</strong>: Haotang Li,Zhenyu Qi,Hao Qin,Huanrui Yang,Sen He,Kebin Peng<br>
<strong>机构</strong>: The University of Arizona (亚利桑那大学); East Carolina University (东卡罗来纳大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Self-supervised semantic segmentation methods often fail when faced with appearance ambiguities. We argue that this is due to an over-reliance on unstable, appearance-based features such as shadows, glare, and local textures. We propose \textbfGASeg, a novel framework that bridges appearance and geometry by leveraging stable topological information. The core of our method is Differentiable Box-Counting (\textbfDBC) module, which quantifies multi-scale topological statistics from two parallel streams: geometric-based features and appearance-based features. To force the model to learn these stable structural representations, we introduce Topological Augmentation (\textbfTopoAug), an adversarial strategy that simulates real-world ambiguities by applying morphological operators to the input images. A multi-objective loss, \textbfGALoss, then explicitly enforces cross-modal alignment between geometric-based and appearance-based features. Extensive experiments demonstrate that GASeg achieves state-of-the-art performance on four benchmarks, including COCO-Stuff, Cityscapes, and PASCAL, validating our approach of bridging geometry and appearance via topological information.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-96] GCA-ResUNet: Medical Image Segmentation Using Grouped Coordinate Attention</p>
<p>【速读】：该论文旨在解决医学图像分割中因卷积神经网络（Convolutional Neural Networks, CNNs）固有的局部性及注意力机制同质化导致的长程上下文依赖建模不足问题，尤其是在多器官场景和低对比度区域中表现受限；其解决方案的关键在于提出一种轻量级、可插拔的分组坐标注意力（Grouped Coordinate Attention, GCA）模块，该模块通过将通道维度划分为多个组来显式建模跨通道语义异质性，并引入方向感知的坐标编码以捕捉水平与垂直方向上的结构化空间依赖关系，从而在保持CNN骨干网络高效性的前提下显著增强全局表征能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23990">https://arxiv.org/abs/2512.23990</a><br>
<strong>作者</strong>: Jun Ding,Shang Gao<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Accurate segmentation of heterogeneous anatomical structures is pivotal for computer-aided diagnosis and subsequent clinical decision-making. Although U-Net based convolutional neural networks have achieved remarkable progress, their intrinsic locality and largely homogeneous attention formulations often limit the modeling of long-range contextual dependencies, especially in multi-organ scenarios and low-contrast regions. Transformer-based architectures mitigate this issue by leveraging global self-attention, but they usually require higher computational resources and larger training data, which may impede deployment in resource-constrained clinical this http URL this paper, we propose GCA-ResUNet, an efficient medical image segmentation framework equipped with a lightweight and plug-and-play Grouped Coordinate Attention (GCA) module. The proposed GCA decouples channel-wise context modeling into multiple groups to explicitly account for semantic heterogeneity across channels, and integrates direction-aware coordinate encoding to capture structured spatial dependencies along horizontal and vertical axes. This design enhances global representation capability while preserving the efficiency advantages of CNN backbones. Extensive experiments on two widely used benchmarks, Synapse and ACDC, demonstrate that GCA-ResUNet achieves Dice scores of 86.11% and 92.64%, respectively, outperforming a range of representative CNN and Transformer-based methods, including Swin-UNet and TransUNet. In particular, GCA-ResUNet yields consistent improvements in delineating small anatomical structures with complex boundaries. These results indicate that the proposed approach provides a favorable trade-off between segmentation accuracy and computational efficiency, offering a practical and scalable solution for clinical deployment.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-97] Anomaly detection in satellite imagery through temporal inpainting</p>
<p>【速读】：该论文旨在解决从卫星遥感影像中检测地表变化的难题，尤其针对大气噪声、季节性波动和传感器伪影等复杂因素导致的传统方法灵敏度不足的问题。其解决方案的关键在于利用深度学习模型挖掘卫星时间序列中的时序冗余信息，通过训练一个基于SATLAS基础模型的图像修复（inpainting）模型，从历史观测中预测当前时刻的地表状态，从而识别出传统方法难以发现的微弱异常变化。该方法在2023年土耳其-叙利亚地震事件中验证有效，对断层破裂等突发地表变化的检测灵敏度和特异性显著优于时序中值或Reed-Xiaoli异常检测器，检测阈值约为基线方法的三分之一。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23986">https://arxiv.org/abs/2512.23986</a><br>
<strong>作者</strong>: Bertrand Rouet-Leduc,Claudia Hulbert<br>
<strong>机构</strong>: Disaster Prevention Research Institute, Kyoto University (京都大学防灾研究所); Geolabe (地质实验室)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Geophysics (physics.geo-ph)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Detecting surface changes from satellite imagery is critical for rapid disaster response and environmental monitoring, yet remains challenging due to the complex interplay between atmospheric noise, seasonal variations, and sensor artifacts. Here we show that deep learning can leverage the temporal redundancy of satellite time series to detect anomalies at unprecedented sensitivity, by learning to predict what the surface should look like in the absence of change. We train an inpainting model built upon the SATLAS foundation model to reconstruct the last frame of a Sentinel-2 time series from preceding acquisitions, using globally distributed training data spanning diverse climate zones and land cover types. When applied to regions affected by sudden surface changes, the discrepancy between prediction and observation reveals anomalies that traditional change detection methods miss. We validate our approach on earthquake-triggered surface ruptures from the 2023 Turkey-Syria earthquake sequence, demonstrating detection of a rift feature in Tepehan with higher sensitivity and specificity than temporal median or Reed-Xiaoli anomaly detectors. Our method reaches detection thresholds approximately three times lower than baseline approaches, providing a path towards automated, global-scale monitoring of surface changes from freely available multi-spectral satellite data.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-98] DriveExplorer: Images-Only Decoupled 4D Reconstruction with Progressive Restoration for Driving View Extrapolation</p>
<p>【速读】：该论文旨在解决自动驾驶场景中视图外推（view extrapolation）的问题，即从已知视角生成目标视角下的高质量图像。传统方法依赖于昂贵的传感器数据（如LiDAR点云）或人工标注的3D边界框和车道线信息，限制了实际部署的可行性。其解决方案的关键在于：首先仅使用图像和可选的相机位姿估计全局静态点云与每帧动态点云，并融合为统一表示；随后利用可变形4D高斯（deformable 4D Gaussian, 4DGS）框架进行场景重建；初始训练的4DGS模型生成伪图像用于训练视频扩散模型（video diffusion model），再通过迭代优化——扩散模型逐步提升渲染结果并反馈至4DGS进行精调——最终实现高保真度的视图外推。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23983">https://arxiv.org/abs/2512.23983</a><br>
<strong>作者</strong>: Yuang Jia,Jinlong Wang,Jiayi Zhao,Chunlam Li,Shunzhou Wang,Wei Gao<br>
<strong>机构</strong>: Peking University (北京大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper presents an effective solution for view extrapolation in autonomous driving scenarios. Recent approaches focus on generating shifted novel view images from given viewpoints using diffusion models. However, these methods heavily rely on priors such as LiDAR point clouds, 3D bounding boxes, and lane annotations, which demand expensive sensors or labor-intensive labeling, limiting applicability in real-world deployment. In this work, with only images and optional camera poses, we first estimate a global static point cloud and per-frame dynamic point clouds, fusing them into a unified representation. We then employ a deformable 4D Gaussian framework to reconstruct the scene. The initially trained 4D Gaussian model renders degraded and pseudo-images to train a video diffusion model. Subsequently, progressively shifted Gaussian renderings are iteratively refined by the diffusion model,and the enhanced results are incorporated back as training data for 4DGS. This process continues until extrapolation reaches the target viewpoints. Compared with baselines, our method produces higher-quality images at novel extrapolated viewpoints.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-99] 2VAttack: Adversarial Attack on Text-to-Video Diffusion Models</p>
<p>【速读】：该论文旨在解决文本到视频（Text-to-Video, T2V）扩散模型在面对对抗攻击时的鲁棒性问题，即当前T2V模型对提示词（prompt）微小扰动的敏感性尚未被充分研究。解决方案的关键在于提出了一套系统性的对抗攻击框架T2VAttack，其核心包括两个维度：一是语义目标（semantic objective），用于评估生成视频与文本描述的一致性；二是时间目标（temporal objective），用于衡量视频帧间动态一致性。为实现高效攻击，论文进一步设计了两种方法：T2VAttack-S通过贪婪搜索替换提示中关键词以破坏语义或时间特性，T2VAttack-I则通过迭代插入最小扰动词来增强攻击效果。实验表明，仅需修改一个词即可显著降低视频质量，揭示了现有T2V模型在语义和时序上的脆弱性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23953">https://arxiv.org/abs/2512.23953</a><br>
<strong>作者</strong>: Changzhen Li,Yuecong Min,Jie Zhang,Zheng Yuan,Shiguang Shan,Xilin Chen<br>
<strong>机构</strong>: Hangzhou Institute for Advanced Study, UCAS, school of Intelligent Science and Technology, China; State Key Laboratory of AI Safety, Institute of Computing Technology (ICT), Chinese Academy of Sciences (CAS), Beijing 100190, China; University of Chinese Academy of Sciences (UCAS), Beijing 100049, China<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The rapid evolution of Text-to-Video (T2V) diffusion models has driven remarkable advancements in generating high-quality, temporally coherent videos from natural language descriptions. Despite these achievements, their vulnerability to adversarial attacks remains largely unexplored. In this paper, we introduce T2VAttack, a comprehensive study of adversarial attacks on T2V diffusion models from both semantic and temporal perspectives. Considering the inherently dynamic nature of video data, we propose two distinct attack objectives: a semantic objective to evaluate video-text alignment and a temporal objective to assess the temporal dynamics. To achieve an effective and efficient attack process, we propose two adversarial attack methods: (i) T2VAttack-S, which identifies semantically or temporally critical words in prompts and replaces them with synonyms via greedy search, and (ii) T2VAttack-I, which iteratively inserts optimized words with minimal perturbation to the prompt. By combining these objectives and strategies, we conduct a comprehensive evaluation on the adversarial robustness of several state-of-the-art T2V models, including ModelScope, CogVideoX, Open-Sora, and HunyuanVideo. Our experiments reveal that even minor prompt modifications, such as the substitution or insertion of a single word, can cause substantial degradation in semantic fidelity and temporal dynamics, highlighting critical vulnerabilities in current T2V diffusion models.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-100] U-Net-Like Spiking Neural Networks for Single Image Dehazing <mark class="hl-label red">IJCNN2025</mark></p>
<p>【速读】：该论文旨在解决图像去雾（image dehazing）任务中传统方法依赖大气散射模型效率低、深度学习方法如卷积神经网络（CNNs）难以捕捉长距离依赖关系，而基于Transformer的方法又存在计算资源消耗大的问题。解决方案的关键在于提出一种融合U-Net结构与脉冲神经网络（Spiking Neural Networks, SNNs）的新型架构DehazeSNN，其核心创新是引入正交漏电积分发放模块（Orthogonal Leaky-Integrate-and-Fire Block, OLIFBlock），有效增强跨通道信息交互，在保持高去雾质量的同时显著降低模型复杂度和计算量（如乘加操作数）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23950">https://arxiv.org/abs/2512.23950</a><br>
<strong>作者</strong>: Huibin Li,Haoran Liu,Mingzhe Liu,Yulong Xiao,Peng Li,Guibin Zan<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  9 pages, 4 figures. Accepted at IJCNN 2025 (Rome, Italy). To appear in IEEE/IJCNN 2025 proceedings</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Image dehazing is a critical challenge in computer vision, essential for enhancing image clarity in hazy conditions. Traditional methods often rely on atmospheric scattering models, while recent deep learning techniques, specifically Convolutional Neural Networks (CNNs) and Transformers, have improved performance by effectively analyzing image features. However, CNNs struggle with long-range dependencies, and Transformers demand significant computational resources. To address these limitations, we propose DehazeSNN, an innovative architecture that integrates a U-Net-like design with Spiking Neural Networks (SNNs). DehazeSNN captures multi-scale image features while efficiently managing local and long-range dependencies. The introduction of the Orthogonal Leaky-Integrate-and-Fire Block (OLIFBlock) enhances cross-channel communication, resulting in superior dehazing performance with reduced computational burden. Our extensive experiments show that DehazeSNN is highly competitive to state-of-the-art methods on benchmark datasets, delivering high-quality haze-free images with a smaller model size and less multiply-accumulate operations. The proposed dehazing method is publicly available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-101] Kinematic-Based Assessment of Surgical Actions in Microanastomosis</p>
<p>【速读】：该论文旨在解决微血管吻合术（microanastomosis）训练中评估方法主观性强、效率低的问题，传统依赖专家评分或视频回溯的方式存在评价不一致和耗时长等局限。其解决方案的关键在于提出了一种基于人工智能的自动化框架，核心包括三个模块：基于YOLO与DeepSORT的器械尖端追踪与定位模块、利用自相似矩阵进行动作边界检测和无监督聚类的动作分割模块，以及用于评估手术动作熟练度的监督分类模块。该系统可在边缘计算平台上高效运行，实验证明其在帧级动作分割准确率达92.4%，技能分类准确率达85.5%，可实现客观、实时的反馈，推动外科培训向标准化、数据驱动的方向发展。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23942">https://arxiv.org/abs/2512.23942</a><br>
<strong>作者</strong>: Yan Meng,Daniel Donoho,Marcelle Altshuler,Omar Arnaout<br>
<strong>机构</strong>: Children’s National Hospital (儿童国家医院); Brigham and Women’s Hospital (布里格姆妇女医院); Harvard Medical School (哈佛医学院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Proficiency in microanastomosis is a critical surgical skill in neurosurgery, where the ability to precisely manipulate fine instruments is crucial to successful outcomes. These procedures require sustained attention, coordinated hand movements, and highly refined motor skills, underscoring the need for objective and systematic methods to evaluate and enhance microsurgical training. Conventional assessment approaches typically rely on expert raters supervising the procedures or reviewing surgical videos, which is an inherently subjective process prone to inter-rater variability, inconsistency, and significant time investment. These limitations highlight the necessity for automated and scalable solutions. To address this challenge, we introduce a novel AI-driven framework for automated action segmentation and performance assessment in microanastomosis procedures, designed to operate efficiently on edge computing platforms. The proposed system comprises three main components: (1) an object tip tracking and localization module based on YOLO and DeepSORT; (2) an action segmentation module leveraging self-similarity matrix for action boundary detection and unsupervised clustering; and (3) a supervised classification module designed to evaluate surgical gesture proficiency. Experimental validation on a dataset of 58 expert-rated microanastomosis videos demonstrates the effectiveness of our approach, achieving a frame-level action segmentation accuracy of 92.4% and an overall skill classification accuracy of 85.5% in replicating expert evaluations. These findings demonstrate the potential of the proposed method to provide objective, real-time feedback in microsurgical education, thereby enabling more standardized, data-driven training protocols and advancing competency assessment in high-stakes surgical environments.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-102] Learnable Query Aggregation with KV Routing for Cross-view Geo-localisation</p>
<p>【速读】：该论文旨在解决跨视图地理定位（Cross-view geo-localisation, CVGL）中因视角差异显著而导致的特征聚合与对齐困难问题。其解决方案的关键在于三个核心改进：首先，采用DINOv2主干网络结合卷积适配器微调，提升模型对跨视图变化的适应能力；其次，设计多尺度通道重分配模块，增强空间表示的多样性与稳定性；最后，提出融合Mixture-of-Experts（MoE）路由机制的改进型聚合模块，在交叉注意力框架中动态选择键（keys）和值（values）的专家子空间，实现对异构输入域的自适应处理，从而在减少训练参数的同时取得优异的定位性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23938">https://arxiv.org/abs/2512.23938</a><br>
<strong>作者</strong>: Hualin Ye,Bingxi Liu,Jixiang Du,Yu Qin,Ziyi Chen,Hong Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  7 pages, 4 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Cross-view geo-localisation (CVGL) aims to estimate the geographic location of a query image by matching it with images from a large-scale database. However, the significant view-point discrepancies present considerable challenges for effective feature aggregation and alignment. To address these challenges, we propose a novel CVGL system that incorporates three key improvements. Firstly, we leverage the DINOv2 backbone with a convolution adapter fine-tuning to enhance model adaptability to cross-view variations. Secondly, we propose a multi-scale channel reallocation module to strengthen the diversity and stability of spatial representations. Finally, we propose an improved aggregation module that integrates a Mixture-of-Experts (MoE) routing into the feature aggregation process. Specifically, the module dynamically selects expert subspaces for the keys and values in a cross-attention framework, enabling adaptive processing of heterogeneous input domains. Extensive experiments on the University-1652 and SUES-200 datasets demonstrate that our method achieves competitive performance with fewer trained parameters.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-103] MGML: A Plug-and-Play Meta-Guided Multi-Modal Learning Framework for Incomplete Multimodal Brain Tumor Segmentation</p>
<p>【速读】：该论文旨在解决临床实践中多模态磁共振成像（Multimodal MRI）数据常因缺失而导致病变分割性能下降的问题。其核心挑战在于如何在输入模态不完整的情况下，最大化利用可用的多模态信息以提升分割准确性与模型鲁棒性。解决方案的关键在于提出一种新颖的元引导多模态学习（Meta-guided Multi-modal Learning, MGML）框架，该框架包含两个核心组件：一是元参数自适应模态融合（Meta-parameterized Adaptive Modality Fusion, Meta-AMF），通过生成基于可用模态的自适应软标签监督信号，实现不同输入条件下模态间更一致的信息融合；二是一致性正则化模块，增强分割性能并隐式提升模型的泛化能力。该方法无需修改原始网络结构，可无缝集成至训练流程中，实现在BraTS2020和BraTS2023数据集上优于多个前沿方法的分割效果。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23936">https://arxiv.org/abs/2512.23936</a><br>
<strong>作者</strong>: Yulong Zou,Bo Liu,Cun-Jing Zheng,Yuan-ming Geng,Siyue Li,Qiankun Zuo,Shuihua Wang,Yudong Zhang,Jin Hong<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Leveraging multimodal information from Magnetic Resonance Imaging (MRI) plays a vital role in lesion segmentation, especially for brain tumors. However, in clinical practice, multimodal MRI data are often incomplete, making it challenging to fully utilize the available information. Therefore, maximizing the utilization of this incomplete multimodal information presents a crucial research challenge. We present a novel meta-guided multi-modal learning (MGML) framework that comprises two components: meta-parameterized adaptive modality fusion and consistency regularization module. The meta-parameterized adaptive modality fusion (Meta-AMF) enables the model to effectively integrate information from multiple modalities under varying input conditions. By generating adaptive soft-label supervision signals based on the available modalities, Meta-AMF explicitly promotes more coherent multimodal fusion. In addition, the consistency regularization module enhances segmentation performance and implicitly reinforces the robustness and generalization of the overall framework. Notably, our approach does not alter the original model architecture and can be conveniently integrated into the training pipeline for end-to-end model optimization. We conducted extensive experiments on the public BraTS2020 and BraTS2023 datasets. Compared to multiple state-of-the-art methods from previous years, our method achieved superior performance. On BraTS2020, for the average Dice scores across fifteen missing modality combinations, building upon the baseline, our method obtained scores of 87.55, 79.36, and 62.67 for the whole tumor (WT), the tumor core (TC), and the enhancing tumor (ET), respectively. We have made our source code publicly available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-104] Learning to learn skill assessment for fetal ultrasound scanning</p>
<p>【速读】：该论文旨在解决传统胎儿超声技能评估依赖专家主观评判和耗时反馈的问题，以及现有定量评估方法多采用监督学习且受限于预设因素的局限性。其解决方案的关键在于提出一种双层优化框架（bi-level optimisation framework），通过联合优化临床任务预测器与技能预测器两个网络，无需人工预先定义技能评分，直接以任务执行效果作为技能指标，从而实现对超声操作技能的自动化、客观化量化评估。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23920">https://arxiv.org/abs/2512.23920</a><br>
<strong>作者</strong>: Yipei Wang,Qianye Yang,Lior Drukker,Aris T. Papageorghiou,Yipeng Hu,J. Alison Noble<br>
<strong>机构</strong>: University of Oxford (牛津大学); University College London (伦敦大学学院); Nuffield Department of Women’s &amp; Reproductive Health, University of Oxford (牛津大学妇女与生殖健康系); Rabin-Beilinson Medical Center, Tel-Aviv University Faculty of Medicine (特拉维夫大学医学院拉宾-贝林森医学中心)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Traditionally, ultrasound skill assessment has relied on expert supervision and feedback, a process known for its subjectivity and time-intensive nature. Previous works on quantitative and automated skill assessment have predominantly employed supervised learning methods, often limiting the analysis to predetermined or assumed factors considered influential in determining skill levels. In this work, we propose a novel bi-level optimisation framework that assesses fetal ultrasound skills by how well a task is performed on the acquired fetal ultrasound images, without using manually predefined skill ratings. The framework consists of a clinical task predictor and a skill predictor, which are optimised jointly by refining the two networks simultaneously. We validate the proposed method on real-world clinical ultrasound videos of scanning the fetal head. The results demonstrate the feasibility of predicting ultrasound skills by the proposed framework, which quantifies optimised task performance as a skill indicator.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-105] Scaling Remote Sensing Foundation Models: Data Domain Tradeoffs at the Peta-Scale</p>
<p>【速读】：该论文旨在解决高分辨率遥感（Remote Sensing, RS）领域中基础模型训练缺乏有效扩展规律的问题，尤其是在数据规模远超当前技术水平的情况下如何优化模型性能。其解决方案的关键在于通过大规模实验验证在超过千万亿像素的商业卫星电光（Electro-Optical, EO）数据集上训练视觉Transformer（Vision Transformer, ViT）模型时的缩放行为，发现即使在petascale级别仍处于数据受限而非参数受限的性能区间，从而为遥感领域基础模型的数据采集策略、计算资源分配和优化调度提供了实证依据与实践指导。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23903">https://arxiv.org/abs/2512.23903</a><br>
<strong>作者</strong>: Charith Wickrema,Eliza Mace,Hunter Brown,Heidys Cabrera,Nick Krall,Matthew O’Neill,Shivangi Sarkar,Lowell Weissman,Eric Hughes,Guido Zarrella<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We explore the scaling behaviors of artificial intelligence to establish practical techniques for training foundation models on high-resolution electro-optical (EO) datasets that exceed the current state-of-the-art scale by orders of magnitude. Modern multimodal machine learning (ML) applications, such as generative artificial intelligence (GenAI) systems for image captioning, search, and reasoning, depend on robust, domain-specialized encoders for non-text modalities. In natural-image domains where internet-scale data is plentiful, well-established scaling laws help optimize the joint scaling of model capacity, training compute, and dataset size. Unfortunately, these relationships are much less well-understood in high-value domains like remote sensing (RS). Using over a quadrillion pixels of commercial satellite EO data and the MITRE Federal AI Sandbox, we train progressively larger vision transformer (ViT) backbones, report success and failure modes observed at petascale, and analyze implications for bridging domain gaps across additional RS modalities. We observe that even at this scale, performance is consistent with a data limited regime rather than a model parameter-limited one. These practical insights are intended to inform data-collection strategies, compute budgets, and optimization schedules that advance the future development of frontier-scale RS foundation models.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-106] MRI-to-CT Synthesis With Cranial Suture Segmentations Using A Variational Autoencoder Framework</p>
<p>【速读】：该论文旨在解决儿童颅骨发育与骨缝骨化定量评估中因CT辐射暴露限制而难以进行常规影像学监测的问题。现有MRI虽无电离辐射且软组织对比度优异，但无法清晰显示颅骨缝合线及骨密度等关键结构，导致其在颅骨生长评估中的应用受限。解决方案的关键在于提出一种基于深度学习的图像转换流程，通过训练特定于儿科领域的变分自编码器（Variational Autoencoders, VAEs），将常规T1加权MRI转化为合成CT（synthetic CT, sCT），进而实现颅骨多骨分区分割（平均Dice系数85%）和骨缝概率热图生成（Dice达80%），并从热图中直接提取骨缝分割结果。该方法在结构相似性和分割一致性上与真实CT高度一致（TOST检验p &gt; 0.05），首次实现了仅依赖MRI即可获得可临床使用的颅骨及骨缝高精度三维信息，填补了无创颅骨评估的技术空白。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23894">https://arxiv.org/abs/2512.23894</a><br>
<strong>作者</strong>: Krithika Iyer,Austin Tapp,Athelia Paulli,Gabrielle Dickerson,Syed Muhammad Anwar,Natasha Lepore,Marius George Linguraru<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Quantifying normative pediatric cranial development and suture ossification is crucial for diagnosing and treating growth-related cephalic disorders. Computed tomography (CT) is widely used to evaluate cranial and sutural deformities; however, its ionizing radiation is contraindicated in children without significant abnormalities. Magnetic resonance imaging (MRI) offers radiation free scans with superior soft tissue contrast, but unlike CT, MRI cannot elucidate cranial sutures, estimate skull bone density, or assess cranial vault growth. This study proposes a deep learning driven pipeline for transforming T1 weighted MRIs of children aged 0.2 to 2 years into synthetic CTs (sCTs), predicting detailed cranial bone segmentation, generating suture probability heatmaps, and deriving direct suture segmentation from the heatmaps. With our in-house pediatric data, sCTs achieved 99% structural similarity and a Frechet inception distance of 1.01 relative to real CTs. Skull segmentation attained an average Dice coefficient of 85% across seven cranial bones, and sutures achieved 80% Dice. Equivalence of skull and suture segmentation between sCTs and real CTs was confirmed using two one sided tests (TOST p  0.05). To our knowledge, this is the first pediatric cranial CT synthesis framework to enable suture segmentation on sCTs derived from MRI, despite MRI’s limited depiction of bone and sutures. By combining robust, domain specific variational autoencoders, our method generates perceptually indistinguishable cranial sCTs from routine pediatric MRIs, bridging critical gaps in non invasive cranial evaluation.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-107] Learning to Feel the Future: DreamTacVLA for Contact-Rich Manipulation</p>
<p>【速读】：该论文旨在解决当前视觉-语言-动作（Vision-Language-Action, VLA）模型在接触密集型操作任务中因缺乏对物理接触的感知而表现不佳的问题，尤其是在力、纹理和滑移等细粒度接触动力学建模上的不足。其解决方案的关键在于提出DreamTacVLA框架，通过引入高分辨率触觉图像作为微观视觉输入，并结合腕部相机局部视觉与第三人称宏观视觉，构建多尺度感知体系；同时采用分层空间对齐（Hierarchical Spatial Alignment, HSA）损失函数对齐触觉token与视觉对应区域，再通过触觉世界模型预测未来触觉信号以增强对接触物理的理解，从而实现基于真实观测与想象后果的动作决策，显著提升机器人在复杂接触任务中的成功率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23864">https://arxiv.org/abs/2512.23864</a><br>
<strong>作者</strong>: Guo Ye,Zexi Zhang,Xu Zhao,Shang Wu,Haoran Lu,Shihan Lu,Han Liu<br>
<strong>机构</strong>: Northwestern University (西北大学)<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Vision-Language-Action (VLA) models have shown remarkable generalization by mapping web-scale knowledge to robotic control, yet they remain blind to physical contact. Consequently, they struggle with contact-rich manipulation tasks that require reasoning about force, texture, and slip. While some approaches incorporate low-dimensional tactile signals, they fail to capture the high-resolution dynamics essential for such interactions. To address this limitation, we introduce DreamTacVLA, a framework that grounds VLA models in contact physics by learning to feel the future. Our model adopts a hierarchical perception scheme in which high-resolution tactile images serve as micro-vision inputs coupled with wrist-camera local vision and third-person macro vision. To reconcile these multi-scale sensory streams, we first train a unified policy with a Hierarchical Spatial Alignment (HSA) loss that aligns tactile tokens with their spatial counterparts in the wrist and third-person views. To further deepen the model’s understanding of fine-grained contact dynamics, we finetune the system with a tactile world model that predicts future tactile signals. To mitigate tactile data scarcity and the wear-prone nature of tactile sensors, we construct a hybrid large-scale dataset sourced from both high-fidelity digital twin and real-world experiments. By anticipating upcoming tactile states, DreamTacVLA acquires a rich model of contact physics and conditions its actions on both real observations and imagined consequences. Across contact-rich manipulation tasks, it outperforms state-of-the-art VLA baselines, achieving up to 95% success, highlighting the importance of understanding physical contact for robust, touch-aware robotic agents.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-108] Lifelong Domain Adaptive 3D Human Pose Estimation <mark class="hl-label red">AAAI2026</mark></p>
<p>【速读】：该论文旨在解决3D人体姿态估计（3D Human Pose Estimation, 3D HPE）在跨域适应中的两个核心问题：一是现有领域自适应（Domain Adaptation, DA）方法忽视了目标域姿态数据的非平稳性（non-stationary target pose datasets），二是模型在持续适应新目标域时面临灾难性遗忘（catastrophic forgetting）的问题。为此，作者首次将终身领域自适应（Lifelong Domain Adaptation, Lifelong DA）引入3D HPE任务，提出一种新型框架——在仅能访问当前目标域且无法获取源域及历史目标域数据的前提下，实现对当前域的有效适应并保留先前知识。解决方案的关键在于设计了一个创新的生成对抗网络（Generative Adversarial Network, GAN）架构，包含3D姿态生成器、2D姿态判别器和3D姿态估测器，其中3D姿态生成器融合了姿态感知（pose-aware）、时间感知（temporal-aware）和领域感知（domain-aware）的知识，从而有效缓解域间分布偏移，并显著减轻对先前域知识的遗忘。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23860">https://arxiv.org/abs/2512.23860</a><br>
<strong>作者</strong>: Qucheng Peng,Hongfei Xue,Pu Wang,Chen Chen<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  Accepted by AAAI 2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:3D Human Pose Estimation (3D HPE) is vital in various applications, from person re-identification and action recognition to virtual reality. However, the reliance on annotated 3D data collected in controlled environments poses challenges for generalization to diverse in-the-wild scenarios. Existing domain adaptation (DA) paradigms like general DA and source-free DA for 3D HPE overlook the issues of non-stationary target pose datasets. To address these challenges, we propose a novel task named lifelong domain adaptive 3D HPE. To our knowledge, we are the first to introduce the lifelong domain adaptation to the 3D HPE task. In this lifelong DA setting, the pose estimator is pretrained on the source domain and subsequently adapted to distinct target domains. Moreover, during adaptation to the current target domain, the pose estimator cannot access the source and all the previous target domains. The lifelong DA for 3D HPE involves overcoming challenges in adapting to current domain poses and preserving knowledge from previous domains, particularly combating catastrophic forgetting. We present an innovative Generative Adversarial Network (GAN) framework, which incorporates 3D pose generators, a 2D pose discriminator, and a 3D pose estimator. This framework effectively mitigates domain shifts and aligns original and augmented poses. Moreover, we construct a novel 3D pose generator paradigm, integrating pose-aware, temporal-aware, and domain-aware knowledge to enhance the current domain’s adaptation and alleviate catastrophic forgetting on previous domains. Our method demonstrates superior performance through extensive experiments on diverse domain adaptive 3D HPE datasets.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-109] Pretraining Frame Preservation in Autoregressive Video Memory Compression</p>
<p>【速读】：该论文旨在解决长视频压缩与高效记忆编码的问题，即如何在保持单帧高频率细节的前提下，将长时间视频压缩为短上下文表示，并支持任意时间位置的高质量帧检索。其解决方案的关键在于提出一种名为PFP的神经网络结构，该结构通过显式的预训练目标来保留单帧在任意时间位置上的高频细节，从而使得20秒视频可被压缩至约5k长度的上下文，且随机抽取的帧仍能保持感知质量；此外，该模型可直接微调为自回归视频模型的记忆编码器，在低上下文开销下实现长期历史记忆，同时控制保真度损失。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23851">https://arxiv.org/abs/2512.23851</a><br>
<strong>作者</strong>: Lvmin Zhang,Shengqu Cai,Muyang Li,Chong Zeng,Beijia Lu,Anyi Rao,Song Han,Gordon Wetzstein,Maneesh Agrawala<br>
<strong>机构</strong>: Stanford University (斯坦福大学); MIT (麻省理工学院); Carnegie Mellon University (卡内基梅隆大学); HKUST (香港科技大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:   <a target="_blank" rel="noopener" href="https://github.com/lllyasviel/PFP">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present PFP, a neural network structure to compress long videos into short contexts, with an explicit pretraining objective to preserve the high-frequency details of single frames at arbitrary temporal positions. The baseline model can compress a 20-second video into a context at about 5k length, where random frames can be retrieved with perceptually preserved appearances. Such pretrained models can be directly fine-tuned as memory encoders for autoregressive video models, enabling long history memory with low context cost and relatively low fidelity loss. We evaluate the framework with ablative settings and discuss the trade-offs of possible neural architecture designs.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-110] Video-Based Performance Evaluation for ECR Drills in Synthetic Training Environments</p>
<p>【速读】：该论文旨在解决军事训练中对“进入并清空房间”（Enter and Clear the Room, ECR）这类复杂战术动作的自动化、客观化绩效评估难题，尤其在合成训练环境（Synthetic Training Environment, STE）中如何准确量化认知能力、运动技能与团队协作等多维表现。其解决方案的关键在于构建一个基于视频的分析流程，通过计算机视觉模型提取训练视频中的2D骨骼信息、视线向量（gaze vectors）和移动轨迹，进而设计任务特定指标来衡量心理运动流畅性、情境意识和团队协调性；这些指标被整合进扩展的认知任务分析（Cognitive Task Analysis, CTA）层次结构中，采用加权融合方式生成综合性能评分，从而实现无需额外硬件即可进行可扩展、客观的绩效评估，并支持在Gamemaster与GIFT框架内提供交互式复盘反馈。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23819">https://arxiv.org/abs/2512.23819</a><br>
<strong>作者</strong>: Surya Rayala,Marcos Quinones-Grueiro,Naveeduddin Mohammed,Ashwin T S,Benjamin Goldberg,Randall Spain,Paige Lawton,Gautam Biswas<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  14 pages, 9 figures, I/ITSEC-2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Effective urban warfare training requires situational awareness and muscle memory, developed through repeated practice in realistic yet controlled environments. A key drill, Enter and Clear the Room (ECR), demands threat assessment, coordination, and securing confined spaces. The military uses Synthetic Training Environments that offer scalable, controlled settings for repeated exercises. However, automatic performance assessment remains challenging, particularly when aiming for objective evaluation of cognitive, psychomotor, and teamwork skills. Traditional methods often rely on costly, intrusive sensors or subjective human observation, limiting scalability and accuracy. This paper introduces a video-based assessment pipeline that derives performance analytics from training videos without requiring additional hardware. By utilizing computer vision models, the system extracts 2D skeletons, gaze vectors, and movement trajectories. From these data, we develop task-specific metrics that measure psychomotor fluency, situational awareness, and team coordination. These metrics feed into an extended Cognitive Task Analysis (CTA) hierarchy, which employs a weighted combination to generate overall performance scores for teamwork and cognition. We demonstrate the approach with a case study of real-world ECR drills, providing actionable, domain specific metrics that capture individual and team performance. We also discuss how these insights can support After Action Reviews with interactive dashboards within Gamemaster and the Generalized Intelligent Framework for Tutoring (GIFT), providing intuitive and understandable feedback. We conclude by addressing limitations, including tracking difficulties, ground-truth validation, and the broader applicability of our approach. Future work includes expanding analysis to 3D video data and leveraging video analysis to enable scalable evaluation within STEs.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-111] Leve<mark class="hl-label green">rag</mark> ing Synthetic Priors for Monocular Depth Estimation in Specular Surgical Environments</p>
<p>【速读】：该论文旨在解决单目深度估计（Monocular Depth Estimation, MDE）在镜面反射和充满液体的内窥镜环境中的鲁棒性问题，尤其是现有自监督方法因依赖噪声较大的真实世界伪标签而导致细小手术工具和透明表面边界塌陷的问题。解决方案的关键在于利用Depth Anything V2架构提供的高保真合成先验，其天然能捕捉细结构的精确几何信息，并通过动态向量低秩适配（Dynamic Vector Low-Rank Adaptation, DV-LORA）高效地将这些先验迁移到医疗领域，同时最小化参数预算并缩小合成到真实场景的差距；此外，引入基于物理分层的评估协议以更严谨地量化高镜面反射条件下的性能表现。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23786">https://arxiv.org/abs/2512.23786</a><br>
<strong>作者</strong>: Ankan Aich,Yangming Lee<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Accurate Monocular Depth Estimation (MDE) is critical for robotic surgery but remains fragile in specular, fluid-filled endoscopic environments. Existing self-supervised methods, typically relying on foundation models trained with noisy real-world pseudo-labels, often suffer from boundary collapse on thin surgical tools and transparent surfaces. In this work, we address this by leveraging the high-fidelity synthetic priors of the Depth Anything V2 architecture, which inherently captures precise geometric details of thin structures. We efficiently adapt these priors to the medical domain using Dynamic Vector Low-Rank Adaptation (DV-LORA), minimizing the parameter budget while bridging the synthetic-to-real gap. Additionally, we introduce a physically-stratified evaluation protocol on the SCARED dataset to rigorously quantify performance in high-specularity regimes often masked by aggregate metrics. Our approach establishes a new state-of-the-art, achieving an accuracy ( 1.25) of 98.1% and reducing Squared Relative Error by over 17% compared to established baselines, demonstrating superior robustness in adverse surgical lighting.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-112] A Granular Grassmannian Clustering Framework via the Schubert Variety of Best Fit</p>
<p>【速读】：该论文旨在解决多类子空间聚类任务中如何更准确地计算几何代表性元素的问题，特别是在数据以子空间形式表示时，传统方法（如均值或中位数）在Grassmann流形或旗流形上的表达能力受限。其解决方案的关键在于引入一种可训练的原型——最佳拟合施伯特簇（Schubert Variety of Best Fit, SVBF），该原型定义为一个能尽可能在至少一个固定方向上与每个簇成员相交的子空间，从而替代传统的子空间均值。SVBF-LBG算法将这一思想嵌入Linde-Buzo-Grey (LBG) 聚类框架中，在合成数据、图像、光谱和视频动作等多类数据集上实现了更高的聚类纯度，同时保持了下游分析所需的数学结构。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23766">https://arxiv.org/abs/2512.23766</a><br>
<strong>作者</strong>: Karim Salta,Michael Kirby,Chris Peterson<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computational Geometry (<a target="_blank" rel="noopener" href="http://cs.CG">cs.CG</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Distributed, Parallel, and Cluster Computing (cs.DC)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In many classification and clustering tasks, it is useful to compute a geometric representative for a dataset or a cluster, such as a mean or median. When datasets are represented by subspaces, these representatives become points on the Grassmann or flag manifold, with distances induced by their geometry, often via principal angles. We introduce a subspace clustering algorithm that replaces subspace means with a trainable prototype defined as a Schubert Variety of Best Fit (SVBF) - a subspace that comes as close as possible to intersecting each cluster member in at least one fixed direction. Integrated in the Linde-Buzo-Grey (LBG) pipeline, this SVBF-LBG scheme yields improved cluster purity on synthetic, image, spectral, and video action data, while retaining the mathematical structure required for downstream analysis.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-113] owards autonomous time-calibration of large quantum-dot devices: Detection real-time feedback and noise spectroscopy</p>
<p>【速读】：该论文旨在解决半导体量子点（Quantum-dot, QD）量子比特在扩展至大规模一维或二维阵列时，因静电漂移和电荷噪声导致的操作点偏移与量子比特参数不稳定的问题，从而限制了其性能与可扩展性。解决方案的关键在于利用重复获取的双量子点电荷稳定性图（Charge Stability Diagrams, CSDs）中完整的电荷跃迁线网络，作为局部静电环境的多维探测器；通过精确追踪特定跃迁随时间的运动，实现电压漂移检测、突发电荷重构识别，并自动实施补偿更新以维持稳定工作状态。此方法不仅实现了对10量子比特器件的鲁棒稳定控制，还结合高采样率的射频反射测量，支持时域噪声谱分析，提取噪声功率谱密度、识别两能级波动器（Two-Level Fluctuators, TLFs）并解析阵列内空间噪声关联特性，为基于量子点的量子处理器提供了可扩展的自主校准与表征模块。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24894">https://arxiv.org/abs/2512.24894</a><br>
<strong>作者</strong>: Anantha S. Rao,Barnaby van Straaten,Valentin John,Cécile X. Yu,Stefan D. Oosterhout,Lucas Stehouwer,Giordano Scappucci,M. D. Stewart Jr.,Menno Veldhorst,Francesco Borsoi,Justyna P. Zwolak<br>
<strong>机构</strong>: University of Maryland, College Park (马里兰大学学院公园分校); Delft University of Technology (代尔夫特理工大学); QuTech; Kavli Institute of Nanoscience (卡夫里纳米科学研究所); Netherlands Organisation for Applied Scientific Research (TNO) (荷兰应用科学研究组织); National Institute of Standards and Technology (美国国家标准与技术研究院); Niels Bohr Institute (尼尔斯·玻尔研究所)<br>
<strong>类目</strong>: Mesoscale and Nanoscale Physics (cond-mat.mes-hall); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Emerging Technologies (<a target="_blank" rel="noopener" href="http://cs.ET">cs.ET</a>); Quantum Physics (quant-ph)<br>
<strong>备注</strong>:  12 pages, 4 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The performance and scalability of semiconductor quantum-dot (QD) qubits are limited by electrostatic drift and charge noise that shift operating points and destabilize qubit parameters. As systems expand to large one- and two-dimensional arrays, manual recalibration becomes impractical, creating a need for autonomous stabilization frameworks. Here, we introduce a method that uses the full network of charge-transition lines in repeatedly acquired double-quantum-dot charge stability diagrams (CSDs) as a multidimensional probe of the local electrostatic environment. By accurately tracking the motion of selected transitions in time, we detect voltage drifts, identify abrupt charge reconfigurations, and apply compensating updates to maintain stable operating conditions. We demonstrate our approach on a 10-QD device, showing robust stabilization and real-time diagnostic access to dot-specific noise processes. The high acquisition rate of radio-frequency reflectometry CSD measurements also enables time-domain noise spectroscopy, allowing the extraction of noise power spectral densities, the identification of two-level fluctuators, and the analysis of spatial noise correlations across the array. From our analysis, we find that the background noise at 100~ \mu \si\hertz is dominated by drift with a power law of  1/f^2 , accompanied by a few dominant two-level fluctuators and an average linear correlation length of  (188 \pm 38) ~\si\nano\meter in the device. These capabilities form the basis of a scalable, autonomous calibration and characterization module for QD-based quantum processors, providing essential feedback for long-duration, high-fidelity qubit operations.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-114] Automated Classification of First-Trimester Fetal Heart Views Using Ultrasound-Specific Self-Supervised Learning</p>
<p>【速读】：该论文旨在解决<strong>早期胎儿心脏超声图像自动分析</strong>的难题，特别是在孕早期（first-trimester）由于心脏结构小、信噪比低以及操作者间差异大等因素导致的诊断准确性不足问题。其解决方案的关键在于提出并验证了一种基于<strong>自监督学习的超声基础模型（USF-MAE）</strong>，该模型通过在超过37万张未标注的超声图像上进行掩码自编码（masked autoencoding）预训练，从而学习到通用的超声图像表征，并在此基础上微调用于五类孕早期胎儿心脏视图分类任务。相比传统监督学习方法（如ResNet-18、ResNet-50）和自然图像预训练的Vision Transformer（ViT-B/16），USF-MAE展现出更高的准确率（90.57%）、F1分数（90.71%），且无需依赖复杂的图像预处理或感兴趣区域裁剪，显著提升了对非诊断性帧的区分能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24492">https://arxiv.org/abs/2512.24492</a><br>
<strong>作者</strong>: Youssef Megahed,Aylin Erman,Robin Ducharme,Mark C. Walker,Steven Hawken,Adrian D. C. Chan<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Image and Video Processing (eess.IV); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  7 pages, 4 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Congenital heart disease remains the most common congenital anomaly and a leading cause of neonatal morbidity and mortality. Although first-trimester fetal echocardiography offers an opportunity for earlier detection, automated analysis at this stage is challenging due to small cardiac structures, low signal-to-noise ratio, and substantial inter-operator variability. In this work, we evaluate a self-supervised ultrasound foundation model, USF-MAE, for first-trimester fetal heart view classification. USF-MAE is pretrained using masked autoencoding modelling on more than 370,000 unlabelled ultrasound images spanning over 40 anatomical regions and is subsequently fine-tuned for downstream classification. As a proof of concept, the pretrained Vision Transformer encoder was fine-tuned on an open-source dataset of 6,720 first-trimester fetal echocardiography images to classify five categories: aorta, atrioventricular flows, V sign, X sign, and Other. Model performance was benchmarked against supervised convolutional neural network baselines (ResNet-18 and ResNet-50) and a Vision Transformer (ViT-B/16) model pretrained on natural images (ImageNet-1k). All models were trained and evaluated using identical preprocessing, data splits, and optimization protocols. On an independent test set, USF-MAE achieved the highest performance across all evaluation metrics, with 90.57% accuracy, 91.15% precision, 90.57% recall, and 90.71% F1-score. This represents an improvement of +2.03% in accuracy and +1.98% in F1-score compared with the strongest baseline, ResNet-18. The proposed approach demonstrated robust performance without reliance on aggressive image preprocessing or region-of-interest cropping and showed improved discrimination of non-diagnostic frames.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-115] argeted Semantic Segmentation of Himalayan Glacial Lakes Using Time-Series SAR: Towards Automated GLOF Early Warning</p>
<p>【速读】：该论文旨在解决冰川湖溃决洪水（Glacial Lake Outburst Floods, GLOFs）监测中因传统遥感方法受限于云层遮挡或缺乏针对性而难以实现高效早期预警的问题。其解决方案的关键在于提出了一种“时间优先”（temporal-first）的深度学习训练策略，采用基于EfficientNet-B3骨干网络的U-Net模型，在4个高风险喜马拉雅冰川湖（Tsho Rolpa、Chamlang Tsho、Tilicho和Gokyo Lake）的时序Sentinel-1合成孔径雷达（SAR）数据上进行训练，实现了0.9130的交并比（IoU），验证了该策略在动态识别与自动化预警中的有效性。同时，论文构建了一个容器化（Dockerised）工程架构，通过ASF搜索API自动获取数据并以RESTful接口输出推理结果，推动从静态制图向动态自动化早期预警系统的范式转变。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24117">https://arxiv.org/abs/2512.24117</a><br>
<strong>作者</strong>: Pawan Adhikari,Satish Raj Regmi,Hari Ram Shrestha<br>
<strong>机构</strong>: Space Research Center (空间研究中心); Nepal Academy of Science and Technology (尼泊尔科学与技术学院)<br>
<strong>类目</strong>: Image and Video Processing (eess.IV); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  12 pages, 6 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Glacial Lake Outburst Floods (GLOFs) are one of the most devastating climate change induced hazards. Existing remote monitoring approaches often prioritise maximising spatial coverage to train generalistic models or rely on optical imagery hampered by persistent cloud coverage. This paper presents an end-to-end, automated deep learning pipeline for the targeted monitoring of high-risk Himalayan glacial lakes using time-series Sentinel-1 SAR. We introduce a “temporal-first” training strategy, utilising a U-Net with an EfficientNet-B3 backbone trained on a curated dataset of a cohort of 4 lakes (Tsho Rolpa, Chamlang Tsho, Tilicho and Gokyo Lake). The model achieves an IoU of 0.9130 validating the success and efficacy of the “temporal-first” strategy required for transitioning to Early Warning Systems. Beyond the model, we propose an operational engineering architecture: a Dockerised pipeline that automates data ingestion via the ASF Search API and exposes inference results via a RESTful endpoint. This system shifts the paradigm from static mapping to dynamic and automated early warning, providing a scalable architectural foundation for future development in Early Warning Systems.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-116] One-Shot Structured Pruning of Quantum Neural Networks via q-Group Engineering and Quantum Geometric Metrics</p>
<p>【速读】：该论文旨在解决量子神经网络（Quantum Neural Networks, QNNs）在噪声中等规模量子（Noisy Intermediate-Scale Quantum, NISQ）设备上部署时面临的严重门级冗余问题，这种冗余导致电路复杂度高、资源消耗大且难以实现高效计算。解决方案的关键在于提出一种基于q-变形群代数结构和任务相关量子几何的单次结构化剪枝框架——q-iPrune。其核心创新在于：通过任务相关的q重叠距离（q-overlap distance）在代数一致的子群内比较每个门的功能相似性，并仅当用子群代表门替换原门可保证所有任务可观测量的偏差被严格控制时才进行剪枝，从而实现理论上完备、功能等价且计算可行的门级冗余消除。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24019">https://arxiv.org/abs/2512.24019</a><br>
<strong>作者</strong>: Haijian Shao,Wei Liu,Xing Deng,Yingtao Jiang<br>
<strong>机构</strong>: Jiangsu University of Science and Technology (江苏科技大学); University of Nevada, Las Vegas (内华达大学拉斯维加斯分校)<br>
<strong>类目</strong>: Quantum Physics (quant-ph); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  10 pages, 2 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Quantum neural networks (QNNs) suffer from severe gate-level redundancy, which hinders their deployment on noisy intermediate-scale quantum (NISQ) devices. In this work, we propose q-iPrune, a one-shot structured pruning framework grounded in the algebraic structure of  q -deformed groups and task-conditioned quantum geometry. Unlike prior heuristic or gradient-based pruning methods, q-iPrune formulates redundancy directly at the gate level. Each gate is compared within an algebraically consistent subgroup using a task-conditioned  q -overlap distance, which measures functional similarity through state overlaps on a task-relevant ensemble. A gate is removed only when its replacement by a subgroup representative provably induces a bounded deviation on all task observables. We establish three rigorous theoretical guarantees. First, we prove completeness of redundancy pruning: no gate that violates the prescribed similarity threshold is removed. Second, we show that the pruned circuit is functionally equivalent up to an explicit, task-conditioned error bound, with a closed-form dependence on the redundancy tolerance and the number of replaced gates. Third, we prove that the pruning procedure is computationally feasible, requiring only polynomial-time comparisons and avoiding exponential enumeration over the Hilbert space. To adapt pruning decisions to hardware imperfections, we introduce a noise-calibrated deformation parameter  \lambda  that modulates the  q -geometry and redundancy tolerance. Experiments on standard quantum machine learning benchmarks demonstrate that q-iPrune achieves substantial gate reduction while maintaining bounded task performance degradation, consistent with our theoretical guarantees.          Comments: 10 pages, 2 figures   Subjects:  Quantum Physics (quant-ph); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)  Cite as: arXiv:2512.24019 [quant-ph]    (or  arXiv:2512.24019v1 [quant-ph] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24019">https://doi.org/10.48550/arXiv.2512.24019</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)        Submission history From: Haijian Shao [view email]       [v1]         Tue, 30 Dec 2025 06:37:28 UTC (41 KB)<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-117] A multimodal Transformer for InSAR-based ground deformation forecasting with cross-site generalization across Europe</p>
<p>【速读】：该论文旨在解决近实时、区域尺度地表形变预测难题，即如何从欧洲地表运动服务（EGMS）提供的时序数据中准确预测下一时刻的位移图，以支持城市规划、关键基础设施管理和自然灾害缓解。其核心挑战在于形变信号包含长期趋势、季节性周期与突发不连续事件（如地震阶跃）的叠加，且空间异质性强。解决方案的关键在于提出一种基于多模态补丁的Transformer架构，该模型同时利用近期位移快照、静态运动指标（平均速度、加速度、季节振幅）和日序谐波编码作为输入，在固定时间间隔下实现单步位移图预估，显著优于CNN-LSTM、CNN-LSTM+注意力机制及多模态STGCN等基线模型，测试集上达到RMSE = 0.90 mm、R² = 0.97的性能表现。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23906">https://arxiv.org/abs/2512.23906</a><br>
<strong>作者</strong>: Wendong Yao,Binhua Huang,Soumyabrata Dev<br>
<strong>机构</strong>: The ADAPT SFI Research Centre, Dublin, Ireland; School of Computer Science, University College Dublin, Belfield, Dublin, Ireland<br>
<strong>类目</strong>: ignal Processing (eess.SP); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  submitted to ISPRS Journal of Photogrammetry and Remote Sensing for review</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Near-real-time regional-scale monitoring of ground deformation is increasingly required to support urban planning, critical infrastructure management, and natural hazard mitigation. While Interferometric Synthetic Aperture Radar (InSAR) and continental-scale services such as the European Ground Motion Service (EGMS) provide dense observations of past motion, predicting the next observation remains challenging due to the superposition of long-term trends, seasonal cycles, and occasional abrupt discontinuities (e.g., co-seismic steps), together with strong spatial heterogeneity. In this study we propose a multimodal patch-based Transformer for single-step, fixed-interval next-epoch nowcasting of displacement maps from EGMS time series (resampled to a 64x64 grid over 100 km x 100 km tiles). The model ingests recent displacement snapshots together with (i) static kinematic indicators (mean velocity, acceleration, seasonal amplitude) computed in a leakage-safe manner from the training window only, and (ii) harmonic day-of-year encodings. On the eastern Ireland tile (E32N34), the STGCN is strongest in the displacement-only setting, whereas the multimodal Transformer clearly outperforms CNN-LSTM, CNN-LSTM+Attn, and multimodal STGCN when all models receive the same multimodal inputs, achieving RMSE = 0.90 mm and  R^2  = 0.97 on the test set with the best threshold accuracies.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-118] Leve<mark class="hl-label green">rag</mark> ing Machine Learning for Early Detection of Lung Diseases</p>
<p>【速读】：该论文旨在解决医疗资源匮乏地区对呼吸系统疾病（如新冠肺炎、肺癌和肺炎）进行快速、准确且非侵入性诊断的难题。其解决方案的关键在于将传统图像处理技术与先进的深度学习神经网络模型相结合，通过训练和验证多种卷积神经网络（CNNs）、VGG16、InceptionV3 和 EfficientNetB0 模型，在胸部X光图像上实现高精度的病灶识别，从而为临床提供可靠的辅助诊断工具，推动预测性和预防性医疗模式的应用。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23757">https://arxiv.org/abs/2512.23757</a><br>
<strong>作者</strong>: Bahareh Rahmani,Harsha Reddy Bindela,Rama Kanth Reddy Gosula,Krishna Yedubati,Mohammad Amir Salari,Leslie Hinyard,Payam Norouzzadeh,Eli Snir,Martin Schoen<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Image and Video Processing (eess.IV); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:A combination of traditional image processing methods with advanced neural networks concretes a predictive and preventive healthcare paradigm. This study offers rapid, accurate, and non-invasive diagnostic solutions that can significantly impact patient outcomes, particularly in areas with limited access to radiologists and healthcare resources. In this project, deep learning methods apply in enhancing the diagnosis of respiratory diseases such as COVID-19, lung cancer, and pneumonia from chest x-rays. We trained and validated various neural network models, including CNNs, VGG16, InceptionV3, and EfficientNetB0, with high accuracy, precision, recall, and F1 scores to highlight the models’ reliability and potential in real-world diagnostic applications.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-119] q3-MuPa: Quick Quiet Quantitative Multi-Parametric MRI using Physics-Informed Diffusion Models</p>
<p>【速读】：该论文旨在解决传统定量磁共振成像（qMRI）在扫描噪声大、运动敏感性强以及数据采集效率低等问题，尤其针对多参数T1、T2和质子密度（proton density）映射的精度与速度瓶颈。其解决方案的关键在于提出一种融合物理模型与深度生成模型的扩散模型方法：利用去噪扩散概率模型（DDPM）从四倍加速的MuPa-ZTE图像序列中重建高质量qMRI参数图，并在推理阶段引入MuPa-ZTE前向信号模型作为显式数据一致性（data consistency, DC）约束，从而实现高保真度、低噪声且结构细节保留良好的多参数映射。该方法仅依赖数字脑体模生成的合成数据进行训练，无需真实扫描数据，同时在真实人体和病理场景中表现出优异的泛化能力，最终形成名为q3-MuPa的快速、安静、定量的多参数成像框架。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23726">https://arxiv.org/abs/2512.23726</a><br>
<strong>作者</strong>: Shishuai Wang,Florian Wiesinger,Noemi Sgambelluri,Carolin Pirkl,Stefan Klein,Juan A. Hernandez-Tamames,Dirk H.J. Poot<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Medical Physics (physics.med-ph); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The 3D fast silent multi-parametric mapping sequence with zero echo time (MuPa-ZTE) is a novel quantitative MRI (qMRI) acquisition that enables nearly silent scanning by using a 3D phyllotaxis sampling scheme. MuPa-ZTE improves patient comfort and motion robustness, and generates quantitative maps of T1, T2, and proton density using the acquired weighted image series. In this work, we propose a diffusion model-based qMRI mapping method that leverages both a deep generative model and physics-based data consistency to further improve the mapping performance. Furthermore, our method enables additional acquisition acceleration, allowing high-quality qMRI mapping from a fourfold-accelerated MuPa-ZTE scan (approximately 1 minute). Specifically, we trained a denoising diffusion probabilistic model (DDPM) to map MuPa-ZTE image series to qMRI maps, and we incorporated the MuPa-ZTE forward signal model as an explicit data consistency (DC) constraint during inference. We compared our mapping method against a baseline dictionary matching approach and a purely data-driven diffusion model. The diffusion models were trained entirely on synthetic data generated from digital brain phantoms, eliminating the need for large real-scan datasets. We evaluated on synthetic data, a NISM/ISMRM phantom, healthy volunteers, and a patient with brain metastases. The results demonstrated that our method produces 3D qMRI maps with high accuracy, reduced noise and better preservation of structural details. Notably, it generalised well to real scans despite training on synthetic data alone. The combination of the MuPa-ZTE acquisition and our physics-informed diffusion model is termed q3-MuPa, a quick, quiet, and quantitative multi-parametric mapping framework, and our findings highlight its strong clinical potential.<br>
zh</p>
</div></div>
<h3 id="人工智能">人工智能</h3>
<div class="note blue no-icon flat"><p>[AI-0] Coordinated Humanoid Manipulation with Choice Policies</p>
<p>【速读】：该论文旨在解决人形机器人在人类-centric环境中实现头部、双手与腿部等多肢体协同操作的挑战，尤其是如何高效收集高质量示范数据并学习复杂多模态行为以适应非结构化环境。其解决方案的关键在于提出一种模块化的遥操作接口与可扩展的学习框架相结合的方法：首先通过分解控制任务为手眼协调、抓取原语、手臂末端跟踪和行走等直观子模块，实现高效的数据采集；进而引入Choice Policy——一种生成多个候选动作并学习评分的模仿学习方法，从而在保证快速推理的同时有效建模多模态行为。实验表明，该方法在洗碗机装载和全身协同操作白板擦拭两项真实场景任务中显著优于扩散策略和标准行为克隆，且验证了手眼协调对长时程任务成功的重要性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25072">https://arxiv.org/abs/2512.25072</a><br>
<strong>作者</strong>: Haozhi Qi,Yen-Jen Wang,Toru Lin,Brent Yi,Yi Ma,Koushil Sreenath,Jitendra Malik<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  Code and Website: <a target="_blank" rel="noopener" href="https://choice-policy.github.io/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Humanoid robots hold great promise for operating in human-centric environments, yet achieving robust whole-body coordination across the head, hands, and legs remains a major challenge. We present a system that combines a modular teleoperation interface with a scalable learning framework to address this problem. Our teleoperation design decomposes humanoid control into intuitive submodules, which include hand-eye coordination, grasp primitives, arm end-effector tracking, and locomotion. This modularity allows us to collect high-quality demonstrations efficiently. Building on this, we introduce Choice Policy, an imitation learning approach that generates multiple candidate actions and learns to score them. This architecture enables both fast inference and effective modeling of multimodal behaviors. We validate our approach on two real-world tasks: dishwasher loading and whole-body loco-manipulation for whiteboard wiping. Experiments show that Choice Policy significantly outperforms diffusion policies and standard behavior cloning. Furthermore, our results indicate that hand-eye coordination is critical for success in long-horizon tasks. Our work demonstrates a practical path toward scalable data collection and learning for coordinated humanoid manipulation in unstructured environments.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-1] Vulcan: Instance-Optimal Systems Heuristics Through <mark class="hl-label green">LLM</mark> -Driven Search</p>
<p>【速读】：该论文旨在解决现代操作系统与分布式系统中资源管理任务（如调度、缓存和主动队列管理）长期依赖人工设计启发式策略所带来的高成本与低适应性问题，这些问题因硬件、工作负载和环境的持续变化而愈发突出。解决方案的关键在于提出Vulcan框架，通过将策略（policy）与机制（mechanism）解耦，并利用大语言模型（LLM）生成代码的能力，在任务无关的接口下实现实例最优启发式的自动合成。该方法借助进化搜索在LLM生成的代码空间中寻找高性能策略，既保持了表达能力以覆盖多种系统策略，又通过约束设计使小型廉价LLM也能生成正确且可执行的代码，从而显著优于传统人工设计的先进算法（缓存淘汰优化提升最高达69%，内存分层优化提升7.9%）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25065">https://arxiv.org/abs/2512.25065</a><br>
<strong>作者</strong>: Rohit Dwivedula,Divyanshu Saxena,Sujay Yadalam,Daehyeok Kim,Aditya Akella<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Operating Systems (cs.OS); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Distributed, Parallel, and Cluster Computing (cs.DC)<br>
<strong>备注</strong>:  27 pages, 11 figures, 7 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Resource-management tasks in modern operating and distributed systems continue to rely primarily on hand-designed heuristics for tasks such as scheduling, caching, or active queue management. Designing performant heuristics is an expensive, time-consuming process that we are forced to continuously go through due to the constant flux of hardware, workloads and environments. We propose a new alternative: synthesizing instance-optimal heuristics – specialized for the exact workloads and hardware where they will be deployed – using code-generating large language models (LLMs). To make this synthesis tractable, Vulcan separates policy and mechanism through LLM-friendly, task-agnostic interfaces. With these interfaces, users specify the inputs and objectives of their desired policy, while Vulcan searches for performant policies via evolutionary search over LLM-generated code. This interface is expressive enough to capture a wide range of system policies, yet sufficiently constrained to allow even small, inexpensive LLMs to generate correct and executable code. We use Vulcan to synthesize performant heuristics for cache eviction and memory tiering, and find that these heuristics outperform all human-designed state-of-the-art algorithms by upto 69% and 7.9% in performance for each of these tasks respectively.          Comments: 27 pages, 11 figures, 7 tables   Subjects:  Operating Systems (cs.OS); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Distributed, Parallel, and Cluster Computing (cs.DC)  Cite as: arXiv:2512.25065 [cs.OS]    (or  arXiv:2512.25065v1 [cs.OS] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.25065">https://doi.org/10.48550/arXiv.2512.25065</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-2] Context-aware <mark class="hl-label green">LLM</mark> -based AI <mark class="hl-label green">Agents</mark>  for Human-centered Energy Management Systems in Smart Buildings</p>
<p>【速读】：该论文旨在解决现有建筑能源管理系统（BEMS）在智能化、用户交互与上下文感知能力方面的局限性，尤其在自然语言交互和动态环境适应性方面存在不足。其解决方案的关键在于构建一个基于大语言模型（LLM）的BEMS AI代理概念框架，该框架包含感知（sensing）、中央控制（brain）和执行（actuation and user interaction）三个模块，并形成闭环反馈机制，从而实现对能源数据的捕获、分析与解释，以智能响应用户查询并管理连接设备。通过利用LLM的自主数据分析能力，系统能够提供情境感知的能耗洞察、成本预测及设备调度服务，显著提升了人机交互效率与能效管理水平。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25055">https://arxiv.org/abs/2512.25055</a><br>
<strong>作者</strong>: Tianzhi He,Farrokh Jazizadeh<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Human-Computer Interaction (cs.HC)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This study presents a conceptual framework and a prototype assessment for Large Language Model (LLM)-based Building Energy Management System (BEMS) AI agents to facilitate context-aware energy management in smart buildings through natural language interaction. The proposed framework comprises three modules: perception (sensing), central control (brain), and action (actuation and user interaction), forming a closed feedback loop that captures, analyzes, and interprets energy data to respond intelligently to user queries and manage connected appliances. By leveraging the autonomous data analytics capabilities of LLMs, the BEMS AI agent seeks to offer context-aware insights into energy consumption, cost prediction, and device scheduling, thereby addressing limitations in existing energy management systems. The prototype’s performance was evaluated using 120 user queries across four distinct real-world residential energy datasets and different evaluation metrics, including latency, functionality, capability, accuracy, and cost-effectiveness. The generalizability of the framework was demonstrated using ANOVA tests. The results revealed promising performance, measured by response accuracy in device control (86%), memory-related tasks (97%), scheduling and automation (74%), and energy analysis (77%), while more complex cost estimation tasks highlighted areas for improvement with an accuracy of 49%. This benchmarking study moves toward formalizing the assessment of LLM-based BEMS AI agents and identifying future research directions, emphasizing the trade-off between response accuracy and computational efficiency.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-3] A Modal Logic for Possibilistic <mark class="hl-label green">Reasoning</mark>  with Fuzzy Formal Contexts</p>
<p>【速读】：该论文旨在解决在模糊形式背景（fuzzy formal contexts）下进行可能性推理（possibilistic reasoning）的逻辑建模问题，特别是如何通过形式化语言精确表达和推理模糊概念及其相关结构。解决方案的关键在于提出了一种双类加权模态逻辑（two-sort weighted modal logic），其中包含两类加权模态算子：经典必要性（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">□</mi></mrow><annotation encoding="application/x-tex">\Box</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm">□</span></span></span></span>）和充分性（<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊟</mo></mrow><annotation encoding="application/x-tex">\boxminus</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm">⊟</span></span></span></span>），其公式基于可能性理论在模糊形式背景下进行语义解释；同时，该逻辑系统具有完备性，即其公理化体系对所有模糊上下文模型均成立，并能有效刻画形式概念分析（Formal Concept Analysis, FCA）中的三大核心概念——形式概念、对象导向概念和属性导向概念的c-截集推广版本（c-cut concepts）。此外，作者还展示了该逻辑可扩展至多关系模糊上下文（multi-relational fuzzy contexts），支持不同模糊关系的布尔组合，从而增强了其在复杂知识表示与推理场景中的适用性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24980">https://arxiv.org/abs/2512.24980</a><br>
<strong>作者</strong>: Prosenjit Howlader,Churn-Jung Liau<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Logic in Computer Science (cs.LO); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  25 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce a two-sort weighted modal logic for possibilistic reasoning with fuzzy formal contexts. The syntax of the logic includes two types of weighted modal operators corresponding to classical necessity ( \Box ) and sufficiency ( \boxminus ) modalities and its formulas are interpreted in fuzzy formal contexts based on possibility theory. We present its axiomatization that is \emphsound with respect to the class of all fuzzy context models. In addition, both the necessity and sufficiency fragments of the logic are also individually complete with respect to the class of all fuzzy context models. We highlight the expressive power of the logic with some illustrative examples. As a formal context is the basic construct of formal concept analysis (FCA), we generalize three main notions in FCA, i.e., formal concepts, object oriented concepts, and property oriented concepts, to their corresponding  c -cut concepts in fuzzy formal contexts. Then, we show that our logical language can represent all three of these generalized notions. Finally, we demonstrate the possibility of extending our logic to reasoning with multi-relational fuzzy contexts, in which the Boolean combinations of different fuzzy relations are allowed.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-4] Semi-overlapping Multi-bandit Best Arm Identification for Sequential Support Network Learning</p>
<p>【速读】：该论文旨在解决多参与方在共享但不对称、计算密集型任务中评估各自贡献并同时选择最优候选伙伴的难题，其核心目标是通过试验学习一个表示最高性能贡献的有向图（即支持网络）。解决方案的关键在于提出一种新的纯探索模型——半重叠多臂赌博机（SOMMAB），其中单次评估可因各赌博机臂之间的结构重叠而为多个赌博机提供不同反馈；作者进一步设计了适用于SOMMAB的广义GapE算法，并推导出改进的指数误差界，该界线性依赖于重叠程度，揭示了共享评估带来的显著样本复杂度优势。此方法为从稀疏候选集中识别支持网络提供了理论基础与更优性能保障，适用于多任务学习、辅助任务学习、联邦学习及多智能体系统等场景。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24959">https://arxiv.org/abs/2512.24959</a><br>
<strong>作者</strong>: András Antos(1),András Millinghoffer(1 and 2),Péter Antal(1 and 2) ((1) Department of Artificial Intelligence and Systems Engineering, Budapest University of Technology and Economics, (2) E-Group ICT Software Zrt., Budapest, Hungary)<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  29 pages, 2 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Many modern AI and ML problems require evaluating partners’ contributions through shared yet asymmetric, computationally intensive processes and the simultaneous selection of the most beneficial candidates. Sequential approaches to these problems can be unified under a new framework, Sequential Support Network Learning (SSNL), in which the goal is to select the most beneficial candidate set of partners for all participants using trials; that is, to learn a directed graph that represents the highest-performing contributions. We demonstrate that a new pure-exploration model, the semi-overlapping multi-(multi-armed) bandit (SOMMAB), in which a single evaluation provides distinct feedback to multiple bandits due to structural overlap among their arms, can be used to learn a support network from sparse candidate lists efficiently. We develop a generalized GapE algorithm for SOMMABs and derive new exponential error bounds that improve the best known constant in the exponent for multi-bandit best-arm identification. The bounds scale linearly with the degree of overlap, revealing significant sample-complexity gains arising from shared evaluations. From an application point of view, this work provides a theoretical foundation and improved performance guarantees for sequential learning tools for identifying support networks from sparse candidates in multiple learning problems, such as in multi-task learning (MTL), auxiliary task learning (ATL), federated learning (FL), and in multi-agent systems (MAS).          Comments: 29 pages, 2 figures   Subjects:  Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)   ACMclasses: F.2.1; G.3; I.2.6   Cite as: arXiv:2512.24959 [cs.LG]    (or  arXiv:2512.24959v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24959">https://doi.org/10.48550/arXiv.2512.24959</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-5] AMAP <mark class="hl-label green">Agent</mark> ic <mark class="hl-label green">Planning</mark>  Technical Report</p>
<p>【速读】：该论文旨在解决复杂时空任务中大语言模型（Large Language Model, LLM）的推理与工具协同能力不足的问题，特别是在受限兴趣点发现和行程规划等场景下的表现瓶颈。其核心解决方案在于提出STAgent——一个专为时空理解设计的代理型大语言模型，关键创新包括：(1) 构建稳定且支持十余种领域特定工具的异步交互环境，实现训练与推理的高效解耦；(2) 提出分层数据筛选框架，以极低比例（1:10,000）识别高质量、高难度且多样化的查询样本；(3) 设计级联式训练流程，从初始监督微调（SFT）阶段评估查询难度出发，逐步过渡至高置信度样本精调与低置信度样本强化学习优化，从而在保持通用能力的同时显著提升专业任务性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24957">https://arxiv.org/abs/2512.24957</a><br>
<strong>作者</strong>: Yulan Hu,Xiangwen Zhang,Sheng Ouyang,Hao Yi,Lu Xu,Qinglin Lang,Lide Tan,Xiang Cheng,Tianchen Ye,Zhicong Li,Ge Chen,Wenjin Yang,Zheng Pan,Shaopan Xiong,Siran Yang,Ju Huang,Yan Zhang,Jiamang Wang,Yong Liu,Yinfeng Huang,Tucheng Lin,Xin Li,Ning Guo<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present STAgent, an agentic large language model tailored for spatio-temporal understanding, designed to solve complex tasks such as constrained point-of-interest discovery and itinerary planning. STAgent is a specialized model capable of interacting with ten distinct tools within spatio-temporal scenarios, enabling it to explore, verify, and refine intermediate steps during complex reasoning. Notably, STAgent effectively preserves its general capabilities. We empower STAgent with these capabilities through three key contributions: (1) a stable tool environment that supports over ten domain-specific tools, enabling asynchronous rollout and training; (2) a hierarchical data curation framework that identifies high-quality data like a needle in a haystack, curating high-quality queries with a filter ratio of 1:10,000, emphasizing both diversity and difficulty; and (3) a cascaded training recipe that starts with a seed SFT stage acting as a guardian to measure query difficulty, followed by a second SFT stage fine-tuned on queries with high certainty, and an ultimate RL stage that leverages data of low certainty. Initialized with Qwen3-30B-A3B to establish a strong SFT foundation and leverage insights into sample difficulty, STAgent yields promising performance on TravelBench while maintaining its general capabilities across a wide range of general benchmarks, thereby demonstrating the effectiveness of our proposed agentic model.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-6] MSACL: Multi-Step Actor-Critic Learning with Lyapunov Certificates for Exponentially Stabilizing Control</p>
<p>【速读】：该论文旨在解决无模型强化学习（Model-Free Reinforcement Learning, MFRL）中可证明稳定性的难题，尤其是在探索与严格安全性之间难以平衡的问题。其解决方案的关键在于提出MSACL框架，该框架将指数稳定性理论（Exponential Stability Theory）与最大熵强化学习（Maximum Entropy RL）相结合，通过多步李雅普诺夫证书学习（Multi-step Lyapunov Certificate Learning）实现安全可控的策略优化。具体而言，MSACL利用离线多步数据学习满足理论稳定性条件的李雅普诺夫证书，并引入指数稳定性标签（Exponential Stability Labels, ESL）和λ加权聚合机制，有效缓解多步学习中的偏差-方差权衡问题；同时，基于稳定性感知的优势函数指导策略优化，确保策略促进快速李雅普诺夫下降。实验表明，该方法在简单奖励下即可实现指数稳定性和快速收敛，并具备对不确定性的强鲁棒性及对未见轨迹的良好泛化能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24955">https://arxiv.org/abs/2512.24955</a><br>
<strong>作者</strong>: Yongwei Zhang,Yuanzhe Xing,Quan Quan,Zhikun She<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Systems and Control (<a target="_blank" rel="noopener" href="http://eess.SY">eess.SY</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Achieving provable stability in model-free reinforcement learning (RL) remains a challenge, particularly in balancing exploration with rigorous safety. This article introduces MSACL, a framework that integrates exponential stability theory with maximum entropy RL through multi-step Lyapunov certificate learning. Unlike methods relying on complex reward engineering, MSACL utilizes off-policy multi-step data to learn Lyapunov certificates satisfying theoretical stability conditions. By introducing Exponential Stability Labels (ESL) and a  \lambda -weighted aggregation mechanism, the framework effectively balances the bias-variance trade-off in multi-step learning. Policy optimization is guided by a stability-aware advantage function, ensuring the learned policy promotes rapid Lyapunov descent. We evaluate MSACL across six benchmarks, including stabilization and nonlinear tracking tasks, demonstrating its superiority over state-of-the-art Lyapunov-based RL algorithms. MSACL achieves exponential stability and rapid convergence under simple rewards, while exhibiting significant robustness to uncertainties and generalization to unseen trajectories. Sensitivity analysis establishes the multi-step horizon  n=20  as a robust default across diverse systems. By linking Lyapunov theory with off-policy actor-critic frameworks, MSACL provides a foundation for verifiably safe learning-based control. Source code and benchmark environments will be made publicly available.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-7] AI-Driven Cloud Resource Optimization for Multi-Cluster Environments</p>
<p>【速读】：该论文旨在解决多集群云系统中资源管理效率低下的问题，现有方法多为反应式且以单集群为中心，难以在动态工作负载下实现全局优化，导致资源利用率低下、响应延迟和运维开销增加。其解决方案的关键在于提出了一种基于人工智能（AI）的自适应资源优化框架，通过融合预测性学习、策略感知决策与持续反馈机制，实现跨集群的主动协同资源管理；该框架利用跨集群遥测数据和历史执行模式分析，动态调整资源配置，在性能、成本与可靠性之间实现平衡，从而提升整体资源效率并加快对工作负载波动的稳定响应速度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24914">https://arxiv.org/abs/2512.24914</a><br>
<strong>作者</strong>: Vinoth Punniyamoorthy,Akash Kumar Agarwal,Bikesh Kumar,Abhirup Mazumder,Kabilan Kannan,Sumit Saha<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Modern cloud-native systems increasingly rely on multi-cluster deployments to support scalability, resilience, and geographic distribution. However, existing resource management approaches remain largely reactive and cluster-centric, limiting their ability to optimize system-wide behavior under dynamic workloads. These limitations result in inefficient resource utilization, delayed adaptation, and increased operational overhead across distributed environments. This paper presents an AI-driven framework for adaptive resource optimization in multi-cluster cloud systems. The proposed approach integrates predictive learning, policy-aware decision-making, and continuous feedback to enable proactive and coordinated resource management across clusters. By analyzing cross-cluster telemetry and historical execution patterns, the framework dynamically adjusts resource allocation to balance performance, cost, and reliability objectives. A prototype implementation demonstrates improved resource efficiency, faster stabilization during workload fluctuations, and reduced performance variability compared to conventional reactive approaches. The results highlight the effectiveness of intelligent, self-adaptive infrastructure management as a key enabler for scalable and resilient cloud platforms.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-8] Semi-Automated Data Annotation in Multisensor Datasets for Autonomous Vehicle Testing</p>
<p>【速读】：该论文旨在解决大规模多模态驾驶场景数据集在波兰条件下进行人工标注时成本高、耗时长的问题。解决方案的关键在于构建一个半自动化数据标注流水线，采用“人在回路”（human-in-the-loop）策略，将人工智能与人类专家知识相结合：系统利用3D目标检测算法自动生成初始标注，支持迭代式模型再训练，并集成数据匿名化和领域自适应技术，从而显著降低标注成本与时间，同时保证跨传感器模态的一致性和高质量标注结果。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24896">https://arxiv.org/abs/2512.24896</a><br>
<strong>作者</strong>: Andrii Gamalii,Daniel Górniak,Robert Nowak,Bartłomiej Olber,Krystian Radlak,Jakub Winter<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This report presents the design and implementation of a semi-automated data annotation pipeline developed within the DARTS project, whose goal is to create a large-scale, multimodal dataset of driving scenarios recorded in Polish conditions. Manual annotation of such heterogeneous data is both costly and time-consuming. To address this challenge, the proposed solution adopts a human-in-the-loop approach that combines artificial intelligence with human expertise to reduce annotation cost and duration. The system automatically generates initial annotations, enables iterative model retraining, and incorporates data anonymization and domain adaptation techniques. At its core, the tool relies on 3D object detection algorithms to produce preliminary annotations. Overall, the developed tools and methodology result in substantial time savings while ensuring consistent, high-quality annotations across different sensor modalities. The solution directly supports the DARTS project by accelerating the preparation of large annotated dataset in the project’s standardized format, strengthening the technological base for autonomous vehicle research in Poland.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-9] A study on constraint extraction and exception exclusion in care worker scheduling</p>
<p>【速读】：该论文旨在解决长期照护机构中自动排班系统难以适配各机构差异化约束条件的问题。现有方法在通用场景下表现良好，但在实际应用中，不同照护设施的运营规则（如连续工作日模式、人员组合要求等）存在显著差异，导致排班算法难以直接适用。解决方案的关键在于提出一种基于约束模板（constraint templates）的灵活提取机制，通过调整关注天数、人员数量及提取焦点（模式或频率），系统性地识别并生成多种硬性与软性约束；同时引入异常约束排除机制，避免不具普遍性的特殊情形干扰排班优化过程。实验表明，该方法能确保所有硬约束被满足，并有效减少软约束违反次数，从而提升排班方案的实际可行性与质量。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24853">https://arxiv.org/abs/2512.24853</a><br>
<strong>作者</strong>: Koki Suenaga,Tomohiro Furuta,Satoshi Ono<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Technologies for automatically generating work schedules have been extensively studied; however, in long-term care facilities, the conditions vary between facilities, making it essential to interview the managers who create shift schedules to design facility-specific constraint conditions. The proposed method utilizes constraint templates to extract combinations of various components, such as shift patterns for consecutive days or staff combinations. The templates can extract a variety of constraints by changing the number of days and the number of staff members to focus on and changing the extraction focus to patterns or frequency. In addition, unlike existing constraint extraction techniques, this study incorporates mechanisms to exclude exceptional constraints. The extracted constraints can be employed by a constraint programming solver to create care worker schedules. Experiments demonstrated that our proposed method successfully created schedules that satisfied all hard constraints and reduced the number of violations for soft constraints by circumventing the extraction of exceptional constraints.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-10] GenZ: Foundational models as latent variable generators within traditional statistical models</p>
<p>【速读】：该论文旨在解决大语言模型（Large Language Models, LLMs）在预测任务中难以捕捉数据集特定模式的问题，尽管其具备广泛的领域知识，但往往无法有效建模局部特征与目标变量之间的关系。解决方案的关键在于提出一种名为GenZ的混合模型，通过迭代地对比统计建模误差所识别出的项目组，发现可解释的语义特征描述，并将其与统计模型参数联合优化，形成广义EM算法框架。该方法利用冻结的LLM对基于发现特征分类的项目进行判断，将这些判断视为潜在二值特征的噪声观测，进而学习其与真实数值目标之间的统计关联，从而显著提升预测性能并揭示数据驱动的语义模式。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24834">https://arxiv.org/abs/2512.24834</a><br>
<strong>作者</strong>: Marko Jojic,Nebojsa Jojic<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present GenZ, a hybrid model that bridges foundational models and statistical modeling through interpretable semantic features. While large language models possess broad domain knowledge, they often fail to capture dataset-specific patterns critical for prediction tasks. Our approach addresses this by discovering semantic feature descriptions through an iterative process that contrasts groups of items identified via statistical modeling errors, rather than relying solely on the foundational model’s domain understanding. We formulate this as a generalized EM algorithm that jointly optimizes semantic feature descriptors and statistical model parameters. The method prompts a frozen foundational model to classify items based on discovered features, treating these judgments as noisy observations of latent binary features that predict real-valued targets through learned statistical relationships. We demonstrate the approach on two domains: house price prediction (hedonic regression) and cold-start collaborative filtering for movie recommendations. On house prices, our model achieves 12% median relative error using discovered semantic features from multimodal listing data, substantially outperforming a GPT-5 baseline (38% error) that relies on the LLM’s general domain knowledge. For Netflix movie embeddings, our model predicts collaborative filtering representations with 0.59 cosine similarity purely from semantic descriptions – matching the performance that would require approximately 4000 user ratings through traditional collaborative filtering. The discovered features reveal dataset-specific patterns (e.g., architectural details predicting local housing markets, franchise membership predicting user preferences) that diverge from the model’s domain knowledge alone.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-11] Explaining Why Things Go Where They Go: Interpretable Constructs of Human Organizational Preferences</p>
<p>【速读】：该论文旨在解决机器人在家庭物品重新排列任务中依赖隐式偏好模型的问题，这类模型虽能有效预测人类行为，但缺乏对人类决策可解释因素的洞察。解决方案的关键在于提出了一种基于四个可解释构念的显式物体排列偏好建模方法：空间实用性（spatial practicality，将物品放置于其自然适配的空间位置）、习惯便利性（habitual convenience，使常用物品易于触及）、语义一致性（semantic coherence，将功能或情境相关的物品放在一起）和常识适当性（commonsense appropriateness，将物品置于人们通常预期的位置）。研究通过63名参与者在线问卷验证了这些构念的心理区分性和解释力，并将其集成至蒙特卡洛树搜索（MCTS）规划器中，实验证明基于参与者偏好的规划结果与人类生成的排列高度一致，从而实现了偏好建模的可解释性与机器人规划的合理性统一。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24829">https://arxiv.org/abs/2512.24829</a><br>
<strong>作者</strong>: Emmanuel Fashae,Michael Burke,Leimin Tian,Lingheng Meng,Pamela Carreno-Medrano<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Human-Computer Interaction (cs.HC); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
<strong>备注</strong>:  Accepted to the 2026 ACM/IEEE International Conference on Human-Robot Interaction (HRI '26)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Robotic systems for household object rearrangement often rely on latent preference models inferred from human demonstrations. While effective at prediction, these models offer limited insight into the interpretable factors that guide human decisions. We introduce an explicit formulation of object arrangement preferences along four interpretable constructs: spatial practicality (putting items where they naturally fit best in the space), habitual convenience (making frequently used items easy to reach), semantic coherence (placing items together if they are used for the same task or are contextually related), and commonsense appropriateness (putting things where people would usually expect to find them). To capture these constructs, we designed and validated a self-report questionnaire through a 63-participant online study. Results confirm the psychological distinctiveness of these constructs and their explanatory power across two scenarios (kitchen and living room). We demonstrate the utility of these constructs by integrating them into a Monte Carlo Tree Search (MCTS) planner and show that when guided by participant-derived preferences, our planner can generate reasonable arrangements that closely align with those generated by participants. This work contributes a compact, interpretable formulation of object arrangement preferences and a demonstration of how it can be operationalized for robot planning.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-12] LeanCat: A Benchmark Suite for Formal Category Theory in Lean (Part I: 1-Categories)</p>
<p>【速读】：该论文旨在解决当前大型语言模型（Large Language Models, LLMs）在形式化数学证明中对抽象结构和库驱动推理（library-mediated reasoning）能力评估不足的问题，尤其针对现代数学核心——范畴论（category theory）的 formalization 能力缺乏系统性评测。解决方案的关键在于构建 LeanCat，一个面向 Lean 证明助手的范畴论形式化基准，包含100个完整形式化的命题级任务，按主题族和难度层级（易/中/难）进行组织，并通过LLM辅助与人工评分相结合的方式进行标注。该基准作为结构化接口推理的“压力测试”，验证了当前模型在抽象层次上的推理能力，同时引入 LeanBridge 方法利用 LeanExplore 检索 Mathlib 库实现性能提升，为 AI 和人类在 Lean 中实现可靠、研究级别的形式化提供可复用的评估节点。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24796">https://arxiv.org/abs/2512.24796</a><br>
<strong>作者</strong>: Rongge Xu,Hui Dai,Yiming Fu,Jiedong Jiang,Tianjiao Nie,Hongwei Wang,Junkai Wang,Holiverse Yang,Jiatong Yang,Zhi-Hao Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Logic in Computer Science (cs.LO); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Formal Languages and Automata Theory (cs.FL); Machine Learning (cs.LG); Category Theory (math.CT)<br>
<strong>备注</strong>:  11 pages, 4 figures, 1 table</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language models (LLMs) have made rapid progress in formal theorem proving, yet current benchmarks under-measure the kind of abstraction and library-mediated reasoning that organizes modern mathematics. In parallel with FATE’s emphasis on frontier algebra, we introduce LeanCat, a Lean benchmark for category-theoretic formalization – a unifying language for mathematical structure and a core layer of modern proof engineering – serving as a stress test of structural, interface-level reasoning. Part I: 1-Categories contains 100 fully formalized statement-level tasks, curated into topic families and three difficulty tiers via an LLM-assisted + human grading process. The best model solves 8.25% of tasks at pass@1 (32.50%/4.17%/0.00% by Easy/Medium/High) and 12.00% at pass@4 (50.00%/4.76%/0.00%). We also evaluate LeanBridge which use LeanExplore to search Mathlib, and observe consistent gains over single-model baselines. LeanCat is intended as a compact, reusable checkpoint for tracking both AI and human progress toward reliable, research-level formalization in Lean.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-13] HiGR: Efficient Generative Slate Recommendation via Hierarchical <mark class="hl-label green">Planning</mark>  and Multi-Objective Preference Alignment</p>
<p>【速读】：该论文旨在解决生成式 slate 推荐中现有自回归方法存在的两个核心问题：一是物品标记（item tokenization）语义纠缠，导致生成控制困难；二是序列解码效率低下且缺乏对整个推荐列表的全局规划能力。其解决方案的关键在于提出 HiGR 框架，通过三层创新实现高效、可控且高质量的推荐：首先，采用基于残差量化（residual quantization）与对比约束的自动编码器对物品进行语义结构化标记，提升生成可控性；其次，将生成过程解耦为列表级规划阶段（list-level planning）与物品级解码阶段（item-level decoding），实现从整体意图到具体项的分层决策；最后，引入列表级偏好对齐目标（listwise preference alignment），直接利用隐式用户反馈优化推荐列表质量。这一设计显著提升了推荐效果与推理效率，在离线指标上优于SOTA方法超10%，推理速度提升5倍，并在在线A/B测试中分别带来平均观看时长和视频播放量的正向提升。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24787">https://arxiv.org/abs/2512.24787</a><br>
<strong>作者</strong>: Yunsheng Pang,Zijian Liu,Yudong Li,Shaojie Zhu,Zijian Luo,Chenyun Yu,Sikai Wu,Shichen Shen,Cong Xu,Bin Wang,Kai Jiang,Hongyong Yu,Chengxiang Zhuo,Zang Li<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Slate recommendation, where users are presented with a ranked list of items simultaneously, is widely adopted in online platforms. Recent advances in generative models have shown promise in slate recommendation by modeling sequences of discrete semantic IDs autoregressively. However, existing autoregressive approaches suffer from semantically entangled item tokenization and inefficient sequential decoding that lacks holistic slate planning. To address these limitations, we propose HiGR, an efficient generative slate recommendation framework that integrates hierarchical planning with listwise preference alignment. First, we propose an auto-encoder utilizing residual quantization and contrastive constraints to tokenize items into semantically structured IDs for controllable generation. Second, HiGR decouples generation into a list-level planning stage for global slate intent, followed by an item-level decoding stage for specific item selection. Third, we introduce a listwise preference alignment objective to directly optimize slate quality using implicit user feedback. Experiments on our large-scale commercial media platform demonstrate that HiGR delivers consistent improvements in both offline evaluations and online deployment. Specifically, it outperforms state-of-the-art methods by over 10% in offline recommendation quality with a 5x inference speedup, while further achieving a 1.22% and 1.73% increase in Average Watch Time and Average Video Views in online A/B tests.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-14] LSRE: Latent Semantic Rule Encoding for Real-Time Semantic Risk Detection in Autonomous Driving</p>
<p>【速读】：该论文旨在解决自动驾驶系统在复杂人类社会规则（如礼让应急车辆、遵守交警手势等）下难以实时进行语义风险评估的问题。这些问题虽对人类直观易懂，但难以通过显式编程实现，而现有大型视觉语言模型（VLMs）虽能理解此类语义，却因推理开销大无法满足实时性要求。解决方案的关键在于提出LSRE（Latent Semantic Rule Encoding）框架，将稀疏采样的VLM判断结果映射到递归世界模型的潜在空间中，构建决策边界，并以轻量级潜在分类器形式编码语言定义的安全语义，从而在不进行每帧VLM查询的前提下实现10 Hz的实时语义风险检测，同时保持高准确率和低延迟。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24712">https://arxiv.org/abs/2512.24712</a><br>
<strong>作者</strong>: Qian Cheng,Weitao Zhou,Cheng Jing,Nanshan Deng,Junze Wen,Zhaoyang Liu,Kun Jiang,Diange Yang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Real-world autonomous driving must adhere to complex human social rules that extend beyond legally codified traffic regulations. Many of these semantic constraints, such as yielding to emergency vehicles, complying with traffic officers’ gestures, or stopping for school buses, are intuitive for humans yet difficult to encode explicitly. Although large vision-language models (VLMs) can interpret such semantics, their inference cost makes them impractical for real-time this http URL work proposes LSRE, a Latent Semantic Rule Encoding framework that converts sparsely sampled VLM judgments into decision boundaries within the latent space of a recurrent world model. By encoding language-defined safety semantics into a lightweight latent classifier, LSRE enables real-time semantic risk assessment at 10 Hz without per-frame VLM queries. Experiments on six semantic-failure scenarios in CARLA demonstrate that LSRE attains semantic risk detection accuracy comparable to a large VLM baseline, while providing substantially earlier hazard anticipation and maintaining low computational latency. LSRE further generalizes to rarely seen semantic-similar test cases, indicating that language-guided latent classification offers an effective and deployable mechanism for semantic safety monitoring in autonomous driving.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-15] BandiK: Efficient Multi-Task Decomposition Using a Multi-Bandit Framework</p>
<p>【速读】：该论文旨在解决多任务学习中辅助任务子集选择的难题，尤其是如何高效识别对目标任务有益的辅助任务组合，以避免负迁移（negative transfer）并降低计算开销。其核心挑战在于候选辅助任务集合数量呈指数级增长、评估成本高，且不同目标任务间的复杂度差异大。解决方案的关键在于提出一种三阶段方法 BandiK，利用多臂赌博机（Multi-Armed Bandit, MAB）框架进行高效筛选：首先估计任务间的成对知识迁移潜力；其次基于此构建线性数量的候选集合（而非指数级）；最后通过多赌博机结构整合多个任务特定的MAB，利用同一神经网络在不同任务上的共享“半重叠臂”特性，显著提升评估效率并优化资源分配。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24708">https://arxiv.org/abs/2512.24708</a><br>
<strong>作者</strong>: András Millinghoffer(1 and 2),András Formanek(1 and 3),András Antos(1),Péter Antal(1 and 2) ((1) Department of Artificial Intelligence and Systems Engineering, Faculty of Electrical Engineering and Informatics, Budapest University of Technology and Economics, (2) E-Group ICT Software Zrt., Budapest, Hungary, (3) Department of Electrical Engineering (ESAT), STADIUS Center for Dynamical Systems, Signal Processing and Data Analytics, KU Leuven)<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  8 pages, 14 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The challenge of effectively transferring knowledge across multiple tasks is of critical importance and is also present in downstream tasks with foundation models. However, the nature of transfer, its transitive-intransitive nature, is still an open problem, and negative transfer remains a significant obstacle. Selection of beneficial auxiliary task sets in multi-task learning is frequently hindered by the high computational cost of their evaluation, the high number of plausible candidate auxiliary sets, and the varying complexity of selection across target tasks. To address these constraints, we introduce BandiK, a novel three-stage multi-task auxiliary task subset selection method using multi-bandits, where each arm pull evaluates candidate auxiliary sets by training and testing a multiple output neural network on a single random train-test dataset split. Firstly, BandiK estimates the pairwise transfers between tasks, which helps in identifying which tasks are likely to benefit from joint learning. In the second stage, it constructs a linear number of candidate sets of auxiliary tasks (in the number of all tasks) for each target task based on the initial estimations, significantly reducing the exponential number of potential auxiliary task sets. Thirdly, it employs a Multi-Armed Bandit (MAB) framework for each task, where the arms correspond to the performance of candidate auxiliary sets realized as multiple output neural networks over train-test data set splits. To enhance efficiency, BandiK integrates these individual task-specific MABs into a multi-bandit structure. The proposed multi-bandit solution exploits that the same neural network realizes multiple arms of different individual bandits corresponding to a given candidate set. This semi-overlapping arm property defines a novel multi-bandit cost/reward structure utilized in BandiK.          Comments: 8 pages, 14 figures   Subjects:  Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)   ACMclasses: F.2.1; G.3; I.2.6   Cite as: arXiv:2512.24708 [cs.LG]    (or  arXiv:2512.24708v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24708">https://doi.org/10.48550/arXiv.2512.24708</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-16] Nested Learning: The Illusion of Deep Learning Architectures <mark class="hl-label red">NEURIPS</mark></p>
<p>【速读】：该论文旨在解决当前机器学习模型在持续学习（continual learning）、自我改进（self-improvement）以及高效求解问题能力方面的根本性挑战，尤其是如何实现模型对知识的长期记忆与动态适应。其解决方案的核心在于提出一种新的学习范式——嵌套学习（Nested Learning, NL），该范式将机器学习模型形式化为一组嵌套的、多层级和/或并行的优化问题，每个问题具有独立的上下文流（context flow）。NL的关键创新在于：(1) 提出可表达性强的优化器，揭示经典梯度优化算法（如Adam、SGD with Momentum）本质为关联记忆模块，用于压缩梯度信息；(2) 构建自修改学习模块，使模型能够通过学习自身更新规则来动态调整结构；(3) 设计连续记忆系统（Continuum Memory System），超越传统长短时记忆划分，支持更灵活的记忆组织。基于此，作者进一步构建了名为Hope的持续学习模块，在语言建模、知识整合、少样本泛化及长上下文推理等任务中展现出潜力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24695">https://arxiv.org/abs/2512.24695</a><br>
<strong>作者</strong>: Ali Behrouz,Meisam Razaviyayn,Peilin Zhong,Vahab Mirrokni<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  A version of this work is published at Neural Information Processing Systems (NeurIPS) 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Despite the recent progresses, particularly in developing Language Models, there are fundamental challenges and unanswered questions about how such models can continually learn/memorize, self-improve, and find effective solutions. In this paper, we present a new learning paradigm, called Nested Learning (NL), that coherently represents a machine learning model with a set of nested, multi-level, and/or parallel optimization problems, each of which with its own context flow. Through the lenses of NL, existing deep learning methods learns from data through compressing their own context flow, and in-context learning naturally emerges in large models. NL suggests a philosophy to design more expressive learning algorithms with more levels, resulting in higher-order in-context learning and potentially unlocking effective continual learning capabilities. We advocate for NL by presenting three core contributions: (1) Expressive Optimizers: We show that known gradient-based optimizers, such as Adam, SGD with Momentum, etc., are in fact associative memory modules that aim to compress the gradients’ information (by gradient descent). Building on this insight, we present other more expressive optimizers with deep memory and/or more powerful learning rules; (2) Self-Modifying Learning Module: Taking advantage of NL’s insights on learning algorithms, we present a sequence model that learns how to modify itself by learning its own update algorithm; and (3) Continuum Memory System: We present a new formulation for memory system that generalizes the traditional viewpoint of long/short-term memory. Combining our self-modifying sequence model with the continuum memory system, we present a continual learning module, called Hope, showing promising results in language modeling, knowledge incorporation, and few-shot generalization tasks, continual learning, and long-context reasoning tasks.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-17] Battery<mark class="hl-label green">Agent</mark> : Synergizing Physics-Informed Interpretation with <mark class="hl-label green">LLM</mark>  <mark class="hl-label green">Reasoning</mark>  for Intelligent Battery Fault Diagnosis</p>
<p>【速读】：该论文旨在解决锂离子电池故障诊断中深度学习方法存在的两大局限性：一是模型“黑箱”特性导致的可解释性差，二是受限于二分类范式难以提供根因分析与维护建议。解决方案的关键在于提出BatteryAgent框架，其核心创新是将物理知识特征与大语言模型（Large Language Models, LLMs）的推理能力相融合，构建包含三个模块的分层架构：物理感知层提取10个基于电化学机制的特征以平衡降维与物理保真度；检测与归因层利用梯度提升决策树和SHAP值量化特征贡献；推理与诊断层则通过LLM作为代理核心，建立“数值-语义”桥梁，结合SHAP归因与机制知识库生成包含故障类型、根因分析及维护建议的综合报告，从而实现从被动检测向智能诊断的范式转变。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24686">https://arxiv.org/abs/2512.24686</a><br>
<strong>作者</strong>: Songqi Zhou,Ruixue Liu,Boman Su,Jiazhou Wang,Yixing Wang,Benben Jiang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Systems and Control (<a target="_blank" rel="noopener" href="http://eess.SY">eess.SY</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Fault diagnosis of lithium-ion batteries is critical for system safety. While existing deep learning methods exhibit superior detection accuracy, their “black-box” nature hinders interpretability. Furthermore, restricted by binary classification paradigms, they struggle to provide root cause analysis and maintenance recommendations. To address these limitations, this paper proposes BatteryAgent, a hierarchical framework that integrates physical knowledge features with the reasoning capabilities of Large Language Models (LLMs). The framework comprises three core modules: (1) A Physical Perception Layer that utilizes 10 mechanism-based features derived from electrochemical principles, balancing dimensionality reduction with physical fidelity; (2) A Detection and Attribution Layer that employs Gradient Boosting Decision Trees and SHAP to quantify feature contributions; and (3) A Reasoning and Diagnosis Layer that leverages an LLM as the agent core. This layer constructs a “numerical-semantic” bridge, combining SHAP attributions with a mechanism knowledge base to generate comprehensive reports containing fault types, root cause analysis, and maintenance suggestions. Experimental results demonstrate that BatteryAgent effectively corrects misclassifications on hard boundary samples, achieving an AUROC of 0.986, which significantly outperforms current state-of-the-art methods. Moreover, the framework extends traditional binary detection to multi-type interpretable diagnosis, offering a new paradigm shift from “passive detection” to “intelligent diagnosis” for battery safety management.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-18] Multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis under unseen working conditions</p>
<p>【速读】：该论文旨在解决智能故障诊断在实际应用场景中面临的两大挑战：一是模型在未见过的工作条件下性能显著下降，二是现有方法多依赖单一模态传感信号，未能充分利用多模态信息的互补性以提升模型泛化能力。其解决方案的关键在于提出一种具有双解耦机制的多模态跨域混合融合模型（multi-modal cross-domain mixed fusion model with dual disentanglement），通过解耦模态不变特征与模态特有特征、以及域不变表示与域特定表示，实现全面的多模态表征学习和鲁棒的域泛化能力；同时设计跨域混合融合策略以随机混合不同域的模态信息，增强模态与域的多样性，并引入三模态自适应融合机制以高效整合异构多模态信息，从而显著提升故障诊断的准确性与泛化性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24679">https://arxiv.org/abs/2512.24679</a><br>
<strong>作者</strong>: Pengcheng Xia,Yixiang Huang,Chengjin Qin,Chengliang Liu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Signal Processing (eess.SP)<br>
<strong>备注</strong>:  21 pages, 8 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Intelligent fault diagnosis has become an indispensable technique for ensuring machinery reliability. However, existing methods suffer significant performance decline in real-world scenarios where models are tested under unseen working conditions, while domain adaptation approaches are limited to their reliance on target domain samples. Moreover, most existing studies rely on single-modal sensing signals, overlooking the complementary nature of multi-modal information for improving model generalization. To address these limitations, this paper proposes a multi-modal cross-domain mixed fusion model with dual disentanglement for fault diagnosis. A dual disentanglement framework is developed to decouple modality-invariant and modality-specific features, as well as domain-invariant and domain-specific representations, enabling both comprehensive multi-modal representation learning and robust domain generalization. A cross-domain mixed fusion strategy is designed to randomly mix modality information across domains for modality and domain diversity augmentation. Furthermore, a triple-modal fusion mechanism is introduced to adaptively integrate multi-modal heterogeneous information. Extensive experiments are conducted on induction motor fault diagnosis under both unseen constant and time-varying working conditions. The results demonstrate that the proposed method consistently outperforms advanced methods and comprehensive ablation studies further verify the effectiveness of each proposed component and multi-modal fusion. The code is available at: this https URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-19] VLA-RAIL: A Real-Time Asynchronous Inference Linker for VLA Models and Robots</p>
<p>【速读】：该论文旨在解决当前视觉-语言-动作（Vision-Language-Action, VLA）模型在机器人运动控制中因动作片段（action chunk）融合策略不当而导致的执行抖动（jitter）、停顿甚至中断问题，这些问题限制了动作执行速度并降低了任务成功率。解决方案的关键在于提出VLA-RAIL框架，其核心包括两个组件：一是轨迹平滑器（Trajectory Smoother），通过多项式拟合有效滤除单个动作片段轨迹中的噪声与抖动；二是片段融合器（Chunk Fuser），实现当前执行轨迹与新到达动作片段之间的无缝对齐，确保位置、速度和加速度在相邻片段间的连续性，从而保障机器人运动的实时性、平滑性和高效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24673">https://arxiv.org/abs/2512.24673</a><br>
<strong>作者</strong>: Yongsheng Zhao,Lei Zhao,Baoping Cheng,Gongxin Yao,Xuanzhang Wen,Han Gao<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Systems and Control (<a target="_blank" rel="noopener" href="http://eess.SY">eess.SY</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Vision-Language-Action (VLA) models have achieved remarkable breakthroughs in robotics, with the action chunk playing a dominant role in these advances. Given the real-time and continuous nature of robotic motion control, the strategies for fusing a queue of successive action chunks have a profound impact on the overall performance of VLA models. Existing methods suffer from jitter, stalling, or even pauses in robotic action execution, which not only limits the achievable execution speed but also reduces the overall success rate of task completion. This paper introduces VLA-RAIL (A Real-Time Asynchronous Inference Linker), a novel framework designed to address these issues by conducting model inference and robot motion control asynchronously and guaranteeing smooth, continuous, and high-speed action execution. The core contributions of the paper are two fold: a Trajectory Smoother that effectively filters out the noise and jitter in the trajectory of one action chunk using polynomial fitting and a Chunk Fuser that seamlessly align the current executing trajectory and the newly arrived chunk, ensuring position, velocity, and acceleration continuity between two successive action chunks. We validate the effectiveness of VLA-RAIL on a benchmark of dynamic simulation tasks and several real-world manipulation tasks. Experimental results demonstrate that VLA-RAIL significantly reduces motion jitter, enhances execution speed, and improves task success rates, which will become a key infrastructure for the large-scale deployment of VLA models.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-20] Hybrid Motion <mark class="hl-label green">Planning</mark>  with Deep Reinforcement Learning for Mobile Robot Navigation</p>
<p>【速读】：该论文旨在解决自主移动机器人在复杂动态环境中同时实现长距离路径规划与安全避障的问题。传统基于图的规划方法虽能有效处理大规模空间中的全局路径搜索，但缺乏对突发障碍物的实时响应能力；而深度强化学习（Deep Reinforcement Learning, DRL）方法虽具备良好的局部避障性能，却因缺乏全局语义信息难以到达远距离目标。解决方案的关键在于提出一种混合运动规划框架——HMP-DRL（Hybrid Motion Planning with Deep Reinforcement Learning），其核心是将图-based全局规划生成的路径转化为一系列检查点（checkpoints），并嵌入到局部DRL策略的状态空间和奖励函数中，从而赋予局部控制器全局路径引导能力；同时引入实体感知奖励结构（entity-aware reward structure），根据周围代理的语义类型动态调整安全距离和惩罚机制，确保社会合规性。实验表明，该方法在成功率、碰撞率和到达时间等关键指标上显著优于现有主流方法。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24651">https://arxiv.org/abs/2512.24651</a><br>
<strong>作者</strong>: Yury Kolomeytsev,Dmitry Golembiovsky<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  22 pages, 4 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Autonomous mobile robots operating in complex, dynamic environments face the dual challenge of navigating large-scale, structurally diverse spaces with static obstacles while safely interacting with various moving agents. Traditional graph-based planners excel at long-range pathfinding but lack reactivity, while Deep Reinforcement Learning (DRL) methods demonstrate strong collision avoidance but often fail to reach distant goals due to a lack of global context. We propose Hybrid Motion Planning with Deep Reinforcement Learning (HMP-DRL), a hybrid framework that bridges this gap. Our approach utilizes a graph-based global planner to generate a path, which is integrated into a local DRL policy via a sequence of checkpoints encoded in both the state space and reward function. To ensure social compliance, the local planner employs an entity-aware reward structure that dynamically adjusts safety margins and penalties based on the semantic type of surrounding agents. We validate the proposed method through extensive testing in a realistic simulation environment derived from real-world map data. Comprehensive experiments demonstrate that HMP-DRL consistently outperforms other methods, including state-of-the-art approaches, in terms of key metrics of robot navigation: success rate, collision rate, and time to reach the goal. Overall, these findings confirm that integrating long-term path guidance with semantically-aware local control significantly enhances both the safety and reliability of autonomous navigation in complex human-centric settings.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-21] DynaFix: Iterative Automated Program Repair Driven by Execution-Level Dynamic Information</p>
<p>【速读】：该论文旨在解决当前自动化程序修复（Automated Program Repair, APR）方法在利用大语言模型（Large Language Models, LLMs）时存在的关键局限性：一是多数方法仅依赖静态分析，忽视了程序运行时的行为信息；二是虽有尝试引入动态信号，但通常仅限于训练阶段或一次性注入修复提示中，缺乏迭代使用机制，无法充分捕捉程序执行过程。解决方案的关键在于提出DynaFix，一种基于执行级别动态信息驱动的迭代式修复方法。其核心创新是每轮修复中收集变量状态、控制流路径和调用栈等细粒度运行时信息，并将其结构化为提示以引导LLM生成候选补丁；若补丁未通过验证，则重新执行修改后的程序获取新反馈，形成闭环迭代优化机制，从而更贴近人类开发者逐步调试的逻辑，显著提升复杂Bug修复的有效性和效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24635">https://arxiv.org/abs/2512.24635</a><br>
<strong>作者</strong>: Zhili Huang,Ling Xu,Chao Liu,Weifeng Sun,Xu Zhang,Yan Lei,Meng Yan,Hongyu Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: oftware Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  22 pages, 7 figures, preprint version</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Automated Program Repair (APR) aims to automatically generate correct patches for buggy programs. Recent approaches leveraging large language models (LLMs) have shown promise but face limitations. Most rely solely on static analysis, ignoring runtime behaviors. Some attempt to incorporate dynamic signals, but these are often restricted to training or fine-tuning, or injected only once into the repair prompt, without iterative use. This fails to fully capture program execution. Current iterative repair frameworks typically rely on coarse-grained feedback, such as pass/fail results or exception types, and do not leverage fine-grained execution-level information effectively. As a result, models struggle to simulate human stepwise debugging, limiting their effectiveness in multi-step reasoning and complex bug repair. To address these challenges, we propose DynaFix, an execution-level dynamic information-driven APR method that iteratively leverages runtime information to refine the repair process. In each repair round, DynaFix captures execution-level dynamic information such as variable states, control-flow paths, and call stacks, transforming them into structured prompts to guide LLMs in generating candidate patches. If a patch fails validation, DynaFix re-executes the modified program to collect new execution information for the next attempt. This iterative loop incrementally improves patches based on updated feedback, similar to the stepwise debugging practices of human developers. We evaluate DynaFix on the Defects4J v1.2 and v2.0 benchmarks. DynaFix repairs 186 single-function bugs, a 10% improvement over state-of-the-art baselines, including 38 bugs previously unrepaired. It achieves correct patches within at most 35 attempts, reducing the patch search space by 70% compared with existing methods, thereby demonstrating both effectiveness and efficiency in repairing complex bugs.          Comments: 22 pages, 7 figures, preprint version   Subjects:  Software Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)  Cite as: arXiv:2512.24635 [<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>]    (or  arXiv:2512.24635v1 [<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24635">https://doi.org/10.48550/arXiv.2512.24635</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-22] AI-Driven Acoustic Voice Biomarker-Based Hierarchical Classification of Benign Laryngeal Voice Disorders from Sustained Vowels</p>
<p>【速读】：该论文旨在解决良性喉部声音障碍（benign laryngeal voice disorders）的自动化分类问题，此类障碍常表现为发声困难（dysphonia），且可作为全身生理功能紊乱的无创指标。现有方法在区分不同类别（如功能性、结构性或炎症性病变）时存在判别能力不足的问题，尤其难以将结构/炎症类疾病与功能性障碍有效区分开。解决方案的关键在于提出一个临床启发式的分层机器学习框架，包含三个阶段：第一阶段利用卷积神经网络提取的梅尔频谱图特征与21个可解释声学生物标志物融合进行病理与非病理语音的二分类筛查；第二阶段通过三次支持向量机（cubic SVM）对语音进行粗粒度分组（健康、功能/心理性、结构/炎症性）；第三阶段引入前两阶段的概率输出作为先验信息，提升对结构性和炎症性疾病的细粒度识别能力。该框架结合了深度谱表示与可解释声学特征，在Saarbruecken Voice Database上验证优于传统多类分类器及通用自监督模型（如META HuBERT和Google HeAR），显著增强了诊断透明度与临床适用性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24628">https://arxiv.org/abs/2512.24628</a><br>
<strong>作者</strong>: Mohsen Annabestani,Samira Aghadoost,Anais Rameau,Olivier Elemento,Gloria Chia-Yi Chiang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: ound (<a target="_blank" rel="noopener" href="http://cs.SD">cs.SD</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Benign laryngeal voice disorders affect nearly one in five individuals and often manifest as dysphonia, while also serving as non-invasive indicators of broader physiological dysfunction. We introduce a clinically inspired hierarchical machine learning framework for automated classification of eight benign voice disorders alongside healthy controls, using acoustic features extracted from short, sustained vowel phonations. Experiments utilized 15,132 recordings from 1,261 speakers in the Saarbruecken Voice Database, covering vowels /a/, /i/, and /u/ at neutral, high, low, and gliding pitches. Mirroring clinical triage workflows, the framework operates in three sequential stages: Stage 1 performs binary screening of pathological versus non-pathological voices by integrating convolutional neural network-derived mel-spectrogram features with 21 interpretable acoustic biomarkers; Stage 2 stratifies voices into Healthy, Functional or Psychogenic, and Structural or Inflammatory groups using a cubic support vector machine; Stage 3 achieves fine-grained classification by incorporating probabilistic outputs from prior stages, improving discrimination of structural and inflammatory disorders relative to functional conditions. The proposed system consistently outperformed flat multi-class classifiers and pre-trained self-supervised models, including META HuBERT and Google HeAR, whose generic objectives are not optimized for sustained clinical phonation. By combining deep spectral representations with interpretable acoustic features, the framework enhances transparency and clinical alignment. These results highlight the potential of quantitative voice biomarkers as scalable, non-invasive tools for early screening, diagnostic triage, and longitudinal monitoring of vocal health.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-23] AutoFed: Manual-Free Federated Traffic Prediction via Personalized Prompt</p>
<p>【速读】：该论文旨在解决交通预测任务中因数据隐私限制导致的联邦学习（Federated Learning, FL）在非独立同分布（non-IID）客户端间知识共享受限的问题，同时克服现有个性化联邦学习（Personalized Federated Learning, PFL）框架对超参数调优的依赖，从而提升实际部署可行性。其解决方案的关键在于提出AutoFed框架，该框架受提示学习（prompt learning）启发，引入一个联邦表示器（federated representor），通过客户端对齐适配器（client-aligned adapter）将本地数据压缩为一个紧凑的全局共享提示矩阵（prompt matrix），进而作为条件引导个性化预测器，使每个客户端既能利用跨客户端的知识，又能保留本地特征，实现无需人工超参数调优的高效个性化交通预测。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24625">https://arxiv.org/abs/2512.24625</a><br>
<strong>作者</strong>: Zijian Zhao,Yitong Shang,Sen Li<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Accurate traffic prediction is essential for Intelligent Transportation Systems, including ride-hailing, urban road planning, and vehicle fleet management. However, due to significant privacy concerns surrounding traffic data, most existing methods rely on local training, resulting in data silos and limited knowledge sharing. Federated Learning (FL) offers an efficient solution through privacy-preserving collaborative training; however, standard FL struggles with the non-independent and identically distributed (non-IID) problem among clients. This challenge has led to the emergence of Personalized Federated Learning (PFL) as a promising paradigm. Nevertheless, current PFL frameworks require further adaptation for traffic prediction tasks, such as specialized graph feature engineering, data processing, and network architecture design. A notable limitation of many prior studies is their reliance on hyper-parameter optimization across datasets-information that is often unavailable in real-world scenarios-thus impeding practical deployment. To address this challenge, we propose AutoFed, a novel PFL framework for traffic prediction that eliminates the need for manual hyper-parameter tuning. Inspired by prompt learning, AutoFed introduces a federated representor that employs a client-aligned adapter to distill local data into a compact, globally shared prompt matrix. This prompt then conditions a personalized predictor, allowing each client to benefit from cross-client knowledge while maintaining local specificity. Extensive experiments on real-world datasets demonstrate that AutoFed consistently achieves superior performance across diverse scenarios. The code of this paper is provided at this https URL .<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-24] Dynamic Large Concept Models: Latent <mark class="hl-label green">Reasoning</mark>  in an Adaptive Semantic Space</p>
<p>【速读】：该论文旨在解决大语言模型（Large Language Models, LLMs）在处理自然语言时存在的计算效率低下问题，即对所有词元（token）采用统一计算资源分配，而忽视了语言本身具有高度非均匀的信息密度特性——某些局部区域可预测性强、冗余度高，而语义关键过渡区域则需要更多计算资源。为此，作者提出动态大概念模型（Dynamic Large Concept Models, DLCM），其核心创新在于构建一个层次化语言建模框架，通过从潜在表示中学习语义边界，将计算从词元层面迁移至压缩后的概念空间（concept space），从而提升推理效率。DLCM无需预定义语言单元即可端到端发现变长概念，并引入首个“压缩感知缩放定律”（compression-aware scaling law），解耦词元级容量、概念级推理容量与压缩比，实现固定浮点运算次数（FLOPs）下的最优算力分配。此外，为稳定训练这一异构架构，论文进一步设计了去耦合的μP参数化方法（decoupled μP parametrization），支持跨宽度和压缩率的零样本超参数迁移，最终在平均每个概念包含4个词元（R=4）的实际设置下，将约三分之一的推理算力重新分配至更高容量的推理主干网络，在12个零样本基准测试中实现平均+2.69%的性能提升。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24617">https://arxiv.org/abs/2512.24617</a><br>
<strong>作者</strong>: Xingwei Qu,Shaowen Wang,Zihao Huang,Kai Hua,Fan Yin,Rui-Jie Zhu,Jundong Zhou,Qiyang Min,Zihao Wang,Yizhi Li,Tianyu Zhang,He Xing,Zheng Zhang,Yuxuan Song,Tianyu Zheng,Zhiyuan Zeng,Chenghua Lin,Ge Zhang,Wenhao Huang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) apply uniform computation to all tokens, despite language exhibiting highly non-uniform information density. This token-uniform regime wastes capacity on locally predictable spans while under-allocating computation to semantically critical transitions. We propose  \textbfDynamic Large Concept Models (DLCM) , a hierarchical language modeling framework that learns semantic boundaries from latent representations and shifts computation from tokens to a compressed concept space where reasoning is more efficient. DLCM discovers variable-length concepts end-to-end without relying on predefined linguistic units. Hierarchical compression fundamentally changes scaling behavior. We introduce the first  \textbfcompression-aware scaling law , which disentangles token-level capacity, concept-level reasoning capacity, and compression ratio, enabling principled compute allocation under fixed FLOPs. To stably train this heterogeneous architecture, we further develop a  \textbfdecoupled  \mu P parametrization  that supports zero-shot hyperparameter transfer across widths and compression regimes. At a practical setting ( R=4 , corresponding to an average of four tokens per concept), DLCM reallocates roughly one-third of inference compute into a higher-capacity reasoning backbone, achieving a  \textbf+2.69 %  average improvement  across 12 zero-shot benchmarks under matched inference FLOPs.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-25] Youtu-<mark class="hl-label green">Agent</mark> : Scaling <mark class="hl-label green">Agent</mark>  Productivity with Automated Generation and Hybrid Policy Optimization</p>
<p>【速读】：该论文旨在解决现有大语言模型（Large Language Model, LLM）代理框架面临的两大问题：高配置成本和能力静态性。具体而言，构建高质量代理通常需要大量人工进行工具集成与提示工程，而部署后的代理在动态环境中难以适应，且缺乏低成本的微调机制。解决方案的关键在于提出 Youtu-Agent 框架，其核心创新包括：(1) 一种结构化的配置系统，解耦执行环境、工具集与上下文管理，实现灵活复用与自动化合成；(2) 两种生成范式——Workflow 模式用于标准任务，Meta-Agent 模式可自动生成工具代码、提示词与配置以应对复杂非标需求；(3) 一套混合策略优化体系，包含 Agent Practice 模块（通过上下文内优化积累经验而不更新参数）和 Agent RL 模块（支持分布式强化学习实现端到端大规模稳定训练），从而实现代理的持续演化与性能提升。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24615">https://arxiv.org/abs/2512.24615</a><br>
<strong>作者</strong>: Yuchen Shi,Yuzheng Cai,Siqi Cai,Zihan Xu,Lichao Chen,Yulei Qin,Zhijian Zhou,Xiang Fei,Chaofan Qiu,Xiaoyu Tan,Gang Li,Zongyi Li,Haojia Lin,Guocan Cai,Yong Mao,Yunsheng Wu,Ke Li,Xing Sun<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose \textbfYoutu-Agent, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a \textbfWorkflow mode for standard tasks and a \textbfMeta-Agent mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an \textbfAgent Practice module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an \textbfAgent RL module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47%) and GAIA (72.8%) using open-weight models. Our automated generation pipeline achieves over 81% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7% and +5.4% respectively. Moreover, our Agent RL training achieves 40% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35% and 21% on Maths and general/multi-hop QA benchmarks.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-26] Chat-Driven Optimal Management for Virtual Network Services</p>
<p>【速读】：该论文旨在解决传统意图驱动网络（Intent-Based Networking, IBN）方法在用户自然语言指令解析后难以保证配置可行性的关键问题。现有IBN依赖统计语言模型进行意图理解，但无法确保生成的网络配置满足资源约束和拓扑逻辑。为此，作者提出了一种两阶段框架：第一阶段为“解释器”（Interpreter），利用自然语言处理（NLP）技术从用户聊天输入中提取意图，将其转化为参数调整方向（如增加、减少或维持CPU需求或延迟边界）；第二阶段为“优化器”（Optimizer），基于整数线性规划（Integer Linear Programming, ILP）计算可行的虚拟机（VM）部署与路由方案。该方案的核心创新在于将可解释的NLP意图提取与严格的优化建模相结合，从而实现安全、可靠且用户友好的虚拟网络动态重构。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24614">https://arxiv.org/abs/2512.24614</a><br>
<strong>作者</strong>: Yuya Miyaoka,Masaki Inoue,Kengo Urata,Shigeaki Harada<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Networking and Internet Architecture (<a target="_blank" rel="noopener" href="http://cs.NI">cs.NI</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper proposes a chat-driven network management framework that integrates natural language processing (NLP) with optimization-based virtual network allocation, enabling intuitive and reliable reconfiguration of virtual network services. Conventional intent-based networking (IBN) methods depend on statistical language models to interpret user intent but cannot guarantee the feasibility of generated configurations. To overcome this, we develop a two-stage framework consisting of an Interpreter, which extracts intent from natural language prompts using NLP, and an Optimizer, which computes feasible virtual machine (VM) placement and routing via an integer linear programming. In particular, the Interpreter translates user chats into update directions, i.e., whether to increase, decrease, or maintain parameters such as CPU demand and latency bounds, thereby enabling iterative refinement of the network configuration. In this paper, two intent extractors, which are a Sentence-BERT model with support vector machine (SVM) classifiers and a large language model (LLM), are introduced. Experiments in single-user and multi-user settings show that the framework dynamically updates VM placement and routing while preserving feasibility. The LLM-based extractor achieves higher accuracy with fewer labeled samples, whereas the Sentence-BERT with SVM classifiers provides significantly lower latency suitable for real-time operation. These results underscore the effectiveness of combining NLP-driven intent extraction with optimization-based allocation for safe, interpretable, and user-friendly virtual network management.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-27] Group Deliberation Oriented Multi-<mark class="hl-label green">Agent</mark>  Conversational Model for Complex <mark class="hl-label green">Reasoning</mark></p>
<p>【速读】：该论文旨在解决单一大型语言模型（Large Language Model, LLM）在复杂推理任务中表现受限的问题，尤其在多跳推理（multi-hop reasoning）场景下缺乏多样性、一致性与事实准确性。其解决方案的关键在于提出一种面向群体讨论（group deliberation）的多智能体对话模型，采用生成-验证-集成三级角色分工架构：生成代理（opinion generation agent）产出多样化的推理视角，验证代理（evidence verification agent）通过外部知识检索量化事实支持度，仲裁代理（consistency arbitration agent）整合逻辑一致的结论；同时引入自博弈机制扩展多路径推理轨迹，并结合检索增强模块动态补充外部知识，最终通过融合事实一致性与逻辑连贯性的复合奖励函数及改进的近端策略优化算法实现协同训练。该设计显著提升了推理准确率与一致性，优于主流多智能体方法。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24613">https://arxiv.org/abs/2512.24613</a><br>
<strong>作者</strong>: Zheyu Shi,Dong Qiu,Shanlong Yu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Accepted by IEEE ITCA 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper proposes a group deliberation oriented multi-agent conversational model to address the limitations of single large language models in complex reasoning tasks. The model adopts a three-level role division architecture consisting of generation, verification, and integration. An opinion generation agent produces diverse reasoning perspectives, an evidence verification agent retrieves external knowledge and quantifies factual support, and a consistency arbitration agent integrates logically coherent conclusions. A self-game mechanism is introduced to expand multi-path reasoning trajectories, while a retrieval enhancement module dynamically supplements external knowledge. A composite reward function combining factual consistency and logical coherence is designed, and an improved proximal policy optimization strategy is applied for collaborative training. Experimental results show that the proposed model improves multi-hop reasoning accuracy by 16.8 percent on HotpotQA, 14.3 percent on 2WikiMultihopQA, and 19.2 percent on MeetingBank, while improving consistency by 21.5 percent. The model achieves higher reasoning efficiency than mainstream multi-agent approaches, providing an effective and stable solution for complex reasoning tasks.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-28] Reinforcement Learning-Augmented <mark class="hl-label green">LLM</mark>  <mark class="hl-label green">Agents</mark>  for Collaborative Decision Making and Performance Optimization</p>
<p>【速读】：该论文旨在解决大型语言模型（Large Language Models, LLMs）在多智能体协作场景中缺乏协同意识、难以优化全局性能的问题。其核心解决方案是构建一个强化学习增强的LLM代理框架，将合作建模为去中心化部分可观测马尔可夫决策过程（Decentralized Partially Observable Markov Decision Process, Dec-POMDP），并采用集中训练、去中心化执行（Centralized Training with Decentralized Execution, CTDE）策略；关键创新在于提出群体相对策略优化（Group Relative Policy Optimization, GRPO），在训练阶段利用全局信号联合优化各代理策略，并设计简化联合奖励函数以平衡任务质量、执行速度与协调成本，从而显著提升协作效率与一致性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24609">https://arxiv.org/abs/2512.24609</a><br>
<strong>作者</strong>: Dong Qiu,Duo Xu,Limengxi Yue<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Accepted by IEEE ICFTIC 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) perform well in language tasks but often lack collaborative awareness and struggle to optimize global performance in multi-agent settings. We present a reinforcement learning-augmented LLM agent framework that formulates cooperation as a decentralized partially observable Markov decision process (Dec-POMDP) and adopts centralized training with decentralized execution (CTDE). We introduce Group Relative Policy Optimization (GRPO) to jointly optimize agent policies with access to global signals during training, together with a simplified joint reward that balances task quality, speed, and coordination cost. On collaborative writing and coding benchmarks, our framework delivers a 3x increase in task processing speed over single-agent baselines, 98.7% structural/style consistency in writing, and a 74.6% test pass rate in coding. The approach consistently outperforms strong multi-agent LLM baselines and provides a practical path toward reliable collaboration in complex workflows.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-29] Syn<mark class="hl-label green">RAG</mark> : A Large Language Model Framework for Executable Query Generation in Heterogeneous SIEM System</p>
<p>【速读】：该论文旨在解决多源安全信息与事件管理（Security Information and Event Management, SIEM）平台间查询语言异构性带来的威胁检测与事件调查效率低下问题。由于不同SIEM系统（如Palo Alto Networks Qradar、Google SecOps、Splunk等）在架构和查询语法上的显著差异，SOC分析师需针对每个平台单独编写查询语句，导致人力成本高、培训负担重且难以实现跨平台统一监控。解决方案的关键在于提出SynRAG框架，该框架能够从一个平台无关的高层次规范自动生成适配多种SIEM平台的具体查询语句，从而实现跨异构SIEM环境的无缝威胁检测与事件调查，避免了手动翻译和重复开发，显著提升了分析效率与可扩展性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24571">https://arxiv.org/abs/2512.24571</a><br>
<strong>作者</strong>: Md Hasan Saju,Austin Page,Akramul Azim,Jeff Gardiner,Farzaneh Abazari,Frank Eargle<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Security Information and Event Management (SIEM) systems are essential for large enterprises to monitor their IT infrastructure by ingesting and analyzing millions of logs and events daily. Security Operations Center (SOC) analysts are tasked with monitoring and analyzing this vast data to identify potential threats and take preventive actions to protect enterprise assets. However, the diversity among SIEM platforms, such as Palo Alto Networks Qradar, Google SecOps, Splunk, Microsoft Sentinel and the Elastic Stack, poses significant challenges. As these systems differ in attributes, architecture, and query languages, making it difficult for analysts to effectively monitor multiple platforms without undergoing extensive training or forcing enterprises to expand their workforce. To address this issue, we introduce SynRAG, a unified framework that automatically generates threat detection or incident investigation queries for multiple SIEM platforms from a platform-agnostic specification. SynRAG can generate platformspecific queries from a single high-level specification written by analysts. Without SynRAG, analysts would need to manually write separate queries for each SIEM platform, since query languages vary significantly across systems. This framework enables seamless threat detection and incident investigation across heterogeneous SIEM environments, reducing the need for specialized training and manual query translation. We evaluate SynRAG against state-of-the-art language models, including GPT, Llama, DeepSeek, Gemma, and Claude, using Qradar and SecOps as representative SIEM systems. Our results demonstrate that SynRAG generates significantly better queries for crossSIEM threat detection and incident investigation compared to the state-of-the-art base models.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-30] MCP<mark class="hl-label green">Agent</mark> Bench: A Real-world Task Benchmark for Evaluating <mark class="hl-label green">LLM</mark>  <mark class="hl-label green">Agent</mark>  MCP Tool Use</p>
<p>【速读】：该论文旨在解决当前大型语言模型（Large Language Models, LLMs）在使用外部工具时的评估基准存在的两个核心问题：一是依赖外部MCP服务导致评估不可靠，二是缺乏对任务难度的感知能力。解决方案的关键在于提出MCPAgentBench，一个基于真实世界MCP定义构建的基准测试框架，其包含真实任务与模拟工具的数据集，并通过动态沙箱环境引入带干扰项的候选工具列表，从而有效评估代理在复杂多步骤场景下的工具选择与识别能力；同时引入任务完成率和执行效率等综合指标，实现对LLM工具调用能力的全面量化评估。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24565">https://arxiv.org/abs/2512.24565</a><br>
<strong>作者</strong>: Wenrui Liu,Zixiang Liu,Elsie Dai,Wenhan Yu,Lei Yu,Tong Yang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) are increasingly serving as autonomous agents, and their utilization of external tools via the Model Context Protocol (MCP) is considered a future trend. Current MCP evaluation sets suffer from issues such as reliance on external MCP services and a lack of difficulty awareness. To address these limitations, we propose MCPAgentBench, a benchmark based on real-world MCP definitions designed to evaluate the tool-use capabilities of agents. We construct a dataset containing authentic tasks and simulated MCP tools. The evaluation employs a dynamic sandbox environment that presents agents with candidate tool lists containing distractors, thereby testing their tool selection and discrimination abilities. Furthermore, we introduce comprehensive metrics to measure both task completion rates and execution efficiency. Experiments conducted on various latest mainstream Large Language Models reveal significant performance differences in handling complex, multi-step tool invocations. All code is open-source at Github.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-31] Localized Calibrated Uncertainty in Code Language Models</p>
<p>【速读】：该论文旨在解决大型语言模型（Large Language Models, LLMs）生成代码时与用户意图不一致的问题，即生成的代码可能存在偏差，需要人工干预和编辑。为支持这一过程，研究者提出了一种关键方法：通过构建“最小意图对齐补丁”（Minimal Intent Aligning Patches）的数据集来定位代码中可能被修改的部分，并评估不同技术在预测这些修改位置上的校准能力。解决方案的核心在于设计一种轻量级监督模型（probe），利用白盒探测技术进行高效任意跨度查询，能够在远大于训练数据规模的LLM生成代码上实现低校准误差（约0.2）和良好的Brier技能得分，从而有效估计哪些代码行会被编辑，提升了代码生成过程中的可控性与可解释性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24560">https://arxiv.org/abs/2512.24560</a><br>
<strong>作者</strong>: David Gros,Prem Devanbu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: oftware Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language models (LLMs) can generate complicated source code from natural language prompts. However, LLMs can generate output that deviates from what the user wants, requiring supervision and editing. To support this process, we offer techniques to localize where generations might be misaligned from user intent. We first create a dataset of “Minimal Intent Aligning Patches” of repaired LLM generated programs. Each program uses test cases to verify correctness. After creating a dataset of programs, we measure how well various techniques can assign a well-calibrated probability to indicate which parts of code will be edited in a minimal patch (i.e., give a probability that corresponds with empirical odds it is edited). We compare white-box probing (where we propose a technique for efficient arbitrary-span querying), against black-box reflective and self-consistency based approaches. We find probes with a small supervisor model can achieve low calibration error and Brier Skill Score of approx 0.2 estimating edited lines on code generated by models many orders of magnitude larger. We discuss the generalizability of the techniques, and the connections to AI oversight and control, finding a probe trained only on code shows some signs of generalizing to natural language errors if new probability scaling is allowed.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-32] Evaluating the <mark class="hl-label green">Reasoning</mark>  Abilities of <mark class="hl-label green">LLM</mark> s on Underrepresented Mathematics Competition Problems</p>
<p>【速读】：该论文旨在解决当前大型语言模型（Large Language Models, LLMs）在数学推理能力评估中存在局限性的问题，特别是由于现有研究多依赖相同基准数据集而导致结论泛化能力不足、难以全面反映数学任务多样性挑战的现状。其解决方案的关键在于引入未被充分研究的数学竞赛题（如密苏里高校数学竞赛题），涵盖微积分（Calculus）、解析几何（Analytic Geometry）和离散数学（Discrete Mathematics）三个领域，对GPT-4o-mini、Gemini-2.0-Flash与DeepSeek-V3三类主流LLMs进行系统性评测，并通过对比正确答案与模型推理过程，识别不同模型在各类问题中的错误模式。结果表明，DeepSeek-V3在所有领域表现最优，而几何类题目普遍成为模型短板，且各模型错误类型呈现显著差异：DeepSeek-V3主要犯计算与逻辑错误，GPT-4o-mini多因逻辑或方法选择不当出错，Gemini则常因推理不完整或过早下结论导致失误。此方法有效揭示了LLMs在结构化推理中的差异化弱点，尤其凸显了几何推理仍是当前LLMs的核心挑战之一。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24505">https://arxiv.org/abs/2512.24505</a><br>
<strong>作者</strong>: Samuel Golladay,Majid Bani-Yaghoub<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  7 pages, submitted to ACM Transactions on Intelligent Systems and Technology</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Understanding the limitations of Large Language Models, or LLMs, in mathematical reasoning has been the focus of several recent studies. However, the majority of these studies use the same datasets for benchmarking, which limits the generalizability of their findings and may not fully capture the diverse challenges present in mathematical tasks. The purpose of the present study is to analyze the performance of LLMs on underrepresented mathematics competition problems. We prompted three leading LLMs, namely GPT-4o-mini, Gemini-2.0-Flash, and DeepSeek-V3, with the Missouri Collegiate Mathematics Competition problems in the areas of Calculus, Analytic Geometry, and Discrete Mathematics. The LLMs responses were then compared to the known correct solutions in order to determine the accuracy of the LLM for each problem domain. We also analyzed the LLMs reasoning to explore patterns in errors across problem types and models. DeepSeek-V3 has the best performance in all three categories of Calculus, Analytic Geometry, and Discrete Mathematics, both in reasoning and correct final answers. All three LLMs exhibited notably weak performance in Geometry. The majority of errors made by DeepSeek-V3 were attributed to computational and logical mistakes, whereas GPT-4o-mini frequently exhibited logical and approach-related errors. Gemini, on the other hand, tended to struggle with incomplete reasoning and drawing rushed conclusions. In conclusion, evaluating LLMs on underrepresented mathematics competition datasets can provide deeper insights into their distinct error patterns and highlight ongoing challenges in structured reasoning, particularly within the domain of Geometry.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-33] hinking on Maps: How Foundation Model <mark class="hl-label green">Agents</mark>  Explore Remember and <mark class="hl-label green">Reason</mark>  Map Environments</p>
<p>【速读】：该论文旨在解决当前基础模型（Foundation Model, FM）在符号化地图环境中的空间理解能力评估不足的问题，尤其是现有方法多依赖静态地图输入或文本查询，忽略了空间认知的交互性与经验驱动特性。其解决方案的关键在于提出一个交互式评估框架，通过让FM代理在部分可观测的网格地图中逐步探索道路、交叉口和兴趣点（Points of Interest, POIs），并基于六类空间任务系统性地分析探索策略、记忆表征与推理机制的作用。研究发现，记忆表征（特别是序列和图结构记忆）对空间经验的巩固至关重要，显著提升路径规划等结构密集型任务的表现；而推理方案则影响知识调用效率，高级提示可支持更有效的多步推理。此外，空间推理性能在模型规模达到一定阈值后趋于饱和，表明提升地图空间理解需针对性优化空间表示与推理机制，而非单纯依赖模型扩展。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24504">https://arxiv.org/abs/2512.24504</a><br>
<strong>作者</strong>: Zhiwei Wei,Yuxing Liu,Hua Liao,Wenjia Xu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  43 pages, 8 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Map environments provide a fundamental medium for representing spatial structure. Understanding how foundation model (FM) agents understand and act in such environments is therefore critical for enabling reliable map-based reasoning and applications. However, most existing evaluations of spatial ability in FMs rely on static map inputs or text-based queries, overlooking the interactive and experience-driven nature of spatial this http URL this paper, we propose an interactive evaluation framework to analyze how FM agents explore, remember, and reason in symbolic map environments. Agents incrementally explore partially observable grid-based maps consisting of roads, intersections, and points of interest (POIs), receiving only local observations at each step. Spatial understanding is then evaluated using six kinds of spatial tasks. By systematically varying exploration strategies, memory representations, and reasoning schemes across multiple foundation models, we reveal distinct functional roles of these components. Exploration primarily affects experience acquisition but has a limited impact on final reasoning accuracy. In contrast, memory representation plays a central role in consolidating spatial experience, with structured memories particularly sequential and graph-based representations, substantially improving performance on structure-intensive tasks such as path planning. Reasoning schemes further shape how stored spatial knowledge is used, with advanced prompts supporting more effective multi-step inference. We further observe that spatial reasoning performance saturates across model versions and scales beyond a certain capability threshold, indicating that improvements in map-based spatial understanding require mechanisms tailored to spatial representation and reasoning rather than scaling alone.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-34] Can Small Training Runs Reliably Guide Data Curation? Rethinking Proxy-Model Practice</p>
<p>【速读】：该论文试图解决的问题是：在前沿人工智能公司中，数据团队常通过训练小型代理模型（proxy models）来评估预训练数据配方（data recipes），但当前尚缺乏对小规模实验结论是否能可靠迁移至大规模模型训练的充分理解。论文指出，标准实验协议中为追求“公平比较”而固定小模型训练配置的做法存在根本性缺陷——因为最优训练配置本质上依赖于数据特性，导致不同数据配方下的性能排序可能因超参数微调而反转，且该做法与实际大规模模型开发流程中必经的超参数优化步骤脱节。解决方案的关键在于重构评估目标：应识别出在特定数据上经过调优后表现最佳的数据配方；为此，作者提出一个简单有效的改进方法——在代理模型训练中使用降低的学习率（reduced learning rates），该策略在理论上可保持随机特征模型下数据集按最优损失排序的一致性，并在23个涵盖四个关键数据筛选维度的数据配方上实证验证其显著提升小规模实验的可靠性，从而以较低成本实现与全量大模型训练高度相关的相对性能排序。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24503">https://arxiv.org/abs/2512.24503</a><br>
<strong>作者</strong>: Jiachen T. Wang,Tong Wu,Kaifeng Lyu,James Zou,Dawn Song,Ruoxi Jia,Prateek Mittal<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Data teams at frontier AI companies routinely train small proxy models to make critical decisions about pretraining data recipes for full-scale training runs. However, the community has a limited understanding of whether and when conclusions drawn from small-scale experiments reliably transfer to full-scale model training. In this work, we uncover a subtle yet critical issue in the standard experimental protocol for data recipe assessment: the use of identical small-scale model training configurations across all data recipes in the name of “fair” comparison. We show that the experiment conclusions about data quality can flip with even minor adjustments to training hyperparameters, as the optimal training configuration is inherently data-dependent. Moreover, this fixed-configuration protocol diverges from full-scale model development pipelines, where hyperparameter optimization is a standard step. Consequently, we posit that the objective of data recipe assessment should be to identify the recipe that yields the best performance under data-specific tuning. To mitigate the high cost of hyperparameter tuning, we introduce a simple patch to the evaluation protocol: using reduced learning rates for proxy model training. We show that this approach yields relative performance that strongly correlates with that of fully tuned large-scale LLM pretraining runs. Theoretically, we prove that for random-feature models, this approach preserves the ordering of datasets according to their optimal achievable loss. Empirically, we validate this approach across 23 data recipes covering four critical dimensions of data curation, demonstrating dramatic improvements in the reliability of small-scale experiments.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-35] What Drives Success in Physical <mark class="hl-label green">Planning</mark>  with Joint-Embedding Predictive World Models?</p>
<p>【速读】：该论文旨在解决生成式 AI (Generative AI) 中智能体在物理任务上的泛化能力问题，即如何使智能体不仅能在训练环境中完成任务，还能在未见过的新任务和环境中高效执行。其解决方案的关键在于提出一种基于 JEPA-WM（Joint-Embedding Predictive Architecture for World Models）的框架，通过在世界模型（World Model）的学习表征空间中进行规划，而非传统地在输入空间中规划，从而抽象掉无关细节并提升规划效率。研究系统评估了模型架构、训练目标与规划算法对性能的影响，并结合最优选择构建了一个优于 DINO-WM 和 V-JEPA-2-AC 两个基准模型的方案，在模拟环境和真实机器人数据上均验证了其在导航与操作任务中的优越性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24497">https://arxiv.org/abs/2512.24497</a><br>
<strong>作者</strong>: Basile Terver,Tsung-Yen Yang,Jean Ponce,Adrien Bardes,Yann LeCun<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:A long-standing challenge in AI is to develop agents capable of solving a wide range of physical tasks and generalizing to new, unseen tasks and environments. A popular recent approach involves training a world model from state-action trajectories and subsequently use it with a planning algorithm to solve new tasks. Planning is commonly performed in the input space, but a recent family of methods has introduced planning algorithms that optimize in the learned representation space of the world model, with the promise that abstracting irrelevant details yields more efficient planning. In this work, we characterize models from this family as JEPA-WMs and investigate the technical choices that make algorithms from this class work. We propose a comprehensive study of several key components with the objective of finding the optimal approach within the family. We conducted experiments using both simulated environments and real-world robotic data, and studied how the model architecture, the training objective, and the planning algorithm affect planning success. We combine our findings to propose a model that outperforms two established baselines, DINO-WM and V-JEPA-2-AC, in both navigation and manipulation tasks. Code, data and checkpoints are available at this https URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-36] HOLOGRAPH: Active Causal Discovery via Sheaf-Theoretic Alignment of Large Language Model Priors</p>
<p>【速读】：该论文旨在解决从观测数据中进行因果发现时面临的可识别性限制问题，尤其是现有基于大语言模型（Large Language Models, LLMs）的方法因依赖启发式整合而缺乏理论基础。其解决方案的关键在于引入HOLOGRAPH框架，通过层化理论（sheaf theory）形式化LLM引导的因果发现过程：将局部因果信念表示为变量子集上的预层（presheaf）截面，其中一致的全局因果结构对应于全局截面的存在，而拓扑障碍则表现为非零的层上同调（sheaf cohomology）。该方法进一步提出代数潜在投影（Algebraic Latent Projection）处理隐藏混杂因素，并在信念流形上使用自然梯度下降（Natural Gradient Descent）实现优化，从而在合成与真实世界基准测试中实现了具有数学严谨性的因果发现性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24478">https://arxiv.org/abs/2512.24478</a><br>
<strong>作者</strong>: Hyunjun Kim<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Methodology (<a target="_blank" rel="noopener" href="http://stat.ME">stat.ME</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Causal discovery from observational data remains fundamentally limited by identifiability constraints. Recent work has explored leveraging Large Language Models (LLMs) as sources of prior causal knowledge, but existing approaches rely on heuristic integration that lacks theoretical grounding. We introduce HOLOGRAPH, a framework that formalizes LLM-guided causal discovery through sheaf theory–representing local causal beliefs as sections of a presheaf over variable subsets. Our key insight is that coherent global causal structure corresponds to the existence of a global section, while topological obstructions manifest as non-vanishing sheaf cohomology. We propose the Algebraic Latent Projection to handle hidden confounders and Natural Gradient Descent on the belief manifold for principled optimization. Experiments on synthetic and real-world benchmarks demonstrate that HOLOGRAPH provides rigorous mathematical foundations while achieving competitive performance on causal discovery tasks with 50-100 variables. Our sheaf-theoretic analysis reveals that while Identity, Transitivity, and Gluing axioms are satisfied to numerical precision (10^-6), the Locality axiom fails for larger graphs, suggesting fundamental non-local coupling in latent variable projections. Code is available at [this https URL](this https URL).<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-37] Foundation models on the bridge: Semantic hazard detection and safety maneuvers for maritime autonomy with vision-language models</p>
<p>【速读】：该论文旨在解决自主船舶在“警报到接管”（alert-to-takeover）窗口期内如何有效应对超出其操作设计域（Operational Design Domain, ODD）的语义复杂场景的问题，尤其是在缺乏明确几何线索时（如“潜水员标志”或“附近着火”等需理解语义信息的情境）。传统基于几何感知的自主系统难以准确识别此类情境，导致无法触发合适的应急响应。解决方案的关键在于引入一种名为Semantic Lookout的视觉-语言模型（Vision-Language Model, VLM）驱动的快速-慢速异常处理流水线，其中核心组件是一个仅依赖摄像头、候选动作受限的VLM fallback maneuver selector，能够在连续人类授权下从水体合法且世界锚定的轨迹中选择一个谨慎动作（或保持位置），实现短时程、可人工干预的避险操作。实验表明，该方法在40个港口场景中实现了亚10秒延迟下的高语义理解能力与风险缓解效果，显著优于纯几何基线，并通过实船测试验证了端到端可行性，为符合国际海事组织（IMO）MASS代码要求的语义感知级备用策略提供了可行路径。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24470">https://arxiv.org/abs/2512.24470</a><br>
<strong>作者</strong>: Kim Alexander Christensen,Andreas Gudahl Tufte,Alexey Gusev,Rohan Sinha,Milan Ganai,Ole Andreas Alsos,Marco Pavoned,Martin Steinert<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  17 pages without bibliography or appendix. The main paper has 16 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The draft IMO MASS Code requires autonomous and remotely supervised maritime vessels to detect departures from their operational design domain, enter a predefined fallback that notifies the operator, permit immediate human override, and avoid changing the voyage plan without approval. Meeting these obligations in the alert-to-takeover gap calls for a short-horizon, human-overridable fallback maneuver. Classical maritime autonomy stacks struggle when the correct action depends on meaning (e.g., diver-down flag means people in the water, fire close by means hazard). We argue (i) that vision-language models (VLMs) provide semantic awareness for such out-of-distribution situations, and (ii) that a fast-slow anomaly pipeline with a short-horizon, human-overridable fallback maneuver makes this practical in the handover window. We introduce Semantic Lookout, a camera-only, candidate-constrained vision-language model (VLM) fallback maneuver selector that selects one cautious action (or station-keeping) from water-valid, world-anchored trajectories under continuous human authority. On 40 harbor scenes we measure per-call scene understanding and latency, alignment with human consensus (model majority-of-three voting), short-horizon risk-relief on fire hazard scenes, and an on-water alert-fallback maneuver-operator handover. Sub-10 s models retain most of the awareness of slower state-of-the-art models. The fallback maneuver selector outperforms geometry-only baselines and increases standoff distance on fire scenes. A field run verifies end-to-end operation. These results support VLMs as semantic fallback maneuver selectors compatible with the draft IMO MASS Code, within practical latency budgets, and motivate future work on domain-adapted, hybrid autonomy that pairs foundation-model semantics with multi-sensor bird’s-eye-view perception and short-horizon replanning.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-38] Align While Search: Belief-Guided Exploratory Inference for World-Grounded Embodied <mark class="hl-label green">Agents</mark></p>
<p>【速读】：该论文旨在解决大语言模型（Large Language Model, LLM）代理在部分可观测环境下的推理适应性问题，即如何在不依赖梯度更新或额外训练的前提下，提升代理对隐含世界状态的准确建模能力。其解决方案的关键在于提出一种测试时自适应代理，通过后验引导的信念精炼机制迭代更新外部结构化信念，并基于轻量级LLM代理估计的信息增益选择动作，从而实现对环境状态的高效推理与对齐。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24461">https://arxiv.org/abs/2512.24461</a><br>
<strong>作者</strong>: Seohui Bae,Jeonghye Kim,Youngchul Sung,Woohyung Lim<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In this paper, we propose a test-time adaptive agent that performs exploratory inference through posterior-guided belief refinement without relying on gradient-based updates or additional training for LLM agent operating under partial observability. Our agent maintains an external structured belief over the environment state, iteratively updates it via action-conditioned observations, and selects actions by maximizing predicted information gain over the belief space. We estimate information gain using a lightweight LLM-based surrogate and assess world alignment through a novel reward that quantifies the consistency between posterior belief and ground-truth environment configuration. Experiments show that our method outperforms inference-time scaling baselines such as prompt-augmented or retrieval-enhanced LLMs, in aligning with latent world states with significantly lower integration overhead.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-39] Privacy-Preserving Semantic Communications via Multi-Task Learning and Adversarial Perturbations</p>
<p>【速读】：该论文旨在解决语义通信（Semantic Communication）系统中因学习到的语义表示可能泄露敏感信息给未授权接收者（如窃听者）而导致的安全问题。解决方案的关键在于提出一种基于深度学习的语义通信框架，该框架通过联合优化合法传输端与接收端的任务性能，并在迭代式极小极大（min-max）优化过程中主动降低窃听者的语义推断能力；同时引入一个辅助层，对传输波形叠加对抗性扰动（adversarially crafted perturbation），以进一步抑制语义泄露，且无需重新训练合法链路即可有效提升隐私保护效果。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24452">https://arxiv.org/abs/2512.24452</a><br>
<strong>作者</strong>: Yalin E. Sagduyu,Tugba Erpek,Aylin Yener,Sennur Ulukus<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Networking and Internet Architecture (<a target="_blank" rel="noopener" href="http://cs.NI">cs.NI</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Information Theory (<a target="_blank" rel="noopener" href="http://cs.IT">cs.IT</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Semantic communications conveys task-relevant meaning rather than focusing solely on message reconstruction, improving bandwidth efficiency and robustness for next-generation wireless systems. However, learned semantic representations can still leak sensitive information to unintended receivers (eavesdroppers). This paper presents a deep learning-based semantic communication framework that jointly supports multiple receiver tasks while explicitly limiting semantic leakage to an eavesdropper. The legitimate link employs a learned encoder at the transmitter, while the receiver trains decoders for semantic inference and data reconstruction. The security problem is formulated via an iterative min-max optimization in which an eavesdropper is trained to improve its semantic inference, while the legitimate transmitter-receiver pair is trained to preserve task performance while reducing the eavesdropper’s success. We also introduce an auxiliary layer that superimposes a cooperative, adversarially crafted perturbation on the transmitted waveform to degrade semantic leakage to an eavesdropper. Performance is evaluated over Rayleigh fading channels with additive white Gaussian noise using MNIST and CIFAR-10 datasets. Semantic accuracy and reconstruction quality improve with increasing latent dimension, while the min-max mechanism reduces the eavesdropper’s inference performance significantly without degrading the legitimate receiver. The perturbation layer is successful in reducing semantic leakage even when the legitimate link is trained only for its own task. This comprehensive framework motivates semantic communication designs with tunable, end-to-end privacy against adaptive adversaries in realistic wireless settings.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-40] PackKV: Reducing KV Cache Memory Footprint through <mark class="hl-label green">LLM</mark> -Aware Lossy Compression</p>
<p>【速读】：该论文旨在解决基于Transformer的大语言模型（Large Language Models, LLMs）在长文本推理过程中因键值缓存（Key-Value Cache, KV cache）占用大量显存而导致的内存瓶颈问题。其核心挑战在于，随着序列长度和批量大小的增加，KV cache的内存需求可迅速扩展至数GB，严重限制了模型的可扩展性和推理效率。解决方案的关键在于提出一种通用且高效的KV缓存管理框架PackKV，该框架通过针对KV缓存数据特性设计的新型有损压缩技术，实现了压缩算法与系统架构的协同优化。PackKV不仅兼容KV缓存动态增长的特性，还显著降低了内存占用并消除了解压开销，从而在保持高计算效率的同时，相较于最先进的量化方法，在K缓存和V缓存上分别实现平均153.2%和179.6%的内存压缩率，并在A100和RTX Pro 6000 GPU上分别带来75.7%和171.7%的矩阵向量乘法执行吞吐量提升。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24449">https://arxiv.org/abs/2512.24449</a><br>
<strong>作者</strong>: Bo Jiang,Taolue Yang,Youyuan Liu,Xubin He,Sheng Di,Sian Jin<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Transformer-based large language models (LLMs) have demonstrated remarkable potential across a wide range of practical applications. However, long-context inference remains a significant challenge due to the substantial memory requirements of the key-value (KV) cache, which can scale to several gigabytes as sequence length and batch size increase. In this paper, we present \textbfPackKV, a generic and efficient KV cache management framework optimized for long-context generation. %, which synergistically supports both latency-critical and throughput-critical inference scenarios. PackKV introduces novel lossy compression techniques specifically tailored to the characteristics of KV cache data, featuring a careful co-design of compression algorithms and system architecture. Our approach is compatible with the dynamically growing nature of the KV cache while preserving high computational efficiency. Experimental results show that, under the same and minimum accuracy drop as state-of-the-art quantization methods, PackKV achieves, on average, \textbf153.2% higher memory reduction rate for the K cache and \textbf179.6% for the V cache. Furthermore, PackKV delivers extremely high execution throughput, effectively eliminating decompression overhead and accelerating the matrix-vector multiplication operation. Specifically, PackKV achieves an average throughput improvement of \textbf75.7% for K and \textbf171.7% for V across A100 and RTX Pro 6000 GPUs, compared to cuBLAS matrix-vector multiplication kernels, while demanding less GPU memory bandwidth. Code available on this https URL<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-41] Fast and Realistic Automated Scenario Simulations and Reporting for an Autonomous Racing Stack</p>
<p>【速读】：该论文旨在解决自动驾驶赛车系统在开发与验证过程中面临的高效、自动化仿真与测试难题，特别是针对高动态场景（如高速超车）和关键模块（如定位）的可靠性验证问题。解决方案的关键在于构建了一个基于高保真车辆模型（以功能模拟单元FMU形式集成）的自动化仿真与报告流水线，支持本地或GitHub CI/CD环境运行，可实现高达实时速度三倍的仿真效率；同时通过预定义的运行场景配置和故障注入模块（模拟传感器延迟、扰动及节点输出篡改），显著提升了对复杂工况下系统鲁棒性的验证能力，并结合自动化报告设计优化了仿真分析效果。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24402">https://arxiv.org/abs/2512.24402</a><br>
<strong>作者</strong>: Giovanni Lambertini,Matteo Pini,Eugenio Mascaro,Francesco Moretti,Ayoub Raji,Marko Bertogna<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Software Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Systems and Control (<a target="_blank" rel="noopener" href="http://eess.SY">eess.SY</a>)<br>
<strong>备注</strong>:  Accepted to the 2026 IEEE/SICE International Symposium on System Integration (SII 2026)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In this paper, we describe the automated simulation and reporting pipeline implemented for our autonomous racing stack, this http URL. The backbone of the simulation is based on a high-fidelity model of the vehicle interfaced as a Functional Mockup Unit (FMU). The pipeline can execute the software stack and the simulation up to three times faster than real-time, locally or on GitHub for Continuous Integration/- Continuous Delivery (CI/CD). As the most important input of the pipeline, there is a set of running scenarios. Each scenario allows the initialization of the ego vehicle in different initial conditions (position and speed), as well as the initialization of any other configuration of the stack. This functionality is essential to validate efficiently critical modules, like the one responsible for high-speed overtaking maneuvers or localization, which are among the most challenging aspects of autonomous racing. Moreover, we describe how we implemented a fault injection module, capable of introducing sensor delays and perturbations as well as modifying outputs of any node of the stack. Finally, we describe the design of our automated reporting process, aimed at maximizing the effectiveness of the simulation analysis.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-42] FAST-IDS: A Fast Two-Stage Intrusion Detection System with Hybrid Compression for Real-Time Threat Detection in Connected and Autonomous Vehicles</p>
<p>【速读】：该论文旨在解决车联网环境中的智能驾驶车辆（Connected and Autonomous Vehicles, CAVs）在资源受限条件下部署入侵检测系统（Intrusion Detection System, IDS）的难题。其解决方案的关键在于提出了一种多阶段入侵检测系统架构，并结合混合模型压缩技术，使得该系统能够在计算和存储资源有限的边缘设备上高效运行，从而实现对CAVs的安全防护。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24391">https://arxiv.org/abs/2512.24391</a><br>
<strong>作者</strong>: Devika S,Vishnu Hari,Pratik Narang,Tejasvi Alladi,Vinay Chamola<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We have implemented a multi-stage IDS for CAVs that can be deployed to resourec-constrained environments after hybrid model compression.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-43] ubular Riemannian Laplace Approximations for Bayesian Neural Networks</p>
<p>【速读】：该论文旨在解决传统欧氏拉普拉斯近似（Euclidean Laplace approximation）在现代深度神经网络中因损失函数表面高度各向异性和曲率大、对称性群复杂而导致的近似效果不佳的问题。其解决方案的关键在于提出一种基于流形结构的<strong>管状黎曼拉普拉斯近似（Tubular Riemannian Laplace, TRL）</strong>，通过引入Fisher/Gauss-Newton度量来分离先验主导的切向不确定性与数据主导的横截不确定性，并将后验建模为沿低损失峡谷延伸的概率管状结构，从而在高维参数空间中实现高效且可靠的贝叶斯推断。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24381">https://arxiv.org/abs/2512.24381</a><br>
<strong>作者</strong>: Rodrigo Pereira David<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Laplace approximations are among the simplest and most practical methods for approximate Bayesian inference in neural networks, yet their Euclidean formulation struggles with the highly anisotropic, curved loss surfaces and large symmetry groups that characterize modern deep models. Recent work has proposed Riemannian and geometric Gaussian approximations to adapt to this structure. Building on these ideas, we introduce the Tubular Riemannian Laplace (TRL) approximation. TRL explicitly models the posterior as a probabilistic tube that follows a low-loss valley induced by functional symmetries, using a Fisher/Gauss-Newton metric to separate prior-dominated tangential uncertainty from data-dominated transverse uncertainty. We interpret TRL as a scalable reparametrised Gaussian approximation that utilizes implicit curvature estimates to operate in high-dimensional parameter spaces. Our empirical evaluation on ResNet-18 (CIFAR-10 and CIFAR-100) demonstrates that TRL achieves excellent calibration, matching or exceeding the reliability of Deep Ensembles (in terms of ECE) while requiring only a fraction (1/5) of the training cost. TRL effectively bridges the gap between single-model efficiency and ensemble-grade reliability.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-44] FedSecureFormer: A Fast Federated and Secure Transformer Framework for Lightweight Intrusion Detection in Connected and Autonomous Vehicles</p>
<p>【速读】：该论文旨在解决车联网（Connected and Autonomous Vehicles, CAV）环境中入侵检测的挑战，尤其是在分布式数据场景下如何实现高效、隐私保护的模型训练。其解决方案的关键在于构建一个仅包含最小层数的编码器型Transformer架构，并结合联邦学习（Federated Learning, FL）技术，以在保证模型性能的同时降低计算开销并增强数据隐私性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24345">https://arxiv.org/abs/2512.24345</a><br>
<strong>作者</strong>: Devika S,Vishnu Hari,Pratik Narang,Tejasvi Alladi,F. Richard Yu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This works presents an encoder-only transformer built with minimum layers for intrusion detection in the domain of Connected and Autonomous Vehicles using Federated Learning.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-45] Empower Low-Altitude Economy: A Reliability-Aware Dynamic Weighting Allocation for Multi-modal UAV Beam Prediction</p>
<p>【速读】：该论文旨在解决低空经济（Low-altitude Economy, LAE）背景下无人飞行器（Unmanned Aerial Vehicles, UAVs）通信中快速准确的波束预测问题，尤其针对现有多模态方法因静态权重分配导致在不同飞行场景下可靠性不一致、模态失配及对分布偏移敏感的问题。解决方案的关键在于提出一种可靠性感知的动态加权机制，结合语义感知的多模态波束预测框架（SaM2B），通过轻量级环境视觉、飞行姿态和地理空间数据，在时间维度上自适应调整各模态贡献权重；同时引入跨模态对比学习，将多源特征表示映射至共享语义空间，提升模型在模态噪声和分布变化下的判别能力与鲁棒性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24324">https://arxiv.org/abs/2512.24324</a><br>
<strong>作者</strong>: Haojin Li,Anbang Zhang,Chen Sun,Chenyuan Feng,Kaiqian Qu,Tony Q. S. Quek,Haijun Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The low-altitude economy (LAE) is rapidly expanding driven by urban air mobility, logistics drones, and aerial sensing, while fast and accurate beam prediction in uncrewed aerial vehicles (UAVs) communications is crucial for achieving reliable connectivity. Current research is shifting from single-signal to multi-modal collaborative approaches. However, existing multi-modal methods mostly employ fixed or empirical weights, assuming equal reliability across modalities at any given moment. Indeed, the importance of different modalities fluctuates dramatically with UAV motion scenarios, and static weighting amplifies the negative impact of degraded modalities. Furthermore, modal mismatch and weak alignment further undermine cross-scenario generalization. To this end, we propose a reliability-aware dynamic weighting scheme applied to a semantic-aware multi-modal beam prediction framework, named SaM2B. Specifically, SaM2B leverages lightweight cues such as environmental visual, flight posture, and geospatial data to adaptively allocate contributions across modalities at different time points through reliability-aware dynamic weight updates. Moreover, by utilizing cross-modal contrastive learning, we align the “multi-source representation beam semantics” associated with specific beam information to a shared semantic space, thereby enhancing discriminative power and robustness under modal noise and distribution shifts. Experiments on real-world low-altitude UAV datasets show that SaM2B achieves more satisfactory results than baseline methods.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-46] DRL-TH: Jointly Utilizing Temporal Graph Attention and Hierarchical Fusion for UGV Navigation in Crowded Environments</p>
<p>【速读】：该论文旨在解决无人地面车辆（UGV）在拥挤环境中自主导航与避障时，现有深度强化学习（DRL）方法因依赖单帧观测和简单特征拼接导致难以捕捉时序上下文信息、动态适应能力不足的问题。其解决方案的关键在于提出一种基于时序图注意力机制与分层图池化的DRL导航框架（DRL-TH）：首先引入时序引导的图注意力网络（TG-GAT），通过在注意力评分中嵌入时序权重来建模连续帧间的关联，实现对场景演化过程的隐式估计；其次设计图层次抽象模块（GHAM），结合分层池化与可学习加权融合策略，动态整合RGB与激光雷达（LiDAR）多模态特征，从而在多尺度上实现平衡的表征学习。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24284">https://arxiv.org/abs/2512.24284</a><br>
<strong>作者</strong>: Ruitong Li,Lin Zhang,Yuenan Zhao,Chengxin Liu,Ran Song,Wei Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Deep reinforcement learning (DRL) methods have demonstrated potential for autonomous navigation and obstacle avoidance of unmanned ground vehicles (UGVs) in crowded environments. Most existing approaches rely on single-frame observation and employ simple concatenation for multi-modal fusion, which limits their ability to capture temporal context and hinders dynamic adaptability. To address these challenges, we propose a DRL-based navigation framework, DRL-TH, which leverages temporal graph attention and hierarchical graph pooling to integrate historical observations and adaptively fuse multi-modal information. Specifically, we introduce a temporal-guided graph attention network (TG-GAT) that incorporates temporal weights into attention scores to capture correlations between consecutive frames, thereby enabling the implicit estimation of scene evolution. In addition, we design a graph hierarchical abstraction module (GHAM) that applies hierarchical pooling and learnable weighted fusion to dynamically integrate RGB and LiDAR features, achieving balanced representation across multiple scales. Extensive experiments demonstrate that our DRL-TH outperforms existing methods in various crowded environments. We also implemented DRL-TH control policy on a real UGV and showed that it performed well in real world scenarios.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-47] Constrained Language Model Policy Optimization via Risk-aware Stepwise Alignment</p>
<p>【速读】：该论文旨在解决预训练语言模型（Language Models, LMs）在微调过程中因偏离参考策略（reference policy）而引发的风险控制不足问题，尤其针对罕见但可能造成严重危害的有害行为缺乏鲁棒性的问题。现有安全对齐方法如Safe RLHF和SACPO多基于风险中性范式，难以有效应对上述风险。解决方案的关键在于提出一种名为Risk-aware Stepwise Alignment (RSA) 的新方法，其核心创新是将一类嵌套风险度量（nested risk measures）显式引入策略优化过程，将安全对齐建模为一个token级的风险感知约束策略优化问题，并通过分步对齐程序实现基于嵌套风险度量的token级策略更新。该设计不仅能缓解因模型过度偏离参考策略带来的风险，还能明确抑制低概率但高影响的有害行为，从而在保持模型有用性的同时显著降低尾部风险（tail risks）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24263">https://arxiv.org/abs/2512.24263</a><br>
<strong>作者</strong>: Lijun Zhang,Lin Li,Wei Wei,Yajie Qi,Huizhong Song,Jun Wang,Yaodong Yang,Jiye Liang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:When fine-tuning pre-trained Language Models (LMs) to exhibit desired behaviors, maintaining control over risk is critical for ensuring both safety and trustworthiness. Most existing safety alignment methods, such as Safe RLHF and SACPO, typically operate under a risk-neutral paradigm that is insufficient to address the risks arising from deviations from the reference policy and offers limited robustness against rare but potentially catastrophic harmful behaviors. To address this limitation, we propose Risk-aware Stepwise Alignment (RSA), a novel alignment method that explicitly incorporates risk awareness into the policy optimization process by leveraging a class of nested risk measures. Specifically, RSA formulates safety alignment as a token-level risk-aware constrained policy optimization problem and solves it through a stepwise alignment procedure that yields token-level policy updates derived from the nested risk measures. This design offers two key benefits: (1) it mitigates risks induced by excessive model shift away from a reference policy, and (2) it explicitly suppresses low-probability yet high-impact harmful behaviors. Moreover, we provide theoretical analysis on policy optimality under mild assumptions. Experimental results demonstrate that our method achieves high levels of helpfulness while ensuring strong safety and significantly suppresses tail risks, namely low-probability yet high-impact unsafe responses.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-48] Deep Reinforcement Learning for Solving the Fleet Size and Mix Vehicle Routing Problem</p>
<p>【速读】：该论文旨在解决 Fleet Size and Mix Vehicle Routing Problem (FSMVRP)，即车辆数量与车型混合路径优化问题，该问题需同时决策车队组成与路径规划，在短时租赁和按需物流等实际场景中具有重要应用价值，但其复杂性高，尤其在大规模和时间受限环境下求解困难。解决方案的关键在于提出一种基于深度强化学习（Deep Reinforcement Learning, DRL）的方法，将 FSMVRP 建模为马尔可夫决策过程（Markov Decision Process, MDP），并设计了一种新型策略网络 FRIPN（Fleet Routing Integration Policy Network），能够融合车队配置与路径决策；其中引入了专门的输入嵌入机制，包括剩余图嵌入（remaining graph embedding），以提升车辆调度决策的有效性，从而在数秒内生成近优解，显著优于传统方法在计算效率和可扩展性方面的表现。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24251">https://arxiv.org/abs/2512.24251</a><br>
<strong>作者</strong>: Pengfu Wan,Jiawei Chen,Gangyan Xu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG); Optimization and Control (math.OC)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The Fleet Size and Mix Vehicle Routing Problem (FSMVRP) is a prominent variant of the Vehicle Routing Problem (VRP), extensively studied in operations research and computational science. FSMVRP requires simultaneous decisions on fleet composition and routing, making it highly applicable to real-world scenarios such as short-term vehicle rental and on-demand logistics. However, these requirements also increase the complexity of FSMVRP, posing significant challenges, particularly in large-scale and time-constrained environments. In this paper, we propose a deep reinforcement learning (DRL)-based approach for solving FSMVRP, capable of generating near-optimal solutions within a few seconds. Specifically, we formulate the problem as a Markov Decision Process (MDP) and develop a novel policy network, termed FRIPN, that seamlessly integrates fleet composition and routing decisions. Our method incorporates specialized input embeddings designed for distinctdecision objectives, including a remaining graph embedding to facilitate effective vehicle employment decisions. Comprehensive experiments are conducted on both randomly generated instances and benchmark datasets. The experimental results demonstrate that our method exhibits notable advantages in terms of computational efficiency and scalability, particularly in large-scale and time-constrained scenarios. These strengths highlight the potential of our approach for practical applications and provide valuable inspiration for extending DRL-based techniques to other variants of VRP.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-49] SCP: Accelerating Discovery with a Global Web of Autonomous Scientific <mark class="hl-label green">Agents</mark></p>
<p>【速读】：该论文旨在解决当前科学研究中跨平台、跨机构协作效率低下与工具集成复杂的问题，尤其是在多智能体（AI agents）与人类研究人员协同开展科学发现时面临的标准化缺失和流程碎片化挑战。解决方案的关键在于提出并实现SCP（Science Context Protocol），其核心创新在于两个方面：一是通过统一资源描述与调用规范，实现软件工具、模型、数据集及物理仪器等科学资源的协议级标准化，使异构系统间可无缝发现、调用与组合；二是构建以中央SCP Hub与联邦式SCP Server为核心的受控服务架构，实现实验全生命周期（注册、规划、执行、监控、归档）的可追溯、安全可控的工作流编排，从而为多机构、多智能体驱动的科学探索提供基础性基础设施。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24189">https://arxiv.org/abs/2512.24189</a><br>
<strong>作者</strong>: Yankai Jiang,Wenjie Lou,Lilong Wang,Zhenyu Tang,Shiyang Feng,Jiaxuan Lu,Haoran Sun,Yaning Pan,Shuang Gu,Haoyang Su,Feng Liu,Wangxu Wei,Pan Tan,Dongzhan Zhou,Fenghua Ling,Cheng Tan,Bo Zhang,Xiaosong Wang,Lei Bai,Bowen Zhou<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Multiagent Systems (<a target="_blank" rel="noopener" href="http://cs.MA">cs.MA</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce SCP: the Science Context Protocol, an open-source standard designed to accelerate discovery by enabling a global network of autonomous scientific agents. SCP is built on two foundational pillars: (1) Unified Resource Integration: At its core, SCP provides a universal specification for describing and invoking scientific resources, spanning software tools, models, datasets, and physical instruments. This protocol-level standardization enables AI agents and applications to discover, call, and compose capabilities seamlessly across disparate platforms and institutional boundaries. (2) Orchestrated Experiment Lifecycle Management: SCP complements the protocol with a secure service architecture, which comprises a centralized SCP Hub and federated SCP Servers. This architecture manages the complete experiment lifecycle (registration, planning, execution, monitoring, and archival), enforces fine-grained authentication and authorization, and orchestrates traceable, end-to-end workflows that bridge computational and physical laboratories. Based on SCP, we have constructed a scientific discovery platform that offers researchers and agents a large-scale ecosystem of more than 1,600 tool resources. Across diverse use cases, SCP facilitates secure, large-scale collaboration between heterogeneous AI systems and human researchers while significantly reducing integration overhead and enhancing reproducibility. By standardizing scientific context and tool orchestration at the protocol level, SCP establishes essential infrastructure for scalable, multi-institution, agent-driven science.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-50] Developing controlled natural language for formal specification patterns using AI assistants</p>
<p>【速读】：该论文旨在解决软件需求工程中自然语言表述不一致、模糊性高导致的形式化规约难以准确映射的问题，尤其针对事件驱动的时序需求场景。其解决方案的关键在于构建一种受控自然语言（Controlled Natural Language, CNL）的系统化生成方法：首先基于形式化规约模板提取逻辑属性并构造通用自然语言需求模式；其次利用AI助手根据属性定义和具体语义生成缩减后的自然语言需求语料库（通过提示工程实现部分属性的偏置评估）；最后通过对生成模式的语法结构分析，正式化受控自然语言的句法规范。该方法实现了从形式化规约到可读性强且语义清晰的自然语言需求的自动化转换，提升了需求描述的准确性与一致性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24159">https://arxiv.org/abs/2512.24159</a><br>
<strong>作者</strong>: Natalia Garanina,Vladimir Zyubin,Igor Anureev<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: oftware Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Formal Languages and Automata Theory (cs.FL)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Using an AI assistant, we developed a method for systematically constructing controlled natural language for requirements based on formal specification patterns containing logical attributes. The method involves three stages: 1) compiling a generalized natural language requirement pattern that utilizes all attributes of the formal specification template; 2) generating, using the AI assistant, a corpus of natural language requirement patterns, reduced by partially evaluating attributes (the developed prompt utilizes the generalized template, attribute definitions, and specific formal semantics of the requirement patterns); and 3) formalizing the syntax of the controlled natural language based on an analysis of the grammatical structure of the resulting patterns. The method has been tested for event-driven temporal requirements.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-51] Graph-Based Exploration for ARC-AGI-3 Interactive <mark class="hl-label green">Reasoning</mark>  Tasks</p>
<p>【速读】：该论文旨在解决当前大语言模型（Large Language Models, LLMs）在处理交互式推理任务时表现不佳的问题，特别是针对ARC-AGI-3基准中游戏化任务的挑战——这些任务要求智能体通过有限交互推断任务机制并适应复杂度递增的关卡。解决方案的关键在于提出一种无需训练的基于图结构的探索方法：通过视觉帧分割提取有意义的组件，结合视觉显著性优先选择动作，并构建有向图来显式追踪已探索状态与转移关系；该策略通过维护状态-动作对的访问历史，动态优先选择能最短路径到达未测试状态的动作，从而实现系统性的状态空间探索。实验表明，该方法在ARC-AGI-3预览挑战赛中平均解决30/52个关卡，显著优于前沿LLM代理，验证了结构化探索在稀疏反馈环境中对任务动态建模的重要性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24156">https://arxiv.org/abs/2512.24156</a><br>
<strong>作者</strong>: Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present a training-free graph-based approach for solving interactive reasoning tasks in the ARC-AGI-3 benchmark. ARC-AGI-3 comprises game-like tasks where agents must infer task mechanics through limited interactions, and adapt to increasing complexity as levels progress. Success requires forming hypotheses, testing them, and tracking discovered mechanics. The benchmark has revealed that state-of-the-art LLMs are currently incapable of reliably solving these tasks. Our method combines vision-based frame processing with systematic state-space exploration using graph-structured representations. It segments visual frames into meaningful components, prioritizes actions based on visual salience, and maintains a directed graph of explored states and transitions. By tracking visited states and tested actions, the agent prioritizes actions that provide the shortest path to untested state-action pairs. On the ARC-AGI-3 Preview Challenge, this structured exploration strategy solves a median of 30 out of 52 levels across six games and ranks 3rd on the private leaderboard, substantially outperforming frontier LLM-based agents. These results demonstrate that explicit graph-structured exploration, even without learning, can serve as a strong baseline for interactive reasoning and underscore the importance of systematic state tracking and action prioritization in sparse-feedback environments where current LLMs fail to capture task dynamics. The code is open source and available at this https URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-52] Unified Embodied VLM <mark class="hl-label green">Reasoning</mark>  with Robotic Action via Autoregressive Discretized Pre-training</p>
<p>【速读】：该论文旨在解决通用机器人系统在开放世界环境中同时实现广泛泛化能力与高精度动作执行的难题，这一挑战源于当前视觉-语言-动作（Vision-Language-Action, VLA）模型中 embodied reasoning（具身推理）与精确控制之间的脱节。解决方案的关键在于提出两个核心组件：一是引入 Embodied Reasoning Intelligence Quotient (ERIQ)，一个大规模具身推理基准，通过解耦推理与执行，量化评估具身推理能力并揭示其与端到端 VLA 泛化性能间的强正相关性；二是提出 FACT（Flow-matching-based Action Tokenizer），一种基于流匹配的动作分词方法，将连续控制转化为离散序列以保留高保真轨迹重建能力，从而构建 GenieReasoner 模型，在统一空间中联合优化推理与动作策略，显著优于现有连续和离散动作基线，在真实场景中提升了机器人操作的鲁棒性和泛化能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24125">https://arxiv.org/abs/2512.24125</a><br>
<strong>作者</strong>: Yi Liu,Sukai Wang,Dafeng Wei,Xiaowei Cai,Linqing Zhong,Jiange Yang,Guanghui Ren,Jinyu Zhang,Maoqing Yao,Chuankang Li,Xindong He,Liliang Chen,Jianlan Luo<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:General-purpose robotic systems operating in open-world environments must achieve both broad generalization and high-precision action execution, a combination that remains challenging for existing Vision-Language-Action (VLA) models. While large Vision-Language Models (VLMs) improve semantic generalization, insufficient embodied reasoning leads to brittle behavior, and conversely, strong reasoning alone is inadequate without precise control. To provide a decoupled and quantitative assessment of this bottleneck, we introduce Embodied Reasoning Intelligence Quotient (ERIQ), a large-scale embodied reasoning benchmark in robotic manipulation, comprising 6K+ question-answer pairs across four reasoning dimensions. By decoupling reasoning from execution, ERIQ enables systematic evaluation and reveals a strong positive correlation between embodied reasoning capability and end-to-end VLA generalization. To bridge the gap from reasoning to precise execution, we propose FACT, a flow-matching-based action tokenizer that converts continuous control into discrete sequences while preserving high-fidelity trajectory reconstruction. The resulting GenieReasoner jointly optimizes reasoning and action in a unified space, outperforming both continuous-action and prior discrete-action baselines in real-world tasks. Together, ERIQ and FACT provide a principled framework for diagnosing and overcoming the reasoning-precision trade-off, advancing robust, general-purpose robotic manipulation.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-53] CogRec: A Cognitive Recommender <mark class="hl-label green">Agent</mark>  Fusing <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  and Soar for Explainable Recommendation</p>
<p>【速读】：该论文旨在解决大型语言模型（Large Language Models, LLMs）在推荐系统中应用时面临的三大核心挑战：模型的“黑箱”特性导致可解释性差、易产生知识幻觉（knowledge hallucination），以及在线学习能力有限，从而影响推荐系统的可信度与适应性。同时，传统认知架构如Soar虽具备结构化和可解释的推理能力，但其知识获取过程极为繁琐。解决方案的关键在于提出一种新型认知推荐代理CogRec，该代理融合LLM与Soar认知架构的优势：以Soar作为符号推理核心引擎，利用LLM初始化工作记忆中的生产规则（production rules），并通过感知-认知-行动（Perception-Cognition-Action, PCA）循环实现动态决策；当遇到认知瓶颈（impasse）时，CogRec调用LLM生成合理解并经由Soar的归纳机制转化为新的符号规则，从而实现持续在线学习与高可解释性的推荐输出。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24113">https://arxiv.org/abs/2512.24113</a><br>
<strong>作者</strong>: Jiaxin Hu,Tao Wang,Bingsan Yang,Hongrun Wang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
<strong>备注</strong>:  9 pages, 6 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) have demonstrated a remarkable capacity in understanding user preferences for recommendation systems. However, they are constrained by several critical challenges, including their inherent “Black-Box” characteristics, susceptibility to knowledge hallucination, and limited online learning capacity. These factors compromise their trustworthiness and adaptability. Conversely, cognitive architectures such as Soar offer structured and interpretable reasoning processes, yet their knowledge acquisition is notoriously laborious. To address these complementary challenges, we propose a novel cognitive recommender agent called CogRec which synergizes the strengths of LLMs with the Soar cognitive architecture. CogRec leverages Soar as its core symbolic reasoning engine and leverages an LLM for knowledge initialization to populate its working memory with production rules. The agent operates on a Perception-Cognition-Action(PCA) cycle. Upon encountering an impasse, it dynamically queries the LLM to obtain a reasoned solution. This solution is subsequently transformed into a new symbolic production rule via Soar’s chunking mechanism, thereby enabling robust online learning. This learning paradigm allows the agent to continuously evolve its knowledge base and furnish highly interpretable rationales for its recommendations. Extensive evaluations conducted on three public datasets demonstrate that CogRec demonstrates significant advantages in recommendation accuracy, explainability, and its efficacy in addressing the long-tail problem.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-54] Multilevel Fair Allocation</p>
<p>【速读】：该论文旨在解决具有树状层级结构的多层公平资源分配问题，其中每个代理（agent）与其子节点之间存在局部分配关系，而整个分配过程需沿树结构自顶向下迭代至叶节点。其核心挑战在于设计算法，在保证效率的同时维持良好的公平性。解决方案的关键在于提出两种原创算法：第一种是通用的多项式时间顺序算法，采用自顶向下的策略，具备理论保障的效率与公平性；第二种是对近期提出的General Yankee Swap算法的扩展，适用于多层场景，虽仅提供效率保证，但在实践中展现出优异的公平性表现。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24105">https://arxiv.org/abs/2512.24105</a><br>
<strong>作者</strong>: Maxime Lucet,Nawal Benabbou,Aurélie Beynier,Nicolas Maudet<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Science and Game Theory (<a target="_blank" rel="noopener" href="http://cs.GT">cs.GT</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce the concept of multilevel fair allocation of resources with tree-structured hierarchical relations among agents. While at each level it is possible to consider the problem locally as an allocation of an agent to its children, the multilevel allocation can be seen as a trace capturing the fact that the process is iterated until the leaves of the tree. In principle, each intermediary node may have its own local allocation mechanism. The main challenge is then to design algorithms which can retain good fairness and efficiency properties. In this paper we propose two original algorithms under the assumption that leaves of the tree have matroid-rank utility functions and the utility of any internal node is the sum of the utilities of its children. The first one is a generic polynomial-time sequential algorithm that comes with theoretical guarantees in terms of efficiency and fairness. It operates in a top-down fashion – as commonly observed in real-world applications – and is compatible with various local algorithms. The second one extends the recently proposed General Yankee Swap to the multilevel setting. This extension comes with efficiency guarantees only, but we show that it preserves excellent fairness properties in practice.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-55] Enhancing <mark class="hl-label green">LLM</mark>  <mark class="hl-label green">Planning</mark>  Capabilities through Intrinsic Self-Critique</p>
<p>【速读】：该论文旨在解决大型语言模型（Large Language Models, LLMs）在规划任务中性能提升受限的问题，尤其是如何通过内在机制实现自我改进，而非依赖外部验证器或监督信号。其解决方案的关键在于提出一种基于内在自评（intrinsic self-critique）的迭代修正与优化方法：首先采用少样本（few-shot）学习作为基础策略，随后扩展为多样本（many-shot）方法，并引入一个迭代过程对模型自身生成的答案进行批判性评估与修正。实证结果表明，该方法在Blocksworld、Logistics和Mini-grid等规划数据集上显著优于现有基线，实现了当前（2024年10月检查点版本）LLM模型在该类任务中的最先进性能，证明了自评机制在无需外部监督下即可有效提升模型规划能力的核心价值。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24103">https://arxiv.org/abs/2512.24103</a><br>
<strong>作者</strong>: Bernd Bohnet,Pierre-Alexandre Kamienny,Hanie Sedghi,Dilan Gorur,Pranjal Awasthi,Aaron Parisi,Kevin Swersky,Rosanne Liu,Azade Nova,Noah Fiedel<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We demonstrate an approach for LLMs to critique their \emphown answers with the goal of enhancing their performance that leads to significant improvements over established planning benchmarks. Despite the findings of earlier research that has cast doubt on the effectiveness of LLMs leveraging self critique methods, we show significant performance gains on planning datasets in the Blocksworld domain through intrinsic self-critique, without external source such as a verifier. We also demonstrate similar improvements on Logistics and Mini-grid datasets, exceeding strong baseline accuracies. We employ a few-shot learning technique and progressively extend it to a many-shot approach as our base method and demonstrate that it is possible to gain substantial improvement on top of this already competitive approach by employing an iterative process for correction and refinement. We illustrate how self-critique can significantly boost planning performance. Our empirical results present new state-of-the-art on the class of models considered, namely LLM model checkpoints from October 2024. Our primary focus lies on the method itself, demonstrating intrinsic self-improvement capabilities that are applicable regardless of the specific model version, and we believe that applying our method to more complex search techniques and more capable models will lead to even better performance.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-56] FedLiTeCAN : A Federated Lightweight Transformer for Fast and Robust CAN Bus Intrusion Detection</p>
<p>【速读】：该论文旨在解决车联网（Connected and Autonomous Vehicles, CAV）环境中入侵检测系统（Intrusion Detection System, IDS）的计算资源受限与检测精度不足的问题。其解决方案的关键在于设计并实现一种轻量级Transformer模型，通过优化网络结构和参数效率，在保证检测性能的同时显著降低计算开销，从而适应CAV场景下对实时性与资源约束的严格要求。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24088">https://arxiv.org/abs/2512.24088</a><br>
<strong>作者</strong>: Devika S,Pratik Narang,Tejasvi Alladi<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This work implements a lightweight Transformer model for IDS in the domain of Connected and Autonomous Vehicles<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-57] Random Multiplexing</p>
<p>【速读】：该论文旨在解决传统多路复用技术（如SC-FDE和OFDM）在高移动性场景中因依赖特定信道结构而导致鲁棒性不足的问题，尤其是在动态、真实无线环境中难以保持低复杂度检测性能的挑战。解决方案的关键在于引入一种与物理信道解耦的随机多路复用技术（random multiplexing），通过在随机变换域构建等效输入各向同性信道矩阵，实现传输信号在统计意义上的衰落信道遍历性；在此基础上，结合低复杂度的跨域记忆AMP（CD-MAMP）检测器，利用时域信道稀疏性和等效信道随机性，理论上保证了任意有界范数且谱收敛信道矩阵下AMP类检测器的渐近最优最大后验概率（replica MAP）比特误码率（BER）性能，并推导出最优功率分配策略以最小化BER并最大化受限容量，从而实现了在多样化无线应用中的普适性与性能优化。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24087">https://arxiv.org/abs/2512.24087</a><br>
<strong>作者</strong>: Lei Liu,Yuhao Chi,Shunqi Huang,Zhaoyang Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Information Theory (<a target="_blank" rel="noopener" href="http://cs.IT">cs.IT</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG); Signal Processing (eess.SP); Statistics Theory (<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:As wireless communication applications evolve from traditional multipath environments to high-mobility scenarios like unmanned aerial vehicles, multiplexing techniques have advanced accordingly. Traditional single-carrier frequency-domain equalization (SC-FDE) and orthogonal frequency-division multiplexing (OFDM) have given way to emerging orthogonal time-frequency space (OTFS) and affine frequency-division multiplexing (AFDM). These approaches exploit specific channel structures to diagonalize or sparsify the effective channel, thereby enabling low-complexity detection. However, their reliance on these structures significantly limits their robustness in dynamic, real-world environments. To address these challenges, this paper studies a random multiplexing technique that is decoupled from the physical channels, enabling its application to arbitrary norm-bounded and spectrally convergent channel matrices. Random multiplexing achieves statistical fading-channel ergodicity for transmitted signals by constructing an equivalent input-isotropic channel matrix in the random transform domain. It guarantees the asymptotic replica MAP bit-error rate (BER) optimality of AMP-type detectors for linear systems with arbitrary norm-bounded, spectrally convergent channel matrices and signaling configurations, under the unique fixed point assumption. A low-complexity cross-domain memory AMP (CD-MAMP) detector is considered, leveraging the sparsity of the time-domain channel and the randomness of the equivalent channel. Optimal power allocations are derived to minimize the replica MAP BER and maximize the replica constrained capacity of random multiplexing systems. The optimal coding principle and replica constrained-capacity optimality of CD-MAMP detector are investigated for random multiplexing systems. Additionally, the versatility of random multiplexing in diverse wireless applications is explored.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-58] LoongFlow: Directed Evolutionary Search via a Cognitive Plan-Execute-Summarize Paradigm</p>
<p>【速读】：该论文旨在解决传统进化方法在从静态大语言模型（Large Language Models, LLMs）向自进化智能体（self-improving agents）过渡过程中，因缺乏结构化推理而导致的早熟收敛（premature convergence）和高维代码空间中探索效率低下等问题。其解决方案的关键在于提出LoongFlow框架，该框架将LLM融入一个认知驱动的“规划-执行-总结”（Plan-Execute-Summarize, PES）范式，使进化搜索过程具备更强的推理能力；同时引入混合进化记忆系统，通过多岛模型（Multi-Island models）与MAP-Elites结合自适应玻尔兹曼选择（adaptive Boltzmann selection），理论上平衡探索与利用的权衡，维持多样化的行为生态位，从而防止优化停滞并显著提升解的质量与计算效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24077">https://arxiv.org/abs/2512.24077</a><br>
<strong>作者</strong>: Chunhui Wan,Xunan Dai,Zhuo Wang,Minglei Li,Yanpeng Wang,Yinan Mao,Yu Lan,Zhiwen Xiao<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The transition from static Large Language Models (LLMs) to self-improving agents is hindered by the lack of structured reasoning in traditional evolutionary approaches. Existing methods often struggle with premature convergence and inefficient exploration in high-dimensional code spaces. To address these challenges, we introduce LoongFlow, a self-evolving agent framework that achieves state-of-the-art solution quality with significantly reduced computational costs. Unlike “blind” mutation operators, LoongFlow integrates LLMs into a cognitive “Plan-Execute-Summarize” (PES) paradigm, effectively mapping the evolutionary search to a reasoning-heavy process. To sustain long-term architectural coherence, we incorporate a hybrid evolutionary memory system. By synergizing Multi-Island models with MAP-Elites and adaptive Boltzmann selection, this system theoretically balances the exploration-exploitation trade-off, maintaining diverse behavioral niches to prevent optimization stagnation. We instantiate LoongFlow with a General Agent for algorithmic discovery and an ML Agent for pipeline optimization. Extensive evaluations on the AlphaEvolve benchmark and Kaggle competitions demonstrate that LoongFlow outperforms leading baselines (e.g., OpenEvolve, ShinkaEvolve) by up to 60% in evolutionary efficiency while discovering superior solutions. LoongFlow marks a substantial step forward in autonomous scientific discovery, enabling the generation of expert-level solutions with reduced computational overhead.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-59] ROAD: Reflective Optimization via Automated Debugging for Zero-Shot <mark class="hl-label green">Agent</mark>  Alignment</p>
<p>【速读】：该论文旨在解决大型语言模型（Large Language Model, LLM）在实际软件工程场景中进行自动提示优化（Automatic Prompt Optimization, APO）时，因缺乏高质量标注开发数据集而导致的冷启动难题。现有方法依赖于大规模、结构化的黄金标准数据集来计算适应度分数，但在真实环境中，开发者往往只能获取混乱的生产日志和不断演化的错误模式。解决方案的关键在于提出ROAD（Reflective Optimization via Automated Debugging）框架，其核心创新是将提示优化视为一种动态调试过程而非随机搜索，并引入由Analyzer（根因分析）、Optimizer（模式聚合）和Coach（策略集成）组成的多智能体架构，将非结构化失败日志转化为结构化的决策树协议（Decision Tree Protocols），从而实现样本高效、可解释且性能提升显著的提示优化。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24040">https://arxiv.org/abs/2512.24040</a><br>
<strong>作者</strong>: Natchaya Temyingyong,Daman Jain,Neeraj Kumarsahu,Prabhat Kumar,Rachata Phondi,Wachiravit Modecrua,Krittanon Kaewtawee,Krittin Pachtrachai,Touchapon Kraisingkorn<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  22 pages, 1 figure</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Automatic Prompt Optimization (APO) has emerged as a critical technique for enhancing Large Language Model (LLM) performance, yet current state-of-the-art methods typically rely on large, labeled gold-standard development sets to compute fitness scores for evolutionary or Reinforcement Learning (RL) approaches. In real-world software engineering, however, such curated datasets are rarely available during the initial cold start of agent development, where engineers instead face messy production logs and evolving failure modes. We present ROAD (Reflective Optimization via Automated Debugging), a novel framework that bypasses the need for refined datasets by treating optimization as a dynamic debugging investigation rather than a stochastic search. Unlike traditional mutation strategies, ROAD utilizes a specialized multi-agent architecture, comprising an Analyzer for root-cause analysis, an Optimizer for pattern aggregation, and a Coach for strategy integration, to convert unstructured failure logs into robust, structured Decision Tree Protocols. We evaluated ROAD across both a standardized academic benchmark and a live production Knowledge Management engine. Experimental results demonstrate that ROAD is highly sample-efficient, achieving a 5.6 percent increase in success rate (73.6 percent to 79.2 percent) and a 3.8 percent increase in search accuracy within just three automated iterations. Furthermore, on complex reasoning tasks in the retail domain, ROAD improved agent performance by approximately 19 percent relative to the baseline. These findings suggest that mimicking the human engineering loop of failure analysis and patching offers a viable, data-efficient alternative to resource-intensive RL training for deploying reliable LLM agents.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-60] Kidney Exchange: Faster Parameterized Algorithms and Tighter Lower Bounds <mark class="hl-label red">AAMAS2026</mark></p>
<p>【速读】：该论文针对肾交换问题（Kidney Exchange Problem）中的计算复杂性挑战展开研究，旨在设计更高效的参数化算法以提升实际应用中的可扩展性。其核心问题是：在存在配对不兼容患者-供体对和 altruistic donor（无私捐献者）的情况下，如何高效地找到最大数量的肾脏移植方案，同时受限于小循环规模和法律基础设施的约束。解决方案的关键在于提出一种新的确定性固定参数可追踪（FPT）算法，其时间复杂度为 $ O^\star\left((4e)^t\right) \approx O^\star\left(10.88^t\right) $，其中 $ t $ 为接受健康肾脏的患者数，优于当前最优的 $ O^\star\left(14^t\right) $ 算法。此外，论文还通过证明该问题在路径宽（pathwidth）参数下属于 W[1]-hard 类，揭示了其在参数化复杂性框架下的固有难度，从而深化了对该问题计算边界的理解。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24037">https://arxiv.org/abs/2512.24037</a><br>
<strong>作者</strong>: Aritra Banik,Sujoy Bhore,Palash Dey,Abhishek Sahu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Data Structures and Algorithms (cs.DS); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computational Complexity (<a target="_blank" rel="noopener" href="http://cs.CC">cs.CC</a>)<br>
<strong>备注</strong>:  Accepted as a full paper in AAMAS 2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The kidney exchange mechanism allows many patient-donor pairs who are otherwise incompatible with each other to come together and exchange kidneys along a cycle. However, due to infrastructure and legal constraints, kidney exchange can only be performed in small cycles in practice. In reality, there are also some altruistic donors who do not have any paired patients. This allows us to also perform kidney exchange along paths that start from some altruistic donor. Unfortunately, the computational task is NP-complete. To overcome this computational barrier, an important line of research focuses on designing faster algorithms, both exact and using the framework of parameterized complexity. The standard parameter for the kidney exchange problem is the number  t  of patients that receive a healthy kidney. The current fastest known deterministic FPT algorithm for this problem, parameterized by  t , is  O^\star\left(14^t\right) . In this work, we improve this by presenting a deterministic FPT algorithm that runs in time  O^\star\left((4e)^t\right)\approx O^\star\left(10.88^t\right) . This problem is also known to be W[1]-hard parameterized by the treewidth of the underlying undirected graph. A natural question here is whether the kidney exchange problem admits an FPT algorithm parameterized by the pathwidth of the underlying undirected graph. We answer this negatively in this paper by proving that this problem is W[1]-hard parameterized by the pathwidth of the underlying undirected graph. We also present some parameterized intractability results improving the current understanding of the problem under the framework of parameterized complexity.          Comments: Accepted as a full paper in AAMAS 2026   Subjects:  Data Structures and Algorithms (cs.DS); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computational Complexity (<a target="_blank" rel="noopener" href="http://cs.CC">cs.CC</a>)  Cite as: arXiv:2512.24037 [cs.DS]    (or  arXiv:2512.24037v1 [cs.DS] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24037">https://doi.org/10.48550/arXiv.2512.24037</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-61] SPARK: Search Personalization via <mark class="hl-label green">Agent</mark> -Driven Retrieval and Knowledge-sharing <mark class="hl-label red">WSDM</mark> <mark class="hl-label red">WSDM2026</mark></p>
<p>【速读】：该论文旨在解决个性化搜索中用户信息需求动态演变、多维复杂的问题，传统系统受限于静态用户画像或单一检索流程难以有效建模此类行为。解决方案的关键在于提出SPARK框架，通过角色驱动的大型语言模型（Large Language Model, LLM）代理协作机制实现任务特异性检索与涌现式个性化：其核心是构建由角色（role）、专业领域（expertise）、任务上下文（task context）和领域（domain）定义的“人格空间”，并引入Persona Coordinator动态激活最相关的专业化代理；每个代理独立执行检索增强生成（Retrieval-Augmented Generation, RAG）过程，并依托长短时记忆存储与上下文感知推理模块进行知识维护与决策；代理间通过结构化通信协议（如共享内存、迭代辩论和接力式知识传递）实现协同，从而在最小协调规则下形成分布式智能，提升个性化质量与系统适应性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24008">https://arxiv.org/abs/2512.24008</a><br>
<strong>作者</strong>: Gaurab Chhetri,Subasish Das,Tausif Islam Chowdhury<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  This is the author’s preprint. Accepted to WEBGRAPH 2026 (co-located with WSDM 2026), Boise, Idaho, USA, Feb 26, 2026. Final version will appear in WSDM 2026 Companion Proceedings. Conf: <a target="_blank" rel="noopener" href="https://wsdm-conference.org/2026/">this https URL</a> Workshop: <a target="_blank" rel="noopener" href="https://aiimlab.org/events/WSDM_2026_WEB_and_GRAPH_2026_Workshop_on_Web_and_Graphs_Responsible_Intelligence_and_Social_Media.html">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Personalized search demands the ability to model users’ evolving, multi-dimensional information needs; a challenge for systems constrained by static profiles or monolithic retrieval pipelines. We present SPARK (Search Personalization via Agent-Driven Retrieval and Knowledge-sharing), a framework in which coordinated persona-based large language model (LLM) agents deliver task-specific retrieval and emergent personalization. SPARK formalizes a persona space defined by role, expertise, task context, and domain, and introduces a Persona Coordinator that dynamically interprets incoming queries to activate the most relevant specialized agents. Each agent executes an independent retrieval-augmented generation process, supported by dedicated long- and short-term memory stores and context-aware reasoning modules. Inter-agent collaboration is facilitated through structured communication protocols, including shared memory repositories, iterative debate, and relay-style knowledge transfer. Drawing on principles from cognitive architectures, multi-agent coordination theory, and information retrieval, SPARK models how emergent personalization properties arise from distributed agent behaviors governed by minimal coordination rules. The framework yields testable predictions regarding coordination efficiency, personalization quality, and cognitive load distribution, while incorporating adaptive learning mechanisms for continuous persona refinement. By integrating fine-grained agent specialization with cooperative retrieval, SPARK provides insights for next-generation search systems capable of capturing the complexity, fluidity, and context sensitivity of human information-seeking behavior.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-62] ESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems</p>
<p>【速读】：该论文针对仿真优化（Simulation Optimization, SO）中普遍存在的噪声评估、高计算成本以及复杂多峰搜索空间等挑战，提出了一种名为Tabu-Enhanced Simulation Optimization (TESO) 的新型元启发式框架。其解决方案的关键在于融合自适应搜索与基于记忆的策略：通过短期禁忌列表（Tabu List）防止循环并促进多样化探索，利用长期精英记忆（Elite Memory）通过对高性能解进行扰动来引导局部 intensification，并引入一个允许对优异候选解突破禁忌限制的期望准则（aspiration criterion），从而在随机环境中实现探索（exploration）与开发（exploitation）的动态平衡。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24007">https://arxiv.org/abs/2512.24007</a><br>
<strong>作者</strong>: Bulent Soykan,Sean Mondesire,Ghaith Rabadi<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Neural and Evolutionary Computing (<a target="_blank" rel="noopener" href="http://cs.NE">cs.NE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  11 pages, 2 figures, Presented at the Winter Simulation Conference 2025, Seattle, Washington (December 2025)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Simulation optimization (SO) is frequently challenged by noisy evaluations, high computational costs, and complex, multimodal search landscapes. This paper introduces Tabu-Enhanced Simulation Optimization (TESO), a novel metaheuristic framework integrating adaptive search with memory-based strategies. TESO leverages a short-term Tabu List to prevent cycling and encourage diversification, and a long-term Elite Memory to guide intensification by perturbing high-performing solutions. An aspiration criterion allows overriding tabu restrictions for exceptional candidates. This combination facilitates a dynamic balance between exploration and exploitation in stochastic environments. We demonstrate TESO’s effectiveness and reliability using an queue optimization problem, showing improved performance compared to benchmarks and validating the contribution of its memory components. Source code and data are available at: this https URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-63] racing the Hearts Pathways: ECG Representation Learning from a Cardiac Conduction Perspective <mark class="hl-label red">AAAI2026</mark></p>
<p>【速读】：该论文旨在解决现有自监督学习方法在多导联心电图（multi-lead electrocardiogram, ECG）表示学习中的两个关键问题：一是忽略心脏传导过程中心搏间的细微差异，这些差异蕴含独特的生理信息；二是未能遵循ECG诊断指南中从单个心搏到单导联再到导联组合的层级逻辑。解决方案的关键在于提出一个两阶段框架CLEAR-HUG：第一阶段设计了Conduction-LEAd Reconstructor (CLEAR)，通过稀疏注意力机制重建每个心搏信号，同时捕捉心搏间特异性变化与普遍共性；第二阶段引入Hierarchical lead-Unified Group head (HUG)头结构，模拟临床诊断流程，实现从心搏到导联组合的层次化特征整合，从而提升模型对心脏传导机制的理解并增强与专家诊断规范的一致性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24002">https://arxiv.org/abs/2512.24002</a><br>
<strong>作者</strong>: Tan Pan,Yixuan Sun,Chen Jiang,Qiong Gao,Rui Sun,Xingmeng Zhang,Zhenqi Yang,Limei Han,Yixiu Liang,Yuan Cheng,Kaiyu Guo<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Accepted to AAAI2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The multi-lead electrocardiogram (ECG) stands as a cornerstone of cardiac diagnosis. Recent strides in electrocardiogram self-supervised learning (eSSL) have brightened prospects for enhancing representation learning without relying on high-quality annotations. Yet earlier eSSL methods suffer a key limitation: they focus on consistent patterns across leads and beats, overlooking the inherent differences in heartbeats rooted in cardiac conduction processes, while subtle but significant variations carry unique physiological signatures. Moreover, representation learning for ECG analysis should align with ECG diagnostic guidelines, which progress from individual heartbeats to single leads and ultimately to lead combinations. This sequential logic, however, is often neglected when applying pre-trained models to downstream tasks. To address these gaps, we propose CLEAR-HUG, a two-stage framework designed to capture subtle variations in cardiac conduction across leads while adhering to ECG diagnostic guidelines. In the first stage, we introduce an eSSL model termed Conduction-LEAd Reconstructor (CLEAR), which captures both specific variations and general commonalities across heartbeats. Treating each heartbeat as a distinct entity, CLEAR employs a simple yet effective sparse attention mechanism to reconstruct signals without interference from other heartbeats. In the second stage, we implement a Hierarchical lead-Unified Group head (HUG) for disease diagnosis, mirroring clinical workflow. Experimental results across six tasks show a 6.84% improvement, validating the effectiveness of CLEAR-HUG. This highlights its ability to enhance representations of cardiac conduction and align patterns with expert diagnostic guidelines.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-64] PhyAVBench: A Challenging Audio Physics-Sensitivity Benchmark for Physically Grounded Text-to-Audio-Video Generation</p>
<p>【速读】：该论文旨在解决当前文本到音频视频（Text-to-audio-video, T2AV）生成模型在物理合理性上的不足，尤其是其对声学物理机制理解的局限性，导致生成的音频与现实世界中的声音特性不一致。为系统评估现有模型对音频物理原理的建模能力，作者提出PhyAVBench——一个面向音频物理敏感性的基准测试集，其核心创新在于引入“音频物理敏感性测试”（Audio-Physics Sensitivity Test, APST）范式，通过控制1,000组文本提示中的物理变量（如材质、形状、运动状态等），诱导音效变化，并结合50个细粒度测试点（涵盖衍射、赫姆霍兹共振等复杂声学现象）进行量化评估。关键在于：该基准设计确保了测试数据的高保真度和无泄露性（每组提示至少关联20段真实录制视频），并通过人工迭代校正保障内容质量，从而推动T2AV模型从仅关注音画同步向真正具备物理一致性生成能力迈进。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23994">https://arxiv.org/abs/2512.23994</a><br>
<strong>作者</strong>: Tianxin Xie,Wentao Lei,Guanjie Huang,Pengfei Zhang,Kai Jiang,Chunhui Zhang,Fengji Ma,Haoyu He,Han Zhang,Jiangshan He,Jinting Wang,Linghan Fang,Lufei Gao,Orkesh Ablet,Peihua Zhang,Ruolin Hu,Shengyu Li,Weilin Lin,Xiaoyang Feng,Xinyue Yang,Yan Rong,Yanyun Wang,Zihang Shao,Zelin Zhao,Chenxing Li,Shan Yang,Wenfu Wang,Meng Yu,Dong Yu,Li Liu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: ound (<a target="_blank" rel="noopener" href="http://cs.SD">cs.SD</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  6 major physical dimensions, 50 fine-grained test points, 1,000 groups of variable-controlled test samples</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Text-to-audio-video (T2AV) generation underpins a wide range of applications demanding realistic audio-visual content, including virtual reality, world modeling, gaming, and filmmaking. However, existing T2AV models remain incapable of generating physically plausible sounds, primarily due to their limited understanding of physical principles. To situate current research progress, we present PhyAVBench, a challenging audio physics-sensitivity benchmark designed to systematically evaluate the audio physics grounding capabilities of existing T2AV models. PhyAVBench comprises 1,000 groups of paired text prompts with controlled physical variables that implicitly induce sound variations, enabling a fine-grained assessment of models’ sensitivity to changes in underlying acoustic conditions. We term this evaluation paradigm the Audio-Physics Sensitivity Test (APST). Unlike prior benchmarks that primarily focus on audio-video synchronization, PhyAVBench explicitly evaluates models’ understanding of the physical mechanisms underlying sound generation, covering 6 major audio physics dimensions, 4 daily scenarios (music, sound effects, speech, and their mix), and 50 fine-grained test points, ranging from fundamental aspects such as sound diffraction to more complex phenomena, e.g., Helmholtz resonance. Each test point consists of multiple groups of paired prompts, where each prompt is grounded by at least 20 newly recorded or collected real-world videos, thereby minimizing the risk of data leakage during model pre-training. Both prompts and videos are iteratively refined through rigorous human-involved error correction and quality control to ensure high quality. We argue that only models with a genuine grasp of audio-related physical principles can generate physically consistent audio-visual content. We hope PhyAVBench will stimulate future progress in this critical yet largely unexplored domain.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-65] MeLeMaD: Adaptive Malware Detection via Chunk-wise Feature Selection and Meta-Learning</p>
<p>【速读】：该论文旨在解决恶意软件检测中面临的鲁棒性不足、适应性差以及高维大规模数据处理效率低下的问题（即：Malware Detection Challenges）。其解决方案的关键在于提出了一种基于元学习的新型框架——MeLeMaD，该框架利用模型无关元学习（Model-Agnostic Meta-Learning, MAML）的快速适应能力，并结合一种专为高维恶意软件特征设计的分块梯度提升特征选择方法（Chunk-wise Feature Selection based on Gradient Boosting, CFSGB），从而在多个基准和自建数据集上实现了显著优于现有方法的检测性能（如CIC-AndMal2020上准确率达98.04%，BODMAS上达99.97%），有效提升了检测系统的泛化能力和计算效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23987">https://arxiv.org/abs/2512.23987</a><br>
<strong>作者</strong>: Ajvad Haneef K,Karan Kuwar Singh,Madhu Kumar S D<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  20 pages, 8 Figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Confronting the substantial challenges of malware detection in cybersecurity necessitates solutions that are both robust and adaptable to the ever-evolving threat environment. The paper introduces Meta Learning Malware Detection (MeLeMaD), a novel framework leveraging the adaptability and generalization capabilities of Model-Agnostic Meta-Learning (MAML) for malware detection. MeLeMaD incorporates a novel feature selection technique, Chunk-wise Feature Selection based on Gradient Boosting (CFSGB), tailored for handling large-scale, high-dimensional malware datasets, significantly enhancing the detection efficiency. Two benchmark malware datasets (CIC-AndMal2020 and BODMAS) and a custom dataset (EMBOD) were used for rigorously validating the MeLeMaD, achieving a remarkable performance in terms of key evaluation measures, including accuracy, precision, recall, F1-score, MCC, and AUC. With accuracies of 98.04% on CIC-AndMal2020 and 99.97% on BODMAS, MeLeMaD outperforms the state-of-the-art approaches. The custom dataset, EMBOD, also achieves a commendable accuracy of 97.85%. The results underscore the MeLeMaD’s potential to address the challenges of robustness, adaptability, and large-scale, high-dimensional datasets in malware detection, paving the way for more effective and efficient cybersecurity solutions.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-66] Coding With AI: From a Reflection on Industrial Practices to Future Computer Science and Software Engineering Education</p>
<p>【速读】：该论文试图解决的问题是：当前关于生成式 AI（Generative AI）辅助编程的研究主要聚焦于个体开发者或教育场景，缺乏对工业界实践中 LLM 编程工具使用方式、相关风险及开发流程变革的系统性理解。解决方案的关键在于通过质性分析 57 个高质量 YouTube 视频（发布于 2024 年底至 2025 年），提炼专业开发者在真实工作环境中对 LLM 编程的认知、实践模式与挑战，识别出生产力提升与代码质量、安全、可维护性等新风险，并据此提出面向计算机科学与软件工程教育的改革方向——即强化问题求解能力、架构思维、代码审查训练以及早期融入 LLM 工具的项目式学习，以实现教育体系与快速演进的职业现实相匹配。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23982">https://arxiv.org/abs/2512.23982</a><br>
<strong>作者</strong>: Hung-Fu Chang,MohammadShokrolah Shirazi,Lizhou Cao,Supannika Koolmanojwong Mobasser<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: oftware Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  21 pages, 5 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advances in large language models (LLMs) have introduced new paradigms in software development, including vibe coding, AI-assisted coding, and agentic coding, fundamentally reshaping how software is designed, implemented, and maintained. Prior research has primarily examined AI-based coding at the individual level or in educational settings, leaving industrial practitioners’ perspectives underexplored. This paper addresses this gap by investigating how LLM coding tools are used in professional practice, the associated concerns and risks, and the resulting transformations in development workflows, with particular attention to implications for computing education. We conducted a qualitative analysis of 57 curated YouTube videos published between late 2024 and 2025, capturing reflections and experiences shared by practitioners. Following a filtering and quality assessment process, the selected sources were analyzed to compare LLM-based and traditional programming, identify emerging risks, and characterize evolving workflows. Our findings reveal definitions of AI-based coding practices, notable productivity gains, and lowered barriers to entry. Practitioners also report a shift in development bottlenecks toward code review and concerns regarding code quality, maintainability, security vulnerabilities, ethical issues, erosion of foundational problem-solving skills, and insufficient preparation of entry-level engineers. Building on these insights, we discuss implications for computer science and software engineering education and argue for curricular shifts toward problem-solving, architectural thinking, code review, and early project-based learning that integrates LLM tools. This study offers an industry-grounded perspective on AI-based coding and provides guidance for aligning educational practices with rapidly evolving professional realities.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-67] Causify DataFlow: A Framework For High-performance Machine Learning Stream Computing</p>
<p>【速读】：该论文旨在解决传统数据科学工作流在从批处理原型迁移到流式生产系统时存在的关键问题，包括因果性破坏、批次边界伪影以及实时故障难以复现等挑战。其核心解决方案是提出一个基于有向无环图（Directed Acyclic Graph, DAG）的统一执行模型，通过引入“时间点幂等性”（point-in-time idempotency）机制，确保任意时刻 $ t $ 的输出仅依赖于 $ t $ 之前固定长度的上下文窗口，从而实现批处理与流式环境下的行为一致性，无需代码变更。此外，该框架自动追踪知识时间（knowledge time）以强制因果约束，避免未来窥探（future-peeking）错误，并支持灵活的时间和特征维度分块（tiling），使同一模型可通过配置调整运行频率与内存占用，显著提升部署效率与可维护性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23977">https://arxiv.org/abs/2512.23977</a><br>
<strong>作者</strong>: Giacinto Paolo Saggese,Paul Smith<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present DataFlow, a computational framework for building, testing, and deploying high-performance machine learning systems on unbounded time-series data. Traditional data science workflows assume finite datasets and require substantial reimplementation when moving from batch prototypes to streaming production systems. This gap introduces causality violations, batch boundary artifacts, and poor reproducibility of real-time failures. DataFlow resolves these issues through a unified execution model based on directed acyclic graphs (DAGs) with point-in-time idempotency: outputs at any time t depend only on a fixed-length context window preceding t. This guarantee ensures that models developed in batch mode execute identically in streaming production without code changes. The framework enforces strict causality by automatically tracking knowledge time across all transformations, eliminating future-peeking bugs. DataFlow supports flexible tiling across temporal and feature dimensions, allowing the same model to operate at different frequencies and memory profiles via configuration alone. It integrates natively with the Python data science stack and provides fit/predict semantics for online learning, caching and incremental computation, and automatic parallelization through DAG-based scheduling. We demonstrate its effectiveness across domains including financial trading, IoT, fraud detection, and real-time analytics.         Subjects:  Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)  Cite as: arXiv:2512.23977 [cs.LG]    (or  arXiv:2512.23977v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.23977">https://doi.org/10.48550/arXiv.2512.23977</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-68] A Community-Aware Framework for Influence Maximization with Explicit Accounting for Inter-Community Influence</p>
<p>【速读】：该论文旨在解决影响最大化（Influence Maximization, IM）问题中因忽略社区间相互影响而导致的效率与效果不足的问题。传统基于社区的方法通常假设社区之间相互独立，从而在现实复杂网络中限制了信息传播的准确性与覆盖范围。解决方案的关键在于提出Community-IM++框架，其核心创新包括：基于社区扩散度（Community-based Diffusion Degree, CDD）的启发式策略以显式建模跨社区扩散，并结合渐进式预算分配机制，在保证近似贪婪性能的同时显著降低计算开销；此外，通过懒惰评估（lazy evaluation）减少冗余计算，实现对大规模社交网络中种子节点的高效识别与部署。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23973">https://arxiv.org/abs/2512.23973</a><br>
<strong>作者</strong>: Eliot W. Robson,Abhishek K. Umrawal<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: ocial and Information Networks (<a target="_blank" rel="noopener" href="http://cs.SI">cs.SI</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
<strong>备注</strong>:  7 pages, 4 figures, and 1 table</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Influence Maximization (IM) seeks to identify a small set of seed nodes in a social network to maximize expected information spread under a diffusion model. While community-based approaches improve scalability by exploiting modular structure, they typically assume independence between communities, overlooking inter-community influence \unicodex2014 a limitation that reduces effectiveness in real-world networks. We introduce Community-IM++, a scalable framework that explicitly models cross-community diffusion through a principled heuristic based on community-based diffusion degree (CDD) and a progressive budgeting strategy. The algorithm partitions the network, computes CDD to prioritize bridging nodes, and allocates seeds adaptively across communities using lazy evaluation to minimize redundant computations. Experiments on large real-world social networks under different edge weight models show that Community-IM++ achieves near-greedy influence spread at up to 100 times lower runtime, while outperforming Community-IM and degree heuristics across budgets and structural conditions. These results demonstrate the practicality of Community-IM++ for large-scale applications such as viral marketing, misinformation control, and public health campaigns, where efficiency and cross-community reach are critical.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-69] Physics-informed Graph Neural Networks for Operational Flood Modeling <mark class="hl-label red">IJCAI</mark></p>
<p>【速读】：该论文旨在解决物理驱动的洪水模型在实际操作场景中因计算成本高而难以实现快速预测的问题。传统基于物理机制的数值洪水模型虽然精度高，但其复杂的计算过程限制了在需要实时响应的应用中的部署。为此，论文提出了一种新型图神经网络（Graph Neural Network, GNN）架构——DUALFloodGNN，其关键在于通过显式损失项在全局和局部尺度上嵌入物理约束，从而在保持高计算效率的同时提升预测准确性。该模型采用共享的消息传递框架联合预测节点处的水体体积与边上的水流，同时引入多步损失结合动态课程学习策略以优化自回归推理性能，显著优于现有标准GNN及最先进的洪水GNN模型。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23964">https://arxiv.org/abs/2512.23964</a><br>
<strong>作者</strong>: Carlo Malapad Acosta,Herath Mudiyanselage Viraj Vidura Herath,Jia Yu Lim,Abhishek Saha,Sanka Rasnayaka,Lucy Marshall<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  To be submitted to IJCAI</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Flood models inform strategic disaster management by simulating the spatiotemporal hydrodynamics of flooding. While physics-based numerical flood models are accurate, their substantial computational cost limits their use in operational settings where rapid predictions are essential. Models designed with graph neural networks (GNNs) provide both speed and accuracy while having the ability to process unstructured spatial domains. Given its flexible input and architecture, GNNs can be leveraged alongside physics-informed techniques with ease, significantly improving interpretability. This study introduces a novel flood GNN architecture, DUALFloodGNN, which embeds physical constraints at both global and local scales through explicit loss terms. The model jointly predicts water volume at nodes and flow along edges through a shared message-passing framework. To improve performance for autoregressive inference, model training is conducted with a multi-step loss enhanced with dynamic curriculum learning. Compared with standard GNN architectures and state-of-the-art GNN flood models, DUALFloodGNN achieves substantial improvements in predicting multiple hydrologic variables while maintaining high computational efficiency. The model is open-sourced at this https URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-70] An Comparative Analysis about KYC on a Recommendation System Toward <mark class="hl-label green">Agent</mark> ic Recommendation System</p>
<p>【速读】：该论文旨在解决金融领域中客户身份验证（Know Your Customer, KYC）流程的自动化与个性化推荐难题，特别是在多内容垂直领域（如广告、新闻、八卦、用户生成内容和科技）下如何提升推荐系统的精准性与效率。其解决方案的关键在于构建一个基于代理型人工智能（agentic AI）的大规模推荐系统，并通过在不同KYC使用强度下对比Normalized Discounted Cumulative Gain (nDCG)指标在k=1、k=3和k=5截断点的表现，验证了该架构在复杂场景中的有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23961">https://arxiv.org/abs/2512.23961</a><br>
<strong>作者</strong>: Junjie H. Xu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Multiagent Systems (<a target="_blank" rel="noopener" href="http://cs.MA">cs.MA</a>)<br>
<strong>备注</strong>:  5 pages, 1 figure</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This research presents a cutting-edge recommendation system utilizing agentic AI for KYC (Know Your Customer in the financial domain), and its evaluation across five distinct content verticals: Advertising (Ad), News, Gossip, Sharing (User-Generated Content), and Technology (Tech). The study compares the performance of four experimental groups, grouping by the intense usage of KYC, benchmarking them against the Normalized Discounted Cumulative Gain (nDCG) metric at truncation levels of  k=1 ,  k=3 , and  k=5 . By synthesizing experimental data with theoretical frameworks and industry benchmarks from platforms such as Baidu and Xiaohongshu, this research provides insight by showing experimental results for engineering a large-scale agentic recommendation system.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-71] A Proof-of-Concept for Explainable Disease Diagnosis Using <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  and Answer Set Programming</p>
<p>【速读】：该论文旨在解决当前医疗领域中疾病预测准确率不足以及符号人工智能（Symbolic AI）在临床实践中应用受限的问题，后者主要受限于构建高质量知识库所需的巨大人力成本。解决方案的关键在于提出一个名为McCoy的框架，该框架将大语言模型（Large Language Models, LLMs）与答案集编程（Answer Set Programming, ASP）相结合：LLM负责从医学文献自动提取并转化为ASP逻辑规则，再与患者数据融合后由ASP求解器进行推理，从而实现高可解释性的诊断决策。这一集成方法有效降低了知识工程负担，并充分发挥了LLM的语义理解能力与ASP的逻辑推理优势。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23932">https://arxiv.org/abs/2512.23932</a><br>
<strong>作者</strong>: Ioanna Gemou,Evangelos Lamprou<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Accurate disease prediction is vital for timely intervention, effective treatment, and reducing medical complications. While symbolic AI has been applied in healthcare, its adoption remains limited due to the effort required for constructing high-quality knowledge bases. This work introduces McCoy, a framework that combines Large Language Models (LLMs) with Answer Set Programming (ASP) to overcome this barrier. McCoy orchestrates an LLM to translate medical literature into ASP code, combines it with patient data, and processes it using an ASP solver to arrive at the final diagnosis. This integration yields a robust, interpretable prediction framework that leverages the strengths of both paradigms. Preliminary results show McCoy has strong performance on small-scale disease diagnosis tasks.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-72] Interactive Machine Learning: From Theory to Scale <mark class="hl-label red">DATE</mark></p>
<p>【速读】：该论文致力于解决交互式机器学习（Interactive Machine Learning）中的三大核心问题：在存在噪声数据和复杂模型类下的主动学习（Active Learning）、大规模动作空间下的序列决策（Sequential Decision Making），以及部分反馈环境中的模型选择（Model Selection）。其解决方案的关键在于提出新的算法设计原则并建立理论极限，具体包括：首次设计出无需低噪声假设即可实现指数级标签节省的计算高效主动学习算法；开发出与动作空间规模无关的通用上下文Bandit算法，确保效率与可扩展性；以及首次对序列决策中模型选择的基本代价进行紧致刻画。这些成果共同推动了交互式学习的理论基础发展，实现了统计最优性和计算效率的统一，并为实际部署提供了可信赖的指导。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23924">https://arxiv.org/abs/2512.23924</a><br>
<strong>作者</strong>: Yinglun Zhu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
<strong>备注</strong>:  Updated Ph.D. dissertation (typos corrected; minor technical and structural revisions)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Machine learning has achieved remarkable success across a wide range of applications, yet many of its most effective methods rely on access to large amounts of labeled data or extensive online interaction. In practice, acquiring high-quality labels and making decisions through trial-and-error can be expensive, time-consuming, or risky, particularly in large-scale or high-stakes settings. This dissertation studies interactive machine learning, in which the learner actively influences how information is collected or which actions are taken, using past observations to guide future interactions. We develop new algorithmic principles and establish fundamental limits for interactive learning along three dimensions: active learning with noisy data and rich model classes, sequential decision making with large action spaces, and model selection under partial feedback. Our results include the first computationally efficient active learning algorithms achieving exponential label savings without low-noise assumptions; the first efficient, general-purpose contextual bandit algorithms whose guarantees are independent of the size of the action space; and the first tight characterizations of the fundamental cost of model selection in sequential decision making. Overall, this dissertation advances the theoretical foundations of interactive learning by developing algorithms that are statistically optimal and computationally efficient, while also providing principled guidance for deploying interactive learning methods in large-scale, real-world settings.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-73] Efficient Deep Learning for Short-Term Solar Irradiance Time Series Forecasting: A Benchmark Study in Ho Chi Minh City</p>
<p>【速读】：该论文旨在解决光伏发电系统中全球水平辐照度（Global Horizontal Irradiance, GHI）短时预测的准确性问题，以缓解太阳能发电在电网中的波动性。其核心解决方案是通过对比十种深度学习架构（包括LSTM、TCN、Transformer、Informer、iTransformer、TSMixer和Mamba等）在胡志明市高分辨率NSRDB卫星数据（2011–2020年）上的表现，识别出最优模型并优化部署路径。关键发现为：Transformer在预测精度上最优（R²=0.9696），且SHAP分析揭示其具有“近期偏好”特征；而Mamba则显式建模了24小时周期依赖关系，体现不同时间建模机制；进一步提出知识蒸馏（Knowledge Distillation）方法，在压缩Transformer模型23.5%参数的同时意外降低平均绝对误差（MAE: 23.78 W/m²），从而为边缘设备上的低延迟部署提供了可行方案。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23898">https://arxiv.org/abs/2512.23898</a><br>
<strong>作者</strong>: Tin Hoang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  preprint, 40 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Reliable forecasting of Global Horizontal Irradiance (GHI) is essential for mitigating the variability of solar energy in power grids. This study presents a comprehensive benchmark of ten deep learning architectures for short-term (1-hour ahead) GHI time series forecasting in Ho Chi Minh City, leveraging high-resolution NSRDB satellite data (2011-2020) to compare established baselines (e.g. LSTM, TCN) against emerging state-of-the-art architectures, including Transformer, Informer, iTransformer, TSMixer, and Mamba. Experimental results identify the Transformer as the superior architecture, achieving the highest predictive accuracy with an R^2 of 0.9696. The study further utilizes SHAP analysis to contrast the temporal reasoning of these architectures, revealing that Transformers exhibit a strong “recency bias” focused on immediate atmospheric conditions, whereas Mamba explicitly leverages 24-hour periodic dependencies to inform predictions. Furthermore, we demonstrate that Knowledge Distillation can compress the high-performance Transformer by 23.5% while surprisingly reducing error (MAE: 23.78 W/m^2), offering a proven pathway for deploying sophisticated, low-latency forecasting on resource-constrained edge devices.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-74] How <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  Systematically Misrepresent American Climate Opinions</p>
<p>【速读】：该论文旨在解决生成式 AI（Generative AI）在模拟美国公众气候意见时，对交叉身份群体（如种族与性别交叉群体）的代表性偏差问题。现有研究虽关注大语言模型（Large Language Models, LLMs）输出中的交叉性现象，但缺乏与真实人类响应的对比验证。论文的关键解决方案在于：通过将六种LLMs针对978名具有代表性的美国受访者画像的提示（prompt）与实际问卷回答进行系统比对，发现LLMs存在对气候关切度的“压缩效应”——即低估高关切群体、高估低关切群体，且这种偏差具有交叉性特征，例如在黑人群体中错误应用了与白人和西班牙裔群体一致的性别假设，从而导致政策制定中潜在的不公平结果。这一方法突破了传统审计手段难以捕捉的隐性偏差，为提升AI在公共政策领域的公平性和准确性提供了实证依据。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23889">https://arxiv.org/abs/2512.23889</a><br>
<strong>作者</strong>: Sola Kim,Jieshu Wang,Marco A. Janssen,John M. Anderies<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Federal agencies and researchers increasingly use large language models to analyze and simulate public opinion. When AI mediates between the public and policymakers, accuracy across intersecting identities becomes consequential; inaccurate group-level estimates can mislead outreach, consultation, and policy design. While research examines intersectionality in LLM outputs, no study has compared these outputs against real human responses across intersecting identities. Climate policy is one such domain, and this is particularly urgent for climate change, where opinion is contested and diverse. We investigate how LLMs represent intersectional patterns in U.S. climate opinions. We prompted six LLMs with profiles of 978 respondents from a nationally representative U.S. climate opinion survey and compared AI-generated responses to actual human answers across 20 questions. We find that LLMs appear to compress the diversity of American climate opinions, predicting less-concerned groups as more concerned and vice versa. This compression is intersectional: LLMs apply uniform gender assumptions that match reality for White and Hispanic Americans but misrepresent Black Americans, where actual gender patterns differ. These patterns, which may be invisible to standard auditing approaches, could undermine equitable climate governance.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-75] Breaking Audio <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  by Attacking Only the Encoder: A Universal Targeted Latent-Space Audio Attack</p>
<p>【速读】：该论文旨在解决音频-语言模型（Audio-Language Models）在多模态推理过程中因编码器层级存在安全漏洞而导致的潜在风险问题。其解决方案的关键在于提出一种通用的目标定向潜空间攻击（universal targeted latent space attack），该方法通过学习一个跨输入和说话人通用的扰动模式，在不访问语言模型的情况下，直接操纵音频的潜在表示（latent representations），从而诱导下游语言生成模块输出攻击者指定的内容。实验表明，该攻击在Qwen2-Audio-7B-Instruct模型上实现了高成功率且感知失真极小，揭示了多模态系统中编码器层级存在的关键且此前被忽视的安全威胁。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23881">https://arxiv.org/abs/2512.23881</a><br>
<strong>作者</strong>: Roee Ziv,Raz Lapid,Moshe Sipper<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: ound (<a target="_blank" rel="noopener" href="http://cs.SD">cs.SD</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Audio-language models combine audio encoders with large language models to enable multimodal reasoning, but they also introduce new security vulnerabilities. We propose a universal targeted latent space attack, an encoder-level adversarial attack that manipulates audio latent representations to induce attacker-specified outputs in downstream language generation. Unlike prior waveform-level or input-specific attacks, our approach learns a universal perturbation that generalizes across inputs and speakers and does not require access to the language model. Experiments on Qwen2-Audio-7B-Instruct demonstrate consistently high attack success rates with minimal perceptual distortion, revealing a critical and previously underexplored attack surface at the encoder level of multimodal systems.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-76] CASCADE: Cumulative <mark class="hl-label green">Agent</mark> ic Skill Creation through Autonomous Development and Evolution</p>
<p>【速读】：该论文旨在解决当前大型语言模型（Large Language Model, LLM）代理依赖预定义工具或脆弱的工具生成机制所导致的能力受限与适应性不足问题，尤其在复杂科学任务场景下表现不佳。其解决方案的关键在于提出CASCADE框架，该框架通过两种元技能实现自我进化：一是基于网络搜索和代码提取的持续学习能力，二是通过内省和知识图谱探索实现的自我反思机制，从而让代理不仅能掌握复杂外部工具，还能将知识编码为可复用的执行技能，显著提升科学任务成功率（在SciSkillBench基准上达到93.3%），并支持跨代理与科学家的知识共享，推动可扩展的AI辅助科学研究。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23880">https://arxiv.org/abs/2512.23880</a><br>
<strong>作者</strong>: Xu Huang,Junwu Chen,Yuxing Fei,Zhuohan Li,Philippe Schwaller,Gerbrand Ceder<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Materials Science (cond-mat.mtrl-sci)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language model (LLM) agents currently depend on predefined tools or brittle tool generation, constraining their capability and adaptability to complex scientific tasks. We introduce CASCADE, a self-evolving agentic framework representing an early instantiation of the transition from “LLM + tool use” to “LLM + skill acquisition”. CASCADE enables agents to master complex external tools and codify knowledge through two meta-skills: continuous learning via web search and code extraction, and self-reflection via introspection and knowledge graph exploration, among others. We evaluate CASCADE on SciSkillBench, a benchmark of 116 materials science and chemistry research tasks. CASCADE achieves a 93.3% success rate using GPT-5, compared to 35.4% without evolution mechanisms. We further demonstrate real-world applications in computational analysis, autonomous laboratory experiments, and selective reproduction of published papers. Along with human-agent collaboration and memory consolidation, CASCADE accumulates executable skills that can be shared across agents and scientists, moving toward scalable AI-assisted scientific research.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-77] Seeking Late Night Life Lines: Experiences of Conversational AI Use in Mental Health Crisis</p>
<p>【速读】：该论文试图解决的问题是在极端心理健康危机场景下，如何有效利用对话式人工智能（Conversational AI）来提供支持，以弥补人类专业心理服务的可及性不足。其解决方案的关键在于将AI代理设计为连接人类之间关系的桥梁，而非替代人类支持本身——通过增强用户对采取积极行动（如寻求专业帮助）的准备度，同时降低可能的负面行为（如自伤或孤立），从而在“人与人支持之间的空隙”中发挥过渡性作用。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23859">https://arxiv.org/abs/2512.23859</a><br>
<strong>作者</strong>: Leah Hope Ajmani,Arka Ghosh,Benjamin Kaveladze,Eugenia Kim,Keertana Namuduri,Theresa Nguyen,Ebele Okoli,Jessica Schleider,Denae Ford,Jina Suh<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Human-Computer Interaction (cs.HC); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Online, people often recount their experiences turning to conversational AI agents (e.g., ChatGPT, Claude, Copilot) for mental health support – going so far as to replace their therapists. These anecdotes suggest that AI agents have great potential to offer accessible mental health support. However, it’s unclear how to meet this potential in extreme mental health crisis use cases. In this work, we explore the first-person experience of turning to a conversational AI agent in a mental health crisis. From a testimonial survey (n = 53) of lived experiences, we find that people use AI agents to fill the in-between spaces of human support; they turn to AI due to lack of access to mental health professionals or fears of burdening others. At the same time, our interviews with mental health experts (n = 16) suggest that human-human connection is an essential positive action when managing a mental health crisis. Using the stages of change model, our results suggest that a responsible AI crisis intervention is one that increases the user’s preparedness to take a positive action while de-escalating any intended negative action. We discuss the implications of designing conversational AI agents as bridges towards human-human connection rather than ends in themselves.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-78] Security Without Detection: Economic Denial as a Primitive for Edge and IoT Defense</p>
<p>【速读】：该论文旨在解决传统基于检测的网络安全机制在资源受限的物联网（IoT）和边缘计算环境中失效的问题，尤其是在面对使用加密、隐蔽和低速率攻击技术的高级威胁时。其核心挑战在于，这些环境通常无法部署复杂的机器学习（Machine Learning, ML）入侵检测系统（Intrusion Detection System, IDS），而传统检测方法难以应对此类攻击。解决方案的关键是提出一种<strong>经济否认安全（Economic Denial Security, EDS）框架</strong>，它不依赖于攻击检测，而是通过利用防御者对环境的控制权与攻击者无法控制环境之间的根本不对称性，使攻击在经济上变得不可行。EDS由四个机制组成：自适应计算难题、诱饵驱动的交互熵、时间拉伸和带宽税，实现可证明的超线性成本放大效应（Theorem 2），并在ESP32类微控制器上仅需12KB内存即可部署，显著提升了边缘设备的安全韧性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23849">https://arxiv.org/abs/2512.23849</a><br>
<strong>作者</strong>: Samaresh Kumar Singh,Joyjit Roy<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  8 pages, 2 figures, submitted to 3rd International Conference on Intelligent Digitization of Systems and Services (IDSS2026)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Detection-based security fails against sophisticated attackers using encryption, stealth, and low-rate techniques, particularly in IoT/edge environments where resource constraints preclude ML-based intrusion detection. We present Economic Denial Security (EDS), a detection-independent framework that makes attacks economically infeasible by exploiting a fundamental asymmetry: defenders control their environment while attackers cannot. EDS composes four mechanisms adaptive computational puzzles, decoy-driven interaction entropy, temporal stretching, and bandwidth taxation achieving provably superlinear cost amplification. We formalize EDS as a Stackelberg game, deriving closed-form equilibria for optimal parameter selection (Theorem 1) and proving that mechanism composition yields 2.1x greater costs than the sum of individual mechanisms (Theorem 2). EDS requires  12KB memory, enabling deployment on ESP32 class microcontrollers. Evaluation on a 20-device heterogeneous IoT testbed across four attack scenarios (n = 30 trials, p  0.001) demonstrates: 32-560x attack slowdown, 85-520:1 cost asymmetry, 8-62% attack success reduction,  20ms latency overhead, and close to 0% false positives. Validation against IoT-23 malware (Mirai, Torii, Hajime) shows 88% standalone mitigation; combined with ML-IDS, EDS achieves 94% mitigation versus 67% for IDS alone a 27% improvement. EDS provides detection-independent protection suitable for resource-constrained environments where traditional approaches fail. The ability to detect and mitigate the malware samples tested was enhanced; however, the benefits provided by EDS were realized even without the inclusion of an IDS. Overall, the implementation of EDS serves to shift the economic balance in favor of the defender and provides a viable method to protect IoT and edge systems methodologies.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-79] From Correctness to Collaboration: Toward a Human-Centered Framework for Evaluating AI <mark class="hl-label green">Agent</mark>  Behavior in Software Engineering</p>
<p>【速读】：该论文旨在解决当前大型语言模型（Large Language Models, LLMs）在软件工程领域从代码生成工具向协作伙伴演进过程中，评估方法滞后于实际应用需求的问题。现有基准测试主要关注代码正确性，难以捕捉人机协同中所需的动态交互行为。其解决方案的关键在于提出两个核心贡献：一是基于对91组用户定义代理规则的分析，构建了一个面向企业级软件工程的代理行为基础分类法，明确四大期望行为维度——遵守标准与流程、保障代码质量与可靠性、有效解决问题、以及与用户协作；二是引入情境自适应行为（Context-Adaptive Behavior, CAB）框架，揭示行为期望沿“时间跨度”（从即时需求到未来理想）和“工作类型”（从生产级开发到快速原型）两个经验驱动轴线变化，从而为人机协作智能的下一代AI代理设计与评估提供以人类为中心的理论基础。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23844">https://arxiv.org/abs/2512.23844</a><br>
<strong>作者</strong>: Tao Dong,Harini Sampath,Ja Young Lee,Sherry Y. Shi,Andrew Macvean<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: oftware Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Human-Computer Interaction (cs.HC)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:As Large Language Models (LLMs) evolve from code generators into collaborative partners for software engineers, our methods for evaluation are lagging. Current benchmarks, focused on code correctness, fail to capture the nuanced, interactive behaviors essential for successful human-AI partnership. To bridge this evaluation gap, this paper makes two core contributions. First, we present a foundational taxonomy of desirable agent behaviors for enterprise software engineering, derived from an analysis of 91 sets of user-defined agent rules. This taxonomy defines four key expectations of agent behavior: Adhere to Standards and Processes, Ensure Code Quality and Reliability, Solving Problems Effectively, and Collaborating with the User. Second, recognizing that these expectations are not static, we introduce the Context-Adaptive Behavior (CAB) Framework. This emerging framework reveals how behavioral expectations shift along two empirically-derived axes: the Time Horizon (from immediate needs to future ideals), established through interviews with 15 expert engineers, and the Type of Work (from enterprise production to rapid prototyping, for example), identified through a prompt analysis of a prototyping agent. Together, these contributions offer a human-centered foundation for designing and evaluating the next generation of AI agents, moving the field’s focus from the correctness of generated code toward the dynamics of true collaborative intelligence.         Subjects:  Software Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Human-Computer Interaction (cs.HC)  Cite as: arXiv:2512.23844 [<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>]    (or  arXiv:2512.23844v1 [<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.23844">https://doi.org/10.48550/arXiv.2512.23844</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-80] Artificial Intelligence for All? Brazilian Teachers on Ethics Equity and the Everyday Challenges of AI in Education</p>
<p>【速读】：该论文试图解决的问题是：巴西K-12教育领域教师对通用人工智能（General Purpose AI）的认知水平与实际应用需求之间的差距，以及在缺乏系统性政策支持和基础设施条件下，如何推动AI在教育中的有效、公平和伦理化整合。解决方案的关键在于构建以教师培训为核心、公共政策为保障、技术资源为基础的协同机制，包括制定官方课程指南、提供结构化教师发展计划、改善学校数字基础设施，并强化伦理规范与数字公民意识教育，从而实现AI在教育场景中从“自发探索”向“制度化落地”的转变。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23834">https://arxiv.org/abs/2512.23834</a><br>
<strong>作者</strong>: Bruno Florentino,Camila Sestito,Wellington Cruz,André de Carvalho,Robson Bonidia<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This study examines the perceptions of Brazilian K-12 education teachers regarding the use of AI in education, specifically General Purpose AI. This investigation employs a quantitative analysis approach, extracting information from a questionnaire completed by 346 educators from various regions of Brazil regarding their AI literacy and use. Educators vary in their educational level, years of experience, and type of educational institution. The analysis of the questionnaires shows that although most educators had only basic or limited knowledge of AI (80.3%), they showed a strong interest in its application, particularly for the creation of interactive content (80.6%), lesson planning (80.2%), and personalized assessment (68.6%). The potential of AI to promote inclusion and personalized learning is also widely recognized (65.5%). The participants emphasized the importance of discussing ethics and digital citizenship, reflecting on technological dependence, biases, transparency, and responsible use of AI, aligning with critical education and the development of conscious students. Despite enthusiasm for the pedagogical potential of AI, significant structural challenges were identified, including a lack of training (43.4%), technical support (41.9%), and limitations of infrastructure, such as low access to computers, reliable Internet connections, and multimedia resources in schools. The study shows that Brazil is still in a bottom-up model for AI integration, missing official curricula to guide its implementation and structured training for teachers and students. Furthermore, effective implementation of AI depends on integrated public policies, adequate teacher training, and equitable access to technology, promoting ethical, inclusive, and contextually grounded adoption of AI in Brazilian K-12 education.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-81] Improved Bounds for Private and Robust Alignment</p>
<p>【速读】：该论文旨在解决语言模型对齐（language model alignment）中的隐私保护与鲁棒性问题，特别是在偏好标签受到隐私约束和/或对抗性污染（adversarial corruption）的情况下，如何在离线（offline）和在线（online）设置下理论地刻画次优间隙（suboptimality gap）的上界。其解决方案的关键在于：首先，通过引入针对对数损失（log loss）和平方损失（square loss）的新统一收敛性保证（uniform convergence guarantees），在隐私和对抗污染双重干扰下建立了更紧致的理论边界；其次，揭示了现有离线算法在同时处理污染水平和隐私参数方面实际上提供了比以往认知更强的保障，从而改进了纯污染场景下的性能上限；最后，首次提出了私有且鲁棒的在线对齐算法框架，为生成式 AI (Generative AI) 的安全可靠训练提供了坚实的理论基础。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23816">https://arxiv.org/abs/2512.23816</a><br>
<strong>作者</strong>: Wenqian Weng,Yi He,Xingyu Zhou<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In this paper, we study the private and robust alignment of language models from a theoretical perspective by establishing upper bounds on the suboptimality gap in both offline and online settings. We consider preference labels subject to privacy constraints and/or adversarial corruption, and analyze two distinct interplays between them: privacy-first and corruption-first. For the privacy-only setting, we show that log loss with an MLE-style algorithm achieves near-optimal rates, in contrast to conventional wisdom. For the joint privacy-and-corruption setting, we first demonstrate that existing offline algorithms in fact provide stronger guarantees – simultaneously in terms of corruption level and privacy parameters – than previously known, which further yields improved bounds in the corruption-only regime. In addition, we also present the first set of results for private and robust online alignment. Our results are enabled by new uniform convergence guarantees for log loss and square loss under privacy and corruption, which we believe have broad applicability across learning theory and statistics.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-82] Zero-Trust <mark class="hl-label green">Agent</mark> ic Federated Learning for Secure IIoT Defense Systems <mark class="hl-label red">MICRO</mark></p>
<p>【速读】：该论文针对工业物联网（IIoT）环境中联邦学习（FL）框架在面对拜占庭 poisoning 攻击时缺乏鲁棒性及代理身份认证机制薄弱的问题，提出了一种纵深防御架构——零信任智能体联邦学习（ZTA-FL）。其核心解决方案包括三方面：(1) 基于可信平台模块（TPM）的密码学证明机制，实现低于 0.0000001 的误接受率，确保参与节点的真实性；(2) 提出一种基于 SHAP 权重的聚合算法，在非独立同分布（non-IID）数据条件下提供可解释的拜占庭检测，并具备理论保障；(3) 在设备端实施隐私保护的对抗训练，提升模型对恶意扰动的鲁棒性。实验表明，ZTA-FL 在多个入侵检测基准上实现了高检测准确率（97.8%）、强抗攻击能力（30% 拜占庭攻击下仍达 93.2% 准确率）和通信效率优化（降低 34% 通信开销），显著优于现有方法如 FLAME。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23809">https://arxiv.org/abs/2512.23809</a><br>
<strong>作者</strong>: Samaresh Kumar Singh,Joyjit Roy,Martin So<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Distributed, Parallel, and Cluster Computing (cs.DC); Multiagent Systems (<a target="_blank" rel="noopener" href="http://cs.MA">cs.MA</a>)<br>
<strong>备注</strong>:  9 Pages and 6 figures, Submitted in conference 2nd IEEE Conference on Secure and Trustworthy Cyber Infrastructure for IoT and Microelectronics, Houston TX, USA</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent attacks on critical infrastructure, including the 2021 Oldsmar water treatment breach and 2023 Danish energy sector compromises, highlight urgent security gaps in Industrial IoT (IIoT) deployments. While Federated Learning (FL) enables privacy-preserving collaborative intrusion detection, existing frameworks remain vulnerable to Byzantine poisoning attacks and lack robust agent authentication. We propose Zero-Trust Agentic Federated Learning (ZTA-FL), a defense in depth framework combining: (1) TPM-based cryptographic attestation achieving less than 0.0000001 false acceptance rate, (2) a novel SHAP-weighted aggregation algorithm providing explainable Byzantine detection under non-IID conditions with theoretical guarantees, and (3) privacy-preserving on-device adversarial training. Comprehensive experiments across three IDS benchmarks (Edge-IIoTset, CIC-IDS2017, UNSW-NB15) demonstrate that ZTA-FL achieves 97.8 percent detection accuracy, 93.2 percent accuracy under 30 percent Byzantine attacks (outperforming FLAME by 3.1 percent, p less than 0.01), and 89.3 percent adversarial robustness while reducing communication overhead by 34 percent. We provide theoretical analysis, failure mode characterization, and release code for reproducibility.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-83] Prompt-Induced Over-Generation as Denial-of-Service: A Black-Box Attack-Side Benchmark</p>
<p>【速读】：该论文旨在解决大型语言模型（Large Language Models, LLMs）在生成过程中出现的过量生成（Over-Generation）问题，即模型在输出结束标记（End-of-Sequence, EOS）前生成大量冗余token，导致回答质量下降、延迟和成本增加，并可能被恶意利用为拒绝服务（Denial-of-Service, DoS）攻击。其关键解决方案是构建一个黑盒、仅查询式的攻击基准测试平台，用于系统性评估基于提示词（prompt-based）的攻击方法；在此基础上提出了两种纯提示词攻击策略：一是基于进化算法的过量生成提示搜索（Evolutionary Over-Generation Prompt Search, EOGen），通过在token空间中搜索抑制EOS并诱导长续写的前缀；二是基于目标条件强化学习的攻击者（RL-GOAL），训练神经网络生成满足指定长度目标的提示前缀。实验表明，这两种方法均能显著提升过量生成因子（Over-Generation Factor, OGF），其中RL-GOAL表现更优，最大平均OGF达2.81 ± 1.38，验证了提示驱动攻击的有效性和潜在威胁。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23779">https://arxiv.org/abs/2512.23779</a><br>
<strong>作者</strong>: Manu,Yi Guo,Jo Plested,Tim Lynar,Kanchana Thilakarathna,Nirhoshan Sivaroopan,Jack Yang,Wangli Yang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  12 pages, 2 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language models (LLMs) can be driven into over-generation, emitting thousands of tokens before producing an end-of-sequence (EOS) token. This degrades answer quality, inflates latency and cost, and can be weaponized as a denial-of-service (DoS) attack. Recent work has begun to study DoS-style prompt attacks, but typically focuses on a single attack algorithm or assumes white-box access, without an attack-side benchmark that compares prompt-based attackers in a black-box, query-only regime with a known tokenizer. We introduce such a benchmark and study two prompt-only attackers. The first is Evolutionary Over-Generation Prompt Search (EOGen), which searches the token space for prefixes that suppress EOS and induce long continuations. The second is a goal-conditioned reinforcement learning attacker (RL-GOAL) that trains a network to generate prefixes conditioned on a target length. To characterize behavior, we introduce Over-Generation Factor (OGF), the ratio of produced tokens to a model’s context window, along with stall and latency summaries. Our evolutionary attacker achieves mean OGF = 1.38 +/- 1.15 and Success@OGF = 2 of 24.5 percent on Phi-3. RL-GOAL is stronger: across victims it achieves higher mean OGF (up to 2.81 +/- 1.38).<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-84] A Survey on Graph Neural Networks for Fraud Detection in Ride Hailing Platforms</p>
<p>【速读】：该论文旨在解决网约车平台中欺诈行为检测的难题，特别是针对类别不平衡和欺诈行为隐蔽性（fraudulent camouflage）带来的挑战。其解决方案的关键在于利用图神经网络（Graph Neural Networks, GNNs）建模用户、司机与订单之间的复杂关系结构，从而提升异常行为识别的准确性。研究系统梳理了GNN在异常检测中的架构与方法论进展，指出当前模型在真实场景适用性和技术优化方面仍存在显著改进空间，强调未来需结合实际业务数据进一步验证并增强检测策略的有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23777">https://arxiv.org/abs/2512.23777</a><br>
<strong>作者</strong>: Kanishka Hewageegana,Janani Harischandra,Nipuna Senanayake,Gihan Danansuriya,Kavindu Hapuarachchi,Pooja Illangarathne<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  12 pages, 8 figures, 2 tables. Presented at the 2024 7th International Conference on Artificial Intelligence and Big Data (ICAIBD)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This study investigates fraud detection in ride hailing platforms through Graph Neural Networks (GNNs),focusing on the effectiveness of various models. By analyzing prevalent fraudulent activities, the research highlights and compares the existing work related to fraud detection which can be useful when addressing fraudulent incidents within the online ride hailing platforms. Also, the paper highlights addressing class imbalance and fraudulent camouflage. It also outlines a structured overview of GNN architectures and methodologies applied to anomaly detection, identifying significant methodological progress and gaps. The paper calls for further exploration into real-world applicability and technical improvements to enhance fraud detection strategies in the rapidly evolving ride-hailing industry.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-85] FineFT: Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading</p>
<p>【速读】：该论文旨在解决强化学习（Reinforcement Learning, RL）在加密货币期货交易中应用时面临的两大挑战：一是高杠杆导致的奖励波动剧烈，使训练过程不稳定且难以收敛；二是现有方法缺乏对自身能力边界的自知能力，在遭遇新型市场状态（如黑天鹅事件）时易引发重大损失。解决方案的关键在于提出一种高效且具备风险感知能力的集成强化学习框架——FineFT，其核心机制包括三阶段设计：第一阶段通过基于集成时序差分误差（ensemble TD errors）的选择性更新策略提升Q学习器的收敛性；第二阶段利用变分自编码器（Variational Autoencoder, VAE）识别各Q学习器的能力边界并筛选出高盈利个体；第三阶段依据VAE输出的风险评估动态选择最优策略组合，结合保守策略以维持收益并有效控制新市场状态下的风险暴露。实验证明该方法在高频率、5倍杠杆的加密货币期货环境中显著优于12个前沿基线模型，在多个金融指标上实现更高收益的同时将风险降低超过40%。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23773">https://arxiv.org/abs/2512.23773</a><br>
<strong>作者</strong>: Molei Qin,Xinyu Cai,Yewen Li,Haochong Xia,Chuqiao Zong,Shuo Sun,Xinrun Wang,Bo An<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Futures are contracts obligating the exchange of an asset at a predetermined date and price, notable for their high leverage and liquidity and, therefore, thrive in the Crypto market. RL has been widely applied in various quantitative tasks. However, most methods focus on the spot and could not be directly applied to the futures market with high leverage because of 2 challenges. First, high leverage amplifies reward fluctuations, making training stochastic and difficult to converge. Second, prior works lacked self-awareness of capability boundaries, exposing them to the risk of significant loss when encountering new market state (e.g.,a black swan event like COVID-19). To tackle these challenges, we propose the Efficient and Risk-Aware Ensemble Reinforcement Learning for Futures Trading (FineFT), a novel three-stage ensemble RL framework with stable training and proper risk management. In stage I, ensemble Q learners are selectively updated by ensemble TD errors to improve convergence. In stage II, we filter the Q-learners based on their profitabilities and train VAEs on market states to identify the capability boundaries of the learners. In stage III, we choose from the filtered ensemble and a conservative policy, guided by trained VAEs, to maintain profitability and mitigate risk with new market states. Through extensive experiments on crypto futures in a high-frequency trading environment with high fidelity and 5x leverage, we demonstrate that FineFT outperforms 12 SOTA baselines in 6 financial metrics, reducing risk by more than 40% while achieving superior profitability compared to the runner-up. Visualization of the selective update mechanism shows that different agents specialize in distinct market dynamics, and ablation studies certify routing with VAEs reduces maximum drawdown effectively, and selective update improves convergence and performance.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-86] Safety-Biased Policy Optimisation: Towards Hard-Constrained Reinforcement Learning via Trust Regions</p>
<p>【速读】：该论文旨在解决安全关键领域中强化学习（Reinforcement Learning, RL）面临的难题：如何在严格遵守安全约束的前提下最大化奖励。现有方法如拉格朗日法和投影法往往难以保证近零安全违规，或在硬性约束下牺牲奖励性能。解决方案的关键在于提出一种名为Safety-Biased Trust Region Policy Optimisation (SB-TRPO) 的新型信任区域算法，其通过自适应地将策略更新偏向于满足约束条件，同时仍追求奖励提升；具体而言，SB-TRPO 使用成本与奖励的自然策略梯度的凸组合进行信任区域更新，确保每一步都实现固定比例的最优成本降低，从而在理论上保障局部安全进展，并在梯度对齐时实现奖励优化。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23770">https://arxiv.org/abs/2512.23770</a><br>
<strong>作者</strong>: Ankit Kanwar,Dominik Wagner,Luke Ong<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Reinforcement learning (RL) in safety-critical domains requires agents to maximise rewards while strictly adhering to safety constraints. Existing approaches, such as Lagrangian and projection-based methods, often either fail to ensure near-zero safety violations or sacrifice reward performance in the face of hard constraints. We propose Safety-Biased Trust Region Policy Optimisation (SB-TRPO), a new trust-region algorithm for hard-constrained RL. SB-TRPO adaptively biases policy updates towards constraint satisfaction while still seeking reward improvement. Concretely, it performs trust-region updates using a convex combination of the natural policy gradients of cost and reward, ensuring a fixed fraction of optimal cost reduction at each step. We provide a theoretical guarantee of local progress towards safety, with reward improvement when gradients are suitably aligned. Experiments on standard and challenging Safety Gymnasium tasks show that SB-TRPO consistently achieves the best balance of safety and meaningful task completion compared to state-of-the-art methods.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-87] Uncovering Discrimination Clusters: Quantifying and Explaining Systematic Fairness Violations</p>
<p>【速读】：该论文旨在解决算法决策中个体公平性（individual fairness）检测的局限性问题，即传统方法仅关注单对输入在受保护属性（如种族或性别）微小差异下是否产生显著不同的结果，而无法识别系统性或聚集性的歧视模式，这些模式可能影响整个子群体。解决方案的关键在于提出“歧视聚类”（discrimination clustering）的概念，并开发HyFair这一混合技术：它结合形式化符号分析（通过SMT和MILP求解器）以认证个体公平性，同时引入随机搜索来发现因受保护属性微小扰动导致输出分裂为多个显著不同簇的局部区域。这种组合既能在无反例时提供形式化保证，又能识别出纯符号方法难以处理的严重不公平现象；此外，针对高k不公平输入集，还设计了基于决策树风格的可解释性解释方法，从而揭示算法偏见的深层结构。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23769">https://arxiv.org/abs/2512.23769</a><br>
<strong>作者</strong>: Ranit Debnath Akash,Ashish Kumar,Verya Monjezi,Ashutosh Trivedi,Gang(Gary)Tan,Saeid Tizpaz-Niari<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: oftware Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  In 40th IEEE/ACM International Conference on Automated Software Engineering (ASE 2025)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Fairness in algorithmic decision-making is often framed in terms of individual fairness, which requires that similar individuals receive similar outcomes. A system violates individual fairness if there exists a pair of inputs differing only in protected attributes (such as race or gender) that lead to significantly different outcomes-for example, one favorable and the other unfavorable. While this notion highlights isolated instances of unfairness, it fails to capture broader patterns of systematic or clustered discrimination that may affect entire subgroups. We introduce and motivate the concept of discrimination clustering, a generalization of individual fairness violations. Rather than detecting single counterfactual disparities, we seek to uncover regions of the input space where small perturbations in protected features lead to k-significantly distinct clusters of outcomes. That is, for a given input, we identify a local neighborhood-differing only in protected attributes-whose members’ outputs separate into many distinct clusters. These clusters reveal significant arbitrariness in treatment solely based on protected attributes that help expose patterns of algorithmic bias that elude pairwise fairness checks. We present HyFair, a hybrid technique that combines formal symbolic analysis (via SMT and MILP solvers) to certify individual fairness with randomized search to discover discriminatory clusters. This combination enables both formal guarantees-when no counterexamples exist-and the detection of severe violations that are computationally challenging for symbolic methods alone. Given a set of inputs exhibiting high k-unfairness, we introduce a novel explanation method to generate interpretable, decision-tree-style artifacts. Our experiments demonstrate that HyFair outperforms state-of-the-art fairness verification and local explanation methods.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-88] Enabling Physical AI at the Edge: Hardware-Accelerated Recovery of System Dynamics</p>
<p>【速读】：该论文旨在解决边缘计算场景下物理AI（Physical AI）中模型恢复（Model Recovery, MR）的硬件效率问题，即如何在资源受限设备上实现低延迟、低功耗且可解释的实时动态系统建模。现有MR方法（如EMILY和PINN+SR）依赖神经微分方程（Neural ODE）框架，其迭代求解过程难以高效加速于边缘硬件。解决方案的关键在于提出MERINDA（Model Recovery in Reconfigurable Dynamic Architecture），一种基于FPGA加速的MR框架：通过引入GRU驱动的离散化动力学、密集逆ODE层、稀疏驱动的dropout机制以及轻量级ODE求解器，将原本昂贵的Neural ODE组件重构为适合流式并行处理的结构，从而实现关键计算核在FPGA上的完全并行化，显著降低能耗（114倍）、内存占用（28倍），同时保持与GPU方案相当的建模精度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23767">https://arxiv.org/abs/2512.23767</a><br>
<strong>作者</strong>: Bin Xu,Ayan Banerjee,Sandeep Gupta<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Hardware Architecture (<a target="_blank" rel="noopener" href="http://cs.AR">cs.AR</a>)<br>
<strong>备注</strong>:  2025 59th Asilomar Conference on Signals, Systems, and Computers</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Physical AI at the edge – enabling autonomous systems to understand and predict real-world dynamics in real time – requires hardware-efficient learning and inference. Model recovery (MR), which identifies governing equations from sensor data, is a key primitive for safe and explainable monitoring in mission-critical autonomous systems operating under strict latency, compute, and power constraints. However, state-of-the-art MR methods (e.g., EMILY and PINN+SR) rely on Neural ODE formulations that require iterative solvers and are difficult to accelerate efficiently on edge hardware. We present \textbfMERINDA (Model Recovery in Reconfigurable Dynamic Architecture), an FPGA-accelerated MR framework designed to make physical AI practical on resource-constrained devices. MERINDA replaces expensive Neural ODE components with a hardware-friendly formulation that combines (i) GRU-based discretized dynamics, (ii) dense inverse-ODE layers, (iii) sparsity-driven dropout, and (iv) lightweight ODE solvers. The resulting computation is structured for streaming parallelism, enabling critical kernels to be fully parallelized on the FPGA. Across four benchmark nonlinear dynamical systems, MERINDA delivers substantial gains over GPU implementations: \textbf114 \times  lower energy (434~J vs.\ 49,375~J), \textbf28 \times  smaller memory footprint (214~MB vs.\ 6,118~MB), and \textbf1.68 \times  faster training, while matching state-of-the-art model-recovery accuracy. These results demonstrate that MERINDA can bring accurate, explainable MR to the edge for real-time monitoring of autonomous systems.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-89] Drift-Based Dataset Stability Benchmark</p>
<p>【速读】：该论文旨在解决网络流量分类中因数据分布变化（即数据漂移或概念漂移）导致的机器学习模型性能骤降问题，尤其是在训练数据集过时或新型协议出现后，模型稳定性难以保障的问题。其解决方案的关键在于提出一种基于概念漂移检测方法的新颖评估框架，并引入机器学习特征权重来增强漂移检测的灵敏度与准确性，从而实现对数据集稳定性的量化评估与优化路径识别。该框架已在CESNET-TLS-Year22数据集上验证，为后续数据集改进提供了可量化的基准和优化依据。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23762">https://arxiv.org/abs/2512.23762</a><br>
<strong>作者</strong>: Dominik Soukup,Richard Plný,Daniel Vašata,Tomáš Čejka<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Networking and Internet Architecture (<a target="_blank" rel="noopener" href="http://cs.NI">cs.NI</a>)<br>
<strong>备注</strong>:  9 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Machine learning (ML) represents an efficient and popular approach for network traffic classification. However, network traffic classification is a challenging domain, and trained models may degrade soon after deployment due to the obsolete datasets and quick evolution of computer networks as new or updated protocols appear. Moreover, significant change in the behavior of a traffic type (and, therefore, the underlying features representing the traffic) can produce a large and sudden performance drop of the deployed model, known as a data or concept drift. In most cases, complete retraining is performed, often without further investigation of root causes, as good dataset quality is assumed. However, this is not always the case and further investigation must be performed. This paper proposes a novel methodology to evaluate the stability of datasets and a benchmark workflow that can be used to compare datasets. The proposed framework is based on a concept drift detection method that also uses ML feature weights to boost the detection performance. The benefits of this work are demonstrated on CESNET-TLS-Year22 dataset. We provide the initial dataset stability benchmark that is used to describe dataset stability and weak points to identify the next steps for optimization. Lastly, using the proposed benchmarking methodology, we show the optimization impact on the created dataset variants.          Comments: 9 pages   Subjects:  Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Networking and Internet Architecture (<a target="_blank" rel="noopener" href="http://cs.NI">cs.NI</a>)  Cite as: arXiv:2512.23762 [cs.LG]    (or  arXiv:2512.23762v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.23762">https://doi.org/10.48550/arXiv.2512.23762</a>   Focus to learn more                      arXiv-issued DOI via DataCite<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-90] Audited Skill-Graph Self-Improvement for <mark class="hl-label green">Agent</mark> ic <mark class="hl-label green">LLM</mark> s via Verifiable Rewards Experience Synthesis and Continual Memory</p>
<p>【速读】：该论文旨在解决自改进型智能体（self-improving agents）在部署过程中面临的<strong>安全与治理挑战</strong>，包括优化压力导致的奖励作弊（reward hacking）、行为漂移难以审计或复现，以及改进过程嵌入于不透明的参数更新中而缺乏可复用、可验证的成果。其核心解决方案是提出<strong>可审计技能图自改进框架（Audited Skill-Graph Self-Improvement, ASG-SI）</strong>，将自改进视为对智能体能力的迭代编译过程，通过从成功轨迹中提取候选改进、标准化为具有显式接口的技能，并在通过验证器支持的回放测试和合约检查后才予以采纳；同时，奖励被分解为基于可回放证据的可重构组件，从而实现对推广决策与学习信号的独立审计。该方法实现了可追溯、可验证的能力积累机制，为可重复评估与操作治理提供了实践路径。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23760">https://arxiv.org/abs/2512.23760</a><br>
<strong>作者</strong>: Ken Huang,Jerry Huang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  11 pages, 4 figures. Includes a complete runnable reference implementation and audit logging framework</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Reinforcement learning is increasingly used to transform large language models into agentic systems that act over long horizons, invoke tools, and manage memory under partial observability. While recent work has demonstrated performance gains through tool learning, verifiable rewards, and continual training, deployed self-improving agents raise unresolved security and governance challenges: optimization pressure can incentivize reward hacking, behavioral drift is difficult to audit or reproduce, and improvements are often entangled in opaque parameter updates rather than reusable, verifiable artifacts. This paper proposes Audited Skill-Graph Self-Improvement (ASG-SI), a framework that treats self-improvement as iterative compilation of an agent into a growing, auditable skill graph. Each candidate improvement is extracted from successful trajectories, normalized into a skill with an explicit interface, and promoted only after passing verifier-backed replay and contract checks. Rewards are decomposed into reconstructible components derived from replayable evidence, enabling independent audit of promotion decisions and learning signals. ASG-SI further integrates experience synthesis for scalable stress testing and continual memory control to preserve long-horizon performance under bounded context. We present a complete system architecture, threat model, and security analysis, and provide a fully runnable reference implementation that demonstrates verifier-backed reward construction, skill compilation, audit logging, and measurable improvement under continual task streams. ASG-SI reframes agentic self-improvement as accumulation of verifiable, reusable capabilities, offering a practical path toward reproducible evaluation and operational governance of self-improving AI agents.          Comments: 11 pages, 4 figures. Includes a complete runnable reference implementation and audit logging framework   Subjects:  Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)   MSC classes: 68T05, 68T20, 68M25 (Learning and adaptive systems, Artificial intelligence, Computer security)   Cite as: arXiv:2512.23760 [<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>]    (or  arXiv:2512.23760v1 [<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.23760">https://doi.org/10.48550/arXiv.2512.23760</a>   Focus to learn more                      arXiv-issued DOI via DataCite<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-91] HINTS: Extraction of Human Insights from Time-Series Without External Sources <mark class="hl-label red">AAAI2026</mark></p>
<p>【速读】：该论文旨在解决现有时间序列预测模型在捕捉人类决策、情绪及集体心理等复杂因素时对外部数据（如新闻和社交媒体）的高度依赖问题，此类依赖带来了显著的财务、计算和实际应用成本。解决方案的关键在于提出一种名为HINTS的自监督学习框架，其核心创新是通过弗里德金-约翰森（Friedkin-Johnsen, FJ）意见动态模型作为结构归纳偏置，从时间序列残差中内生地提取这些隐含的人类因素，并将其以注意力图的形式嵌入到先进的主干预测模型中，从而在不依赖外部数据的前提下提升预测精度并增强可解释性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23755">https://arxiv.org/abs/2512.23755</a><br>
<strong>作者</strong>: Sheo Yon Jhin,Noseong Park<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  AAAI 2026 AI4TS Workshop paper</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Human decision-making, emotions, and collective psychology are complex factors that shape the temporal dynamics observed in financial and economic systems. Many recent time series forecasting models leverage external sources (e.g., news and social media) to capture human factors, but these approaches incur high data dependency costs in terms of financial, computational, and practical implications. In this study, we propose HINTS, a self-supervised learning framework that extracts these latent factors endogenously from time series residuals without external data. HINTS leverages the Friedkin-Johnsen (FJ) opinion dynamics model as a structural inductive bias to model evolving social influence, memory, and bias patterns. The extracted human factors are integrated into a state-of-the-art backbone model as an attention map. Experimental results using nine real-world and benchmark datasets demonstrate that HINTS consistently improves forecasting accuracy. Furthermore, multiple case studies and ablation studies validate the interpretability of HINTS, demonstrating strong semantic alignment between the extracted factors and real-world events, demonstrating the practical utility of HINTS.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-92] Generalized Regularized Evidential Deep Learning Models: Theory and Comprehensive Evaluation</p>
<p>【速读】：该论文旨在解决证据深度学习（Evidential Deep Learning, EDL）模型中因主观逻辑框架限制证据必须非负而导致的激活依赖性学习冻结问题，即在低证据区域梯度极小、导致模型难以有效更新的问题。解决方案的关键在于理论分析不同证据激活函数对学习动态的影响，并在此基础上设计了一类通用的激活函数及其对应的证据正则化项，从而在不同激活区间内实现一致且稳定的证据更新路径，显著提升了模型在多种分类任务和少样本学习场景下的性能与鲁棒性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23753">https://arxiv.org/abs/2512.23753</a><br>
<strong>作者</strong>: Deep Shankar Pandey,Hyomin Choi,Qi Yu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  This work has been submitted to the IEEE for possible publication</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Evidential deep learning (EDL) models, based on Subjective Logic, introduce a principled and computationally efficient way to make deterministic neural networks uncertainty-aware. The resulting evidential models can quantify fine-grained uncertainty using learned evidence. However, the Subjective-Logic framework constrains evidence to be non-negative, requiring specific activation functions whose geometric properties can induce activation-dependent learning-freeze behavior: a regime where gradients become extremely small for samples mapped into low-evidence regions. We theoretically characterize this behavior and analyze how different evidential activations influence learning dynamics. Building on this analysis, we design a general family of activation functions and corresponding evidential regularizers that provide an alternative pathway for consistent evidence updates across activation regimes. Extensive experiments on four benchmark classification problems (MNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet), two few-shot classification problems, and blind face restoration problem empirically validate the developed theory and demonstrate the effectiveness of the proposed generalized regularized evidential models.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-93] Geometric Scaling of Bayesian Inference in <mark class="hl-label green">LLM</mark> s</p>
<p>【速读】：该论文旨在探究现代生产级语言模型是否保留了在受控“风洞”实验中观察到的、支持精确贝叶斯推理的几何结构，即低维值流形（value manifolds）和逐步正交的键（keys）等特征。其解决方案的关键在于：通过分析Pythia、Phi-2、Llama-3和Mistral等多个主流语言模型的最后层值表示，发现它们沿一个主导轴组织，且该轴位置与预测熵高度相关；进一步地，在Pythia-410M模型中对这一熵对齐轴进行靶向干预，结果表明移除或扰动该轴会破坏局部不确定性几何结构，而随机轴干预则无此效应——这说明该几何结构是不确定性的特权读出机制，而非单一计算瓶颈。研究证实，现代语言模型不仅保有贝叶斯推理所需的几何基底，还将其用于近似贝叶斯更新过程。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23752">https://arxiv.org/abs/2512.23752</a><br>
<strong>作者</strong>: Naman Aggarwal,Siddhartha R. Dalal,Vishal Misra<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent work has shown that small transformers trained in controlled &quot;wind-tunnel’’ settings can implement exact Bayesian inference, and that their training dynamics produce a geometric substrate – low-dimensional value manifolds and progressively orthogonal keys – that encodes posterior structure. We investigate whether this geometric signature persists in production-grade language models. Across Pythia, Phi-2, Llama-3, and Mistral families, we find that last-layer value representations organize along a single dominant axis whose position strongly correlates with predictive entropy, and that domain-restricted prompts collapse this structure into the same low-dimensional manifolds observed in synthetic settings. To probe the role of this geometry, we perform targeted interventions on the entropy-aligned axis of Pythia-410M during in-context learning. Removing or perturbing this axis selectively disrupts the local uncertainty geometry, whereas matched random-axis interventions leave it intact. However, these single-layer manipulations do not produce proportionally specific degradation in Bayesian-like behavior, indicating that the geometry is a privileged readout of uncertainty rather than a singular computational bottleneck. Taken together, our results show that modern language models preserve the geometric substrate that enables Bayesian inference in wind tunnels, and organize their approximate Bayesian updates along this substrate.         Subjects:  Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)  Cite as: arXiv:2512.23752 [cs.LG]    (or  arXiv:2512.23752v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.23752">https://doi.org/10.48550/arXiv.2512.23752</a>   Focus to learn more                      arXiv-issued DOI via DataCite<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-94] Coordinate Matrix Machine: A Human-level Concept Learning to Classify Very Similar Documents</p>
<p>【速读】：该论文旨在解决传统机器学习算法在概念学习中数据需求量大、计算资源消耗高以及缺乏可解释性等问题，尤其针对当前主流“红AI”（Red AI）依赖大规模预训练和GPU算力的局限性。其解决方案的关键在于提出Coordinate Matrix Machine（CM²），一种专为增强人类智能而设计的小型模型，通过识别文档结构中的关键几何特征（即人类感知的重要结构坐标），实现仅需单一样本即可完成分类的“一次学习”（one-shot learning）。相比传统向量化方法或复杂深度学习模型，CM²聚焦于结构信息而非语义向量，从而在CPU环境下实现高精度、低延迟、可解释性强且环境友好的绿色AI（Green AI）能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23749">https://arxiv.org/abs/2512.23749</a><br>
<strong>作者</strong>: Amin Sadri,M Maruf Hossain<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  16 pages, 3 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Human-level concept learning argues that humans typically learn new concepts from a single example, whereas machine learning algorithms typically require hundreds of samples to learn a single concept. Our brain subconsciously identifies important features and learns more effectively. \vspace*6pt Contribution: In this paper, we present the Coordinate Matrix Machine (CM ^2 ). This purpose-built small model augments human intelligence by learning document structures and using this information to classify documents. While modern “Red AI” trends rely on massive pre-training and energy-intensive GPU infrastructure, CM ^2  is designed as a Green AI solution. It achieves human-level concept learning by identifying only the structural “important features” a human would consider, allowing it to classify very similar documents using only one sample per class. Advantage: Our algorithm outperforms traditional vectorizers and complex deep learning models that require larger datasets and significant compute. By focusing on structural coordinates rather than exhaustive semantic vectors, CM ^2  offers: 1. High accuracy with minimal data (one-shot learning) 2. Geometric and structural intelligence 3. Green AI and environmental sustainability 4. Optimized for CPU-only environments 5. Inherent explainability (glass-box model) 6. Faster computation and low latency 7. Robustness against unbalanced classes 8. Economic viability 9. Generic, expandable, and extendable          Comments: 16 pages, 3 figures   Subjects:  Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)  Cite as: arXiv:2512.23749 [cs.LG]    (or  arXiv:2512.23749v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.23749">https://doi.org/10.48550/arXiv.2512.23749</a>   Focus to learn more                      arXiv-issued DOI via DataCite<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-95] Hybrid-Code: A Privacy-Preserving Redundant Multi-<mark class="hl-label green">Agent</mark>  Framework for Reliable Local Clinical Coding</p>
<p>【速读】：该论文旨在解决基于云的大语言模型（Large Language Models, LLMs）在临床编码自动化中面临的隐私泄露风险和延迟瓶颈问题，这些问题限制了其在医院本地部署的可行性。解决方案的关键在于提出一种混合神经符号多智能体框架——Hybrid-Code，其核心机制包括：1）一个“编码器”（Coder）智能体，在BioMistral-7B模型成功进行语义推理时使用生成式AI能力，失败时切换至确定性关键词匹配以保障流程完成；2）一个“审计员”（Auditor）智能体，持续验证输出代码是否符合257个标准代码的知识库及临床证据，实现无数据外泄的本地化质量控制。该架构通过冗余设计与符号验证相结合的方式，在确保隐私的前提下显著提升系统可靠性，证明在医疗生产环境中，冗余带来的可靠性比单纯模型性能更重要。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23743">https://arxiv.org/abs/2512.23743</a><br>
<strong>作者</strong>: Yunguo Yu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: oftware Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  18 pages, 1 figure, original research paper</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Clinical coding automation using cloud-based Large Language Models (LLMs) poses privacy risks and latency bottlenecks, rendering them unsuitable for on-premise healthcare deployment. We introduce Hybrid-Code, a hybrid neuro-symbolic multi-agent framework for local clinical coding that ensures production reliability through redundancy and verification. Our system comprises two agents: a Coder that attempts language model-based semantic reasoning using BioMistral-7B but falls back to deterministic keyword matching when model output is unreliable, ensuring pipeline completion; and an Auditor that verifies codes against a 257-code knowledge base and clinical evidence. Evaluating on 1,000 MIMIC-III discharge summaries, we demonstrate no hallucinated codes among accepted outputs within the knowledge base, 24.47% verification rate, and 34.11% coverage (95% CI: 31.2%–37.0%) with 86%+ language model utilization. The Auditor filtered invalid format codes and provided evidence-based quality control (75.53% rejection rate) while ensuring no patient data leaves the hospital firewall. The hybrid architecture – combining language model semantic understanding (when successful), deterministic fallback (when the model fails), and symbolic verification (always active) – ensures both reliability and privacy preservation, addressing critical barriers to AI adoption in healthcare. Our key finding is that reliability through redundancy is more valuable than pure model performance in production healthcare systems, where system failures are unacceptable.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-96] <mark class="hl-label green">Agent</mark> icTCAD: A <mark class="hl-label green">LLM</mark> -based Multi-<mark class="hl-label green">Agent</mark>  Framework for Automated TCAD Code Generation and Device Optimization</p>
<p>【速读】：该论文旨在解决先进工艺节点下器件设计与优化过程中因TCAD（Technology Computer-Aided Design）仿真资源匮乏导致的自动化程度低的问题，尤其针对生成式AI模型难以生成有效TCAD代码的瓶颈。其解决方案的关键在于构建了一个由专家标注的开源TCAD数据集，并基于此微调出一个专用领域语言模型；在此基础上提出AgenticTCAD框架，这是一个以自然语言驱动的多智能体系统，能够实现从需求描述到器件设计与优化的端到端自动化流程。实验证明，该方法可在4.2小时内完成符合IRDS-2024标准的2 nm纳米片晶体管（NS-FET）设计，显著优于人工使用商用工具所需的7.1天。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23742">https://arxiv.org/abs/2512.23742</a><br>
<strong>作者</strong>: Guangxi Fan,Tianliang Ma,Xuguang Sun,Xun Wang,Kain Lu Low,Leilai Shao<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: oftware Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  7 pages, 7 figures, 2 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:With the continued scaling of advanced technology nodes, the design-technology co-optimization (DTCO) paradigm has become increasingly critical, rendering efficient device design and optimization essential. In the domain of TCAD simulation, however, the scarcity of open-source resources hinders language models from generating valid TCAD code. To overcome this limitation, we construct an open-source TCAD dataset curated by experts and fine-tune a domain-specific model for TCAD code generation. Building on this foundation, we propose AgenticTCAD, a natural language - driven multi-agent framework that enables end-to-end automated device design and optimization. Validation on a 2 nm nanosheet FET (NS-FET) design shows that AgenticTCAD achieves the International Roadmap for Devices and Systems (IRDS)-2024 device specifications within 4.2 hours, whereas human experts required 7.1 days with commercial tools.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-97] owards representation agnostic probabilistic programming</p>
<p>【速读】：该论文旨在解决当前概率编程语言和工具中模型表示与特定推理算法紧密耦合的问题，这限制了用户对新型模型表示或混合离散-连续模型的探索。其解决方案的关键在于提出一种因子抽象（factor abstraction），包含五种基本操作，作为独立于底层表示的通用接口来操纵因子。这一设计实现了表示无关的概率编程（representation-agnostic probabilistic programming），使用户能够在单一统一框架内自由混合不同表示方式（如离散表、高斯分布、基于采样的方法），从而支持复杂混合模型的实际推理，而这是现有工具包难以表达的。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23740">https://arxiv.org/abs/2512.23740</a><br>
<strong>作者</strong>: Ole Fenske,Maximilian Popko,Sebastian Bader,Thomas Kirste<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Programming Languages (<a target="_blank" rel="noopener" href="http://cs.PL">cs.PL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Accepted at LAFI@POPL25</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Current probabilistic programming languages and tools tightly couple model representations with specific inference algorithms, preventing experimentation with novel representations or mixed discrete-continuous models. We introduce a factor abstraction with five fundamental operations that serve as a universal interface for manipulating factors regardless of their underlying representation. This enables representation-agnostic probabilistic programming where users can freely mix different representations (e.g. discrete tables, Gaussians distributions, sample-based approaches) within a single unified framework, allowing practical inference in complex hybrid models that current toolkits cannot adequately express.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-98] Enforcing Temporal Constraints for <mark class="hl-label green">LLM</mark>  <mark class="hl-label green">Agents</mark></p>
<p>【速读】：该论文旨在解决大语言模型（Large Language Model, LLM）代理在安全关键场景中无法有效遵守时序安全策略的问题，即代理行为的顺序约束（如“必须先认证后访问数据”）难以通过现有防护机制保障。当前 guardrail 系统依赖模糊的自然语言指令或事后监控，缺乏对时序逻辑的精确建模与运行时验证能力。解决方案的核心是提出 Agent-C 框架，其关键创新在于：设计一种用于表达时序安全属性的领域特定语言（Domain-Specific Language, DSL），将规范自动转换为一阶逻辑公式，并利用 Satisfiability Modulo Theories (SMT) 求解器在 token 生成阶段实时检测违反时序约束的动作；当检测到不合规动作时，采用受限生成技术强制 LLM 输出符合规范的动作，并提供合法替代方案，从而实现运行时的形式化保证。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23738">https://arxiv.org/abs/2512.23738</a><br>
<strong>作者</strong>: Adharsh Kamath,Sishen Zhang,Calvin Xu,Shubham Ugare,Gagandeep Singh,Sasa Misailovic<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Programming Languages (<a target="_blank" rel="noopener" href="http://cs.PL">cs.PL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Formal Languages and Automata Theory (cs.FL); Logic in Computer Science (cs.LO)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:LLM-based agents are deployed in safety-critical applications, yet current guardrail systems fail to prevent violations of temporal safety policies, requirements that govern the ordering and sequencing of agent actions. For instance, agents may access sensitive data before authenticating users or process refunds to unauthorized payment methods, violations that require reasoning about sequences of action rather than an individual action. Existing guardrails rely on imprecise natural language instructions or post-hoc monitoring, and provide no formal guarantees that agents will satisfy temporal constraints. We present Agent-C, a novel framework that provides run-time guarantees ensuring LLM agents adhere to formal temporal safety properties. Agent-C introduces a domain-specific language for expressing temporal properties (e.g., authenticate before accessing data), translates specifications to first-order logic, and uses SMT solving to detect non-compliant agent actions during token generation. When the LLM attempts to generate a non-compliant tool call, Agent-C leverages constrained generation techniques to ensure that every action generated by the LLM complies with the specification, and to generate a compliant alternative to a non-compliant agent action. We evaluate Agent-C across two real-world applications: retail customer service and airline ticket reservation system, and multiple language models (open and closed-source). Our results demonstrate that Agent-C achieves perfect safety (100% conformance, 0% harm), while improving task utility compared to state-of-the-art guardrails and unrestricted agents. On SoTA closed-source models, Agent-C improves conformance (77.4% to 100% for Claude Sonnet 4.5 and 83.7% to 100% for GPT-5), while simultaneously increasing utility (71.8% to 75.2% and 66.1% to 70.6%, respectively), representing a new SoTA frontier for reliable agentic reasoning.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-99] A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation</p>
<p>【速读】：该论文旨在解决计算机辅助设计（Computer-Aided Design, CAD）到网格生成（meshing）流程中的长期瓶颈问题，尤其是在复杂几何体处理、网格质量控制及自动化效率方面的挑战。其解决方案的关键在于引入人工智能（Artificial Intelligence, AI）技术，特别是机器学习方法，以辅助完成零件分类、网格质量预测、去特征化（defeaturing）、非结构化与块结构化网格生成优化、体积参数化支持以及并行网格生成加速等任务。同时，论文还探讨了强化学习和大语言模型（Large Language Models, LLMs）在脚本自动化中的新兴应用，表明AI作为辅助技术可显著扩展传统几何处理与网格工具的能力，推动数据驱动的下一代网格生成工作流的发展。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23719">https://arxiv.org/abs/2512.23719</a><br>
<strong>作者</strong>: Steven Owen,Nathan Brown,Nikos Chrisochoides,Rao Garimella,Xianfeng Gu,Franck Ledoux,Na Lei,Roshan Quadros,Navamita Ray,Nicolas Winovich,Yongjie Jessica Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computational Engineering, Finance, and Science (cs.CE); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  35 pages, 0 figure, accepted by the International Meshing Roundtable conference 2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Artificial intelligence is beginning to ease long-standing bottlenecks in the CAD-to-mesh pipeline. This survey reviews recent advances where machine learning aids part classification, mesh quality prediction, and defeaturing. We explore methods that improve unstructured and block-structured meshing, support volumetric parameterizations, and accelerate parallel mesh generation. We also examine emerging tools for scripting automation, including reinforcement learning and large language models. Across these efforts, AI acts as an assistive technology, extending the capabilities of traditional geometry and meshing tools. The survey highlights representative methods, practical deployments, and key research challenges that will shape the next generation of data-driven meshing workflows.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-100] Comparative Evaluation of Embedding Representations for Financial News Sentiment Analysis</p>
<p>【速读】：该论文旨在解决在资源受限环境下，金融新闻情感分类中因小样本数据导致的标准自然语言处理方法性能下降的问题。其解决方案的关键在于通过对比词向量（Word2Vec）、全局向量（GloVe）和句子变换器（sentence transformer）嵌入表示与梯度提升模型的组合效果，发现预训练嵌入在数据量低于临界阈值时收益递减，且小规模验证集易引发模型选择过程中的过拟合现象。研究强调，仅依赖嵌入质量无法根本缓解情感分类中的数据稀缺问题，建议实践者在标签样本有限时采用少样本学习、数据增强或基于词典的混合方法等替代策略。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.13749">https://arxiv.org/abs/2512.13749</a><br>
<strong>作者</strong>: Joyjit Roy,Samaresh Kumar Singh<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Software Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>)<br>
<strong>备注</strong>:  6 pages, 2 figures. Submitted to IEEE IATMSI-2026 (Track: AI, IoT and Computer Vision Enabled Technologies)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Financial sentiment analysis enhances market understanding; however, standard natural language processing approaches encounter significant challenges when applied to small datasets. This study provides a comparative evaluation of embedding-based methods for financial news sentiment classification in resource-constrained environments. Word2Vec, GloVe, and sentence transformer representations are evaluated in combination with gradient boosting on manually labeled headlines. Experimental results identify a substantial gap between validation and test performance, with models performing worse than trivial baselines despite strong validation metrics. The analysis demonstrates that pretrained embeddings yield diminishing returns below a critical data sufficiency threshold, and that small validation sets contribute to overfitting during model selection. Practical application is illustrated through weekly sentiment aggregation and narrative summarization for market monitoring workflows. The findings offer empirical evidence that embedding quality alone cannot address fundamental data scarcity in sentiment classification. For practitioners operating with limited resources, the results indicate the need to consider alternative approaches such as few-shot learning, data augmentation, or lexicon-enhanced hybrid methods when labeled samples are scarce.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-101] SymSeqBench: a unified framework for the generation and analysis of rule-based symbolic sequences and datasets</p>
<p>【速读】：该论文旨在解决如何在跨领域（如语言、运动、决策等）中对序列学习与处理能力进行统一评估的问题，同时建立与计算理论（特别是形式语言理论，Formal Language Theory, FLT）的联系。其解决方案的关键在于提出两个互补的软件工具：SymSeq用于严格生成和分析结构化符号序列，SeqBench则提供一套基于规则的序列处理任务基准测试套件，从而实现对人工智能系统在认知相关领域中的序列处理能力的标准化评估。该框架以FLT为基础，具有模块化、开放性和可访问性，有助于不同研究领域共享计算范式并推动对认知与行为机制的理解。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24977">https://arxiv.org/abs/2512.24977</a><br>
<strong>作者</strong>: Barna Zajzon,Younes Bouhadjar,Maxime Fabre,Felix Schmidt,Noah Ostendorf,Emre Neftci,Abigail Morrison,Renato Duarte<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Neurons and Cognition (<a target="_blank" rel="noopener" href="http://q-bio.NC">q-bio.NC</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG); Neural and Evolutionary Computing (<a target="_blank" rel="noopener" href="http://cs.NE">cs.NE</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Sequential structure is a key feature of multiple domains of natural cognition and behavior, such as language, movement and decision-making. Likewise, it is also a central property of tasks to which we would like to apply artificial intelligence. It is therefore of great importance to develop frameworks that allow us to evaluate sequence learning and processing in a domain agnostic fashion, whilst simultaneously providing a link to formal theories of computation and computability. To address this need, we introduce two complementary software tools: SymSeq, designed to rigorously generate and analyze structured symbolic sequences, and SeqBench, a comprehensive benchmark suite of rule-based sequence processing tasks to evaluate the performance of artificial learning systems in cognitively relevant domains. In combination, SymSeqBench offers versatility in investigating sequential structure across diverse knowledge domains, including experimental psycholinguistics, cognitive psychology, behavioral analysis, neuromorphic computing and artificial intelligence. Due to its basis in Formal Language Theory (FLT), SymSeqBench provides researchers in multiple domains with a convenient and practical way to apply the concepts of FLT to conceptualize and standardize their experiments, thus advancing our understanding of cognition and behavior through shared computational frameworks and formalisms. The tool is modular, openly available and accessible to the research community.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-102] he Impact of <mark class="hl-label green">LLM</mark> s on Online News Consumption and Production</p>
<p>【速读】：该论文旨在解决生成式 AI（Generative AI, GenAI）对新闻出版业在内容消费、就业结构和生产模式等方面潜在负面影响的问题。研究通过高频率细粒度数据，系统评估了 GenAI 引入后新闻行业的真实变化，并探讨了新闻机构采取的应对策略（如使用 robots.txt 阻止 GenAI 爬虫访问）的实际效果。其解决方案的关键在于采用差异-差异（difference-in-differences）方法，量化分析封锁 GenAI 访问对大型新闻机构网站流量的影响，发现此类措施反而导致总流量下降 23%、真实用户流量下降 14%，从而揭示出传统防御性策略可能适得其反，同时指出当前 GenAI 尚未显著替代编辑与内容生产岗位，且大 publishers 正转向增加富媒体内容和广告定向技术以适应新环境。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24968">https://arxiv.org/abs/2512.24968</a><br>
<strong>作者</strong>: Hangcheng Zhao,Ron Berman<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: General Economics (<a target="_blank" rel="noopener" href="http://econ.GN">econ.GN</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>); Applications (stat.AP)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language models (LLMs) change how consumers acquire information online; their bots also crawl news publishers’ websites for training data and to answer consumer queries; and they provide tools that can lower the cost of content creation. These changes lead to predictions of adverse impact on news publishers in the form of lowered consumer demand, reduced demand for newsroom employees, and an increase in news “slop.” Consequently, some publishers strategically responded by blocking LLM access to their websites using the this http URL file standard. Using high-frequency granular data, we document four effects related to the predicted shifts in news publishing following the introduction of generative AI (GenAI). First, we find a consistent and moderate decline in traffic to news publishers occurring after August 2024. Second, using a difference-in-differences approach, we find that blocking GenAI bots can have adverse effects on large publishers by reducing total website traffic by 23% and real consumer traffic by 14% compared to not blocking. Third, on the hiring side, we do not find evidence that LLMs are replacing editorial or content-production jobs yet. The share of new editorial and content-production job listings increases over time. Fourth, regarding content production, we find no evidence that large publishers increased text volume; instead, they significantly increased rich content and use more advertising and targeting technologies. Together, these findings provide early evidence of some unforeseen impacts of the introduction of LLMs on news production and consumption.         Subjects:  General Economics (<a target="_blank" rel="noopener" href="http://econ.GN">econ.GN</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>); Applications (stat.AP)  Cite as: arXiv:2512.24968 [<a target="_blank" rel="noopener" href="http://econ.GN">econ.GN</a>]    (or  arXiv:2512.24968v1 [<a target="_blank" rel="noopener" href="http://econ.GN">econ.GN</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24968">https://doi.org/10.48550/arXiv.2512.24968</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-103] AstroReview: An <mark class="hl-label green">LLM</mark> -driven Multi-<mark class="hl-label green">Agent</mark>  Framework for Telescope Proposal Peer Review and Refinement</p>
<p>【速读】：该论文旨在解决天文观测设施资源有限背景下，科学提案评审过程面临的效率低、一致性差和透明度不足的问题。随着提案数量激增，传统人工评审已难以满足公平、可重复且可扩展的需求。其解决方案的关键在于提出一个开源的基于智能体（agent-based）的自动化评审框架 AstroReview，该框架将评审流程分为三个阶段：科学新颖性与价值评估、可行性与预期产出分析、以及元评审与可靠性验证；通过任务隔离与显式推理路径设计，有效抑制幻觉并提升透明度。实验表明，仅在第三阶段应用该框架即可实现87%的准确率识别真实通过提案，并且结合迭代反馈机制的提案撰写代理（Proposal Authoring Agent）使修订稿的接受率提升66%，验证了自动化元评审与可靠性验证相结合可在不进行领域微调的情况下显著提高评审质量与效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24754">https://arxiv.org/abs/2512.24754</a><br>
<strong>作者</strong>: Yutong Wang,Yunxiang Xiao,Yonglin Tian,Junyong Li,Jing Wang,Yisheng Lv<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Instrumentation and Methods for Astrophysics (<a target="_blank" rel="noopener" href="http://astro-ph.IM">astro-ph.IM</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Competitive access to modern observatories has intensified as proposal volumes outpace available telescope time, making timely, consistent, and transparent peer review a critical bottleneck for the advancement of astronomy. Automating parts of this process is therefore both scientifically significant and operationally necessary to ensure fair allocation and reproducible decisions at scale. We present AstroReview, an open-source, agent-based framework that automates proposal review in three stages: (i) novelty and scientific merit, (ii) feasibility and expected yield, and (iii) meta-review and reliability verification. Task isolation and explicit reasoning traces curb hallucinations and improve transparency. Without any domain specific fine tuning, AstroReview used in our experiments only for the last stage, correctly identifies genuinely accepted proposals with an accuracy of 87%. The AstroReview in Action module replicates the review and refinement loop; with its integrated Proposal Authoring Agent, the acceptance rate of revised drafts increases by 66% after two iterations, showing that iterative feedback combined with automated meta-review and reliability verification delivers measurable quality gains. Together, these results point to a practical path toward scalable, auditable, and higher throughput proposal review for resource limited facilities.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-104] An Adaptive Disentangled Representation for Multidimensional MRI Reconstruction</p>
<p>【速读】：该论文旨在解决多维磁共振成像（MRI）数据在重建过程中因特征耦合导致的性能瓶颈问题，尤其在数据有限场景下难以有效利用跨维度特征相关性与先验知识。解决方案的关键在于提出一种基于学习的特征解耦表示方法，通过编码器-解码器网络将几何结构和对比度等不同类型的特征分离到独立的低维潜在空间中，并结合风格化解码设计与潜在扩散模型对各特征空间施加更强约束，从而实现更精准的特征建模与重建优化。该方法无需任务特定监督训练或微调，即可在加速T1/T2参数映射任务中显著优于现有最优重建技术。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24674">https://arxiv.org/abs/2512.24674</a><br>
<strong>作者</strong>: Ruiyang Zhao,Fan Lam<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Image and Video Processing (eess.IV); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present a new approach for representing and reconstructing multidimensional magnetic resonance imaging (MRI) data. Our method builds on a novel, learned feature-based image representation that disentangles different types of features, such as geometry and contrast, into distinct low-dimensional latent spaces, enabling better exploitation of feature correlations in multidimensional images and incorporation of pre-learned priors specific to different feature types for reconstruction. More specifically, the disentanglement was achieved via an encoderdecoder network and image transfer training using large public data, enhanced by a style-based decoder design. A latent diffusion model was introduced to impose stronger constraints on distinct feature spaces. New reconstruction formulations and algorithms were developed to integrate the learned representation with a zero-shot selfsupervised learning adaptation and subspace modeling. The proposed method has been evaluated on accelerated T1 and T2 parameter mapping, achieving improved performance over state-of-the-art reconstruction methods, without task-specific supervised training or fine-tuning. This work offers a new strategy for learning-based multidimensional image reconstruction where only limited data are available for problem-specific or task-specific training.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-105] Generative AI-enhanced Sector-based Investment Portfolio Construction</p>
<p>【速读】：该论文旨在解决如何将大型语言模型（Large Language Models, LLMs）应用于基于行业的量化投资组合构建问题，具体聚焦于评估LLMs在识别可投资股票池并进行权重分配后，其组合表现是否优于传统行业指数，并探讨其在不同市场环境下的稳定性。解决方案的关键在于：首先，利用多家主流提供商（OpenAI、Google、Anthropic、DeepSeek和xAI）的LLMs为标普500各行业指数筛选并加权20只股票；其次，将这些LLM生成的股票组合与经典组合优化方法结合，以提升整体绩效与一致性；最后，通过两个独立的样本外时间段（稳定市场期与波动市场期）对比分析，发现LLM选股在稳定市场中显著优于行业基准，但在高波动环境中表现不佳，而融合传统优化技术后可显著改善结果，从而验证了“混合AI-量化框架”在增强投资策略鲁棒性与适应性方面的有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24526">https://arxiv.org/abs/2512.24526</a><br>
<strong>作者</strong>: Alina Voronina,Oleksandr Romanko,Ruiwen Cao,Roy H. Kwon,Rafael Mendoza-Arriaga<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Portfolio Management (<a target="_blank" rel="noopener" href="http://q-fin.PM">q-fin.PM</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computational Engineering, Finance, and Science (cs.CE); Computational Finance (q-fin.CP)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper investigates how Large Language Models (LLMs) from leading providers (OpenAI, Google, Anthropic, DeepSeek, and xAI) can be applied to quantitative sector-based portfolio construction. We use LLMs to identify investable universes of stocks within SP 500 sector indices and evaluate how their selections perform when combined with classical portfolio optimization methods. Each model was prompted to select and weight 20 stocks per sector, and the resulting portfolios were compared with their respective sector indices across two distinct out-of-sample periods: a stable market phase (January-March 2025) and a volatile phase (April-June 2025). Our results reveal a strong temporal dependence in LLM portfolio performance. During stable market conditions, LLM-weighted portfolios frequently outperformed sector indices on both cumulative return and risk-adjusted (Sharpe ratio) measures. However, during the volatile period, many LLM portfolios underperformed, suggesting that current models may struggle to adapt to regime shifts or high-volatility environments underrepresented in their training data. Importantly, when LLM-based stock selection is combined with traditional optimization techniques, portfolio outcomes improve in both performance and consistency. This study contributes one of the first multi-model, cross-provider evaluations of generative AI algorithms in investment management. It highlights that while LLMs can effectively complement quantitative finance by enhancing stock selection and interpretability, their reliability remains market-dependent. The findings underscore the potential of hybrid AI-quantitative frameworks, integrating LLM reasoning with established optimization techniques, to produce more robust and adaptive investment strategies.         Subjects:  Portfolio Management (<a target="_blank" rel="noopener" href="http://q-fin.PM">q-fin.PM</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computational Engineering, Finance, and Science (cs.CE); Computational Finance (q-fin.CP)   MSC classes: 90   ACMclasses: I.2.7; G.1.6; J.4   Cite as: arXiv:2512.24526 [<a target="_blank" rel="noopener" href="http://q-fin.PM">q-fin.PM</a>]    (or  arXiv:2512.24526v1 [<a target="_blank" rel="noopener" href="http://q-fin.PM">q-fin.PM</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24526">https://doi.org/10.48550/arXiv.2512.24526</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-106] Generative Video Compression: Towards 0.01% Compression Rate for Video Transmission</p>
<p>【速读】：该论文旨在解决视频压缩率极低（如0.01%）时仍能保持感知质量与任务相关性的难题，传统压缩方法难以在如此极端压缩比下维持可用性。其解决方案的核心是提出生成式视频压缩（Generative Video Compression, GVC）框架，通过引入现代生成式视频模型，将视频编码为极紧凑的表示，并将内容重建任务交由接收端完成，利用强大的生成先验从极少传输信息中合成高质量视频，从而实现计算资源与压缩率之间的灵活权衡。此方案将通信负担从传输转移到推理阶段，显著提升了压缩效率并拓展了在带宽和算力受限场景（如应急救援、远程监控及移动边缘计算）中的实用性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24300">https://arxiv.org/abs/2512.24300</a><br>
<strong>作者</strong>: Xiangyu Chen,Jixiang Luo,Jingyu Xu,Fangqiu Yi,Chi Zhang,Xuelong Li<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Image and Video Processing (eess.IV); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Multimedia (<a target="_blank" rel="noopener" href="http://cs.MM">cs.MM</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Whether a video can be compressed at an extreme compression rate as low as 0.01%? To this end, we achieve the compression rate as 0.02% at some cases by introducing Generative Video Compression (GVC), a new framework that redefines the limits of video compression by leveraging modern generative video models to achieve extreme compression rates while preserving a perception-centric, task-oriented communication paradigm, corresponding to Level C of the Shannon-Weaver model. Besides, How we trade computation for compression rate or bandwidth? GVC answers this question by shifting the burden from transmission to inference: it encodes video into extremely compact representations and delegates content reconstruction to the receiver, where powerful generative priors synthesize high-quality video from minimal transmitted information. Is GVC practical and deployable? To ensure practical deployment, we propose a compression-computation trade-off strategy, enabling fast inference on consume-grade GPUs. Within the AI Flow framework, GVC opens new possibility for video communication in bandwidth- and resource-constrained environments such as emergency rescue, remote surveillance, and mobile edge computing. Through empirical validation, we demonstrate that GVC offers a viable path toward a new effective, efficient, scalable, and practical video communication paradigm.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-107] Autoregressive long-horizon prediction of plasma edge dynamics</p>
<p>【速读】：该论文旨在解决托卡马克装置中等离子体边缘区域（ scrape-off layer, SOL）和偏滤器（divertor）边界动力学模拟的计算成本过高问题，这一瓶颈限制了参数扫描和长时间瞬态行为的研究。传统高保真流体/中性粒子代码如SOLPS-ITER虽能精确描述SOL物理过程，但其计算开销极大。为此，作者提出基于Transformer架构的自回归代理模型（surrogate model），通过在SOLPS-ITER生成的时空数据上训练，实现对电子温度、电子密度及辐射功率等二维时间依赖场的高效预测。该方案的关键在于利用长时序训练（1–100步）提升模型滚动预测的稳定性并抑制误差累积，从而支持数百至数千步的稳定预测，并保留关键动力学特征（如高辐射区移动）。实测表明，该代理模型相较SOLPS-ITER快几个数量级，显著加速了参数探索与控制导向研究，为未来实时应用奠定基础。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23884">https://arxiv.org/abs/2512.23884</a><br>
<strong>作者</strong>: Hunor Csala,Sebastian De Pascuale,Paul Laiu,Jeremy Lore,Jae-Sun Park,Pei Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Plasma Physics (physics.plasm-ph); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Accurate modeling of scrape-off layer (SOL) and divertor-edge dynamics is vital for designing plasma-facing components in fusion devices. High-fidelity edge fluid/neutral codes such as SOLPS-ITER capture SOL physics with high accuracy, but their computational cost limits broad parameter scans and long transient studies. We present transformer-based, autoregressive surrogates for efficient prediction of 2D, time-dependent plasma edge state fields. Trained on SOLPS-ITER spatiotemporal data, the surrogates forecast electron temperature, electron density, and radiated power over extended horizons. We evaluate model variants trained with increasing autoregressive horizons (1-100 steps) on short- and long-horizon prediction tasks. Longer-horizon training systematically improves rollout stability and mitigates error accumulation, enabling stable predictions over hundreds to thousands of steps and reproducing key dynamical features such as the motion of high-radiation regions. Measured end-to-end wall-clock times show the surrogate is orders of magnitude faster than SOLPS-ITER, enabling rapid parameter exploration. Prediction accuracy degrades when the surrogate enters physical regimes not represented in the training dataset, motivating future work on data enrichment and physics-informed constraints. Overall, this approach provides a fast, accurate surrogate for computationally intensive plasma edge simulations, supporting rapid scenario exploration, control-oriented studies, and progress toward real-time applications in fusion devices.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-108] Quantum Error Mitigation with Attention Graph Transformers for Burgers Equation Solvers on NISQ Hardware</p>
<p>【速读】：该论文旨在解决在噪声中等规模量子（NISQ）硬件上求解粘性Burgers方程时因量子噪声导致的精度不足问题。其核心解决方案是提出一种混合量子-经典框架，结合基于物理的零噪声外推（Zero-Noise Extrapolation, ZNE）与数据驱动的误差缓解方法：首先利用Cole-Hopf变换将非线性Burgers方程转化为扩散方程，并通过Trotter化近似实现量子态演化；随后构建涵盖多种参数（粘度、时间步长、网格分辨率及边界条件）的大规模参数化数据集，包含噪声量子输出、ZNE校正结果、硬件实验数据与高精度经典解；最终训练一个基于注意力机制的图神经网络（Graph Neural Network, GNN），融合电路结构、光锥信息、全局参数及噪声输出，以预测误差缓解后的量子解。该模型在广泛参数范围内显著优于仅使用ZNE的方法，为NISQ设备上的量子偏微分方程求解提供了有效的学习型误差缓解范式。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23817">https://arxiv.org/abs/2512.23817</a><br>
<strong>作者</strong>: Seyed Mohamad Ali Tousi,Adib Bazgir,Yuwen Zhang,G. N. DeSouza<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Quantum Physics (quant-ph); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present a hybrid quantum-classical framework augmented with learned error mitigation for solving the viscous Burgers equation on noisy intermediate-scale quantum (NISQ) hardware. Using the Cole-Hopf transformation, the nonlinear Burgers equation is mapped to a diffusion equation, discretized on uniform grids, and encoded into a quantum state whose time evolution is approximated via Trotterized nearest-neighbor circuits implemented in Qiskit. Quantum simulations are executed on noisy Aer backends and IBM superconducting quantum devices and are benchmarked against high-accuracy classical solutions obtained using a Krylov-based solver applied to the corresponding discretized Hamiltonian. From measured quantum amplitudes, we reconstruct the velocity field and evaluate physical and numerical diagnostics, including the L2 error, shock location, and dissipation rate, both with and without zero-noise extrapolation (ZNE). To enable data-driven error mitigation, we construct a large parametric dataset by sweeping viscosity, time step, grid resolution, and boundary conditions, producing matched tuples of noisy, ZNE-corrected, hardware, and classical solutions together with detailed circuit metadata. Leveraging this dataset, we train an attention-based graph neural network that incorporates circuit structure, light-cone information, global circuit parameters, and noisy quantum outputs to predict error-mitigated solutions. Across a wide range of parameters, the learned model consistently reduces the discrepancy between quantum and classical solutions beyond what is achieved by ZNE alone. We discuss extensions of this approach to higher-dimensional Burgers systems and more general quantum partial differential equation solvers, highlighting learned error mitigation as a promising complement to physics-based noise reduction techniques on NISQ devices.<br>
zh</p>
</div></div>
<h3 id="机器学习">机器学习</h3>
<div class="note pink no-icon flat"><p>[LG-0] On the geometry and topology of representations: the manifolds of modular addition</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25060">https://arxiv.org/abs/2512.25060</a><br>
<strong>作者</strong>: Gabriela Moisescu-Pareja,Gavin McCracken,Harley Wiltzer,Vincent Létourneau,Colin Daniels,Doina Precup,Jonathan Love<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The Clock and Pizza interpretations, associated with architectures differing in either uniform or learnable attention, were introduced to argue that different architectural designs can yield distinct circuits for modular addition. In this work, we show that this is not the case, and that both uniform attention and trainable attention architectures implement the same algorithm via topologically and geometrically equivalent representations. Our methodology goes beyond the interpretation of individual neurons and weights. Instead, we identify all of the neurons corresponding to each learned representation and then study the collective group of neurons as one entity. This method reveals that each learned representation is a manifold that we can study utilizing tools from topology. Based on this insight, we can statistically analyze the learned representations across hundreds of circuits to demonstrate the similarity between learned modular addition circuits that arise naturally from common deep learning paradigms.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-1] Reliable and Resilient Collective Communication Library for <mark class="hl-label green">LLM</mark>  Training and Serving</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25059">https://arxiv.org/abs/2512.25059</a><br>
<strong>作者</strong>: Wei Wang,Nengneng Yu,Sixian Xiong,Zaoxing Liu<br>
<strong>类目</strong>: Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG); Networking and Internet Architecture (<a target="_blank" rel="noopener" href="http://cs.NI">cs.NI</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Modern ML training and inference now span tens to tens of thousands of GPUs, where network faults can waste 10–15% of GPU hours due to slow recovery. Common network errors and link fluctuations trigger timeouts that often terminate entire jobs, forcing expensive checkpoint rollback during training and request reprocessing during inference. We present R ^2 CCL, a fault-tolerant communication library that provides lossless, low-overhead failover by exploiting multi-NIC hardware. R ^2 CCL performs rapid connection migration, bandwidth-aware load redistribution, and resilient collective algorithms to maintain progress under failures. We evaluate R ^2 CCL on two 8-GPU H100 InfiniBand servers and via large-scale ML simulators modeling hundreds of GPUs with diverse failure patterns. Experiments show that R ^2 CCL is highly robust to NIC failures, incurring less than 1% training and less than 3% inference overheads. R ^2 CCL outperforms baselines AdapCC and DejaVu by 12.18 \times  and 47 \times , respectively.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-2] ResponseRank: Data-Efficient Reward Modeling through Preference Strength Learning <mark class="hl-label red">NEURIPS2025</mark></p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25023">https://arxiv.org/abs/2512.25023</a><br>
<strong>作者</strong>: Timo Kaufmann,Yannick Metz,Daniel Keim,Eyke Hüllermeier<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  NeurIPS 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Binary choices, as often used for reinforcement learning from human feedback (RLHF), convey only the direction of a preference. A person may choose apples over oranges and bananas over grapes, but which preference is stronger? Strength is crucial for decision-making under uncertainty and generalization of preference models, but hard to measure reliably. Metadata such as response times and inter-annotator agreement can serve as proxies for strength, but are often noisy and confounded. We propose ResponseRank to address the challenge of learning from noisy strength signals. Our method uses relative differences in proxy signals to rank responses to pairwise comparisons by their inferred preference strength. To control for systemic variation, we compare signals only locally within carefully constructed strata. This enables robust learning of utility differences consistent with strength-derived rankings while making minimal assumptions about the strength signal. Our contributions are threefold: (1) ResponseRank, a novel method that robustly learns preference strength by leveraging locally valid relative strength signals; (2) empirical evidence of improved sample efficiency and robustness across diverse tasks: synthetic preference learning (with simulated response times), language modeling (with annotator agreement), and RL control tasks (with simulated episode returns); and (3) the Pearson Distance Correlation (PDC), a novel metric that isolates cardinal utility learning from ordinal accuracy.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-3] Convergence of the generalization error for deep gradient flow methods for PDEs</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25017">https://arxiv.org/abs/2512.25017</a><br>
<strong>作者</strong>: Chenguang Liu,Antonis Papapantoleon,Jasper Rou<br>
<strong>类目</strong>: Numerical Analysis (<a target="_blank" rel="noopener" href="http://math.NA">math.NA</a>); Machine Learning (cs.LG); Computational Finance (q-fin.CP); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:  28 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The aim of this article is to provide a firm mathematical foundation for the application of deep gradient flow methods (DGFMs) for the solution of (high-dimensional) partial differential equations (PDEs). We decompose the generalization error of DGFMs into an approximation and a training error. We first show that the solution of PDEs that satisfy reasonable and verifiable assumptions can be approximated by neural networks, thus the approximation error tends to zero as the number of neurons tends to infinity. Then, we derive the gradient flow that the training process follows in the ``wide network limit’’ and analyze the limit of this flow as the training time tends to infinity. These results combined show that the generalization error of DGFMs tends to zero as the number of neurons and the training time tend to infinity.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-4] Diffusion Language Models are Provably Optimal Parallel Samplers</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.25014">https://arxiv.org/abs/2512.25014</a><br>
<strong>作者</strong>: Haozhe Jiang,Nika Haghtalab,Lijie Chen<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computational Complexity (<a target="_blank" rel="noopener" href="http://cs.CC">cs.CC</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Diffusion language models (DLMs) have emerged as a promising alternative to autoregressive models for faster inference via parallel token generation. We provide a rigorous foundation for this advantage by formalizing a model of parallel sampling and showing that DLMs augmented with polynomial-length chain-of-thought (CoT) can simulate any parallel sampling algorithm using an optimal number of sequential steps. Consequently, whenever a target distribution can be generated using a small number of sequential steps, a DLM can be used to generate the distribution using the same number of optimal sequential steps. However, without the ability to modify previously revealed tokens, DLMs with CoT can still incur large intermediate footprints. We prove that enabling remasking (converting unmasked tokens to masks) or revision (converting unmasked tokens to other unmasked tokens) together with CoT further allows DLMs to simulate any parallel sampling algorithm with optimal space complexity. We further justify the advantage of revision by establishing a strict expressivity gap: DLMs with revision or remasking are strictly more expressive than those without. Our results not only provide a theoretical justification for the promise of DLMs as the most efficient parallel sampler, but also advocate for enabling revision in DLMs.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-5] Efficiently Estimating Data Efficiency for Language Model Fine-tuning</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24991">https://arxiv.org/abs/2512.24991</a><br>
<strong>作者</strong>: Gyung Hyun Je,Colin Raffel<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:While large language models (LLMs) demonstrate reasonable zero-shot capability across many downstream tasks, fine-tuning is a common practice to improve their performance. However, a task’s data efficiency–i.e., the number of fine-tuning examples needed to achieve a desired level of performance–is often unknown, resulting in costly cycles of incremental annotation and retraining. Indeed, we demonstrate across a curated set of 30 specialized tasks that performant LLMs may struggle zero-shot but can attain stronger performance after fine-tuning. This motivates the need for methods to predict a task’s data efficiency without requiring incremental annotation. After introducing a concrete metric that quantifies a task’s data efficiency, we propose using the gradient cosine similarity of low-confidence examples to predict data efficiency based on a small number of labeled samples. We validate our approach on a diverse set of tasks with varying data efficiencies, attaining 8.6% error in overall data efficiency prediction and typically eliminating hundreds of unnecessary annotations on each task. Our experiment results and implementation code are available on GitHub.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-6] Attribution-Guided Distillation of Matryoshka Sparse Autoencoders</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24975">https://arxiv.org/abs/2512.24975</a><br>
<strong>作者</strong>: Cristina P. Martin-Linares,Jonathan P. Ling<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Sparse autoencoders (SAEs) aim to disentangle model activations into monosemantic, human-interpretable features. In practice, learned features are often redundant and vary across training runs and sparsity levels, which makes interpretations difficult to transfer and reuse. We introduce Distilled Matryoshka Sparse Autoencoders (DMSAEs), a training pipeline that distills a compact core of consistently useful features and reuses it to train new SAEs. DMSAEs run an iterative distillation cycle: train a Matryoshka SAE with a shared core, use gradient X activation to measure each feature’s contribution to next-token loss in the most nested reconstruction, and keep only the smallest subset that explains a fixed fraction of the attribution. Only the core encoder weight vectors are transferred across cycles; the core decoder and all non-core latents are reinitialized each time. On Gemma-2-2B layer 12 residual stream activations, seven cycles of distillation (500M tokens, 65k width) yielded a distilled core of 197 features that were repeatedly selected. Training using this distilled core improves several SAEBench metrics and demonstrates that consistent sets of latent features can be transferred across sparsity levels</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-7] Frequent subgraph-based persistent homology for graph classification</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24917">https://arxiv.org/abs/2512.24917</a><br>
<strong>作者</strong>: Xinyang Chen,Amaël Broustet,Guoting Chen<br>
<strong>类目</strong>: Machine Learning (cs.LG); Algebraic Topology (<a target="_blank" rel="noopener" href="http://math.AT">math.AT</a>)<br>
*<strong>备注</strong>:  Preprint. 18 pages, 10 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Persistent homology (PH) has recently emerged as a powerful tool for extracting topological features. Integrating PH into machine learning and deep learning models enhances topology awareness and interpretability. However, most PH methods on graphs rely on a limited set of filtrations, such as degree-based or weight-based filtrations, which overlook richer features like recurring information across the dataset and thus restrict expressive power. In this work, we propose a novel graph filtration called Frequent Subgraph Filtration (FSF), which is derived from frequent subgraphs and produces stable and information-rich frequency-based persistent homology (FPH) features. We study the theoretical properties of FSF and provide both proofs and experimental validation. Beyond persistent homology itself, we introduce two approaches for graph classification: an FPH-based machine learning model (FPH-ML) and a hybrid framework that integrates FPH with graph neural networks (FPH-GNNs) to enhance topology-aware graph representation learning. Our frameworks bridge frequent subgraph mining and topological data analysis, offering a new perspective on topology-aware feature extraction. Experimental results show that FPH-ML achieves competitive or superior accuracy compared with kernel-based and degree-based filtration methods. When integrated into graph neural networks, FPH yields relative performance gains ranging from 0.4 to 21 percent, with improvements of up to 8.2 percentage points over GCN and GIN backbones across benchmarks.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-8] Spectral Graph Neural Networks for Cognitive Task Classification in fMRI Connectomes</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24901">https://arxiv.org/abs/2512.24901</a><br>
<strong>作者</strong>: Debasis Maji,Arghya Banerjee,Debaditya Barman<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Cognitive task classification using machine learning plays a central role in decoding brain states from neuroimaging data. By integrating machine learning with brain network analysis, complex connectivity patterns can be extracted from functional magnetic resonance imaging connectomes. This process transforms raw blood-oxygen-level-dependent (BOLD) signals into interpretable representations of cognitive processes. Graph neural networks (GNNs) further advance this paradigm by modeling brain regions as nodes and functional connections as edges, capturing topological dependencies and multi-scale interactions that are often missed by conventional approaches. Our proposed SpectralBrainGNN model, a spectral convolution framework based on graph Fourier transforms (GFT) computed via normalized Laplacian eigendecomposition. Experiments on the Human Connectome Project-Task (HCPTask) dataset demonstrate the effectiveness of the proposed approach, achieving a classification accuracy of 96.25%. The implementation is publicly available at this https URL to support reproducibility and future research.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-9] PRISM: A hierarchical multiscale approach for time series forecasting</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24898">https://arxiv.org/abs/2512.24898</a><br>
<strong>作者</strong>: Zihao Chen,Alexandre Andre,Wenrui Ma,Ian Knight,Sergey Shuvaev,Eva Dyer<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Forecasting is critical in areas such as finance, biology, and healthcare. Despite the progress in the field, making accurate forecasts remains challenging because real-world time series contain both global trends, local fine-grained structure, and features on multiple scales in between. Here, we present a new forecasting method, PRISM (Partitioned Representation for Iterative Sequence Modeling), that addresses this challenge through a learnable tree-based partitioning of the signal. At the root of the tree, a global representation captures coarse trends in the signal, while recursive splits reveal increasingly localized views of the signal. At each level of the tree, data are projected onto a time-frequency basis (e.g., wavelets or exponential moving averages) to extract scale-specific features, which are then aggregated across the hierarchy. This design allows the model to jointly capture global structure and local dynamics of the signal, enabling accurate forecasting. Experiments across benchmark datasets show that our method outperforms state-of-the-art methods for forecasting. Overall, these results demonstrate that our hierarchical approach provides a lightweight and flexible framework for forecasting multivariate time series. The code is available at this https URL.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-10] Characterization of Transfer Using Multi-task Learning Curves</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24866">https://arxiv.org/abs/2512.24866</a><br>
<strong>作者</strong>: András Millinghoffer,Bence Bolgár,Péter Antal<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Transfer effects manifest themselves both during training using a fixed data set and in inductive inference using accumulating data. We hypothesize that perturbing the data set by including more samples, instead of perturbing the model by gradient updates, provides a complementary and more fundamental characterization of transfer effects. To capture this phenomenon, we quantitatively model transfer effects using multi-task learning curves approximating the inductive performance over varying sample sizes. We describe an efficient method to approximate multi-task learning curves analogous to the Task Affinity Grouping method applied during training. We compare the statistical and computational approaches to transfer, which indicates considerably higher compute costs for the previous but better power and broader applicability. Evaluations are performed using a benchmark drug-target interaction data set. Our results show that learning curves can better capture the effects of multi-task learning and their multi-task extensions can delineate pairwise and contextual transfer effects in foundation models.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-11] AODDiff: Probabilistic Reconstruction of Aerosol Optical Depth via Diffusion-based Bayesian Inference</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24847">https://arxiv.org/abs/2512.24847</a><br>
<strong>作者</strong>: Linhao Fan,Hongqiang Fang,Jingyang Dai,Yong Jiang,Qixing Zhang<br>
<strong>类目</strong>: Machine Learning (cs.LG); Atmospheric and Oceanic Physics (physics.ao-ph)<br>
*<strong>备注</strong>:  17 pages, 9 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:High-quality reconstruction of Aerosol Optical Depth (AOD) fields is critical for Atmosphere monitoring, yet current models remain constrained by the scarcity of complete training data and a lack of uncertainty this http URL address these limitations, we propose AODDiff, a probabilistic reconstruction framework based on diffusion-based Bayesian inference. By leveraging the learned spatiotemporal probability distribution of the AOD field as a generative prior, this framework can be flexibly adapted to various reconstruction tasks without requiring task-specific retraining. We first introduce a corruption-aware training strategy to learns a spatiotemporal AOD prior solely from naturally incomplete data. Subsequently, we employ a decoupled annealing posterior sampling strategy that enables the more effective and integration of heterogeneous observations as constraints to guide the generation process. We validate the proposed framework through extensive experiments on Reanalysis data. Results across downscaling and inpainting tasks confirm the efficacy and robustness of AODDiff, specifically demonstrating its advantage in maintaining high spatial spectral fidelity. Furthermore, as a generative model, AODDiff inherently enables uncertainty quantification via multiple sampling, offering critical confidence metrics for downstream applications.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-12] Discovering Coordinated Joint Options via Inter-<mark class="hl-label green">Agent</mark>  Relative Dynamics</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24827">https://arxiv.org/abs/2512.24827</a><br>
<strong>作者</strong>: Raul D. Steleac,Mohan Sridharan,David Abel<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Temporally extended actions improve the ability to explore and plan in single-agent settings. In multi-agent settings, the exponential growth of the joint state space with the number of agents makes coordinated behaviours even more valuable. Yet, this same exponential growth renders the design of multi-agent options particularly challenging. Existing multi-agent option discovery methods often sacrifice coordination by producing loosely coupled or fully independent behaviours. Toward addressing these limitations, we describe a novel approach for multi-agent option discovery. Specifically, we propose a joint-state abstraction that compresses the state space while preserving the information necessary to discover strongly coordinated behaviours. Our approach builds on the inductive bias that synchronisation over agent states provides a natural foundation for coordination in the absence of explicit objectives. We first approximate a fictitious state of maximal alignment with the team, the \textitFermat state, and use it to define a measure of \textitspreadness, capturing team-level misalignment on each individual state dimension. Building on this representation, we then employ a neural graph Laplacian estimator to derive options that capture state synchronisation patterns between agents. We evaluate the resulting options across multiple scenarios in two multi-agent domains, showing that they yield stronger downstream coordination capabilities compared to alternative option discovery methods.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-13] Unregularized Linear Convergence in Zero-Sum Game from Preference Feedback</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24818">https://arxiv.org/abs/2512.24818</a><br>
<strong>作者</strong>: Shulun Chen,Runlong Zhou,Zihan Zhang,Maryam Fazel,Simon S. Du<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  28 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Aligning large language models (LLMs) with human preferences has proven effective for enhancing model capabilities, yet standard preference modeling using the Bradley-Terry model assumes transitivity, overlooking the inherent complexity of human population preferences. Nash learning from human feedback (NLHF) addresses this by framing non-transitive preferences as a two-player zero-sum game, where alignment reduces to finding the Nash equilibrium (NE). However, existing algorithms typically rely on regularization, incurring unavoidable bias when computing the duality gap in the original game. In this work, we provide the first convergence guarantee for Optimistic Multiplicative Weights Update ( \mathttOMWU ) in NLHF, showing that it achieves last-iterate linear convergence after a burn-in phase whenever an NE with full support exists, with an instance-dependent linear convergence rate to the original NE, measured by duality gaps. Compared to prior results in Wei et al. (2020), we do not require the assumption of NE uniqueness. Our analysis identifies a novel marginal convergence behavior, where the probability of rarely played actions grows exponentially from exponentially small values, enabling exponentially better dependence on instance-dependent constants than prior results. Experiments corroborate the theoretical strengths of  \mathttOMWU  in both tabular and neural policy classes, demonstrating its potential for LLM applications.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-14] DTI-GP: Bayesian operations for drug-target interactions using deep kernel Gaussian processes</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24810">https://arxiv.org/abs/2512.24810</a><br>
<strong>作者</strong>: Bence Bolgár,András Millinghoffer,Péter Antal<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Precise probabilistic information about drug-target interaction (DTI) predictions is vital for understanding limitations and boosting predictive performance. Gaussian processes (GP) offer a scalable framework to integrate state-of-the-art DTI representations and Bayesian inference, enabling novel operations, such as Bayesian classification with rejection, top- K  selection, and ranking. We propose a deep kernel learning-based GP architecture (DTI-GP), which incorporates a combined neural embedding module for chemical compounds and protein targets, and a GP module. The workflow continues with sampling from the predictive distribution to estimate a Bayesian precedence matrix, which is used in fast and accurate selection and ranking operations. DTI-GP outperforms state-of-the-art solutions, and it allows (1) the construction of a Bayesian accuracy-confidence enrichment score, (2) rejection schemes for improved enrichment, and (3) estimation and search for top- K  selections and ranking with high expected utility.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-15] Self-Supervised Neural Architecture Search for Multimodal Deep Neural Networks</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24793">https://arxiv.org/abs/2512.24793</a><br>
<strong>作者</strong>: Shota Suzuki,Satoshi Ono<br>
<strong>类目</strong>: Machine Learning (cs.LG); Neural and Evolutionary Computing (<a target="_blank" rel="noopener" href="http://cs.NE">cs.NE</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Neural architecture search (NAS), which automates the architectural design process of deep neural networks (DNN), has attracted increasing attention. Multimodal DNNs that necessitate feature fusion from multiple modalities benefit from NAS due to their structural complexity; however, constructing an architecture for multimodal DNNs through NAS requires a substantial amount of labeled training data. Thus, this paper proposes a self-supervised learning (SSL) method for architecture search of multimodal DNNs. The proposed method applies SSL comprehensively for both the architecture search and model pretraining processes. Experimental results demonstrated that the proposed method successfully designed architectures for DNNs from unlabeled training data.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-16] Gradient Descent as Implicit EM in Distance-Based Neural Models</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24780">https://arxiv.org/abs/2512.24780</a><br>
<strong>作者</strong>: Alan Oursland<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  15 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Neural networks trained with standard objectives exhibit behaviors characteristic of probabilistic inference: soft clustering, prototype specialization, and Bayesian uncertainty tracking. These phenomena appear across architectures – in attention mechanisms, classification heads, and energy-based models – yet existing explanations rely on loose analogies to mixture models or post-hoc architectural interpretation. We provide a direct derivation. For any objective with log-sum-exp structure over distances or energies, the gradient with respect to each distance is exactly the negative posterior responsibility of the corresponding component:  \partial L / \partial d_j = -r_j . This is an algebraic identity, not an approximation. The immediate consequence is that gradient descent on such objectives performs expectation-maximization implicitly – responsibilities are not auxiliary variables to be computed but gradients to be applied. No explicit inference algorithm is required because inference is embedded in optimization. This result unifies three regimes of learning under a single mechanism: unsupervised mixture modeling, where responsibilities are fully latent; attention, where responsibilities are conditioned on queries; and cross-entropy classification, where supervision clamps responsibilities to targets. The Bayesian structure recently observed in trained transformers is not an emergent property but a necessary consequence of the objective geometry. Optimization and inference are the same process.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-17] From Trial to Deployment: A SEM Analysis of Traveler Adoptions to Fully Operational Autonomous Taxis</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24767">https://arxiv.org/abs/2512.24767</a><br>
<strong>作者</strong>: Yutong Cai,Hua Wang<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Autonomous taxi services represent a transformative advancement in urban mobility, offering safety, efficiency, and round-the-clock operations. While existing literature has explored user acceptance of autonomous taxis through stated preference experiments and hypothetical scenarios, few studies have investigated actual user behavior based on operational AV services. This study addresses that gap by leveraging survey data from Wuhan, China, where Baidu’s Apollo Robotaxi service operates at scale. We design a realistic survey incorporating actual service attributes and collect 336 valid responses from actual users. Using Structural Equation Modeling, we identify six latent psychological constructs, namely Trust \ Policy Support, Cost Sensitivity, Performance, Behavioral Intention, Lifestyle, and Education. Their influences on adoption behavior, measured by the selection frequency of autonomous taxis in ten scenarios, are examined and interpreted. Results show that Cost Sensitivity and Behavioral Intention are the strongest positive predictors of adoption, while other latent constructs play more nuanced roles. The model demonstrates strong goodness-of-fit across multiple indices. Our findings offer empirical evidence to support policymaking, fare design, and public outreach strategies for scaling autonomous taxis deployments in real-world urban settings.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-18] FPGA Co-Design for Efficient N:M Sparse and Quantized Model Inference</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24713">https://arxiv.org/abs/2512.24713</a><br>
<strong>作者</strong>: Fen-Yu Hsieh,Yun-Chang Teng,Ding-Yong Hong,Jan-Jan Wu<br>
<strong>类目</strong>: Machine Learning (cs.LG); Hardware Architecture (<a target="_blank" rel="noopener" href="http://cs.AR">cs.AR</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language models (LLMs) have demonstrated remarkable performance across a wide range of language processing tasks. However, this success comes at the cost of substantial computation and memory requirements, which significantly impedes their deployment in resource-constrained environments. To address this challenge, this work introduces an automation framework that leverages weight pruning and low-bit quantization, and presents a hardware-software co-design method that generates accelerators on the Field-Programmable Gate Array (FPGA) platform. In particular, we implement a unified pipeline that applies N:M structured pruning and 4-bit integer quantization to reduce the memory footprint, followed by optimized dequantization and matrix multiplication to enhance LLM inference on several hardware platforms, including CPUs, NVIDIA GPUs with Dense and 2:4 Sparse Tensor Cores, and a custom systolic-array-based FPGA accelerator. Utilizing 2:4 sparsity combined with quantization on  4096 \times 4096  matrices, our approach achieves a reduction of up to  4\times  in weight storage and a  1.71\times  speedup in matrix multiplication, yielding a  1.29\times  end-to-end latency reduction compared to dense GPU baselines. Scaling analysis on the LLaMA-7B model further shows that structured sparsity enhances the throughput per token by  1.36\times . These results demonstrate the synergy of fine-grained N:M sparsity and quantization for enabling efficient and deployable LLM inference, while the proposed FPGA accelerator offers a flexible architectural path for supporting a broader class of sparsity patterns beyond the fixed 2:4 hardware constraints.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-19] Causal Discovery with Mixed Latent Confounding via Precision Decomposition</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24696">https://arxiv.org/abs/2512.24696</a><br>
<strong>作者</strong>: Amir Asiaee,Samhita Pal,James O’quinn,James P. Long<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We study causal discovery from observational data in linear Gaussian systems affected by \emphmixed latent confounding, where some unobserved factors act broadly across many variables while others influence only small subsets. This setting is common in practice and poses a challenge for existing methods: differentiable and score-based DAG learners can misinterpret global latent effects as causal edges, while latent-variable graphical models recover only undirected structure. We propose \textscDCL-DECOR, a modular, precision-led pipeline that separates these roles. The method first isolates pervasive latent effects by decomposing the observed precision matrix into a structured component and a low-rank component. The structured component corresponds to the conditional distribution after accounting for pervasive confounders and retains only local dependence induced by the causal graph and localized confounding. A correlated-noise DAG learner is then applied to this deconfounded representation to recover directed edges while modeling remaining structured error correlations, followed by a simple reconciliation step to enforce bow-freeness. We provide identifiability results that characterize the recoverable causal target under mixed confounding and show how the overall problem reduces to well-studied subproblems with modular guarantees. Synthetic experiments that vary the strength and dimensionality of pervasive confounding demonstrate consistent improvements in directed edge recovery over applying correlated-noise DAG learning directly to the confounded data.         Subjects:  Machine Learning (cs.LG)  Cite as: arXiv:2512.24696 [cs.LG]    (or  arXiv:2512.24696v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24696">https://doi.org/10.48550/arXiv.2512.24696</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-20] Mobility-Assisted Decentralized Federated Learning: Convergence Analysis and A Data-Driven Approach</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24694">https://arxiv.org/abs/2512.24694</a><br>
<strong>作者</strong>: Reza Jahani,Md Farhamdur Reza,Richeng Jin,Huaiyu Dai<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  Under review for potential publication in IEEE Transactions on Cognitive Communications and Networking</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Decentralized Federated Learning (DFL) has emerged as a privacy-preserving machine learning paradigm that enables collaborative training among users without relying on a central server. However, its performance often degrades significantly due to limited connectivity and data heterogeneity. As we move toward the next generation of wireless networks, mobility is increasingly embedded in many real-world applications. The user mobility, either natural or induced, enables clients to act as relays or bridges, thus enhancing information flow in sparse networks; however, its impact on DFL has been largely overlooked despite its potential. In this work, we systematically investigate the role of mobility in improving DFL performance. We first establish the convergence of DFL in sparse networks under user mobility and theoretically demonstrate that even random movement of a fraction of users can significantly boost performance. Building upon this insight, we propose a DFL framework that utilizes mobile users with induced mobility patterns, allowing them to exploit the knowledge of data distribution to determine their trajectories to enhance information propagation through the network. Through extensive experiments, we empirically confirm our theoretical findings, validate the superiority of our approach over baselines, and provide a comprehensive analysis of how various network parameters influence DFL performance in mobile networks.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-21] HeteroHBA: A Generative Structure-Manipulating Backdoor Attack on Heterogeneous Graphs</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24665">https://arxiv.org/abs/2512.24665</a><br>
<strong>作者</strong>: Honglin Gao,Lan Zhao,Junhao Ren,Xiang Li,Gaoxi Xiao<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Heterogeneous graph neural networks (HGNNs) have achieved strong performance in many real-world applications, yet targeted backdoor poisoning on heterogeneous graphs remains less studied. We consider backdoor attacks for heterogeneous node classification, where an adversary injects a small set of trigger nodes and connections during training to force specific victim nodes to be misclassified into an attacker-chosen label at test time while preserving clean performance. We propose HeteroHBA, a generative backdoor framework that selects influential auxiliary neighbors for trigger attachment via saliency-based screening and synthesizes diverse trigger features and connection patterns to better match the local heterogeneous context. To improve stealthiness, we combine Adaptive Instance Normalization (AdaIN) with a Maximum Mean Discrepancy (MMD) loss to align the trigger feature distribution with benign statistics, thereby reducing detectability, and we optimize the attack with a bilevel objective that jointly promotes attack success and maintains clean accuracy. Experiments on multiple real-world heterogeneous graphs with representative HGNN architectures show that HeteroHBA consistently achieves higher attack success than prior backdoor baselines with comparable or smaller impact on clean accuracy; moreover, the attack remains effective under our heterogeneity-aware structural defense, CSD. These results highlight practical backdoor risks in heterogeneous graph learning and motivate the development of stronger defenses.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-22] A Scalable Framework for logP Prediction: From Terabyte-Scale Data Integration to Interpretable Ensemble Modeling</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24643">https://arxiv.org/abs/2512.24643</a><br>
<strong>作者</strong>: Malikussaid,Septian Caesar Floresko,Ade Romadhony,Isman Kurniawan,Warih Maharani,Hilal Hudan Nuha<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computational Engineering, Finance, and Science (cs.CE); Databases (cs.DB); Biomolecules (<a target="_blank" rel="noopener" href="http://q-bio.BM">q-bio.BM</a>)<br>
*<strong>备注</strong>:  18 pages, 15 figures, 4 equations, 2 algorithms, 6 tables, to be published in KST 2026, unabridged version</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This study presents a large-scale predictive modeling framework for logP prediction using 426850 bioactive compounds rigorously curated from the intersection of three authoritative chemical databases: PubChem, ChEMBL, and eMolecules. We developed a novel computational infrastructure to address the data integration challenge, reducing processing time from a projected over 100 days to 3.2 hours through byte-offset indexing architecture, a 740-fold improvement. Our comprehensive analysis revealed critical insights into the multivariate nature of lipophilicity: while molecular weight exhibited weak bivariate correlation with logP, SHAP analysis on ensemble models identified it as the single most important predictor globally. We systematically evaluated multiple modeling approaches, discovering that linear models suffered from inherent heteroskedasticity that classical remediation strategies, including weighted least squares and Box-Cox transformation, failed to address. Tree-based ensemble methods, including Random Forest and XGBoost, proved inherently robust to this violation, achieving an R-squared of 0.765 and RMSE of 0.731 logP units on the test set. Furthermore, a stratified modeling strategy, employing specialized models for drug-like molecules (91 percent of dataset) and extreme cases (nine percent), achieved optimal performance: an RMSE of 0.838 for the drug-like subset and an R-squared of 0.767 for extreme molecules, the highest of all evaluated approaches. These findings provide actionable guidance for molecular design, establish robust baselines for lipophilicity prediction using only 2D descriptors, and demonstrate that well-curated, descriptor-based ensemble models remain competitive with state-of-the-art graph neural network architectures.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-23] CPR: Causal Physiological Representation Learning for Robust ECG Analysis under Distribution Shifts</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24564">https://arxiv.org/abs/2512.24564</a><br>
<strong>作者</strong>: Shunbo Jia,Caizhi Liao<br>
<strong>类目</strong>: Machine Learning (cs.LG); Signal Processing (eess.SP)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Deep learning models for Electrocardiogram (ECG) diagnosis have achieved remarkable accuracy but exhibit fragility against adversarial perturbations, particularly Smooth Adversarial Perturbations (SAP) that mimic biological morphology. Existing defenses face a critical dilemma: Adversarial Training (AT) provides robustness but incurs a prohibitive computational burden, while certified methods like Randomized Smoothing (RS) introduce significant inference latency, rendering them impractical for real-time clinical monitoring. We posit that this vulnerability stems from the models’ reliance on non-robust spurious correlations rather than invariant pathological features. To address this, we propose Causal Physiological Representation Learning (CPR). Unlike standard denoising approaches that operate without semantic constraints, CPR incorporates a Physiological Structural Prior within a causal disentanglement framework. By modeling ECG generation via a Structural Causal Model (SCM), CPR enforces a structural intervention that strictly separates invariant pathological morphology (P-QRS-T complex) from non-causal artifacts. Empirical results on PTB-XL demonstrate that CPR significantly outperforms standard clinical preprocessing methods. Specifically, under SAP attacks, CPR achieves an F1 score of 0.632, surpassing Median Smoothing (0.541 F1) by 9.1%. Crucially, CPR matches the certified robustness of Randomized Smoothing while maintaining single-pass inference efficiency, offering a superior trade-off between robustness, efficiency, and clinical interpretability.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-24] From Perception to Punchline: Empowering VLM with the Art of In-the-wild Meme</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24555">https://arxiv.org/abs/2512.24555</a><br>
<strong>作者</strong>: Xueyan Li,Yingyi Xue,Mengjie Jiang,Qingzi Zhu,Yazhe Niu<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  46 pages, 20 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Generating humorous memes is a challenging multimodal task that moves beyond direct image-to-caption supervision. It requires a nuanced reasoning over visual content, contextual cues, and subjective humor. To bridge this gap between visual perception and humorous punchline creation, we propose HUMOR, a novel framework that guides VLMs through hierarchical reasoning and aligns them with group-wise human preferences. First, HUMOR employs a hierarchical, multi-path Chain-of-Thought (CoT): the model begins by identifying a template-level intent, then explores diverse reasoning paths under different contexts, and finally anchors onto a high-quality, context-specific path. This CoT supervision, which traces back from ground-truth captions, enhances reasoning diversity. We further analyze that this multi-path exploration with anchoring maintains a high expected humor quality, under the practical condition that high-quality paths retain significant probability mass. Second, to capture subjective humor, we train a pairwise reward model that operates within groups of memes sharing the same template. Following established theory, this approach ensures a consistent and robust proxy for human preference, even with subjective and noisy labels. The reward model then enables a group-wise reinforcement learning optimization, guaranteeing providing a theoretical guarantee for monotonic improvement within the trust region. Extensive experiments show that HUMOR empowers various VLMs with superior reasoning diversity, more reliable preference alignment, and higher overall meme quality. Beyond memes, our work presents a general training paradigm for open-ended, human-aligned multimodal generation, where success is guided by comparative judgment within coherent output group.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-25] A Graph Neural Network with Auxiliary Task Learning for Missing PMU Data Reconstruction</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24542">https://arxiv.org/abs/2512.24542</a><br>
<strong>作者</strong>: Bo Li,Zijun Chen,Haiwang Zhong,Di Cao,Guangchun Ruan<br>
<strong>类目</strong>: ystems and Control (<a target="_blank" rel="noopener" href="http://eess.SY">eess.SY</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In wide-area measurement systems (WAMS), phasor measurement unit (PMU) measurement is prone to data missingness due to hardware failures, communication delays, and cyber-attacks. Existing data-driven methods are limited by inadaptability to concept drift in power systems, poor robustness under high missing rates, and reliance on the unrealistic assumption of full system observability. Thus, this paper proposes an auxiliary task learning (ATL) method for reconstructing missing PMU data. First, a K-hop graph neural network (GNN) is proposed to enable direct learning on the subgraph consisting of PMU nodes, overcoming the limitation of the incompletely observable system. Then, an auxiliary learning framework consisting of two complementary graph networks is designed for accurate reconstruction: a spatial-temporal GNN extracts spatial-temporal dependencies from PMU data to reconstruct missing values, and another auxiliary GNN utilizes the low-rank property of PMU data to achieve unsupervised online learning. In this way, the low-rank properties of the PMU data are dynamically leveraged across the architecture to ensure robustness and self-adaptation. Numerical results demonstrate the superior offline and online performance of the proposed method under high missing rates and incomplete observability.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-26] Generalising E-prop to Deep Networks</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24506">https://arxiv.org/abs/2512.24506</a><br>
<strong>作者</strong>: Beren Millidge<br>
<strong>类目</strong>: Machine Learning (cs.LG); Neural and Evolutionary Computing (<a target="_blank" rel="noopener" href="http://cs.NE">cs.NE</a>)<br>
*<strong>备注</strong>:  30/12/25 initial upload</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recurrent networks are typically trained with backpropagation through time (BPTT). However, BPTT requires storing the history of all states in the network and then replaying them sequentially backwards in time. This computation appears extremely implausible for the brain to implement. Real Time Recurrent Learning (RTRL) proposes an mathematically equivalent alternative where gradient information is propagated forwards in time locally alongside the regular forward pass, however it has significantly greater computational complexity than BPTT which renders it impractical for large networks. E-prop proposes an approximation of RTRL which reduces its complexity to the level of BPTT while maintaining a purely online forward update which can be implemented by an eligibility trace at each synapse. However, works on RTRL and E-prop ubiquitously investigate learning in a single layer with recurrent dynamics. However, learning in the brain spans multiple layers and consists of both hierarchal dynamics in depth as well as time. In this mathematical note, we extend the E-prop framework to handle arbitrarily deep networks, deriving a novel recursion relationship across depth which extends the eligibility traces of E-prop to deeper layers. Our results thus demonstrate an online learning algorithm can perform accurate credit assignment across both time and depth simultaneously, allowing the training of deep recurrent networks without backpropagation through time.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-27] Generative forecasting with joint probability models</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24446">https://arxiv.org/abs/2512.24446</a><br>
<strong>作者</strong>: Patrick Wyrod,Ashesh Chattopadhyay,Daniele Venturi<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computational Physics (physics.comp-ph)<br>
*<strong>备注</strong>:  18 pages, 11 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Chaotic dynamical systems exhibit strong sensitivity to initial conditions and often contain unresolved multiscale processes, making deterministic forecasting fundamentally limited. Generative models offer an appealing alternative by learning distributions over plausible system evolutions; yet, most existing approaches focus on next-step conditional prediction rather than the structure of the underlying dynamics. In this work, we reframe forecasting as a fully generative problem by learning the joint probability distribution of lagged system states over short temporal windows and obtaining forecasts through marginalization. This new perspective allows the model to capture nonlinear temporal dependencies, represent multistep trajectory segments, and produce next-step predictions consistent with the learned joint distribution. We also introduce a general, model-agnostic training and inference framework for joint generative forecasting and show how it enables assessment of forecast robustness and reliability using three complementary uncertainty quantification metrics (ensemble variance, short-horizon autocorrelation, and cumulative Wasserstein drift), without access to ground truth. We evaluate the performance of the proposed method on two canonical chaotic dynamical systems, the Lorenz-63 system and the Kuramoto-Sivashinsky equation, and show that joint generative models yield improved short-term predictive skill, preserve attractor geometry, and achieve substantially more accurate long-range statistical behaviour than conventional conditional next-step models.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-28] Adaptive Learning Guided by Bias-Noise-Alignment Diagnostics</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24445">https://arxiv.org/abs/2512.24445</a><br>
<strong>作者</strong>: Akash Samanta,Sheldon Williamson<br>
<strong>类目</strong>: Machine Learning (cs.LG); Systems and Control (<a target="_blank" rel="noopener" href="http://eess.SY">eess.SY</a>)<br>
*<strong>备注</strong>:  This preprint focuses on the theoretical framework and diagnostic behavior. Comprehensive experimental validation in application-specific settings is deferred to a companion experimental study</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Learning systems deployed in nonstationary and safety-critical environments often suffer from instability, slow convergence, or brittle adaptation when learning dynamics evolve over time. While modern optimization, reinforcement learning, and meta-learning methods adapt to gradient statistics, they largely ignore the temporal structure of the error signal itself. This paper proposes a diagnostic-driven adaptive learning framework that explicitly models error evolution through a principled decomposition into bias, capturing persistent drift; noise, capturing stochastic variability; and alignment, capturing repeated directional excitation leading to overshoot. These diagnostics are computed online from lightweight statistics of loss or temporal-difference error trajectories and are independent of model architecture or task domain. We show that the proposed bias-noise-alignment decomposition provides a unifying control backbone for supervised optimization, actor-critic reinforcement learning, and learned optimizers. Building on this framework, we derive diagnostic-driven instantiations including a stabilized supervised optimizer, a diagnostic-regulated actor-critic scheme, and a diagnostic-conditioned learned optimizer. Under standard smoothness assumptions, we establish bounded effective updates and stability properties for all cases. Representative diagnostic illustrations in actor-critic learning highlight how the proposed signals modulate adaptation in response to temporal-difference error structure. Overall, this work elevates error evolution to a first-class object in adaptive learning and provides an interpretable, lightweight foundation for reliable learning in dynamic environments.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-29] Sparse classification with positive-confidence data in high dimensions</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24443">https://arxiv.org/abs/2512.24443</a><br>
<strong>作者</strong>: TheTien Mai,Mai Anh Nguyen,Trung Nghia Nguyen<br>
<strong>类目</strong>: Machine Learning (cs.LG); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:High-dimensional learning problems, where the number of features exceeds the sample size, often require sparse regularization for effective prediction and variable selection. While established for fully supervised data, these techniques remain underexplored in weak-supervision settings such as Positive-Confidence (Pconf) classification. Pconf learning utilizes only positive samples equipped with confidence scores, thereby avoiding the need for negative data. However, existing Pconf methods are ill-suited for high-dimensional regimes. This paper proposes a novel sparse-penalization framework for high-dimensional Pconf classification. We introduce estimators using convex (Lasso) and non-convex (SCAD, MCP) penalties to address shrinkage bias and improve feature recovery. Theoretically, we establish estimation and prediction error bounds for the L1-regularized Pconf estimator, proving it achieves near minimax-optimal sparse recovery rates under Restricted Strong Convexity condition. To solve the resulting composite objective, we develop an efficient proximal gradient algorithm. Extensive simulations demonstrate that our proposed methods achieve predictive performance and variable selection accuracy comparable to fully supervised approaches, effectively bridging the gap between weak supervision and high-dimensional statistics.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-30] Efficient Inference for Inverse Reinforcement Learning and Dynamic Discrete Choice Models</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24407">https://arxiv.org/abs/2512.24407</a><br>
<strong>作者</strong>: Lars van der Laan,Aurelien Bibaut,Nathan Kallus<br>
<strong>类目</strong>: Machine Learning (cs.LG); Statistics Theory (<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Inverse reinforcement learning (IRL) and dynamic discrete choice (DDC) models explain sequential decision-making by recovering reward functions that rationalize observed behavior. Flexible IRL methods typically rely on machine learning but provide no guarantees for valid inference, while classical DDC approaches impose restrictive parametric specifications and often require repeated dynamic programming. We develop a semiparametric framework for debiased inverse reinforcement learning that yields statistically efficient inference for a broad class of reward-dependent functionals in maximum entropy IRL and Gumbel-shock DDC models. We show that the log-behavior policy acts as a pseudo-reward that point-identifies policy value differences and, under a simple normalization, the reward itself. We then formalize these targets, including policy values under known and counterfactual softmax policies and functionals of the normalized reward, as smooth functionals of the behavior policy and transition kernel, establish pathwise differentiability, and derive their efficient influence functions. Building on this characterization, we construct automatic debiased machine-learning estimators that allow flexible nonparametric estimation of nuisance components while achieving  \sqrtn -consistency, asymptotic normality, and semiparametric efficiency. Our framework extends classical inference for DDC models to nonparametric rewards and modern machine-learning tools, providing a unified and computationally tractable approach to statistical inference in IRL.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-31] MaRCA: Multi-<mark class="hl-label green">Agent</mark>  Reinforcement Learning for Dynamic Computation Allocation in Large-Scale Recommender Systems</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24325">https://arxiv.org/abs/2512.24325</a><br>
<strong>作者</strong>: Wan Jiang,Xinyi Zang,Yudong Zhao,Yusi Zou,Yunfei Lu,Junbo Tong,Yang Liu,Ming Li,Jiani Shi,Xin Yang<br>
<strong>类目</strong>: Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>); Machine Learning (cs.LG); Multiagent Systems (<a target="_blank" rel="noopener" href="http://cs.MA">cs.MA</a>)<br>
*<strong>备注</strong>:  12 pages, 5 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Modern recommender systems face significant computational challenges due to growing model complexity and traffic scale, making efficient computation allocation critical for maximizing business revenue. Existing approaches typically simplify multi-stage computation resource allocation, neglecting inter-stage dependencies, thus limiting global optimality. In this paper, we propose MaRCA, a multi-agent reinforcement learning framework for end-to-end computation resource allocation in large-scale recommender systems. MaRCA models the stages of a recommender system as cooperative agents, using Centralized Training with Decentralized Execution (CTDE) to optimize revenue under computation resource constraints. We introduce an AutoBucket TestBench for accurate computation cost estimation, and a Model Predictive Control (MPC)-based Revenue-Cost Balancer to proactively forecast traffic loads and adjust the revenue-cost trade-off accordingly. Since its end-to-end deployment in the advertising pipeline of a leading global e-commerce platform in November 2024, MaRCA has consistently handled hundreds of billions of ad requests per day and has delivered a 16.67% revenue uplift using existing computation resources.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-32] Early Prediction of Sepsis using Heart Rate Signals and Genetic Optimized LSTM Algorithm</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24253">https://arxiv.org/abs/2512.24253</a><br>
<strong>作者</strong>: Alireza Rafiei,Farshid Hajati,Alireza Rezaee,Amirhossien Panahi,Shahadat Uddin<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Sepsis, characterized by a dysregulated immune response to infection, results in significant mortality, morbidity, and healthcare costs. The timely prediction of sepsis progression is crucial for reducing adverse outcomes through early intervention. Despite the development of numerous models for Intensive Care Unit (ICU) patients, there remains a notable gap in approaches for the early detection of sepsis in non-ward settings. This research introduces and evaluates four novel machine learning algorithms designed for predicting the onset of sepsis on wearable devices by analyzing heart rate data. The architecture of these models was refined through a genetic algorithm, optimizing for performance, computational complexity, and memory requirements. Performance metrics were subsequently extracted for each model to evaluate their feasibility for implementation on wearable devices capable of accurate heart rate monitoring. The models were initially tailored for a prediction window of one hour, later extended to four hours through transfer learning. The encouraging outcomes of this study suggest the potential for wearable technology to facilitate early sepsis detection outside ICU and ward environments.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-33] Micro-Macro Tensor Neural Surrogates for Uncertainty Quantification in Collisional Plasma</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24205">https://arxiv.org/abs/2512.24205</a><br>
<strong>作者</strong>: Wei Chen,Giacomo Dimarco,Lorenzo Pareschi<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Plasma kinetic equations exhibit pronounced sensitivity to microscopic perturbations in model parameters and data, making reliable and efficient uncertainty quantification (UQ) essential for predictive simulations. However, the cost of uncertainty sampling, the high-dimensional phase space, and multiscale stiffness pose severe challenges to both computational efficiency and error control in traditional numerical methods. These aspects are further emphasized in presence of collisions where the high-dimensional nonlocal collision integrations and conservation properties pose severe constraints. To overcome this, we present a variance-reduced Monte Carlo framework for UQ in the Vlasov–Poisson–Landau (VPL) system, in which neural network surrogates replace the multiple costly evaluations of the Landau collision term. The method couples a high-fidelity, asymptotic-preserving VPL solver with inexpensive, strongly correlated surrogates based on the Vlasov–Poisson–Fokker–Planck (VPFP) and Euler–Poisson (EP) equations. For the surrogate models, we introduce a generalization of the separable physics-informed neural network (SPINN), developing a class of tensor neural networks based on an anisotropic micro-macro decomposition, to reduce velocity-moment costs, model complexity, and the curse of dimensionality. To further increase correlation with VPL, we calibrate the VPFP model and design an asymptotic-preserving SPINN whose small- and large-Knudsen limits recover the EP and VP systems, respectively. Numerical experiments show substantial variance reduction over standard Monte Carlo, accurate statistics with far fewer high-fidelity samples, and lower wall-clock time, while maintaining robustness to stochastic dimension.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-34] Paired Seed Evaluation: Statistical Reliability for Learning-Based Simulators</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24145">https://arxiv.org/abs/2512.24145</a><br>
<strong>作者</strong>: Udit Sharma<br>
<strong>类目</strong>: Machine Learning (cs.LG); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:  12 pages, 3 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Machine learning systems appear stochastic but are deterministically random, as seeded pseudorandom number generators produce identical realisations across executions. Learning-based simulators are widely used to compare algorithms, design choices, and interventions under such dynamics, yet evaluation outcomes often exhibit high variance due to random initialisation and learning stochasticity. We analyse the statistical structure of comparative evaluation in these settings and show that standard independent evaluation designs fail to exploit shared sources of randomness across alternatives. We formalise a paired seed evaluation design in which competing systems are evaluated under identical random seeds, inducing matched realisations of stochastic components and strict variance reduction whenever outcomes are positively correlated at the seed level. This yields tighter confidence intervals, higher statistical power, and effective sample size gains at fixed computational budgets. Empirically, seed-level correlations are typically large and positive, producing order-of-magnitude efficiency gains. Paired seed evaluation is weakly dominant in practice, improving statistical reliability when correlation is present and reducing to independent evaluation without loss of validity when it is not.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-35] Colorful Pinball: Density-Weighted Quantile Regression for Conditional Guarantee of Conformal Prediction</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24139">https://arxiv.org/abs/2512.24139</a><br>
<strong>作者</strong>: Qianyi Chen,Bo Li<br>
<strong>类目</strong>: Machine Learning (cs.LG); Methodology (<a target="_blank" rel="noopener" href="http://stat.ME">stat.ME</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:While conformal prediction provides robust marginal coverage guarantees, achieving reliable conditional coverage for specific inputs remains challenging. Although exact distribution-free conditional coverage is impossible with finite samples, recent work has focused on improving the conditional coverage of standard conformal procedures. Distinct from approaches that target relaxed notions of conditional coverage, we directly minimize the mean squared error of conditional coverage by refining the quantile regression components that underpin many conformal methods. Leveraging a Taylor expansion, we derive a sharp surrogate objective for quantile regression: a density-weighted pinball loss, where the weights are given by the conditional density of the conformity score evaluated at the true quantile. We propose a three-headed quantile network that estimates these weights via finite differences using auxiliary quantile levels at (1-\alpha \pm \delta), subsequently fine-tuning the central quantile by optimizing the weighted loss. We provide a theoretical analysis with exact non-asymptotic guarantees characterizing the resulting excess risk. Extensive experiments on diverse high-dimensional real-world datasets demonstrate remarkable improvements in conditional coverage performance.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-36] Autoregressivity in the Latent Space of a GP-VAE Language Model: An Empirical Ablation Study</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24102">https://arxiv.org/abs/2512.24102</a><br>
<strong>作者</strong>: Yves Ruffenach<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  A focused ablation study analyzing the role of latent autoregression in GP-VAE models</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper provides an ablation-based analysis of latent autoregression in GP-VAE models, building upon our previous work introducing the architecture. Language models typically rely on an autoregressive factorization over tokens. In contrast, our prior work proposed shifting sequential structure to the latent space through a causal Gaussian process, while using a non-autoregressive decoder. Here, we conduct a systematic ablation study of the role played by latent autoregression. We compare (i) a full GP-VAE model with autoregressive latent dynamics, (ii) a non-autoregressive ablation in which latent variables are independent, and (iii) a standard token-level autoregressive Transformer. Our results show that, within the considered regime (medium-scale corpora and short training contexts), latent autoregression induces latent trajectories that are significantly more compatible with the Gaussian-process prior and exhibit greater long-horizon stability. In contrast, removing autoregression leads to degraded latent structure and unstable long-range behavior. These findings highlight the role of latent autoregression as an effective mechanism for organizing long-range structure, while remaining complementary to token-level autoregressive modeling. They should be interpreted as an empirical analysis of representational structure rather than as a proposal for a new architecture.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-37] Multi-Scenario Highway Lane-Change Intention Prediction: A Temporal Physics-Informed Multi-Modal Framework</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24075">https://arxiv.org/abs/2512.24075</a><br>
<strong>作者</strong>: Jiazhao Shi,Ziyu Wang,Yichen Lin,Shoufeng Lu<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Lane-change intention prediction is safety-critical for autonomous driving and ADAS, but remains difficult in naturalistic traffic due to noisy kinematics, severe class imbalance, and limited generalization across heterogeneous highway scenarios. We propose Temporal Physics-Informed AI (TPI-AI), a hybrid framework that fuses deep temporal representations with physics-inspired interaction cues. A two-layer bidirectional LSTM (Bi-LSTM) encoder learns compact embeddings from multi-step trajectory histories; we concatenate these embeddings with kinematics-, safety-, and interaction-aware features (e.g., headway, TTC, and safe-gap indicators) and train a LightGBM classifier for three-class intention recognition (No-LC, Left-LC, Right-LC). To improve minority-class reliability, we apply imbalance-aware optimization including resampling/weighting and fold-wise threshold calibration. Experiments on two large-scale drone-based datasets, highD (straight highways) and exiD (ramp-rich environments), use location-based splits and evaluate prediction horizons T = 1, 2, 3 s. TPI-AI outperforms standalone LightGBM and Bi-LSTM baselines, achieving macro-F1 of 0.9562, 0.9124, 0.8345 on highD and 0.9247, 0.8197, 0.7605 on exiD at T = 1, 2, 3 s, respectively. These results show that combining physics-informed interaction features with learned temporal embeddings yields robust multi-scenario lane-change intention prediction.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-38] me-varying Mixing Matrix Design for Energy-efficient Decentralized Federated Learning</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24069">https://arxiv.org/abs/2512.24069</a><br>
<strong>作者</strong>: Xusheng Zhang,Tuan Nguyen,Ting He<br>
<strong>类目</strong>: Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We consider the design of mixing matrices to minimize the operation cost for decentralized federated learning (DFL) in wireless networks, with focus on minimizing the maximum per-node energy consumption. As a critical hyperparameter for DFL, the mixing matrix controls both the convergence rate and the needs of agent-to-agent communications, and has thus been studied extensively. However, existing designs mostly focused on minimizing the communication time, leaving open the minimization of per-node energy consumption that is critical for energy-constrained devices. This work addresses this gap through a theoretically-justified solution for mixing matrix design that aims at minimizing the maximum per-node energy consumption until convergence, while taking into account the broadcast nature of wireless communications. Based on a novel convergence theorem that allows arbitrarily time-varying mixing matrices, we propose a multi-phase design framework that activates time-varying communication topologies under optimized budgets to trade off the per-iteration energy consumption and the convergence rate while balancing the energy consumption across nodes. Our evaluations based on real data have validated the efficacy of the proposed solution in combining the low energy consumption of sparse mixing matrices and the fast convergence of dense mixing matrices.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-39] How and Why <mark class="hl-label green">LLM</mark> s Generalize: A Fine-Grained Analysis of <mark class="hl-label green">LLM</mark>  <mark class="hl-label green">Reasoning</mark>  from Cognitive Behaviors to Low-Level Patterns</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24063">https://arxiv.org/abs/2512.24063</a><br>
<strong>作者</strong>: Haoyue Bai,Yiyou Sun,Wenjie Hu,Shi Qiu,Maggie Ziyu Huan,Peiyang Song,Robert Nowak,Dawn Song<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) display strikingly different generalization behaviors: supervised fine-tuning (SFT) often narrows capability, whereas reinforcement-learning (RL) tuning tends to preserve it. The reasons behind this divergence remain unclear, as prior studies have largely relied on coarse accuracy metrics. We address this gap by introducing a novel benchmark that decomposes reasoning into atomic core skills such as calculation, fact retrieval, simulation, enumeration, and diagnostic, providing a concrete framework for addressing the fundamental question of what constitutes reasoning in LLMs. By isolating and measuring these core skills, the benchmark offers a more granular view of how specific cognitive abilities emerge, transfer, and sometimes collapse during post-training. Combined with analyses of low-level statistical patterns such as distributional divergence and parameter statistics, it enables a fine-grained study of how generalization evolves under SFT and RL across mathematical, scientific reasoning, and non-reasoning tasks. Our meta-probing framework tracks model behavior at different training stages and reveals that RL-tuned models maintain more stable behavioral profiles and resist collapse in reasoning skills, whereas SFT models exhibit sharper drift and overfit to surface patterns. This work provides new insights into the nature of reasoning in LLMs and points toward principles for designing training strategies that foster broad, robust generalization.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-40] Hyperspherical Graph Representation Learning via Adaptive Neighbor-Mean Alignment and Uniformity</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24062">https://arxiv.org/abs/2512.24062</a><br>
<strong>作者</strong>: Rui Chen,Junjun Guo,Hongbin Wang,Yan Xiang,Yantuan Xian,Zhengtao Yu<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  Submitted to Pattern Recognition</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Graph representation learning (GRL) aims to encode structural and semantic dependencies of graph-structured data into low-dimensional embeddings. However, existing GRL methods often rely on surrogate contrastive objectives or mutual information maximization, which typically demand complex architectures, negative sampling strategies, and sensitive hyperparameter tuning. These design choices may induce over-smoothing, over-squashing, and training instability. In this work, we propose HyperGRL, a unified framework for hyperspherical graph representation learning via adaptive neighbor-mean alignment and sampling-free uniformity. HyperGRL embeds nodes on a unit hypersphere through two adversarially coupled objectives: neighbor-mean alignment and sampling-free uniformity. The alignment objective uses the mean representation of each node’s local neighborhood to construct semantically grounded, stable targets that capture shared structural and feature patterns. The uniformity objective formulates dispersion via an L2-based hyperspherical regularization, encouraging globally uniform embedding distributions while preserving discriminative information. To further stabilize training, we introduce an entropy-guided adaptive balancing mechanism that dynamically regulates the interplay between alignment and uniformity without requiring manual tuning. Extensive experiments on node classification, node clustering, and link prediction demonstrate that HyperGRL delivers superior representation quality and generalization across diverse graph structures, achieving average improvements of 1.49%, 0.86%, and 0.74% over the strongest existing methods, respectively. These findings highlight the effectiveness of geometrically grounded, sampling-free contrastive objectives for graph representation learning.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-41] RepetitionCurse: Measuring and Understanding Router Imbalance in Mixture-of-Experts <mark class="hl-label green">LLM</mark> s under DoS Stress</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23995">https://arxiv.org/abs/2512.23995</a><br>
<strong>作者</strong>: Ruixuan Huang,Qingyue Wang,Hantao Huang,Yudong Gao,Dong Chen,Shuai Wang,Wei Wang<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Mixture-of-Experts architectures have become the standard for scaling large language models due to their superior parameter efficiency. To accommodate the growing number of experts in practice, modern inference systems commonly adopt expert parallelism to distribute experts across devices. However, the absence of explicit load balancing constraints during inference allows adversarial inputs to trigger severe routing concentration. We demonstrate that out-of-distribution prompts can manipulate the routing strategy such that all tokens are consistently routed to the same set of top- k  experts, which creates computational bottlenecks on certain devices while forcing others to idle. This converts an efficiency mechanism into a denial-of-service attack vector, leading to violations of service-level agreements for time to first token. We propose RepetitionCurse, a low-cost black-box strategy to exploit this vulnerability. By identifying a universal flaw in MoE router behavior, RepetitionCurse constructs adversarial prompts using simple repetitive token patterns in a model-agnostic manner. On widely deployed MoE models like Mixtral-8x7B, our method increases end-to-end inference latency by 3.063x, degrading service availability significantly.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-42] Information-Theoretic Quality Metric of Low-Dimensional Embeddings</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23981">https://arxiv.org/abs/2512.23981</a><br>
<strong>作者</strong>: Sebastián Gutiérrez-Bernal(1),Hector Medel Cobaxin(1),Abiel Galindo González(1) ((1) Tecnológico de Monterrey, Monterrey, N.L., Mexico)<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  18 pages, 6 figures, submitted to Machine Learning (Springer Nature)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In this work we study the quality of low-dimensional embeddings from an explicitly information-theoretic perspective. We begin by noting that classical evaluation metrics such as stress, rank-based neighborhood criteria, or Local Procrustes quantify distortions in distances or in local geometries, but do not directly assess how much information is preserved when projecting high-dimensional data onto a lower-dimensional space. To address this limitation, we introduce the Entropy Rank Preservation Measure (ERPM), a local metric based on the Shannon entropy of the singular-value spectrum of neighborhood matrices and on the stable rank, which quantifies changes in uncertainty between the original representation and its reduced projection, providing neighborhood-level indicators and a global summary statistic. To validate the results of the metric, we compare its outcomes with the Mean Relative Rank Error (MRRE), which is distance-based, and with Local Procrustes, which is based on geometric properties, using a financial time series and a manifold commonly studied in the literature. We observe that distance-based criteria exhibit very low correlation with geometric and spectral measures, while ERPM and Local Procrustes show strong average correlation but display significant discrepancies in local regimes, leading to the conclusion that ERPM complements existing metrics by identifying neighborhoods with severe information loss, thereby enabling a more comprehensive assessment of embeddings, particularly in information-sensitive applications such as the construction of early-warning indicators.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-43] Assured Autonomy: How Operations Research Powers and Orchestrates Generative AI Systems</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23978">https://arxiv.org/abs/2512.23978</a><br>
<strong>作者</strong>: Tinglong Dai,David Simchi-Levi,Michelle Xiao Wu,Yao Xie<br>
<strong>类目</strong>: Machine Learning (cs.LG); Optimization and Control (math.OC); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:  Authors are listed alphabetically</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Generative artificial intelligence (GenAI) is shifting from conversational assistants toward agentic systems – autonomous decision-making systems that sense, decide, and act within operational workflows. This shift creates an autonomy paradox: as GenAI systems are granted greater operational autonomy, they should, by design, embody more formal structure, more explicit constraints, and stronger tail-risk discipline. We argue stochastic generative models can be fragile in operational domains unless paired with mechanisms that provide verifiable feasibility, robustness to distribution shift, and stress testing under high-consequence scenarios. To address this challenge, we develop a conceptual framework for assured autonomy grounded in operations research (OR), built on two complementary approaches. First, flow-based generative models frame generation as deterministic transport characterized by an ordinary differential equation, enabling auditability, constraint-aware generation, and connections to optimal transport, robust optimization, and sequential decision control. Second, operational safety is formulated through an adversarial robustness lens: decision rules are evaluated against worst-case perturbations within uncertainty or ambiguity sets, making unmodeled risks part of the design. This framework clarifies how increasing autonomy shifts OR’s role from solver to guardrail to system architect, with responsibility for control logic, incentive protocols, monitoring regimes, and safety boundaries. These elements define a research agenda for assured autonomy in safety-critical, reliability-sensitive operational domains.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-44] Exploring the Potential of Spiking Neural Networks in UWB Channel Estimation</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23975">https://arxiv.org/abs/2512.23975</a><br>
<strong>作者</strong>: Youdong Zhang,Xu He,Xiaolin Meng<br>
<strong>类目</strong>: Emerging Technologies (<a target="_blank" rel="noopener" href="http://cs.ET">cs.ET</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Although existing deep learning-based Ultra-Wide Band (UWB) channel estimation methods achieve high accuracy, their computational intensity clashes sharply with the resource constraints of low-cost edge devices. Motivated by this, this letter explores the potential of Spiking Neural Networks (SNNs) for this task and develops a fully unsupervised SNN solution. To enable a comprehensive performance analysis, we devise an extensive set of comparative strategies and evaluate them on a compelling public benchmark. Experimental results show that our unsupervised approach still attains 80% test accuracy, on par with several supervised deep learning-based strategies. Moreover, compared with complex deep learning methods, our SNN implementation is inherently suited to neuromorphic deployment and offers a drastic reduction in model complexity, bringing significant advantages for future neuromorphic practice.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-45] DivQAT: Enhancing Robustness of Quantized Convolutional Neural Networks against Model Extraction Attacks</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23948">https://arxiv.org/abs/2512.23948</a><br>
<strong>作者</strong>: Kacem Khaled,Felipe Gohring de Magalhães,Gabriela Nicolescu<br>
<strong>类目</strong>: Machine Learning (cs.LG); Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Convolutional Neural Networks (CNNs) and their quantized counterparts are vulnerable to extraction attacks, posing a significant threat of IP theft. Yet, the robustness of quantized models against these attacks is little studied compared to large models. Previous defenses propose to inject calculated noise into the prediction probabilities. However, these defenses are limited since they are not incorporated during the model design and are only added as an afterthought after training. Additionally, most defense techniques are computationally expensive and often have unrealistic assumptions about the victim model that are not feasible in edge device implementations and do not apply to quantized models. In this paper, we propose DivQAT, a novel algorithm to train quantized CNNs based on Quantization Aware Training (QAT) aiming to enhance their robustness against extraction attacks. To the best of our knowledge, our technique is the first to modify the quantization process to integrate a model extraction defense into the training process. Through empirical validation on benchmark vision datasets, we demonstrate the efficacy of our technique in defending against model extraction attacks without compromising model accuracy. Furthermore, combining our quantization technique with other defense mechanisms improves their effectiveness compared to traditional QAT.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-46] Improved Balanced Classification with Theoretically Grounded Loss Functions <mark class="hl-label red">NEURIPS2025</mark></p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23947">https://arxiv.org/abs/2512.23947</a><br>
<strong>作者</strong>: Corinna Cortes,Mehryar Mohri,Yutao Zhong<br>
<strong>类目</strong>: Machine Learning (cs.LG); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:  NeurIPS 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The balanced loss is a widely adopted objective for multi-class classification under class imbalance. By assigning equal importance to all classes, regardless of their frequency, it promotes fairness and ensures that minority classes are not overlooked. However, directly minimizing the balanced classification loss is typically intractable, which makes the design of effective surrogate losses a central question. This paper introduces and studies two advanced surrogate loss families: Generalized Logit-Adjusted (GLA) loss functions and Generalized Class-Aware weighted (GCA) losses. GLA losses generalize Logit-Adjusted losses, which shift logits based on class priors, to the broader general cross-entropy loss family. GCA loss functions extend the standard class-weighted losses, which scale losses inversely by class frequency, by incorporating class-dependent confidence margins and extending them to the general cross-entropy family. We present a comprehensive theoretical analysis of consistency for both loss families. We show that GLA losses are Bayes-consistent, but only  H -consistent for complete (i.e., unbounded) hypothesis sets. Moreover, their  H -consistency bounds depend inversely on the minimum class probability, scaling at least as  1/\mathsf p_\min . In contrast, GCA losses are  H -consistent for any hypothesis set that is bounded or complete, with  H -consistency bounds that scale more favorably as  1/\sqrt\mathsf p_\min , offering significantly stronger theoretical guarantees in imbalanced settings. We report the results of experiments demonstrating that, empirically, both the GCA losses with calibrated class-dependent confidence margins and GLA losses can greatly outperform straightforward class-weighted losses as well as the LA losses. GLA generally performs slightly better in common benchmarks, whereas GCA exhibits a slight edge in highly imbalanced settings.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-47] Statistical Guarantees in the Search for Less Discriminatory Algorithms</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23943">https://arxiv.org/abs/2512.23943</a><br>
<strong>作者</strong>: Chris Hays,Ben Laufer,Solon Barocas,Manish Raghavan<br>
<strong>类目</strong>: Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>); Machine Learning (cs.LG); Methodology (<a target="_blank" rel="noopener" href="http://stat.ME">stat.ME</a>)<br>
*<strong>备注</strong>:  37 pages, 10 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent scholarship has argued that firms building data-driven decision systems in high-stakes domains like employment, credit, and housing should search for “less discriminatory algorithms” (LDAs) (Black et al., 2024). That is, for a given decision problem, firms considering deploying a model should make a good-faith effort to find equally performant models with lower disparate impact across social groups. Evidence from the literature on model multiplicity shows that randomness in training pipelines can lead to multiple models with the same performance, but meaningful variations in disparate impact. This suggests that developers can find LDAs simply by randomly retraining models. Firms cannot continue retraining forever, though, which raises the question: What constitutes a good-faith effort? In this paper, we formalize LDA search via model multiplicity as an optimal stopping problem, where a model developer with limited information wants to produce strong evidence that they have sufficiently explored the space of models. Our primary contribution is an adaptive stopping algorithm that yields a high-probability upper bound on the gains achievable from a continued search, allowing the developer to certify (e.g., to a court) that their search was sufficient. We provide a framework under which developers can impose stronger assumptions about the distribution of models, yielding correspondingly stronger bounds. We validate the method on real-world credit, employment and housing datasets.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-48] Constraint Breeds Generalization: Temporal Dynamics as an Inductive Bias</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23916">https://arxiv.org/abs/2512.23916</a><br>
<strong>作者</strong>: Xia Chen<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  8 pages, 7 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Conventional deep learning prioritizes unconstrained optimization, yet biological systems operate under strict metabolic constraints. We propose that these physical constraints shape dynamics to function not as limitations, but as a temporal inductive bias that breeds generalization. Through a phase-space analysis of signal propagation, we reveal a fundamental asymmetry: expansive dynamics amplify noise, whereas proper dissipative dynamics compress phase space that aligns with the network’s spectral bias, compelling the abstraction of invariant features. This condition can be imposed externally via input encoding, or intrinsically through the network’s own temporal dynamics. Both pathways require architectures capable of temporal integration and proper constraints to decode induced invariants, whereas static architectures fail to capitalize on temporal structure. Through comprehensive evaluations across supervised classification, unsupervised reconstruction, and zero-shot reinforcement learning, we demonstrate that a critical “transition” regime maximizes generalization capability. These findings establish dynamical constraints as a distinct class of inductive bias, suggesting that robust AI development requires not only scaling and removing limitations, but computationally mastering the temporal characteristics that naturally promote generalization.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-49] Rethinking Dense Linear Transformations: Stagewise Pairwise Mixing (SPM) for Near-Linear Training in Neural Networks</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23905">https://arxiv.org/abs/2512.23905</a><br>
<strong>作者</strong>: Peter Farag<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  16 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Dense linear layers are a dominant source of computational and parametric cost in modern machine learning models, despite their quadratic complexity and often being misaligned with the compositional structure of learned representations. We introduce Stagewise Pairwise Mixers (SPM), a structured linear operator that replaces dense matrices with a composition of sparse pairwise-mixing stages. An SPM layer implements a global linear transformation in  O(nL)  time with  O(nL)  parameters, where  L  is typically constant or  log_2n , and admits exact closed-form forward and backward computations. SPM is designed as a drop-in replacement for dense linear layers in feedforward networks, recurrent architectures, attention mechanisms, etc. We derive complete forward and backward expressions for two parameterizations: an orthogonal norm-preserving rotation-based variant and a fully general  2 \times 2  mixing variant. Beyond computational savings, the stagewise structure of SPM induces an explicit compositional inductive bias that constrains model capacity and improves generalization when aligned with task structure. We present proof-of-concept experiments demonstrating substantial reductions in wall-clock cost and improved accuracy on structured learning problems, while retaining competitive performance on real-world benchmarks.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-50] Max-Entropy Reinforcement Learning with Flow Matching and A Case Study on LQR</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23870">https://arxiv.org/abs/2512.23870</a><br>
<strong>作者</strong>: Yuyang Zhang,Yang Hu,Bo Dai,Na Li<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Soft actor-critic (SAC) is a popular algorithm for max-entropy reinforcement learning. In practice, the energy-based policies in SAC are often approximated using simple policy classes for efficiency, sacrificing the expressiveness and robustness. In this paper, we propose a variant of the SAC algorithm that parameterizes the policy with flow-based models, leveraging their rich expressiveness. In the algorithm, we evaluate the flow-based policy utilizing the instantaneous change-of-variable technique and update the policy with an online variant of flow matching developed in this paper. This online variant, termed importance sampling flow matching (ISFM), enables policy update with only samples from a user-specified sampling distribution rather than the unknown target distribution. We develop a theoretical analysis of ISFM, characterizing how different choices of sampling distributions affect the learning efficiency. Finally, we conduct a case study of our algorithm on the max-entropy linear quadratic regulator problems, demonstrating that the proposed algorithm learns the optimal action distribution.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-51] Yggdrasil: Bridging Dynamic Speculation and Static Runtime for Latency-Optimal Tree-Based <mark class="hl-label green">LLM</mark>  Decoding <mark class="hl-label red">NEURIPS2025</mark></p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23858">https://arxiv.org/abs/2512.23858</a><br>
<strong>作者</strong>: Yue Guan,Changming Yu,Shihan Fang,Weiming Hu,Zaifeng Pan,Zheng Wang,Zihan Liu,Yangjie Zhou,Yufei Ding,Minyi Guo,Jingwen Leng<br>
<strong>类目</strong>: Machine Learning (cs.LG); Programming Languages (<a target="_blank" rel="noopener" href="http://cs.PL">cs.PL</a>)<br>
*<strong>备注</strong>:  Accepted by NeurIPS 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Speculative decoding improves LLM inference by generating and verifying multiple tokens in parallel, but existing systems suffer from suboptimal performance due to a mismatch between dynamic speculation and static runtime assumptions. We present Yggdrasil, a co-designed system that enables latency-optimal speculative decoding through context-aware tree drafting and compiler-friendly execution. Yggdrasil introduces an equal-growth tree structure for static graph compatibility, a latency-aware optimization objective for draft selection, and stage-based scheduling to reduce overhead. Yggdrasil supports unmodified LLMs and achieves up to  3.98\times  speedup over state-of-the-art baselines across multiple hardware setups.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-52] Flow Matching Neural Processes <mark class="hl-label red">NEURIPS2025</mark></p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23853">https://arxiv.org/abs/2512.23853</a><br>
<strong>作者</strong>: Hussen Abu Hamad,Dan Rosenbaum<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  NeurIPS 2025. For code, see <a target="_blank" rel="noopener" href="https://github.com/danrsm/flowNP">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Neural processes (NPs) are a class of models that learn stochastic processes directly from data and can be used for inference, sampling and conditional sampling. We introduce a new NP model based on flow matching, a generative modeling paradigm that has demonstrated strong performance on various data modalities. Following the NP training framework, the model provides amortized predictions of conditional distributions over any arbitrary points in the data. Compared to previous NP models, our model is simple to implement and can be used to sample from conditional distributions using an ODE solver, without requiring auxiliary conditioning methods. In addition, the model provides a controllable tradeoff between accuracy and running time via the number of steps in the ODE solver. We show that our model outperforms previous state-of-the-art neural process methods on various benchmarks including synthetic 1D Gaussian processes data, 2D images, and real-world weather data.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-53] Exploiting the Prior of Generative Time Series Imputation</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23832">https://arxiv.org/abs/2512.23832</a><br>
<strong>作者</strong>: YuYang Miao,Chang Li,Zehua Chen<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Time series imputation, i.e., filling the missing values of a time recording, finds various applications in electricity, finance, and weather modelling. Previous methods have introduced generative models such as diffusion probabilistic models and Schrodinger bridge models to conditionally generate the missing values from Gaussian noise or directly from linear interpolation results. However, as their prior is not informative to the ground-truth target, their generation process inevitably suffer increased burden and limited imputation accuracy. In this work, we present Bridge-TS, building a data-to-data generation process for generative time series imputation and exploiting the design of prior with two novel designs. Firstly, we propose expert prior, leveraging a pretrained transformer-based module as an expert to fill the missing values with a deterministic estimation, and then taking the results as the prior of ground truth target. Secondly, we explore compositional priors, utilizing several pretrained models to provide different estimation results, and then combining them in the data-to-data generation process to achieve a compositional priors-to-target imputation process. Experiments conducted on several benchmark datasets such as ETT, Exchange, and Weather show that Bridge-TS reaches a new record of imputation accuracy in terms of mean square error and mean absolute error, demonstrating the superiority of improving prior for generative time series imputation.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-54] Deep learning methods for inverse problems using connections between proximal operators and Hamilton-Jacobi equations</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23829">https://arxiv.org/abs/2512.23829</a><br>
<strong>作者</strong>: Oluwatosin Akande,Gabriel P. Langlois,Akwum Onwunta<br>
<strong>类目</strong>: Numerical Analysis (<a target="_blank" rel="noopener" href="http://math.NA">math.NA</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Inverse problems are important mathematical problems that seek to recover model parameters from noisy data. Since inverse problems are often ill-posed, they require regularization or incorporation of prior information about the underlying model or unknown variables. Proximal operators, ubiquitous in nonsmooth optimization, are central to this because they provide a flexible and convenient way to encode priors and build efficient iterative algorithms. They have also recently become key to modern machine learning methods, e.g., for plug-and-play methods for learned denoisers and deep neural architectures for learning priors of proximal operators. The latter was developed partly due to recent work characterizing proximal operators of nonconvex priors as subdifferential of convex potentials. In this work, we propose to leverage connections between proximal operators and Hamilton-Jacobi partial differential equations (HJ PDEs) to develop novel deep learning architectures for learning the prior. In contrast to other existing methods, we learn the prior directly without recourse to inverting the prior after training. We present several numerical results that demonstrate the efficiency of the proposed method in high dimensions.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-55] MS-SSM: A Multi-Scale State Space Model for Efficient Sequence Modeling</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23824">https://arxiv.org/abs/2512.23824</a><br>
<strong>作者</strong>: Mahdi Karami,Ali Behrouz,Peilin Zhong,Razvan Pascanu,Vahab Mirrokni<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  In Second Conference on Language Modeling (COLM) (2025)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:State-space models (SSMs) have recently attention as an efficient alternative to computationally expensive attention-based models for sequence modeling. They rely on linear recurrences to integrate information over time, enabling fast inference, parallelizable training, and control over recurrence stability. However, traditional SSMs often suffer from limited effective memory, requiring larger state sizes for improved recall. Moreover, existing SSMs struggle to capture multi-scale dependencies, which are essential for modeling complex structures in time series, images, and natural language. This paper introduces a multi-scale SSM framework that addresses these limitations by representing sequence dynamics across multiple resolution and processing each resolution with specialized state-space dynamics. By capturing both fine-grained, high-frequency patterns and coarse, global trends, MS-SSM enhances memory efficiency and long-range modeling. We further introduce an input-dependent scale-mixer, enabling dynamic information fusion across resolutions. The proposed approach significantly improves sequence modeling, particularly in long-range and hierarchical tasks, while maintaining computational efficiency. Extensive experiments on benchmarks, including Long Range Arena, hierarchical reasoning, time series classification, and image recognition, demonstrate that MS-SSM consistently outperforms prior SSM-based models, highlighting the benefits of multi-resolution processing in state-space architectures.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-56] abMixNN: A Unified Deep Learning Framework for Structural Mixed Effects Modeling on Tabular Data</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23787">https://arxiv.org/abs/2512.23787</a><br>
<strong>作者</strong>: Deniz Akdemir<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computation (<a target="_blank" rel="noopener" href="http://stat.CO">stat.CO</a>); Methodology (<a target="_blank" rel="noopener" href="http://stat.ME">stat.ME</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present TabMixNN, a flexible PyTorch-based deep learning framework that synthesizes classical mixed-effects modeling with modern neural network architectures for tabular data analysis. TabMixNN addresses the growing need for methods that can handle hierarchical data structures while supporting diverse outcome types including regression, classification, and multitask learning. The framework implements a modular three-stage architecture: (1) a mixed-effects encoder with variational random effects and flexible covariance structures, (2) backbone architectures including Generalized Structural Equation Models (GSEM) and spatial-temporal manifold networks, and (3) outcome-specific prediction heads supporting multiple outcome families. Key innovations include an R-style formula interface for accessibility, support for directed acyclic graph (DAG) constraints for causal structure learning, Stochastic Partial Differential Equation (SPDE) kernels for spatial modeling, and comprehensive interpretability tools including SHAP values and variance decomposition. We demonstrate the framework’s flexibility through applications to longitudinal data analysis, genomic prediction, and spatial-temporal modeling. TabMixNN provides a unified interface for researchers to leverage deep learning while maintaining the interpretability and theoretical grounding of classical mixed-effects models.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-57] Exploring Cumulative Effects in Survival Data Using Deep Learning Networks</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23764">https://arxiv.org/abs/2512.23764</a><br>
<strong>作者</strong>: Kang-Chung Yang,Shinsheng Yuan<br>
<strong>类目</strong>: Machine Learning (cs.LG); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In epidemiological research, modeling the cumulative effects of time-dependent exposures on survival outcomes presents a challenge due to their intricate temporal dynamics. Conventional spline-based statistical methods, though effective, require repeated data transformation for each spline parameter tuning, with survival analysis computations relying on the entire dataset, posing difficulties for large datasets. Meanwhile, existing neural network-based survival analysis methods focus on accuracy but often overlook the interpretability of cumulative exposure patterns. To bridge this gap, we introduce CENNSurv, a novel deep learning approach that captures dynamic risk relationships from time-dependent data. Evaluated on two diverse real-world datasets, CENNSurv revealed a multi-year lagged association between chronic environmental exposure and a critical survival outcome, as well as a critical short-term behavioral shift prior to subscription lapse. This demonstrates CENNSurv’s ability to model complex temporal patterns with improved scalability. CENNSurv provides researchers studying cumulative effects a practical tool with interpretable insights.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-58] Neural Optimal Design of Experiment for Inverse Problems</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23763">https://arxiv.org/abs/2512.23763</a><br>
<strong>作者</strong>: John E. Darges,Babak Maboudi Afkham,Matthias Chung<br>
<strong>类目</strong>: Machine Learning (cs.LG); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce Neural Optimal Design of Experiments, a learning-based framework for optimal experimental design in inverse problems that avoids classical bilevel optimization and indirect sparsity regularization. NODE jointly trains a neural reconstruction model and a fixed-budget set of continuous design variables representing sensor locations, sampling times, or measurement angles, within a single optimization loop. By optimizing measurement locations directly rather than weighting a dense grid of candidates, the proposed approach enforces sparsity by design, eliminates the need for l1 tuning, and substantially reduces computational complexity. We validate NODE on an analytically tractable exponential growth benchmark, on MNIST image sampling, and illustrate its effectiveness on a real world sparse view X ray CT example. In all cases, NODE outperforms baseline approaches, demonstrating improved reconstruction accuracy and task-specific performance.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-59] Learning Coupled System Dynamics under Incomplete Physical Constraints and Missing Data</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23761">https://arxiv.org/abs/2512.23761</a><br>
<strong>作者</strong>: Esha Saha,Hao Wang<br>
<strong>类目</strong>: Machine Learning (cs.LG); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:  38 pages, 15 Figures, 15 Tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Advances in data acquisition and computational methods have accelerated the use of differential equation based modelling for complex systems. Such systems are often described by coupled (or more) variables, yet governing equation is typically available for one variable, while the remaining variable can be accessed only through data. This mismatch between known physics and observed data poses a fundamental challenge for existing physics-informed machine learning approaches, which generally assume either complete knowledge of the governing equations or full data availability across all variables. In this paper, we introduce MUSIC (Multitask Learning Under Sparse and Incomplete Constraints), a sparsity induced multitask neural network framework that integrates partial physical constraints with data-driven learning to recover full-dimensional solutions of coupled systems when physics-constrained and data-informed variables are mutually exclusive. MUSIC employs mesh-free (random) sampling of training data and sparsity regularization, yielding highly compressed models with improved training and evaluation efficiency. We demonstrate that MUSIC accurately learns solutions (shock wave solutions, discontinuous solutions, pattern formation solutions) to complex coupled systems under data-scarce and noisy conditions, consistently outperforming non-sparse formulations. These results highlight MUSIC as a flexible and effective approach for modeling partially observed systems with incomplete physical knowledge.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-60] A Review of Diffusion-based Simulation-Based Inference: Foundations and Applications in Non-Ideal Data Scenarios</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23748">https://arxiv.org/abs/2512.23748</a><br>
<strong>作者</strong>: Haley Rosso,Talea Mayo<br>
<strong>类目</strong>: Machine Learning (cs.LG); Probability (<a target="_blank" rel="noopener" href="http://math.PR">math.PR</a>); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:For complex simulation problems, inferring parameters of scientific interest often precludes the use of classical likelihood-based techniques due to intractable likelihood functions. Simulation-based inference (SBI) methods forego the need for explicit likelihoods by directly utilizing samples from the simulator to learn posterior distributions over parameters  \mathbf\theta  given observed data  \mathbfx_\texto . Recent work has brought attention to diffusion models – a type of generative model rooted in score matching and reverse-time stochastic dynamics – as a flexible framework SBI tasks. This article reviews diffusion-based SBI from first principles to applications in practice. We first recall the mathematical foundations of diffusion modeling (forward noising, reverse-time SDE/ODE, probability flow, and denoising score matching) and explain how conditional scores enable likelihood-free posterior sampling. We then examine where diffusion models address pain points of normalizing flows in neural posterior/likelihood estimation and where they introduce new trade-offs (e.g., iterative sampling costs). The key theme of this review is robustness of diffusion-based SBI in non-ideal conditions common to scientific data: misspecification (mismatch between simulated training data and reality), unstructured or infinite-dimensional observations, and missingness. We synthesize methods spanning foundations drawing from Schrodinger-bridge formulations, conditional and sequential posterior samplers, amortized architectures for unstructured data, and inference-time prior adaptation. Throughout, we adopt consistent notation and emphasize conditions and caveats required for accurate posteriors. The review closes with a discussion of open problems with an eye toward applications of uncertainty quantification for probabilistic geophysical models that may benefit from diffusion-based SBI.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-61] A Comprehensive Study of Deep Learning Model Fixing Approaches</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23745">https://arxiv.org/abs/2512.23745</a><br>
<strong>作者</strong>: Hanmo You,Zan Wang,Zishuo Dong,Luanqi Mo,Jianjun Zhao,Junjie Chen<br>
<strong>类目</strong>: Machine Learning (cs.LG); Software Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Deep Learning (DL) has been widely adopted in diverse industrial domains, including autonomous driving, intelligent healthcare, and aided programming. Like traditional software, DL systems are also prone to faults, whose malfunctioning may expose users to significant risks. Consequently, numerous approaches have been proposed to address these issues. In this paper, we conduct a large-scale empirical study on 16 state-of-the-art DL model fixing approaches, spanning model-level, layer-level, and neuron-level categories, to comprehensively evaluate their performance. We assess not only their fixing effectiveness (their primary purpose) but also their impact on other critical properties, such as robustness, fairness, and backward compatibility. To ensure comprehensive and fair evaluation, we employ a diverse set of datasets, model architectures, and application domains within a uniform experimental setup for experimentation. We summarize several key findings with implications for both industry and academia. For example, model-level approaches demonstrate superior fixing effectiveness compared to others. No single approach can achieve the best fixing performance while improving accuracy and maintaining all other properties. Thus, academia should prioritize research on mitigating these side effects. These insights highlight promising directions for future exploration in this field.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-62] Governing Cloud Data Pipelines with <mark class="hl-label green">Agent</mark> ic AI <mark class="hl-label red">WWW</mark></p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23737">https://arxiv.org/abs/2512.23737</a><br>
<strong>作者</strong>: Aswathnarayan Muthukrishnan Kirubakaran,Adithya Parthasarathy,Nitin Saksena,Ram Sekhar Bodala,Akshay Deshpande,Suhas Malempati,Shiva Carimireddy,Abhirup Mazumder<br>
<strong>类目</strong>: Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:   <a target="_blank" rel="noopener" href="https://www.ijcstjournal.org/volume-13/issue-6/IJCST-V13I6P44.pdf">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Cloud data pipelines increasingly operate under dynamic workloads, evolving schemas, cost constraints, and strict governance requirements. Despite advances in cloud-native orchestration frameworks, most production pipelines rely on static configurations and reactive operational practices, resulting in prolonged recovery times, inefficient resource utilization, and high manual overhead. This paper presents Agentic Cloud Data Engineering, a policy-aware control architecture that integrates bounded AI agents into the governance and control plane of cloud data pipelines. In Agentic Cloud Data Engineering platform, specialized agents analyze pipeline telemetry and metadata, reason over declarative cost and compliance policies, and propose constrained operational actions such as adaptive resource reconfiguration, schema reconciliation, and automated failure recovery. All agent actions are validated against governance policies to ensure predictable and auditable behavior. We evaluate Agentic Cloud Data Engineering platform using representative batch and streaming analytics workloads constructed from public enterprise-style datasets. Experimental results show that Agentic Cloud Data Engineering platform reduces mean pipeline recovery time by up to 45%, lowers operational cost by approximately 25%, and decreases manual intervention events by over 70% compared to static orchestration, while maintaining data freshness and policy compliance. These results demonstrate that policy-bounded agentic control provides an effective and practical approach for governing cloud data pipelines in enterprise environments.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-63] Network Traffic Analysis with Process Mining: The UPSIDE Case Study</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23718">https://arxiv.org/abs/2512.23718</a><br>
<strong>作者</strong>: Francesco Vitale,Paolo Palmiero,Massimiliano Rak,Nicola Mazzocca<br>
<strong>类目</strong>: Machine Learning (cs.LG); Networking and Internet Architecture (<a target="_blank" rel="noopener" href="http://cs.NI">cs.NI</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Online gaming is a popular activity involving the adoption of complex systems and network infrastructures. The relevance of gaming, which generates large amounts of market revenue, drove research in modeling network devices’ behavior to evaluate bandwidth consumption, predict and sustain high loads, and detect malicious activity. In this context, process mining appears promising due to its ability to combine data-driven analyses with model-based insights. In this paper, we propose a process mining-based method that analyzes gaming network traffic, allowing: unsupervised characterization of different states from gaming network data; encoding such states through process mining into interpretable Petri nets; and classification of gaming network traffic data to identify different video games being played. We apply the method to the UPSIDE case study, involving gaming network data of several devices interacting with two video games: Clash Royale and Rocket League. Results demonstrate that the gaming network behavior can be effectively and interpretably modeled through states represented as Petri nets with sufficient coherence (94.02% inter-device similarity) and specificity (174.99% inter-state separation) while maintaining a good classification accuracy of the two different video games (73.84% AUC).</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-64] Basic Inequalities for First-Order Optimization with Applications to Statistical Risk Analysis</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24999">https://arxiv.org/abs/2512.24999</a><br>
<strong>作者</strong>: Seunghoon Paik,Kangjie Zhou,Matus Telgarsky,Ryan J. Tibshirani<br>
<strong>类目</strong>: atistics Theory (<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>); Machine Learning (cs.LG); Numerical Analysis (<a target="_blank" rel="noopener" href="http://math.NA">math.NA</a>); Optimization and Control (math.OC); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:  47 pages, 3 figures (7 subfigures)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce \textitbasic inequalities for first-order iterative optimization algorithms, forming a simple and versatile framework that connects implicit and explicit regularization. While related inequalities appear in the literature, we isolate and highlight a specific form and develop it as a well-rounded tool for statistical analysis. Let  f  denote the objective function to be optimized. Given a first-order iterative algorithm initialized at  \theta_0  with current iterate  \theta_T , the basic inequality upper bounds  f(\theta_T)-f(z)  for any reference point  z  in terms of the accumulated step sizes and the distances between  \theta_0 ,  \theta_T , and  z . The bound translates the number of iterations into an effective regularization coefficient in the loss function. We demonstrate this framework through analyses of training dynamics and prediction risk bounds. In addition to revisiting and refining known results on gradient descent, we provide new results for mirror descent with Bregman divergence projection, for generalized linear models trained by gradient descent and exponentiated gradient descent, and for randomized predictors. We illustrate and supplement these theoretical findings with experiments on generalized linear models.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-65] Are First-Order Diffusion Samplers Really Slower? A Fast Forward-Value Approach</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24927">https://arxiv.org/abs/2512.24927</a><br>
<strong>作者</strong>: Yuchen Jiao,Na Li,Changxiao Cai,Gen Li<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG); Statistics Theory (<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Higher-order ODE solvers have become a standard tool for accelerating diffusion probabilistic model (DPM) sampling, motivating the widespread view that first-order methods are inherently slower and that increasing discretization order is the primary path to faster generation. This paper challenges this belief and revisits acceleration from a complementary angle: beyond solver order, the placement of DPM evaluations along the reverse-time dynamics can substantially affect sampling accuracy in the low-neural function evaluation (NFE) regime. We propose a novel training-free, first-order sampler whose leading discretization error has the opposite sign to that of DDIM. Algorithmically, the method approximates the forward-value evaluation via a cheap one-step lookahead predictor. We provide theoretical guarantees showing that the resulting sampler provably approximates the ideal forward-value trajectory while retaining first-order convergence. Empirically, across standard image generation benchmarks (CIFAR-10, ImageNet, FFHQ, and LSUN), the proposed sampler consistently improves sample quality under the same NFE budget and can be competitive with, and sometimes outperform, state-of-the-art higher-order samplers. Overall, the results suggest that the placement of DPM evaluations provides an additional and largely independent design angle for accelerating diffusion sampling.         Subjects:  Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG); Statistics Theory (<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>)  Cite as: arXiv:2512.24927 [<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>]    (or  arXiv:2512.24927v1 [<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24927">https://doi.org/10.48550/arXiv.2512.24927</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-66] Learning Temporally Consistent Turbulence Between Sparse Snapshots via Diffusion Models</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24813">https://arxiv.org/abs/2512.24813</a><br>
<strong>作者</strong>: Mohammed Sardar,Małgorzata J. Zimoń,Samuel Draycott,Alistair Revell,Alex Skillen<br>
<strong>类目</strong>: Fluid Dynamics (physics.flu-dyn); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  15 pages, 10 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We investigate the statistical accuracy of temporally interpolated spatiotemporal flow sequences between sparse, decorrelated snapshots of turbulent flow fields using conditional Denoising Diffusion Probabilistic Models (DDPMs). The developed method is presented as a proof-of-concept generative surrogate for reconstructing coherent turbulent dynamics between sparse snapshots, demonstrated on a 2D Kolmogorov Flow, and a 3D Kelvin-Helmholtz Instability (KHI). We analyse the generated flow sequences through the lens of statistical turbulence, examining the time-averaged turbulent kinetic energy spectra over generated sequences, and temporal decay of turbulent structures. For the non-stationary Kelvin-Helmholtz Instability, we assess the ability of the proposed method to capture evolving flow statistics across the most strongly time-varying flow regime. We additionally examine instantaneous fields and physically motivated metrics at key stages of the KHI flow evolution.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-67] Limits of quantum generative models with classical sampling hardness</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24801">https://arxiv.org/abs/2512.24801</a><br>
<strong>作者</strong>: Sabrina Herbst,Ivona Brandić,Adrián Pérez-Salinas<br>
<strong>类目</strong>: Quantum Physics (quant-ph); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  29 pages, 9 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Sampling tasks have been successful in establishing quantum advantages both in theory and experiments. This has fueled the use of quantum computers for generative modeling to create samples following the probability distribution underlying a given dataset. In particular, the potential to build generative models on classically hard distributions would immediately preclude classical simulability, due to theoretical separations. In this work, we study quantum generative models from the perspective of output distributions, showing that models that anticoncentrate are not trainable on average, including those exhibiting quantum advantage. In contrast, models outputting data from sparse distributions can be trained. We consider special cases to enhance trainability, and observe that this opens the path for classical algorithms for surrogate sampling. This observed trade-off is linked to verification of quantum processes. We conclude that quantum advantage can still be found in generative models, although its source must be distinct from anticoncentration.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-68] Sparse Offline Reinforcement Learning with Corruption Robustness</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24768">https://arxiv.org/abs/2512.24768</a><br>
<strong>作者</strong>: Nam Phuong Tran,Andi Nika,Goran Radanovic,Long Tran-Thanh,Debmalya Mandal<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We investigate robustness to strong data corruption in offline sparse reinforcement learning (RL). In our setting, an adversary may arbitrarily perturb a fraction of the collected trajectories from a high-dimensional but sparse Markov decision process, and our goal is to estimate a near optimal policy. The main challenge is that, in the high-dimensional regime where the number of samples  N  is smaller than the feature dimension  d , exploiting sparsity is essential for obtaining non-vacuous guarantees but has not been systematically studied in offline RL. We analyse the problem under uniform coverage and sparse single-concentrability assumptions. While Least Square Value Iteration (LSVI), a standard approach for robust offline RL, performs well under uniform coverage, we show that integrating sparsity into LSVI is unnatural, and its analysis may break down due to overly pessimistic bonuses. To overcome this, we propose actor-critic methods with sparse robust estimator oracles, which avoid the use of pointwise pessimistic bonuses and provide the first non-vacuous guarantees for sparse offline RL under single-policy concentrability coverage. Moreover, we extend our results to the contaminated setting and show that our algorithm remains robust under strong contamination. Our results provide the first non-vacuous guarantees in high-dimensional sparse MDPs with single-policy concentrability coverage and corruption, showing that learning a near-optimal policy remains possible in regimes where traditional robust offline RL techniques may fail.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-69] Fairness-Aware Insurance Pricing: A Multi-Objective Optimization Approach</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24747">https://arxiv.org/abs/2512.24747</a><br>
<strong>作者</strong>: Tim J. Boonen,Xinyue Fan,Zixiao Quan<br>
<strong>类目</strong>: Risk Management (q-fin.RM); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Machine learning improves predictive accuracy in insurance pricing but exacerbates trade-offs between competing fairness criteria across different discrimination measures, challenging regulators and insurers to reconcile profitability with equitable outcomes. While existing fairness-aware models offer partial solutions under GLM and XGBoost estimation methods, they remain constrained by single-objective optimization, failing to holistically navigate a conflicting landscape of accuracy, group fairness, individual fairness, and counterfactual fairness. To address this, we propose a novel multi-objective optimization framework that jointly optimizes all four criteria via the Non-dominated Sorting Genetic Algorithm II (NSGA-II), generating a diverse Pareto front of trade-off solutions. We use a specific selection mechanism to extract a premium on this front. Our results show that XGBoost outperforms GLM in accuracy but amplifies fairness disparities; the Orthogonal model excels in group fairness, while Synthetic Control leads in individual and counterfactual fairness. Our method consistently achieves a balanced compromise, outperforming single-model approaches.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-70] A New Decomposition Paradigm for Graph-structured Nonlinear Programs via Message Passing</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24676">https://arxiv.org/abs/2512.24676</a><br>
<strong>作者</strong>: Kuangyu Ding,Marie Maros,Gesualdo Scutari<br>
<strong>类目</strong>: Optimization and Control (math.OC); Information Theory (<a target="_blank" rel="noopener" href="http://cs.IT">cs.IT</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  55 pages, 14 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We study finite-sum nonlinear programs whose decision variables interact locally according to a graph or hypergraph. We propose MP-Jacobi (Message Passing-Jacobi), a graph-compliant decentralized framework that couples min-sum message passing with Jacobi block updates. The (hyper)graph is partitioned into tree clusters. At each iteration, agents update in parallel by solving a cluster subproblem whose objective decomposes into (i) an intra-cluster term evaluated by a single min-sum sweep on the cluster tree (cost-to-go messages) and (ii) inter-cluster couplings handled via a Jacobi correction using neighbors’ latest iterates. This design uses only single-hop communication and yields a convergent message-passing method on loopy graphs. For strongly convex objectives we establish global linear convergence and explicit rates that quantify how curvature, coupling strength, and the chosen partition affect scalability and provide guidance for clustering. To mitigate the computation and communication cost of exact message updates, we develop graph-compliant surrogates that preserve convergence while reducing per-iteration complexity. We further extend MP-Jacobi to hypergraphs; in heavily overlapping regimes, a surrogate-based hyperedge-splitting scheme restores finite-time intra-cluster message updates and maintains convergence. Experiments validate the theory and show consistent improvements over decentralized gradient baselines.          Comments: 55 pages, 14 figures   Subjects:  Optimization and Control (math.OC); Information Theory (<a target="_blank" rel="noopener" href="http://cs.IT">cs.IT</a>); Machine Learning (cs.LG)  Cite as: arXiv:2512.24676 [math.OC]    (or  arXiv:2512.24676v1 [math.OC] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24676">https://doi.org/10.48550/arXiv.2512.24676</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-71] Soliton profiles: Classical Numerical Schemes vs. Neural Network - Based Solvers</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24634">https://arxiv.org/abs/2512.24634</a><br>
<strong>作者</strong>: Chandler Haight,Svetlana Roudenko,Zhongming Wang<br>
<strong>类目</strong>: Pattern Formation and Solitons (<a target="_blank" rel="noopener" href="http://nlin.PS">nlin.PS</a>); Machine Learning (cs.LG); Analysis of PDEs (math.AP); Numerical Analysis (<a target="_blank" rel="noopener" href="http://math.NA">math.NA</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present a comparative study of classical numerical solvers, such as Petviashvili’s method or finite difference with Newton iterations, and neural network-based methods for computing ground states or profiles of solitary-wave solutions to the one-dimensional dispersive PDEs that include the nonlinear Schrödinger, the nonlinear Klein-Gordon and the generalized KdV equations. We confirm that classical approaches retain high-order accuracy and strong computational efficiency for single-instance problems in the one-dimensional setting. Physics-informed neural networks (PINNs) are also able to reproduce qualitative solutions but are generally less accurate and less efficient in low dimensions than classical solvers due to expensive training and slow convergence. We also investigate the operator-learning methods, which, although computationally intensive during training, can be reused across many parameter instances, providing rapid inference after pretraining, making them attractive for applications involving repeated simulations or real-time predictions. For single-instance computations, however, the accuracy of operator-learning methods remains lower than that of classical methods or PINNs, in general.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-72] MultiRisk: Multiple Risk Control via Iterative Score Thresholding</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24587">https://arxiv.org/abs/2512.24587</a><br>
<strong>作者</strong>: Sunay Joshi,Yan Sun,Hamed Hassani,Edgar Dobriban<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:As generative AI systems are increasingly deployed in real-world applications, regulating multiple dimensions of model behavior has become essential. We focus on test-time filtering: a lightweight mechanism for behavior control that compares performance scores to estimated thresholds, and modifies outputs when these bounds are violated. We formalize the problem of enforcing multiple risk constraints with user-defined priorities, and introduce two efficient dynamic programming algorithms that leverage this sequential structure. The first, MULTIRISK-BASE, provides a direct finite-sample procedure for selecting thresholds, while the second, MULTIRISK, leverages data exchangeability to guarantee simultaneous control of the risks. Under mild assumptions, we show that MULTIRISK achieves nearly tight control of all constraint risks. The analysis requires an intricate iterative argument, upper bounding the risks by introducing several forms of intermediate symmetrized risk functions, and carefully lower bounding the risks by recursively counting jumps in symmetrized risk functions between appropriate risk levels. We evaluate our framework on a three-constraint Large Language Model alignment task using the PKU-SafeRLHF dataset, where the goal is to maximize helpfulness subject to multiple safety constraints, and where scores are generated by a Large Language Model judge and a perplexity filter. Our experimental results show that our algorithm can control each individual risk at close to the target level.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-73] Robust Bayesian Dynamic Programming for On-policy Risk-sensitive Reinforcement Learning</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24580">https://arxiv.org/abs/2512.24580</a><br>
<strong>作者</strong>: Shanyu Han,Yangbo He,Yang Liu<br>
<strong>类目</strong>: Risk Management (q-fin.RM); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  63 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We propose a novel framework for risk-sensitive reinforcement learning (RSRL) that incorporates robustness against transition uncertainty. We define two distinct yet coupled risk measures: an inner risk measure addressing state and cost randomness and an outer risk measure capturing transition dynamics uncertainty. Our framework unifies and generalizes most existing RL frameworks by permitting general coherent risk measures for both inner and outer risk measures. Within this framework, we construct a risk-sensitive robust Markov decision process (RSRMDP), derive its Bellman equation, and provide error analysis under a given posterior distribution. We further develop a Bayesian Dynamic Programming (Bayesian DP) algorithm that alternates between posterior updates and value iteration. The approach employs an estimator for the risk-based Bellman operator that combines Monte Carlo sampling with convex optimization, for which we prove strong consistency guarantees. Furthermore, we demonstrate that the algorithm converges to a near-optimal policy in the training environment and analyze both the sample complexity and the computational complexity under the Dirichlet posterior and CVaR. Finally, we validate our approach through two numerical experiments. The results exhibit excellent convergence properties while providing intuitive demonstrations of its advantages in both risk-sensitivity and robustness. Empirically, we further demonstrate the advantages of the proposed algorithm through an application on option hedging.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-74] Probabilistic Computers for Neural Quantum States</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24558">https://arxiv.org/abs/2512.24558</a><br>
<strong>作者</strong>: Shuvro Chowdhury,Jasper Pieterse,Navid Anjum Aadit,Johan H. Mentink,Kerem Y. Camsari<br>
<strong>类目</strong>: Quantum Physics (quant-ph); Disordered Systems and Neural Networks (cond-mat.dis-nn); Emerging Technologies (<a target="_blank" rel="noopener" href="http://cs.ET">cs.ET</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Neural quantum states efficiently represent many-body wavefunctions with neural networks, but the cost of Monte Carlo sampling limits their scaling to large system sizes. Here we address this challenge by combining sparse Boltzmann machine architectures with probabilistic computing hardware. We implement a probabilistic computer on field programmable gate arrays (FPGAs) and use it as a fast sampler for energy-based neural quantum states. For the two-dimensional transverse-field Ising model at criticality, we obtain accurate ground-state energies for lattices up to 80  \times  80 (6400 spins) using a custom multi-FPGA cluster. Furthermore, we introduce a dual-sampling algorithm to train deep Boltzmann machines, replacing intractable marginalization with conditional sampling over auxiliary layers. This enables the training of sparse deep models and improves parameter efficiency relative to shallow networks. Using this algorithm, we train deep Boltzmann machines for a system with 35  \times  35 (1225 spins). Together, these results demonstrate that probabilistic hardware can overcome the sampling bottleneck in variational simulation of quantum many-body systems, opening a path to larger system sizes and deeper variational architectures.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-75] Improving the stability of the covariance-controlled adaptive Langevin thermostat for large-scale Bayesian sampling</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24515">https://arxiv.org/abs/2512.24515</a><br>
<strong>作者</strong>: Jiani Wei,Xiaocheng Shang<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG); Computation (<a target="_blank" rel="noopener" href="http://stat.CO">stat.CO</a>); Methodology (<a target="_blank" rel="noopener" href="http://stat.ME">stat.ME</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Stochastic gradient Langevin dynamics and its variants approximate the likelihood of an entire dataset, via random (and typically much smaller) subsets, in the setting of Bayesian sampling. Due to the (often substantial) improvement of the computational efficiency, they have been widely used in large-scale machine learning applications. It has been demonstrated that the so-called covariance-controlled adaptive Langevin (CCAdL) thermostat, which incorporates an additional term involving the covariance matrix of the noisy force, outperforms popular alternative methods. A moving average is used in CCAdL to estimate the covariance matrix of the noisy force, in which case the covariance matrix will converge to a constant matrix in long-time limit. Moreover, it appears in our numerical experiments that the use of a moving average could reduce the stability of the numerical integrators, thereby limiting the largest usable stepsize. In this article, we propose a modified CCAdL (i.e., mCCAdL) thermostat that uses the scaling part of the scaling and squaring method together with a truncated Taylor series approximation to the exponential to numerically approximate the exact solution to the subsystem involving the additional term proposed in CCAdL. We also propose a symmetric splitting method for mCCAdL, instead of an Euler-type discretisation used in the original CCAdL thermostat. We demonstrate in our numerical experiments that the newly proposed mCCAdL thermostat achieves a substantial improvement in the numerical stability over the original CCAdL thermostat, while significantly outperforming popular alternative stochastic gradient methods in terms of the numerical accuracy for large-scale machine learning applications.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-76] owards mechanistic understanding in a data-driven weather model: internal activations reveal interpretable physical features</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24440">https://arxiv.org/abs/2512.24440</a><br>
<strong>作者</strong>: Theodore MacMillan,Nicholas T. Ouellette<br>
<strong>类目</strong>: Atmospheric and Oceanic Physics (physics.ao-ph); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)<br>
*<strong>备注</strong>:  18 pages, 13 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large data-driven physics models like DeepMind’s weather model GraphCast have empirically succeeded in parameterizing time operators for complex dynamical systems with an accuracy reaching or in some cases exceeding that of traditional physics-based solvers. Unfortunately, how these data-driven models perform computations is largely unknown and whether their internal representations are interpretable or physically consistent is an open question. Here, we adapt tools from interpretability research in Large Language Models to analyze intermediate computational layers in GraphCast, leveraging sparse autoencoders to discover interpretable features in the neuron space of the model. We uncover distinct features on a wide range of length and time scales that correspond to tropical cyclones, atmospheric rivers, diurnal and seasonal behavior, large-scale precipitation patterns, specific geographical coding, and sea-ice extent, among others. We further demonstrate how the precise abstraction of these features can be probed via interventions on the prediction steps of the model. As a case study, we sparsely modify a feature corresponding to tropical cyclones in GraphCast and observe interpretable and physically consistent modifications to evolving hurricanes. Such methods offer a window into the black-box behavior of data-driven physics models and are a step towards realizing their potential as trustworthy predictors and scientifically valuable tools for discovery.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-77] Virasoro Symmetry in Neural Network Field Theories</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24420">https://arxiv.org/abs/2512.24420</a><br>
<strong>作者</strong>: Brandon Robinson<br>
<strong>类目</strong>: High Energy Physics - Theory (hep-th); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  11 pages, 2 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Neural Network Field Theories (NN-FTs) can realize global conformal symmetries via embedding space architectures. These models describe Generalized Free Fields (GFFs) in the infinite width limit. However, they typically lack a local stress-energy tensor satisfying conformal Ward identities. This presents an obstruction to realizing infinite-dimensional, local conformal symmetry typifying 2d Conformal Field Theories (CFTs). We present the first construction of an NN-FT that encodes the full Virasoro symmetry of a 2d CFT. We formulate a neural free boson theory with a local stress tensor  T(z)  by properly choosing the architecture and prior distribution of network parameters. We verify the analytical results through numerical simulation; computing the central charge and the scaling dimensions of vertex operators. We then construct an NN realization of a Majorana Fermion and an  \mathcalN=(1,1)  scalar multiplet, which then enables an extension of the formalism to include super-Virasoro symmetry. Finally, we extend the framework by constructing boundary NN-FTs that preserve (super-)conformal symmetry via the method of images.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-78] Implicit score matching meets denoising score matching: improved rates of convergence and log-density Hessian estimation</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24378">https://arxiv.org/abs/2512.24378</a><br>
<strong>作者</strong>: Konstantin Yakovlev,Anna Markovich,Nikita Puchkin<br>
<strong>类目</strong>: atistics Theory (<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>); Machine Learning (cs.LG); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:  52 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We study the problem of estimating the score function using both implicit score matching and denoising score matching. Assuming that the data distribution exhibiting a low-dimensional structure, we prove that implicit score matching is able not only to adapt to the intrinsic dimension, but also to achieve the same rates of convergence as denoising score matching in terms of the sample size. Furthermore, we demonstrate that both methods allow us to estimate log-density Hessians without the curse of dimensionality by simple differentiation. This justifies convergence of ODE-based samplers for generative diffusion models. Our approach is based on Gagliardo-Nirenberg-type inequalities relating weighted  L^2 -norms of smooth functions and their derivatives.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-79] Deep Learning in Geotechnical Engineering: A Critical Assessment of PINNs and Operator Learning</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24365">https://arxiv.org/abs/2512.24365</a><br>
<strong>作者</strong>: Krishna Kumar<br>
<strong>类目</strong>: Geophysics (physics.geo-ph); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Deep learning methods – physics-informed neural networks (PINNs), deep operator networks (DeepONet), and graph network simulators (GNS) – are increasingly proposed for geotechnical problems. This paper tests these methods against traditional solvers on canonical problems: wave propagation and beam-foundation interaction. PINNs run 90,000 times slower than finite difference with larger errors. DeepONet requires thousands of training simulations and breaks even only after millions of evaluations. Multi-layer perceptrons fail catastrophically when extrapolating beyond training data – the common case in geotechnical prediction. GNS shows promise for geometry-agnostic simulation but faces scaling limits and cannot capture path-dependent soil behavior. For inverse problems, automatic differentiation through traditional solvers recovers material parameters with sub-percent accuracy in seconds. We recommend: use automatic differentiation for inverse problems; apply site-based cross-validation to account for spatial autocorrelation; reserve neural networks for problems where traditional solvers are genuinely expensive and predictions remain within the training envelope. When a method is four orders of magnitude slower with less accuracy, it is not a viable replacement for proven solvers.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-80] OptiVote: Non-Coherent FSO Over-the-Air Majority Vote for Communication-Efficient Distributed Federated Learning in Space Data Centers</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24334">https://arxiv.org/abs/2512.24334</a><br>
<strong>作者</strong>: Anbang Zhang,Chenyuan Feng,Wai Ho Mow,Jia Ye,Shuaishuai Guo,Geyong Min,Tony Q. S. Quek<br>
<strong>类目</strong>: ignal Processing (eess.SP); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The rapid deployment of mega-constellations is driving the long-term vision of space data centers (SDCs), where interconnected satellites form in-orbit distributed computing and learning infrastructures. Enabling distributed federated learning in such systems is challenging because iterative training requires frequent aggregation over inter-satellite links that are bandwidth- and energy-constrained, and the link conditions can be highly dynamic. In this work, we exploit over-the-air computation (AirComp) as an in-network aggregation primitive. However, conventional coherent AirComp relies on stringent phase alignment, which is difficult to maintain in space environments due to satellite jitter and Doppler effects. To overcome this limitation, we propose OptiVote, a robust and communication-efficient non-coherent free-space optical (FSO) AirComp framework for federated learning toward Space Data Centers. OptiVote integrates sign stochastic gradient descent (signSGD) with a majority-vote (MV) aggregation principle and pulse-position modulation (PPM), where each satellite conveys local gradient signs by activating orthogonal PPM time slots. The aggregation node performs MV detection via non-coherent energy accumulation, transforming phase-sensitive field superposition into phase-agnostic optical intensity combining, thereby eliminating the need for precise phase synchronization and improving resilience under dynamic impairments. To mitigate aggregation bias induced by heterogeneous FSO channels, we further develop an importance-aware, channel state information (CSI)-free dynamic power control scheme that balances received energies without additional signaling. We provide theoretical analysis by characterizing the aggregate error probability under statistical FSO channels and establishing convergence guarantees for non-convex objectives.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-81] opological Spatial Graph Coarsening</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24327">https://arxiv.org/abs/2512.24327</a><br>
<strong>作者</strong>: Anna Calissano,Etienne Lasalle<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Computational Geometry (<a target="_blank" rel="noopener" href="http://cs.CG">cs.CG</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Spatial graphs are particular graphs for which the nodes are localized in space (e.g., public transport network, molecules, branching biological structures). In this work, we consider the problem of spatial graph reduction, that aims to find a smaller spatial graph (i.e., with less nodes) with the same overall structure as the initial one. In this context, performing the graph reduction while preserving the main topological features of the initial graph is particularly relevant, due to the additional spatial information. Thus, we propose a topological spatial graph coarsening approach based on a new framework that finds a trade-off between the graph reduction and the preservation of the topological characteristics. The coarsening is realized by collapsing short edges. In order to capture the topological information required to calibrate the reduction level, we adapt the construction of classical topological descriptors made for point clouds (the so-called persistent diagrams) to spatial graphs. This construction relies on the introduction of a new filtration called triangle-aware graph filtration. Our coarsening approach is parameter-free and we prove that it is equivariant under rotations, translations and scaling of the initial spatial graph. We evaluate the performances of our method on synthetic and real spatial graphs, and show that it significantly reduces the graph sizes while preserving the relevant topological information.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-82] Fast reconstruction-based ROI triggering via anomaly detection in the CYGNO optical TPC</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24290">https://arxiv.org/abs/2512.24290</a><br>
<strong>作者</strong>: F. D. Amaro,R. Antonietti,E. Baracchini,L. Benussi,C. Capoccia,M. Caponero,L. G. M. de Carvalho,G. Cavoto,I. A. Costa,A. Croce,M. D’Astolfo,G. D’Imperio,G. Dho,E. Di Marco,J. M. F. dos Santos,D. Fiorina,F. Iacoangeli,Z. Islam,E. Kemp,H. P. Lima Jr.,G. Maccarrone,R. D. P. Mano,D. J. G. Marques,G. Mazzitelli,P. Meloni,A. Messina,V. Monno,C. M. B. Monteiro,R. A. Nobrega,G. M. Oppedisano,I. F. Pains,E. Paoletti,F. Petrucci,S. Piacentini,D. Pierluigi,D. Pinci,F. Renga,A. Russo,G. Saviano,P. A. O. C. Silva,N. J. Spooner,R. Tesauro,S. Tomassini,D. Tozzi<br>
<strong>类目</strong>: Instrumentation and Detectors (physics.ins-det); Machine Learning (cs.LG); Data Analysis, Statistics and Probability (physics.data-an)<br>
*<strong>备注</strong>:  13 pages, 6 figures, Submitted to IOP Machine Learning: Science and Technology</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Optical-readout Time Projection Chambers (TPCs) produce megapixel-scale images whose fine-grained topological information is essential for rare-event searches, but whose size challenges real-time data selection. We present an unsupervised, reconstruction-based anomaly-detection strategy for fast Region-of-Interest (ROI) extraction that operates directly on minimally processed camera frames. A convolutional autoencoder trained exclusively on pedestal images learns the detector noise morphology without labels, simulation, or fine-grained calibration. Applied to standard data-taking frames, localized reconstruction residuals identify particle-induced structures, from which compact ROIs are extracted via thresholding and spatial clustering. Using real data from the CYGNO optical TPC prototype, we compare two pedestal-trained autoencoder configurations that differ only in their training objective, enabling a controlled study of its impact. The best configuration retains (93.0 +/- 0.2)% of reconstructed signal intensity while discarding (97.8 +/- 0.1)% of the image area, with an inference time of approximately 25 ms per frame on a consumer GPU. The results demonstrate that careful design of the training objective is critical for effective reconstruction-based anomaly detection and that pedestal-trained autoencoders provide a transparent and detector-agnostic baseline for online data reduction in optical TPCs.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-83] Variational Quantum Brushes</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24173">https://arxiv.org/abs/2512.24173</a><br>
<strong>作者</strong>: Jui-Ting Lu,Henrique Ennes,Chih-Kang Huang,Ali Abbassi<br>
<strong>类目</strong>: Quantum Physics (quant-ph); Graphics (<a target="_blank" rel="noopener" href="http://cs.GR">cs.GR</a>); Machine Learning (cs.LG); Optimization and Control (math.OC)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Quantum brushes are computational arts software introduced by Ferreira et al (2025) that leverage quantum behavior to generate novel artistic effects. In this outreach paper, we introduce the mathematical framework and describe the implementation of two quantum brushes based on variational quantum algorithms, Steerable and Chemical. While Steerable uses quantum geometric control theory to merge two works of art, Chemical mimics variational eigensolvers for estimating molecular ground energies to evolve colors on an underlying canvas. The implementation of both brushes is available open-source at this https URL and is fully compatible with the original quantum brushes.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-84] Score-based sampling without diffusions: Guidance from a simple and modular scheme</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24152">https://arxiv.org/abs/2512.24152</a><br>
<strong>作者</strong>: M. J. Wainwright<br>
<strong>类目</strong>: atistics Theory (<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>); Machine Learning (cs.LG); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Sampling based on score diffusions has led to striking empirical results, and has attracted considerable attention from various research communities. It depends on availability of (approximate) Stein score functions for various levels of additive noise. We describe and analyze a modular scheme that reduces score-based sampling to solving a short sequence of ``nice’’ sampling problems, for which high-accuracy samplers are known. We show how to design forward trajectories such that both (a) the terminal distribution, and (b) each of the backward conditional distribution is defined by a strongly log concave (SLC) distribution. This modular reduction allows us to exploit \emphany SLC sampling algorithm in order to traverse the backwards path, and we establish novel guarantees with short proofs for both uni-modal and multi-modal densities. The use of high-accuracy routines yields  \varepsilon -accurate answers, in either KL or Wasserstein distances, with polynomial dependence on  \log(1/\varepsilon)  and  \sqrtd  dependence on the dimension.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-85] Quantitative Understanding of PDF Fits and their Uncertainties</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24116">https://arxiv.org/abs/2512.24116</a><br>
<strong>作者</strong>: Amedeo Chiefa,Luigi Del Debbio,Richard Kenway<br>
<strong>类目</strong>: High Energy Physics - Phenomenology (hep-ph); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Parton Distribution Functions (PDFs) play a central role in describing experimental data at colliders and provide insight into the structure of nucleons. As the LHC enters an era of high-precision measurements, a robust PDF determination with a reliable uncertainty quantification has become mandatory in order to match the experimental precision. The NNPDF collaboration has pioneered the use of Machine Learning (ML) techniques for PDF determinations, using Neural Networks (NNs) to parametrise the unknown PDFs in a flexible and unbiased way. The NNs are then trained on experimental data by means of stochastic gradient descent algorithms. The statistical robustness of the results is validated by extensive closure tests using synthetic data. In this work, we develop a theoretical framework based on the Neural Tangent Kernel (NTK) to analyse the training dynamics of neural networks. This approach allows us to derive, under precise assumptions, an analytical description of the neural network evolution during training, enabling a quantitative understanding of the training process. Having an analytical handle on the training dynamics allows us to clarify the role of the NN architecture and the impact of the experimental data in a transparent way. Similarly, we are able to describe the evolution of the covariance of the NN output during training, providing a quantitative description of how uncertainties are propagated from the data to the fitted function. While our results are not a substitute for PDF fitting, they do provide a powerful diagnostic tool to assess the robustness of current fitting methodologies. Beyond its relevance for particle physics phenomenology, our analysis of PDF determinations provides a testbed to apply theoretical ideas about the learning process developed in the ML community.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-86] Constructive Approximation of Random Process via Stochastic Interpolation Neural Network Operators</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24106">https://arxiv.org/abs/2512.24106</a><br>
<strong>作者</strong>: Sachin Saini,Uaday Singh<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG); Probability (<a target="_blank" rel="noopener" href="http://math.PR">math.PR</a>)<br>
*<strong>备注</strong>:  22 Pages, 10 Figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In this paper, we construct a class of stochastic interpolation neural network operators (SINNOs) with random coefficients activated by sigmoidal functions. We establish their boundedness, interpolation accuracy, and approximation capabilities in the mean square sense, in probability, as well as path-wise within the space of second-order stochastic (random) processes ( L^2(\Omega, \mathcalF,\mathbbP) ). Additionally, we provide quantitative error estimates using the modulus of continuity of the processes. These results highlight the effectiveness of SINNOs for approximating stochastic processes with potential applications in COVID-19 case prediction.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-87] Policy Mirror Descent with Temporal Difference Learning: Sample Complexity under Online Markov Data</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24056">https://arxiv.org/abs/2512.24056</a><br>
<strong>作者</strong>: Wenye Li,Hongxu Chen,Jiacai Liu,Ke Wei<br>
<strong>类目</strong>: Optimization and Control (math.OC); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper studies the policy mirror descent (PMD) method, which is a general policy optimization framework in reinforcement learning and can cover a wide range of policy gradient methods by specifying difference mirror maps. Existing sample complexity analysis for policy mirror descent either focuses on the generative sampling model, or the Markovian sampling model but with the action values being explicitly approximated to certain pre-specified accuracy. In contrast, we consider the sample complexity of policy mirror descent with temporal difference (TD) learning under the Markovian sampling model. Two algorithms called Expected TD-PMD and Approximate TD-PMD have been presented, which are off-policy and mixed policy algorithms respectively. Under a small enough constant policy update step size, the  \tildeO(\varepsilon^-2)  (a logarithm factor about  \varepsilon  is hidden in  \tildeO(\cdot) ) sample complexity can be established for them to achieve average-time  \varepsilon -optimality. The sample complexity is further improved to  O(\varepsilon^-2)  (without the hidden logarithm factor) to achieve the last-iterate  \varepsilon -optimality based on adaptive policy update step sizes.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-88] Fundamental limits for weighted empirical approximations of tilted distributions</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23979">https://arxiv.org/abs/2512.23979</a><br>
<strong>作者</strong>: Sarvesh Ravichandran Iyer,Himadri Mandal,Dhruman Gupta,Rushil Gupta,Agniv Bandhyopadhyay,Achal Bassamboo,Varun Gupta,Sandeep Juneja<br>
<strong>类目</strong>: atistics Theory (<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>); Machine Learning (cs.LG); Probability (<a target="_blank" rel="noopener" href="http://math.PR">math.PR</a>); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:  84 pages, 6 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Consider the task of generating samples from a tilted distribution of a random vector whose underlying distribution is unknown, but samples from it are available. This finds applications in fields such as finance and climate science, and in rare event simulation. In this article, we discuss the asymptotic efficiency of a self-normalized importance sampler of the tilted distribution. We provide a sharp characterization of its accuracy, given the number of samples and the degree of tilt. Our findings reveal a surprising dichotomy: while the number of samples needed to accurately tilt a bounded random vector increases polynomially in the tilt amount, it increases at a super polynomial rate for unbounded distributions.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-89] Implicit geometric regularization in flow matching via density weighted Stein operators</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23956">https://arxiv.org/abs/2512.23956</a><br>
<strong>作者</strong>: Shinto Eguchi<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Flow Matching (FM) has emerged as a powerful paradigm for continuous normalizing flows, yet standard FM implicitly performs an unweighted  L^2  regression over the entire ambient space. In high dimensions, this leads to a fundamental inefficiency: the vast majority of the integration domain consists of low-density ``void’’ regions where the target velocity fields are often chaotic or ill-defined. In this paper, we propose  \gamma -Flow Matching ( \gamma -FM), a density-weighted variant that aligns the regression geometry with the underlying probability flow. While density weighting is desirable, naive implementations would require evaluating the intractable target density. We circumvent this by introducing a Dynamic Density-Weighting strategy that estimates the \emphtarget density directly from training particles. This approach allows us to dynamically downweight the regression loss in void regions without compromising the simulation-free nature of FM. Theoretically, we establish that  \gamma -FM minimizes the transport cost on a statistical manifold endowed with the  \gamma -Stein metric. Spectral analysis further suggests that this geometry induces an implicit Sobolev regularization, effectively damping high-frequency oscillations in void regions. Empirically,  \gamma -FM significantly improves vector field smoothness and sampling efficiency on high-dimensional latent datasets, while demonstrating intrinsic robustness to outliers.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-90] Assessing generative modeling approaches for free energy estimates in condensed matter</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23930">https://arxiv.org/abs/2512.23930</a><br>
<strong>作者</strong>: Maximilian Schebek,Jiajun He,Emil Hoffmann,Yuanqi Du,Frank Noé,Jutta Rogal<br>
<strong>类目</strong>: atistical Mechanics (cond-mat.stat-mech); Materials Science (cond-mat.mtrl-sci); Machine Learning (cs.LG); Computational Physics (physics.comp-ph)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The accurate estimation of free energy differences between two states is a long-standing challenge in molecular simulations. Traditional approaches generally rely on sampling multiple intermediate states to ensure sufficient overlap in phase space and are, consequently, computationally expensive. Several generative-model-based methods have recently addressed this challenge by learning a direct bridge between distributions, bypassing the need for intermediate states. However, it remains unclear which approaches provide the best trade-off between efficiency, accuracy, and scalability. In this work, we systematically review these methods and benchmark selected approaches with a focus on condensed-matter systems. In particular, we investigate the performance of discrete and continuous normalizing flows in the context of targeted free energy perturbation as well as FEAT (Free energy Estimators with Adaptive Transport) together with the escorted Jarzynski equality, using coarse-grained monatomic ice and Lennard-Jones solids as benchmark systems. We evaluate accuracy, data efficiency, computational cost, and scalability with system size. Our results provide a quantitative framework for selecting effective free energy estimation strategies in condensed-phase systems.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-91] Stationary Reweighting Yields Local Convergence of Soft Fitted Q-Iteration</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23927">https://arxiv.org/abs/2512.23927</a><br>
<strong>作者</strong>: Lars van der Laan,Nathan Kallus<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Fitted Q-iteration (FQI) and its entropy-regularized variant, soft FQI, are central tools for value-based model-free offline reinforcement learning, but can behave poorly under function approximation and distribution shift. In the entropy-regularized setting, we show that the soft Bellman operator is locally contractive in the stationary norm of the soft-optimal policy, rather than in the behavior norm used by standard FQI. This geometric mismatch explains the instability of soft Q-iteration with function approximation in the absence of Bellman completeness. To restore contraction, we introduce stationary-reweighted soft FQI, which reweights each regression update using the stationary distribution of the current policy. We prove local linear convergence under function approximation with geometrically damped weight-estimation errors, assuming approximate realizability. Our analysis further suggests that global convergence may be recovered by gradually reducing the softmax temperature, and that this continuation approach can extend to the hardmax limit under a mild margin condition.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-92] nsor Computing Interface: An Application-Oriented Lightweight Interface for Portable High-Performance Tensor Network Applications</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23917">https://arxiv.org/abs/2512.23917</a><br>
<strong>作者</strong>: Rong-Yang Sun,Tomonori Shirakawa,Hidehiko Kohshiro,D. N. Sheng,Seiji Yunoki<br>
<strong>类目</strong>: Quantum Physics (quant-ph); Strongly Correlated Electrons (cond-mat.str-el); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  34 pages, 10 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Tensor networks (TNs) are a central computational tool in quantum science and artificial intelligence. However, the lack of unified software interface across tensor-computing frameworks severely limits the portability of TN applications, coupling algorithmic development to specific hardware and software back ends. To address this challenge, we introduce the Tensor Computing Interface (TCI) – an application-oriented, lightweight application programming interface designed to enable framework-independent, high-performance TN applications. TCI provides a well-defined type system that abstracts tensor objects together with a minimal yet expressive set of core functions covering essential tensor manipulations and tensor linear-algebra operations. Through numerical demonstrations on representative tensor-network applications, we show that codes written against TCI can be migrated seamlessly across heterogeneous hardware and software platforms while achieving performance comparable to native framework implementations. We further release an open-source implementation of TCI based on \textitCytnx, demonstrating its practicality and ease of integration with existing tensor-computing frameworks.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-93] A Test of Lookahead Bias in <mark class="hl-label green">LLM</mark>  Forecasts</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23847">https://arxiv.org/abs/2512.23847</a><br>
<strong>作者</strong>: Zhenyu Gao,Wenxi Jiang,Yutong Yan<br>
<strong>类目</strong>: General Finance (<a target="_blank" rel="noopener" href="http://q-fin.GN">q-fin.GN</a>); Machine Learning (cs.LG); Trading and Market Microstructure (<a target="_blank" rel="noopener" href="http://q-fin.TR">q-fin.TR</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We develop a statistical test to detect lookahead bias in economic forecasts generated by large language models (LLMs). Using state-of-the-art pre-training data detection techniques, we estimate the likelihood that a given prompt appeared in an LLM’s training corpus, a statistic we term Lookahead Propensity (LAP). We formally show that a positive correlation between LAP and forecast accuracy indicates the presence and magnitude of lookahead bias, and apply the test to two forecasting tasks: news headlines predicting stock returns and earnings call transcripts predicting capital expenditures. Our test provides a cost-efficient, diagnostic tool for assessing the validity and reliability of LLM-generated forecasts.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-94] Energy-Tweedie: Score meets Score Energy meets Energy</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23818">https://arxiv.org/abs/2512.23818</a><br>
<strong>作者</strong>: Andrej Leban<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  22 pages, 5 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Denoising and score estimation have long been known to be linked via the classical Tweedie’s formula. In this work, we first extend the latter to a wider range of distributions often called “energy models” and denoted elliptical distributions in this work. Next, we examine an alternative view: we consider the denoising posterior  P(X|Y)  as the optimizer of the energy score (a scoring rule) and derive a fundamental identity that connects the (path-) derivative of a (possibly) non-Euclidean energy score to the score of the noisy marginal. This identity can be seen as an analog of Tweedie’s identity for the energy score, and allows for several interesting applications; for example, score estimation, noise distribution parameter estimation, as well as using energy score models in the context of “traditional” diffusion model samplers with a wider array of noising distributions.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-95] Fitted Q Evaluation Without Be<mark class="hl-label green">llm</mark> an Completeness via Stationary Weighting</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23805">https://arxiv.org/abs/2512.23805</a><br>
<strong>作者</strong>: Lars van der Laan,Nathan Kallus<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Fitted Q-evaluation (FQE) is a central method for off-policy evaluation in reinforcement learning, but it generally requires Bellman completeness: that the hypothesis class is closed under the evaluation Bellman operator. This requirement is challenging because enlarging the hypothesis class can worsen completeness. We show that the need for this assumption stems from a fundamental norm mismatch: the Bellman operator is gamma-contractive under the stationary distribution of the target policy, whereas FQE minimizes Bellman error under the behavior distribution. We propose a simple fix: reweight each regression step using an estimate of the stationary density ratio, thereby aligning FQE with the norm in which the Bellman operator contracts. This enables strong evaluation guarantees in the absence of realizability or Bellman completeness, avoiding the geometric error blow-up of standard FQE in this setting while maintaining the practicality of regression-based evaluation.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-96] Spike-Timing-Dependent Plasticity for Bernoulli Message Passing</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23728">https://arxiv.org/abs/2512.23728</a><br>
<strong>作者</strong>: Sepideh Adamiat,Wouter M. Kouw,Bert de Vries<br>
<strong>类目</strong>: Neurons and Cognition (<a target="_blank" rel="noopener" href="http://q-bio.NC">q-bio.NC</a>); Machine Learning (cs.LG); Neural and Evolutionary Computing (<a target="_blank" rel="noopener" href="http://cs.NE">cs.NE</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Bayesian inference provides a principled framework for understanding brain function, while neural activity in the brain is inherently spike-based. This paper bridges these two perspectives by designing spiking neural networks that simulate Bayesian inference through message passing for Bernoulli messages. To train the networks, we employ spike-timing-dependent plasticity, a biologically plausible mechanism for synaptic plasticity which is based on the Hebbian rule. Our results demonstrate that the network’s performance closely matches the true numerical solution. We further demonstrate the versatility of our approach by implementing a factor graph example from coding theory, illustrating signal transmission over an unreliable channel.</p>
</div></div>
<h3 id="信息检索">信息检索</h3>
<div class="note pink no-icon flat"><p>[IR-0] OpenOneRec Technical Report</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24762">https://arxiv.org/abs/2512.24762</a><br>
<strong>作者</strong>: Guorui Zhou,Honghui Bao,Jiaming Huang,Jiaxin Deng,Jinghao Zhang,Junda She,Kuo Cai,Lejian Ren,Lu Ren,Qiang Luo,Qianqian Wang,Qigen Hu,Rongzhou Zhang,Ruiming Tang,Shiyao Wang,Wuchao Li,Xiangyu Wu,Xinchen Luo,Xingmei Wang,Yifei Hu,Yunfan Wu,Zhanyu Liu,Zhiyang Zhang,Zixing Zhang,Bo Chen,Bin Wen,Chaoyi Ma,Chengru Song,Chenglong Chu,Defu Lian,Fan Yang,Feng Jiang,Hongtao Cheng,Huanjie Wang,Kun Gai,Pengfei Zheng,Qiang Wang,Rui Huang,Siyang Mao,Tingting Gao,Wei Yuan,Yan Wang,Yang Zhou,Yi Su,Zexuan Cheng,Zhixin Ling,Ziming Li<br>
<strong>类目</strong>: Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:While the OneRec series has successfully unified the fragmented recommendation pipeline into an end-to-end generative framework, a significant gap remains between recommendation systems and general intelligence. Constrained by isolated data, they operate as domain specialists-proficient in pattern matching but lacking world knowledge, reasoning capabilities, and instruction following. This limitation is further compounded by the lack of a holistic benchmark to evaluate such integrated capabilities. To address this, our contributions are: 1) RecIF Bench  Open Data: We propose RecIF-Bench, a holistic benchmark covering 8 diverse tasks that thoroughly evaluate capabilities from fundamental prediction to complex reasoning. Concurrently, we release a massive training dataset comprising 96 million interactions from 160,000 users to facilitate reproducible research. 2) Framework  Scaling: To ensure full reproducibility, we open-source our comprehensive training pipeline, encompassing data processing, co-pretraining, and post-training. Leveraging this framework, we demonstrate that recommendation capabilities can scale predictably while mitigating catastrophic forgetting of general knowledge. 3) OneRec-Foundation: We release OneRec Foundation (1.7B and 8B), a family of models establishing new state-of-the-art (SOTA) results across all tasks in RecIF-Bench. Furthermore, when transferred to the Amazon benchmark, our models surpass the strongest baselines with an average 26.8% improvement in Recall@10 across 10 diverse datasets (Figure 1). This work marks a step towards building truly intelligent recommender systems. Nonetheless, realizing this vision presents significant technical and theoretical challenges, highlighting the need for broader research engagement in this promising direction.</p>
</div></div>
<div class="note pink no-icon flat"><p>[IR-1] MDiffFR: Modality-Guided Diffusion Generation for Cold-start Items in Federated Recommendation</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24715">https://arxiv.org/abs/2512.24715</a><br>
<strong>作者</strong>: Kang Fu,Honglei Zhang,Xuechao Zou,Yidong Li<br>
<strong>类目</strong>: Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Federated recommendations (FRs) provide personalized services while preserving user privacy by keeping user data on local clients, which has attracted significant attention in recent years. However, due to the strict privacy constraints inherent in FRs, access to user-item interaction data and user profiles across clients is highly restricted, making it difficult to learn globally effective representations for new (cold-start) items. Consequently, the item cold-start problem becomes even more challenging in FRs. Existing solutions typically predict embeddings for new items through the attribute-to-embedding mapping paradigm, which establishes a fixed one-to-one correspondence between item attributes and their embeddings. However, this one-to-one mapping paradigm often fails to model varying data distributions and tends to cause embedding misalignment, as verified by our empirical studies. To this end, we propose MDiffFR, a novel generation-based modality-guided diffusion method for cold-start items in FRs. In this framework, we employ a tailored diffusion model on the server to generate embeddings for new items, which are then distributed to clients for cold-start inference. To align item semantics, we deploy a pre-trained modality encoder to extract modality features as conditional signals to guide the reverse denoising process. Furthermore, our theoretical analysis verifies that the proposed method achieves stronger privacy guarantees compared to existing mapping-based approaches. Extensive experiments on four real datasets demonstrate that our method consistently outperforms all baselines in FRs.</p>
</div></div>
<div class="note pink no-icon flat"><p>[IR-2] MEIC-DT: Memory-Efficient Incremental Clustering for Long-Text Coreference Resolution with Dual-Threshold Constraints</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24711">https://arxiv.org/abs/2512.24711</a><br>
<strong>作者</strong>: Kangyang Luo,Shuzheng Si,Yuzhuo Bai,Cheng Gao,Zhitong Wang,Cheng Huang,Yingli Shen,Yufeng Han,Wenhao Li,Cunliang Kong,Maosong Sun<br>
<strong>类目</strong>: Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In the era of large language models (LLMs), supervised neural methods remain the state-of-the-art (SOTA) for Coreference Resolution. Yet, their full potential is underexplored, particularly in incremental clustering, which faces the critical challenge of balancing efficiency with performance for long texts. To address the limitation, we propose \textbfMEIC-DT, a novel dual-threshold, memory-efficient incremental clustering approach based on a lightweight Transformer. MEIC-DT features a dual-threshold constraint mechanism designed to precisely control the Transformer’s input scale within a predefined memory budget. This mechanism incorporates a Statistics-Aware Eviction Strategy (\textbfSAES), which utilizes distinct statistical profiles from the training and inference phases for intelligent cache management. Furthermore, we introduce an Internal Regularization Policy (\textbfIRP) that strategically condenses clusters by selecting the most representative mentions, thereby preserving semantic integrity. Extensive experiments on common benchmarks demonstrate that MEIC-DT achieves highly competitive coreference performance under stringent memory constraints.</p>
</div></div>
<div class="note pink no-icon flat"><p>[IR-3] On the Factual Consistency of Text-based Explainable Recommendation Models</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24366">https://arxiv.org/abs/2512.24366</a><br>
<strong>作者</strong>: Ben Kabongo,Vincent Guigue<br>
<strong>类目</strong>: Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
*<strong>备注</strong>:  13 pages, 2 figures, 4 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Text-based explainable recommendation aims to generate natural-language explanations that justify item recommendations, to improve user trust and system transparency. Although recent advances leverage LLMs to produce fluent outputs, a critical question remains underexplored: are these explanations factually consistent with the available evidence? We introduce a comprehensive framework for evaluating the factual consistency of text-based explainable recommenders. We design a prompting-based pipeline that uses LLMs to extract atomic explanatory statements from reviews, thereby constructing a ground truth that isolates and focuses on their factual content. Applying this pipeline to five categories from the Amazon Reviews dataset, we create augmented benchmarks for fine-grained evaluation of explanation quality. We further propose statement-level alignment metrics that combine LLM- and NLI-based approaches to assess both factual consistency and relevance of generated explanations. Across extensive experiments on six state-of-the-art explainable recommendation models, we uncover a critical gap: while models achieve high semantic similarity scores (BERTScore F1: 0.81-0.90), all our factuality metrics reveal alarmingly low performance (LLM-based statement-level precision: 4.38%-32.88%). These findings underscore the need for factuality-aware evaluation in explainable recommendation and provide a foundation for developing more trustworthy explanation systems.</p>
</div></div>
<div class="note pink no-icon flat"><p>[IR-4] <mark class="hl-label green">RAG</mark> Part  <mark class="hl-label green">RAG</mark> Mask: Retrieval-Stage Defenses Against Corpus Poisoning in Retrieval-Augmented Generation <mark class="hl-label red">AAAI2026</mark></p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24268">https://arxiv.org/abs/2512.24268</a><br>
<strong>作者</strong>: Pankayaraj Pathmanathan,Michael-Andrei Panaitescu-Liess,Cho-Yu Jason Chiang,Furong Huang<br>
<strong>类目</strong>: Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
*<strong>备注</strong>:  Published at AAAI 2026 Workshop on New Frontiers in Information Retrieval [Oral]</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Retrieval-Augmented Generation (RAG) has emerged as a promising paradigm to enhance large language models (LLMs) with external knowledge, reducing hallucinations and compensating for outdated information. However, recent studies have exposed a critical vulnerability in RAG pipelines corpus poisoning where adversaries inject malicious documents into the retrieval corpus to manipulate model outputs. In this work, we propose two complementary retrieval-stage defenses: RAGPart and RAGMask. Our defenses operate directly on the retriever, making them computationally lightweight and requiring no modification to the generation model. RAGPart leverages the inherent training dynamics of dense retrievers, exploiting document partitioning to mitigate the effect of poisoned points. In contrast, RAGMask identifies suspicious tokens based on significant similarity shifts under targeted token masking. Across two benchmarks, four poisoning strategies, and four state-of-the-art retrievers, our defenses consistently reduce attack success rates while preserving utility under benign conditions. We further introduce an interpretable attack to stress-test our defenses. Our findings highlight the potential and limitations of retrieval-stage defenses, providing practical insights for robust RAG deployments.</p>
</div></div>
<div class="note pink no-icon flat"><p>[IR-5] me-Aware Adaptive Side Information Fusion for Sequential Recommendation <mark class="hl-label red">WSDM’26</mark></p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24246">https://arxiv.org/abs/2512.24246</a><br>
<strong>作者</strong>: Jie Luo,Wenyu Zhang,Xinming Zhang,Yuan Fang<br>
<strong>类目</strong>: Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
*<strong>备注</strong>:  10 pages. Accepted by WSDM’26</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Incorporating item-side information, such as category and brand, into sequential recommendation is a well-established and effective approach for improving performance. However, despite significant advancements, current models are generally limited by three key challenges: they often overlook the fine-grained temporal dynamics inherent in timestamps, exhibit vulnerability to noise in user interaction sequences, and rely on computationally expensive fusion architectures. To systematically address these challenges, we propose the Time-Aware Adaptive Side Information Fusion (TASIF) framework. TASIF integrates three synergistic components: (1) a simple, plug-and-play time span partitioning mechanism to capture global temporal patterns; (2) an adaptive frequency filter that leverages a learnable gate to denoise feature sequences adaptively, thereby providing higher-quality inputs for subsequent fusion modules; and (3) an efficient adaptive side information fusion layer, this layer employs a “guide-not-mix” architecture, where attributes guide the attention mechanism without being mixed into the content-representing item embeddings, ensuring deep interaction while ensuring computational efficiency. Extensive experiments on four public datasets demonstrate that TASIF significantly outperforms state-of-the-art baselines while maintaining excellent efficiency in training. Our source code is available at this https URL.</p>
</div></div>
<div class="note pink no-icon flat"><p>[IR-6] High-dimensional Regret Minimization</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.24078">https://arxiv.org/abs/2512.24078</a><br>
<strong>作者</strong>: Junyu Liao,Ashwin Lall,Mitsunori Ogihara,Raymond Wong<br>
<strong>类目</strong>: Databases (cs.DB); Computational Geometry (<a target="_blank" rel="noopener" href="http://cs.CG">cs.CG</a>); Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multi-criteria decision making in large databases is very important in real world applications. Recently, an interactive query has been studied extensively in the database literature with the advantage of both the top-k query (with limited output size) and the skyline query (which does not require users to explicitly specify their preference function). This approach iteratively asks the user to select the one preferred within a set of options. Based on rounds of feedback, the query learns the implicit preference and returns the most favorable as a recommendation. However, many modern applications in areas like housing or financial product markets feature datasets with hundreds of attributes. Existing interactive algorithms either fail to scale or require excessive user interactions (often exceeding 1000 rounds). Motivated by this, we propose FHDR (Fast High-Dimensional Reduction), a novel framework that takes less than 0.01s with fewer than 30 rounds of interaction. It is considered a breakthrough in the field of interactive queries since most, if not all, existing studies are not scalable to high-dimensional datasets. Extensive experiments demonstrate that FHDR outperforms the best-known algorithms by at least an order of magnitude in execution time and up to several orders of magnitude in terms of the number of interactions required, establishing a new state of the art for scalable interactive regret minimization.         Subjects:  Databases (cs.DB); Computational Geometry (<a target="_blank" rel="noopener" href="http://cs.CG">cs.CG</a>); Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)  Cite as: arXiv:2512.24078 [cs.DB]    (or  arXiv:2512.24078v1 [cs.DB] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.24078">https://doi.org/10.48550/arXiv.2512.24078</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)</p>
</div></div>
<div class="note pink no-icon flat"><p>[IR-7] Deletion Considered Harmful</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.23907">https://arxiv.org/abs/2512.23907</a><br>
<strong>作者</strong>: Paul Englefield,Russell Beale<br>
<strong>类目</strong>: Human-Computer Interaction (cs.HC); Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In a world of information overload, understanding how we can most effectively manage information is crucial to success. We set out to understand how people view deletion, the removal of material no longer needed: does it help by reducing clutter and improving the signal to noise ratio, or does the effort required to decide to delete something make it not worthwhile? How does deletion relate to other strategies like filing; do people who spend extensive time in filing also prune their materials too? We studied the behaviour of 51 knowledge workers though a series of questionnaires and interviews to evaluate a range of tactics they used aimed at organizing, filing, and retrieving digital resources. Our study reveals that deletion is consistently under-adopted compared to other tactics such as Filing, Coverage, Ontology, and Timeliness. Moreover, the empirical data indicate that deletion is actually detrimental to retrieval success and satisfaction. In this paper, we examine the practice of deletion, review the related literature, and present detailed statistical results and clustering outcomes that underscore its adverse effects.</p>
</div></div>
<h3 id="附件下载">附件下载</h3>
<p><a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/lonePatient/lonePatient.github.io/master/arxiv/arxiv_papers_2026-01-01.txt">点击下载今日全部论文列表</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Weitang Liu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://lonepatient.top/2026/01/01/arxiv_papers_2026-01-01.html">http://lonepatient.top/2026/01/01/arxiv_papers_2026-01-01.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://lonepatient.top" target="_blank">闲记算法</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Arxiv/">Arxiv</a></div><div class="post_share"><div class="social-share" data-image="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2026/01/05/arxiv_papers_2026-01-05.html"><img class="prev-cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Arxiv今日论文 | 2026-01-05</div></div></a></div><div class="next-post pull-right"><a href="/2025/12/30/arxiv_papers_2025-12-30.html"><img class="next-cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Arxiv今日论文 | 2025-12-30</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/10/10/ar5iv.html" title="ar5iv"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20231208121727.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-10</div><div class="title">ar5iv</div></div></a></div><div><a href="/2026/02/10/arxiv_papers_2026-02-10.html" title="Arxiv今日论文 | 2026-02-10"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-10</div><div class="title">Arxiv今日论文 | 2026-02-10</div></div></a></div><div><a href="/2025/12/03/arxiv_papers_2025-12-03.html" title="Arxiv今日论文 | 2025-12-03"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-03</div><div class="title">Arxiv今日论文 | 2025-12-03</div></div></a></div><div><a href="/2025/12/04/arxiv_papers_2025-12-04.html" title="Arxiv今日论文 | 2025-12-04"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-04</div><div class="title">Arxiv今日论文 | 2025-12-04</div></div></a></div><div><a href="/2025/12/05/arxiv_papers_2025-12-05.html" title="Arxiv今日论文 | 2025-12-05"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-05</div><div class="title">Arxiv今日论文 | 2025-12-05</div></div></a></div><div><a href="/2025/12/08/arxiv_papers_2025-12-08.html" title="Arxiv今日论文 | 2025-12-08"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-08</div><div class="title">Arxiv今日论文 | 2025-12-08</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Weitang Liu</div><div class="author-info__description">一个致力于记录技术的博客</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">281</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">384</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">92</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/lonePatient"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/lonePatient" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:liuweitangmath@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://weibo.com/277974397" target="_blank" title="Weibo"><i class="fab fa-weibo"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有任何问题可通过留言板或者微信公众号给我留言，谢谢！<img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/202602201201102.jpg"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E5%BD%95"><span class="toc-number">1.</span> <span class="toc-text">目录</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%A7%88-2026-01-01"><span class="toc-number">1.1.</span> <span class="toc-text">概览 (2026-01-01)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"><span class="toc-number">1.3.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"><span class="toc-number">1.4.</span> <span class="toc-text">人工智能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.5.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2"><span class="toc-number">1.6.</span> <span class="toc-text">信息检索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E4%BB%B6%E4%B8%8B%E8%BD%BD"><span class="toc-number">1.7.</span> <span class="toc-text">附件下载</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/02/27/arxiv_papers_2026-02-27.html" title="Arxiv今日论文 | 2026-02-27"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-27"/></a><div class="content"><a class="title" href="/2026/02/27/arxiv_papers_2026-02-27.html" title="Arxiv今日论文 | 2026-02-27">Arxiv今日论文 | 2026-02-27</a><time datetime="2026-02-27T12:30:00.000Z" title="发表于 2026-02-27 12:30:00">2026-02-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/26/arxiv_papers_2026-02-26.html" title="Arxiv今日论文 | 2026-02-26"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-26"/></a><div class="content"><a class="title" href="/2026/02/26/arxiv_papers_2026-02-26.html" title="Arxiv今日论文 | 2026-02-26">Arxiv今日论文 | 2026-02-26</a><time datetime="2026-02-26T12:30:00.000Z" title="发表于 2026-02-26 12:30:00">2026-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/arxiv_papers_2026-02-25.html" title="Arxiv今日论文 | 2026-02-25"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-25"/></a><div class="content"><a class="title" href="/2026/02/25/arxiv_papers_2026-02-25.html" title="Arxiv今日论文 | 2026-02-25">Arxiv今日论文 | 2026-02-25</a><time datetime="2026-02-25T12:30:00.000Z" title="发表于 2026-02-25 12:30:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/2026-02-25-Less-is-Enough-Synthesizing-Diverse-Data-in-Feature-Space-of-LLMs.html" title="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260225222513891.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板"/></a><div class="content"><a class="title" href="/2026/02/25/2026-02-25-Less-is-Enough-Synthesizing-Diverse-Data-in-Feature-Space-of-LLMs.html" title="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板">大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板</a><time datetime="2026-02-25T12:00:00.000Z" title="发表于 2026-02-25 12:00:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/2026-02-25-Midtraining-%E4%B8%AD%E9%97%B4%E8%AE%AD%E7%BB%83-%E6%9E%84%E5%BB%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%90%8E%E8%AE%AD%E7%BB%83%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%A5%E6%A2%81.html" title="mid-training：构建预训练与后训练之间的分布式桥梁"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260225123005910.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="mid-training：构建预训练与后训练之间的分布式桥梁"/></a><div class="content"><a class="title" href="/2026/02/25/2026-02-25-Midtraining-%E4%B8%AD%E9%97%B4%E8%AE%AD%E7%BB%83-%E6%9E%84%E5%BB%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%90%8E%E8%AE%AD%E7%BB%83%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%A5%E6%A2%81.html" title="mid-training：构建预训练与后训练之间的分布式桥梁">mid-training：构建预训练与后训练之间的分布式桥梁</a><time datetime="2026-02-25T00:00:00.000Z" title="发表于 2026-02-25 00:00:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/24/arxiv_papers_2026-02-24.html" title="Arxiv今日论文 | 2026-02-24"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-24"/></a><div class="content"><a class="title" href="/2026/02/24/arxiv_papers_2026-02-24.html" title="Arxiv今日论文 | 2026-02-24">Arxiv今日论文 | 2026-02-24</a><time datetime="2026-02-24T12:30:00.000Z" title="发表于 2026-02-24 12:30:00">2026-02-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/23/arxiv_papers_2026-02-23.html" title="Arxiv今日论文 | 2026-02-23"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-23"/></a><div class="content"><a class="title" href="/2026/02/23/arxiv_papers_2026-02-23.html" title="Arxiv今日论文 | 2026-02-23">Arxiv今日论文 | 2026-02-23</a><time datetime="2026-02-23T12:30:00.000Z" title="发表于 2026-02-23 12:30:00">2026-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/23/Think-Deep,-Not-Just-Long-Measuring-LLM-Reasoning-Effort-via-Deep-Thinking-Tokens.html" title="用&quot;深度思考率&quot;精准度量LLM推理质量"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260223165943195.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="用&quot;深度思考率&quot;精准度量LLM推理质量"/></a><div class="content"><a class="title" href="/2026/02/23/Think-Deep,-Not-Just-Long-Measuring-LLM-Reasoning-Effort-via-Deep-Thinking-Tokens.html" title="用&quot;深度思考率&quot;精准度量LLM推理质量">用&quot;深度思考率&quot;精准度量LLM推理质量</a><time datetime="2026-02-23T12:00:00.000Z" title="发表于 2026-02-23 12:00:00">2026-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/20/arxiv_papers_2026-02-20.html" title="Arxiv今日论文 | 2026-02-20"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-20"/></a><div class="content"><a class="title" href="/2026/02/20/arxiv_papers_2026-02-20.html" title="Arxiv今日论文 | 2026-02-20">Arxiv今日论文 | 2026-02-20</a><time datetime="2026-02-20T12:30:00.000Z" title="发表于 2026-02-20 12:30:00">2026-02-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/20/frontier_training_cn.html" title="前沿大模型训练方法：深度解析与实践指南"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/202602201606857.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="前沿大模型训练方法：深度解析与实践指南"/></a><div class="content"><a class="title" href="/2026/02/20/frontier_training_cn.html" title="前沿大模型训练方法：深度解析与实践指南">前沿大模型训练方法：深度解析与实践指南</a><time datetime="2026-02-20T10:30:00.000Z" title="发表于 2026-02-20 10:30:00">2026-02-20</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2026 By Weitang Liu</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'https://twikoo.lonepatient.top/',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'https://twikoo.lonepatient.top/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo@1.4.11/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (99)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/计算机视觉/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 计算机视觉 (16)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/知识图谱/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 知识图谱 (13)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 深度学习 (139)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="http://lonepatient.top/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230219144729.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-02-18</span><a class="blog-slider__title" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt="">通向AGI之路：大型语言模型（LLM）技术精要</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/07/12/gaiic_2022_ner_top10.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20220712181905.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-07-12</span><a class="blog-slider__title" href="2022/07/12/gaiic_2022_ner_top10.html" alt="">GAIIC2022商品标题识别二等奖获奖解决思路</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2022/07/12/gaiic_2022_ner_top10.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230807190424.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-01-20</span><a class="blog-slider__title" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt="">2025-03|高质量中文预训练模型集合</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>