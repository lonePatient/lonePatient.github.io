<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Arxiv今日论文 | 2025-12-12 | 闲记算法</title><meta name="keywords" content="Arxiv"><meta name="author" content="Weitang Liu"><meta name="copyright" content="Weitang Liu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇博文主要内容为 2025-12-12 从Arxiv.org论文网站获取的最新论文列表，自动更新，按照NLP、CV、ML、AI、IR五个大方向区分，若需要邮件定时接收，请在评论区留下你的邮箱号。 说明：每日论文数据从Arxiv.org获取，每天早上12:00左右定时自动更新。  友情提示: 如何您需要邮箱接收每日论文数据，请在评论处留下你的邮箱。  目录  概览 自然语言处理CL 人工智能AI">
<meta property="og:type" content="article">
<meta property="og:title" content="Arxiv今日论文 | 2025-12-12">
<meta property="og:url" content="http://lonepatient.top/2025/12/12/arxiv_papers_2025-12-12.html">
<meta property="og:site_name" content="闲记算法">
<meta property="og:description" content="本篇博文主要内容为 2025-12-12 从Arxiv.org论文网站获取的最新论文列表，自动更新，按照NLP、CV、ML、AI、IR五个大方向区分，若需要邮件定时接收，请在评论区留下你的邮箱号。 说明：每日论文数据从Arxiv.org获取，每天早上12:00左右定时自动更新。  友情提示: 如何您需要邮箱接收每日论文数据，请在评论处留下你的邮箱。  目录  概览 自然语言处理CL 人工智能AI">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png">
<meta property="article:published_time" content="2025-12-12T10:30:00.000Z">
<meta property="article:modified_time" content="2026-02-27T07:52:12.703Z">
<meta property="article:author" content="Weitang Liu">
<meta property="article:tag" content="Arxiv">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://lonepatient.top/2025/12/12/arxiv_papers_2025-12-12"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//s4.cnzz.com"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script async="async" data-pjax="data-pjax" src="https://s4.cnzz.com/z_stat.php?id=1273275888&amp;web_id=1273275888"></script><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2026-02-27 07:52:12'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    })(window)</script><link rel="stylesheet" href="/css/backgroud.css"><script src="https://cdn.jsdelivr.net/npm/echarts@4.7.0/dist/echarts.min.js"></script><script src="https://at.alicdn.com/t/c/font_3570527_dthoqrrv2tv.css"></script><script charset="UTF-8" id="LA_COLLECT" src="//sdk.51.la/js-sdk-pro.min.js"></script><script>LA.init({id:"JwRQtLKZggvJH4sJ",ck:"JwRQtLKZggvJH4sJ"})</script><link rel="stylesheet" href="/css/universe.css"><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-3536467946304280" crossorigin="anonymous"></script><!-- hexo injector head_end start --><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-double-row-display@1.00/cardlistpost.min.css"/>
<style>#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags:before {content:"\A";
  white-space: pre;}#recent-posts > .recent-post-item >.recent-post-info > .article-meta-wrap > .tags > .article-meta__separator{display:none}</style>
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" src="/img/touxiang.jpeg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">281</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">384</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">92</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 网站</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.aitoolist.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集合</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.deepdh.com"><i class="fa-fw fa fa-star"></i><span> AI工具导航</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.ai-lib.club"><i class="fa-fw fa fa-star"></i><span> 人工智能工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ai-bot.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 教程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://learningprompt.wiki/"><i class="fa-fw fa fa-star"></i><span> Prompt教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 在线</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fa fa-star"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">闲记算法</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fa-fw fa fa-book"></i><span> 找文章</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></li><li><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page" href="/charts/"><i class="fa-fw fa fa-archive"></i><span> 统计</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 网站</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://www.aitoolist.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集合</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.deepdh.com"><i class="fa-fw fa fa-star"></i><span> AI工具导航</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://www.ai-lib.club"><i class="fa-fw fa fa-star"></i><span> 人工智能工具</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://ai-bot.cn"><i class="fa-fw fa fa-star"></i><span> AI工具集</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 教程</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" target="_blank" rel="noopener" href="https://learningprompt.wiki/"><i class="fa-fw fa fa-star"></i><span> Prompt教程</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-tools"></i><span> 在线</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/md_editor/"><i class="fa-fw fa fa-star"></i><span> 在线markdown</span></a></li><li><a class="site-page" target="_blank" rel="noopener" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts"><i class="fa-fw fa fa-star"></i><span> 在线push</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/message/"><i class="fa-fw far fa-comment-dots"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-user-circle"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Arxiv今日论文 | 2025-12-12<a class="post-edit-link" href="https://github.com/lonePatient/blog_source/tree/main/source/_posts/arxiv_papers_2025-12-12.md" title="编辑" target="_blank"><i class="fas fa-pencil-square"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-12-12T10:30:00.000Z" title="发表于 2025-12-12 10:30:00">2025-12-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-02-27T07:52:12.703Z" title="更新于 2026-02-27 07:52:12">2026-02-27</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E6%9C%AF%E4%BC%9A%E8%AE%AE/">学术会议</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%AD%A6%E6%9C%AF%E4%BC%9A%E8%AE%AE/Arxiv/">Arxiv</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">152.8k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>727分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-separator">|</span><span class="post-meta-commentcount"><i class="far fa-comments fa-fw post-meta-icon"></i><span class="post-meta-label">评论数:</span><a href="/2025/12/12/arxiv_papers_2025-12-12.html#post-comment"><span id="twikoo-count"></span></a></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇博文主要内容为 2025-12-12 从<a target="_blank" rel="noopener" href="https://arxiv.org">Arxiv.org</a>论文网站获取的最新论文列表，自动更新，按照NLP、CV、ML、AI、IR五个大方向区分，若需要邮件定时接收，请在评论区留下你的邮箱号。</p>
<div class="note info flat"><p>说明：每日论文数据从<a target="_blank" rel="noopener" href="https://arxiv.org">Arxiv.org</a>获取，每天早上12:00左右定时自动更新。</p>
</div>
<div class="note warning flat"><p>友情提示: 如何您需要<strong>邮箱</strong>接收每日论文数据，请在评论处留下你的邮箱。</p>
</div>
<h2 id="目录">目录</h2>
<ul>
<li><a href="#%E6%A6%82%E8%A7%88">概览</a></li>
<li><a href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86">自然语言处理CL</a></li>
<li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">人工智能AI</a></li>
<li><a href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0">机器学习LG</a></li>
<li><a href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89">计算机视觉CV</a></li>
<li><a href="#%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2">信息检索IR</a></li>
</ul>
<h3 id="概览-2025-12-12">概览 (2025-12-12)</h3>
<p>今日共更新<strong>493</strong>篇论文,其中:</p>
<ul>
<li><strong>自然语言处理</strong>共<strong>49</strong>篇(Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>))</li>
<li><strong>人工智能</strong>共<strong>147</strong>篇(Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>))</li>
<li><strong>计算机视觉</strong>共<strong>119</strong>篇(Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>))</li>
<li><strong>机器学习</strong>共<strong>145</strong>篇(Machine Learning (cs.LG))</li>
</ul>
<h3 id="自然语言处理">自然语言处理</h3>
<div class="note orange no-icon flat"><p>[NLP-0] Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation</p>
<p>【速读】： 该论文旨在解决将强化学习（Reinforcement Learning, RL）应用于3D生成任务时面临的挑战，特别是由于3D对象更高的空间复杂性导致的全局几何一致性与局部纹理精细度敏感性问题。为应对这些挑战，研究者首次系统性地探索了基于RL的文本到3D自回归生成方法，其关键解决方案包括：(1) 提出多维奖励设计策略，强调人类偏好对齐的重要性，并利用通用多模态模型提供鲁棒的3D属性信号；(2) 采用GRPO变体进行token级优化，验证训练数据规模和迭代次数的可扩展性；(3) 引入MME-3DR基准以评估模型隐式推理能力；(4) 提出Hi-GRPO框架，通过分层奖励集成实现从全局到局部的3D生成优化。最终构建了AR3D-R1，首个基于RL增强的文本到3D生成模型，实现了从粗略形状到纹理细化的专家级生成能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10949">https://arxiv.org/abs/2512.10949</a><br>
<strong>作者</strong>: Yiwen Tang,Zoey Guo,Kaixin Zhu,Ray Zhang,Qizhi Chen,Dongzhi Jiang,Junli Liu,Bohan Zeng,Haoming Song,Delin Qu,Tianyi Bai,Dan Xu,Wentao Zhang,Bin Zhao<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  Code is released at <a target="_blank" rel="noopener" href="https://github.com/Ivan-Tang-3D/3DGen-R1">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at this https URL.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-1] Stronger Normalization-Free Transformers</p>
<p>【速读】： 该论文旨在解决深度学习架构中传统归一化层（如LayerNorm、RMSNorm）是否为必需组件的问题，尤其针对近年来提出的动态双曲正切函数（Dynamic Tanh, DyT）所展现的无需显式归一化的潜力进行深入探索。其解决方案的关键在于通过系统分析点对点函数的内在性质对训练稳定性和模型性能的影响，进而开展大规模函数设计搜索，最终提出一种基于重缩放高斯累积分布函数（rescaled Gaussian cumulative distribution function, erf）的新型激活函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="normal">D</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">f</mi></mrow><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">f</mi></mrow><mo stretchy="false">(</mo><mi>α</mi><mi>x</mi><mo>+</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{Derf}(x) = \mathrm{erf}(\alpha x + s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathrm" style="margin-right:0.07778em;">Derf</span></span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathrm" style="margin-right:0.07778em;">erf</span></span><span class="mopen">(</span><span class="mord mathnormal">αx</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span>。该函数在多个领域（包括视觉识别与生成、语音表征和DNA序列建模）均超越LayerNorm、RMSNorm及DyT，且性能提升主要源于更强的泛化能力而非拟合能力，从而为无归一化Transformer架构提供了高效且简洁的新选择。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10938">https://arxiv.org/abs/2512.10938</a><br>
<strong>作者</strong>: Mingzhi Chen,Taiming Lu,Jiachen Zhu,Mingjie Sun,Zhuang Liu<br>
<strong>机构</strong>: Princeton University (普林斯顿大学); NYU (纽约大学); Carnegie Mellon University (卡内基梅隆大学)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Through this exploration, we introduce  \mathrmDerf(x) = \mathrmerf(\alpha x + s) , where  \mathrmerf(x)  is the rescaled Gaussian cumulative distribution function, and identify it as the most performant design. Derf outperforms LayerNorm, RMSNorm, and DyT across a wide range of domains, including vision (image recognition and generation), speech representation, and DNA sequence modeling. Our findings suggest that the performance gains of Derf largely stem from its improved generalization rather than stronger fitting capacity. Its simplicity and stronger performance make Derf a practical choice for normalization-free Transformer architectures.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-2] Asynchronous <mark class="hl-label green">Reasoning</mark> : Training-Free Interactive Thinking <mark class="hl-label green">LLM</mark> s</p>
<p>【速读】： 该论文旨在解决当前大语言模型（Large Language Models, LLMs）在推理过程中因采用串行交互模式而导致实时性差的问题。传统推理机制要求模型在接收到输入后必须完成全部思考过程才能生成输出，这与语音助手或嵌入式设备等实际应用场景中对低延迟、高响应性的需求不兼容。为实现类似人类“听、思、行”异步进行的能力，作者提出了一种无需额外训练的解决方案：利用旋转位置编码（rotary embeddings）的特性，使原本设计用于顺序交互的LLM能够并行地执行思考、接收输入和生成输出。实验表明，该方法可在数学、常识和安全推理任务上显著提升实时性能，将首个非思考token的延迟从数分钟缩短至5秒以内，并减少整体实时延迟6–11倍。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10931">https://arxiv.org/abs/2512.10931</a><br>
<strong>作者</strong>: George Yakushev,Nataliia Babina,Masoud Vahid Dastgerdi,Vyacheslav Zhdanovskiy,Alina Shutova,Denis Kuznedelev<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  Preprint, work in progress</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Many state-of-the-art LLMs are trained to think before giving their answer. Reasoning can greatly improve language model capabilities and safety, but it also makes them less interactive: given a new input, a model must stop thinking before it can respond. Real-world use cases such as voice-based or embedded assistants require an LLM agent to respond and adapt to additional information in real time, which is incompatible with sequential interactions. In contrast, humans can listen, think, and act asynchronously: we begin thinking about the problem while reading it and continue thinking while formulating the answer. In this work, we augment LLMs capable of reasoning to operate in a similar way without additional training. Our method uses the properties of rotary embeddings to enable LLMs built for sequential interactions to simultaneously think, listen, and generate outputs. We evaluate our approach on math, commonsense, and safety reasoning and find that it can generate accurate thinking-augmented answers in real time, reducing time to first non-thinking token from minutes to = 5s. and the overall real-time delays by 6-11x.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-3] CompanionCast: A Multi-<mark class="hl-label green">Agent</mark>  Conversational AI Framework with Spatial Audio for Social Co-Viewing Experiences</p>
<p>【速读】： 该论文旨在解决现代媒体消费日益孤立化的问题，探索如何通过多智能体对话式人工智能系统重构共享观看体验的社会临场感（social presence）。其核心挑战在于如何在不同内容类型中模拟真实观众间的互动动态，并确保对话质量与沉浸感。解决方案的关键在于提出CompanionCast框架，该框架通过角色专业化AI代理（role-specialized AI agents）对视频内容进行多模态感知（包括视觉、音频输入），结合语音合成与空间音频技术实现自然交互；同时创新性地引入LLM-as-a-Judge模块，以迭代评分和优化对话在相关性、真实性、参与度、多样性及人格一致性五个维度的表现，从而提升AI中介共看场景下的社会临场感。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10918">https://arxiv.org/abs/2512.10918</a><br>
<strong>作者</strong>: Yiyang Wang,Chen Chen,Tica Lin,Vishnu Raj,Josh Kimball,Alex Cabral,Josiah Hester<br>
<strong>机构</strong>: Georgia Institute of Technology (佐治亚理工学院); Dolby Laboratories, Inc. (杜比实验室公司)<br>
<strong>类目</strong>: Human-Computer Interaction (cs.HC); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  11 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Social presence is central to the enjoyment of watching content together, yet modern media consumption is increasingly solitary. We investigate whether multi-agent conversational AI systems can recreate the dynamics of shared viewing experiences across diverse content types. We present CompanionCast, a general framework for orchestrating multiple role-specialized AI agents that respond to video content using multimodal inputs, speech synthesis, and spatial audio. Distinctly, CompanionCast integrates an LLM-as-a-Judge module that iteratively scores and refines conversations across five dimensions (relevance, authenticity, engagement, diversity, personality consistency). We validate this framework through sports viewing, a domain with rich dynamics and strong social traditions, where a pilot study with soccer fans suggests that multi-agent interaction improves perceived social presence compared to solo viewing. We contribute: (1) a generalizable framework for orchestrating multi-agent conversations around multimodal video content, (2) a novel evaluator-agent pipeline for conversation quality control, and (3) exploratory evidence of increased social presence in AI-mediated co-viewing. We discuss challenges and future directions for applying this approach to diverse viewing contexts including entertainment, education, and collaborative watching experiences.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-4] Computational emotion analysis with multimodal <mark class="hl-label green">LLM</mark> s: Current evidence on an emerging methodological opportunity</p>
<p>【速读】： 该论文旨在解决当前多模态大语言模型（multimodal large language models, mLLMs）在视频情感唤醒（emotional arousal）分析中的有效性缺乏实证支持的问题。解决方案的关键在于通过两个互补的人工标注视频数据集，系统评估mLLMs在理想条件与真实政治语境（如议会辩论）下的情感唤醒评分可靠性，并揭示其在现实场景中可能出现的性能下降及潜在统计推断偏差，从而强调对生成式AI方法在政治分析中持续、严谨评估的必要性，并提供一个可复现的评估框架。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10882">https://arxiv.org/abs/2512.10882</a><br>
<strong>作者</strong>: Hauke Licht<br>
<strong>机构</strong>: University of Innsbruck (因斯布鲁克大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about the effectiveness of multimodal AI in emotion analysis. This paper addresses this gap by evaluating current multimodal large language models (mLLMs) in video-based analysis of emotional arousal in two complementary data sets of human-labeled video recordings. I find that under ideal circumstances, mLLMs’ emotional arousal ratings are highly reliable and show little to know indication of demographic bias. However, in recordings of speakers in real-world parliamentary debates, mLLMs’ arousal ratings fail to deliver on this promise with potential negative consequences for downstream statistical inferences. This study therefore underscores the need for continued, thorough evaluation of emerging generative AI methods in political analysis and contributes a suitable replicable framework.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-5] Quantifying Emotional Tone in Tolkiens The Hobbit: Dialogue Sentiment Analysis with RegEx NRC-VAD and Python</p>
<p>【速读】： 该论文旨在解决如何通过计算文本分析方法揭示《霍比特人》中对话的情感结构及其对叙事节奏的影响这一问题。其解决方案的关键在于使用正则表达式提取对话文本，结合NRC-VAD词典对情感维度（效价Valence、唤醒度Arousal、支配度Dominance）进行量化，并通过可视化手段（如情感轨迹图和词云）识别出故事进程中情绪的动态变化模式——即整体呈现高正向效价与低唤醒度特征，且支配度随情节推进逐步增强，反映出托尔金在紧张与轻松之间构建的稳定情感节奏。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10865">https://arxiv.org/abs/2512.10865</a><br>
<strong>作者</strong>: Lilin Qiu<br>
<strong>机构</strong>: University of Turin (都灵大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This study analyzes the emotional tone of dialogue in J. R. R. Tolkien’s The Hobbit (1937) using computational text analysis. Dialogue was extracted with regular expressions, then preprocessed, and scored using the NRC-VAD lexicon to quantify emotional dimensions. The results show that the dialogue maintains a generally positive (high valence) and calm (low arousal) tone, with a gradually increasing sense of agency (dominance) as the story progresses. These patterns reflect the novel’s emotional rhythm: moments of danger and excitement are regularly balanced by humor, camaraderie, and relief. Visualizations – including emotional trajectory graphs and word clouds – highlight how Tolkien’s language cycles between tension and comfort. By combining computational tools with literary interpretation, this study demonstrates how digital methods can uncover subtle emotional structures in literature, revealing the steady rhythm and emotional modulation that shape the storytelling in The Hobbit.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-6] LabelFusion: Learning to Fuse <mark class="hl-label green">LLM</mark> s and Transformer Classifiers for Robust Text Classification</p>
<p>【速读】： 该论文旨在解决多分类和多标签文本分类任务中如何有效融合传统Transformer模型与大型语言模型（Large Language Models, LLMs）以实现高准确率且成本可控的预测问题。其解决方案的关键在于提出LabelFusion融合集成方法，通过结构化提示工程（structured prompt-engineering）从LLM获取每类得分，并将其与传统Transformer骨干网络的嵌入向量拼接，输入一个轻量级多层感知机（FusionMLP）进行端到端训练，从而学习到两类模型间的互补优势，实现跨领域的鲁棒性能提升，同时在准确性、延迟和成本之间提供可调的权衡空间。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10793">https://arxiv.org/abs/2512.10793</a><br>
<strong>作者</strong>: Michael Schlee,Christoph Weisser,Timo Kivimäki,Melchizedek Mashiku,Benjamin Saefken<br>
<strong>机构</strong>: Georg-August-Universität Göttingen (哥廷根大学); University of Bath (巴斯大学); Tanaq Management Services LLC; Centers for Disease Control and Prevention (疾病控制与预防中心); Clausthal University of Technology (克劳斯塔尔工业大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:LabelFusion is a fusion ensemble for text classification that learns to combine a traditional transformer-based classifier (e.g., RoBERTa) with one or more Large Language Models (LLMs such as OpenAI GPT, Google Gemini, or DeepSeek) to deliver accurate and cost-aware predictions across multi-class and multi-label tasks. The package provides a simple high-level interface (AutoFusionClassifier) that trains the full pipeline end-to-end with minimal configuration, and a flexible API for advanced users. Under the hood, LabelFusion integrates vector signals from both sources by concatenating the ML backbone’s embeddings with the LLM-derived per-class scores – obtained through structured prompt-engineering strategies – and feeds this joint representation into a compact multi-layer perceptron (FusionMLP) that produces the final prediction. This learned fusion approach captures complementary strengths of LLM reasoning and traditional transformer-based classifiers, yielding robust performance across domains – achieving 92.4% accuracy on AG News and 92.3% on 10-class Reuters 21578 topic classification – while enabling practical trade-offs between accuracy, latency, and cost.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-7] he FACTS Leaderboard: A Comprehensive Benchmark for Large Language Model Factuality</p>
<p>【速读】： 该论文旨在解决当前语言模型在生成文本时缺乏事实准确性的问题，尤其是在多模态、参数化知识、信息检索和长文本生成等多样化场景下的表现评估不足。解决方案的关键在于构建一个全面的评估框架——FACTS Leaderboard Suite，通过四个子榜单（FACTS Multimodal、FACTS Parametric、FACTS Search 和 FACTS Grounding v2）分别衡量模型在图像问答、内部知识推理、外部搜索增强以及基于文档的长文本生成中的事实性表现，并采用自动化评分机制对各子任务进行量化评估，最终以加权平均的方式得出综合得分，从而提供一种鲁棒且平衡的模型事实性能力评测体系。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10791">https://arxiv.org/abs/2512.10791</a><br>
<strong>作者</strong>: Aileen Cheng,Alon Jacovi,Amir Globerson,Ben Golan,Charles Kwong,Chris Alberti,Connie Tao,Eyal Ben-David,Gaurav Singh Tomar,Lukas Haas,Yonatan Bitton,Adam Bloniarz,Aijun Bai,Andrew Wang,Anfal Siddiqui,Arturo Bajuelos Castillo,Aviel Atias,Chang Liu,Corey Fry,Daniel Balle,Deepanway Ghosal,Doron Kukliansky,Dror Marcus,Elena Gribovskaya,Eran Ofek,Honglei Zhuang,Itay Laish,Jan Ackermann,Lily Wang,Meg Risdal,Megan Barnes,Michael Fink,Mohamed Amin,Moran Ambar,Natan Potikha,Nikita Gupta,Nitzan Katz,Noam Velan,Ofir Roval,Ori Ram,Polina Zablotskaia,Prathamesh Bang,Priyanka Agrawal,Rakesh Ghiya,Sanjay Ganapathy,Simon Baumgartner,Sofia Erell,Sushant Prakash,Thibault Sellam,Vikram Rao,Xuanhui Wang,Yaroslav Akulov,Yulong Yang,Zhen Yang,Zhixin Lai,Zhongru Wu,Anca Dragan,Avinatan Hassidim,Fernando Pereira,Slav Petrov,Srinivasan Venkatachary,Tulsee Doshi,Yossi Matias,Sasha Goldshtein,Dipanjan Das<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce The FACTS Leaderboard, an online leaderboard suite and associated set of benchmarks that comprehensively evaluates the ability of language models to generate factually accurate text across diverse scenarios. The suite provides a holistic measure of factuality by aggregating the performance of models on four distinct sub-leaderboards: (1) FACTS Multimodal, which measures the factuality of responses to image-based questions; (2) FACTS Parametric, which assesses models’ world knowledge by answering closed-book factoid questions from internal parameters; (3) FACTS Search, which evaluates factuality in information-seeking scenarios, where the model must use a search API; and (4) FACTS Grounding (v2), which evaluates whether long-form responses are grounded in provided documents, featuring significantly improved judge models. Each sub-leaderboard employs automated judge models to score model responses, and the final suite score is an average of the four components, designed to provide a robust and balanced assessment of a model’s overall factuality. The FACTS Leaderboard Suite will be actively maintained, containing both public and private splits to allow for external participation while guarding its integrity. It can be found at this https URL .<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-8] Replace Dont Expand: Mitigating Context Dilution in Multi-Hop <mark class="hl-label green">RAG</mark>  via Fixed-Budget Evidence Assembly</p>
<p>【速读】： 该论文旨在解决检索增强生成（Retrieval-Augmented Generation, RAG）系统在处理多跳查询（multi-hop queries）时因初始检索遗漏桥接事实（bridge fact）而导致性能下降的问题。现有修正方法如Self-RAG、CRAG和Adaptive-k通常通过扩展上下文或修剪已有列表来应对，但简单增加上下文窗口易引发“上下文稀释”（context dilution），即无关信息挤占关键证据。本文提出无需训练的控制器SEAL-RAG，其核心创新在于采用“替换而非扩展”（replace, don’t expand）策略，在固定检索深度k下主动优化top-k槽位内容：通过执行搜索（Search）→提取（Extract）→评估（Assess）→循环（Loop）的迭代流程，基于实体锚定（entity-anchored）的动态提取构建缺失实体/关系的“间隙规范”（gap specification），触发针对性微查询，并利用以实体优先排序（entity-first ranking）机制精准替换冗余信息，从而提升答案准确率与证据精度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10787">https://arxiv.org/abs/2512.10787</a><br>
<strong>作者</strong>: Moshe Lahmy,Roi Yozevitch<br>
<strong>机构</strong>: Ariel University ( Ariel 大学)<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  24 pages, 2 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Retrieval-Augmented Generation (RAG) systems often fail on multi-hop queries when the initial retrieval misses a bridge fact. Prior corrective approaches, such as Self-RAG, CRAG, and Adaptive- k , typically address this by \textitadding more context or pruning existing lists. However, simply expanding the context window often leads to \textbfcontext dilution, where distractors crowd out relevant information. We propose \textbfSEAL-RAG, a training-free controller that adopts a \textbf``replace, don’t expand’’ strategy to fight context dilution under a fixed retrieval depth  k . SEAL executes a (\textbfSearch  \rightarrow  \textbfExtract  \rightarrow  \textbfAssess  \rightarrow  \textbfLoop) cycle: it performs on-the-fly, entity-anchored extraction to build a live \textitgap specification (missing entities/relations), triggers targeted micro-queries, and uses \textitentity-first ranking to actively swap out distractors for gap-closing evidence. We evaluate SEAL-RAG against faithful re-implementations of Basic RAG, CRAG, Self-RAG, and Adaptive- k  in a shared environment on \textbfHotpotQA and \textbf2WikiMultiHopQA. On HotpotQA ( k=3 ), SEAL improves answer correctness by \textbf+3–13 pp and evidence precision by \textbf+12–18 pp over Self-RAG. On 2WikiMultiHopQA ( k=5 ), it outperforms Adaptive- k  by \textbf+8.0 pp in accuracy and maintains \textbf96% evidence precision compared to 22% for CRAG. These gains are statistically significant ( p0.001 ). By enforcing fixed- k  replacement, SEAL yields a predictable cost profile while ensuring the top- k  slots are optimized for precision rather than mere breadth. We release our code and data at this https URL.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-9] Script Gap: Evaluating <mark class="hl-label green">LLM</mark>  Triage on Indian Languages in Native vs Roman Scripts in a Real World Setting</p>
<p>【速读】： 该论文旨在解决生成式 AI (Generative AI) 在印度高风险临床场景中因用户使用罗马化文本（romanized text）而非本土文字（native script）而导致的可靠性下降问题。其关键发现是：尽管大型语言模型（LLMs）能够正确理解罗马化输入的语义意图，但其最终分类输出仍因正字法噪声（orthographic noise）而变得脆弱，导致在母婴健康分诊任务中出现显著性能下降（F1分数低5–12个百分点），可能引发近两百万次错误分诊。因此，解决方案的关键在于识别并缓解这种“看似理解却无法可靠执行”的安全盲点，而非单纯提升模型对罗马化文本的语义解析能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10780">https://arxiv.org/abs/2512.10780</a><br>
<strong>作者</strong>: Manurag Khullar,Utkarsh Desai,Poorva Malviya,Aman Dalmia,Zheyuan Ryan Shi<br>
<strong>机构</strong>: University of Pittsburgh (匹兹堡大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) are increasingly deployed in high-stakes clinical applications in India. In many such settings, speakers of Indian languages frequently communicate using romanized text rather than native scripts, yet existing research rarely evaluates this orthographic variation using real-world data. We investigate how romanization impacts the reliability of LLMs in a critical domain: maternal and newborn healthcare triage. We benchmark leading LLMs on a real-world dataset of user-generated queries spanning five Indian languages and Nepali. Our results reveal consistent degradation in performance for romanized messages, with F1 scores trailing those of native scripts by 5-12 points. At our partner maternal health organization in India, this gap could cause nearly 2 million excess errors in triage. Crucially, this performance gap by scripts is not due to a failure in clinical reasoning. We demonstrate that LLMs often correctly infer the semantic intent of romanized queries. Nevertheless, their final classification outputs remain brittle in the presence of orthographic noise in romanized inputs. Our findings highlight a critical safety blind spot in LLM-based health systems: models that appear to understand romanized input may still fail to act on it reliably.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-10] Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation</p>
<p>【速读】： 该论文旨在解决大规模多语言语言模型在中低资源语言上性能不足的问题，尤其是在小规模模型下难以达到与特定语言优化模型相当的效果。其核心解决方案是通过模型缩放（scaling）策略，将英语基础模型放大后引入目标语言数据进行适应，而非采用传统的持续预训练方式。研究表明，在获得足够目标语言数据的前提下，放大后的模型能以更少的数据实现与持续预训练小模型相当甚至更优的性能，同时有效缓解灾难性遗忘问题，保持英语能力；此外，论文还探索了缩放后语言特异性模型的合并机制，发现缩放合并优于未缩放合并，为构建模块化、灵活的多语言系统提供了新路径。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10772">https://arxiv.org/abs/2512.10772</a><br>
<strong>作者</strong>: Kevin Glocker,Kätriin Kukk,Romina Oji,Marcel Bollmann,Marco Kuhlmann,Jenny Kunz<br>
<strong>机构</strong>: Linköping University (林雪平大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Achieving high-performing language models which include medium- and lower-resource languages remains a challenge. Massively multilingual models still underperform compared to language-specific adaptations, especially at smaller model scales. In this work, we investigate scaling as an efficient strategy for adapting pretrained models to new target languages. Through comprehensive scaling ablations with approximately FLOP-matched models, we test whether upscaling an English base model enables more effective and resource-efficient adaptation than standard continued pretraining. We find that, once exposed to sufficient target-language data, larger upscaled models can match or surpass the performance of smaller models continually pretrained on much more data, demonstrating the benefits of scaling for data efficiency. Scaling also helps preserve the base model’s capabilities in English, thus reducing catastrophic forgetting. Finally, we explore whether such scaled, language-specific models can be merged to construct modular and flexible multilingual systems. We find that while merging remains less effective than joint multilingual training, upscaled merges perform better than smaller ones. We observe large performance differences across merging methods, suggesting potential for improvement through merging approaches specialized for language-level integration.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-11] OPV: Outcome-based Process Verifier for Efficient Long Chain-of-Thought Verification</p>
<p>【速读】： 该论文旨在解决当前验证机制在复杂推理任务中难以有效检测长链思维（Chain-of-Thought, CoT）过程中错误的问题。具体而言，基于结果的验证器（Outcome-based Verifiers, OVs）无法审查推理中间步骤的可靠性，而基于过程的验证器（Process-based Verifiers, PVs）受限于高质量标注数据稀缺，难以可靠识别复杂长CoT中的错误。解决方案的关键在于提出一种新型的<strong>基于结果的过程验证器（Outcome-based Process Verifier, OPV）</strong>，其通过验证从长CoT中总结出的结果合理性来实现高效且准确的验证，并支持大规模自动标注。为提升OPV性能，作者进一步设计了一种迭代式主动学习框架，结合专家标注与拒绝微调（Rejection Fine-Tuning, RFT）和强化学习（Reinforcement Learning with Verifiable Rewards, RLVR），逐步优化验证能力并显著降低标注成本。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10756">https://arxiv.org/abs/2512.10756</a><br>
<strong>作者</strong>: Zijian Wu,Lingkai Kong,Wenwei Zhang,Songyang Gao,Yuzhe Gu,Zhongrui Cai,Tianyou Ma,Yuhong Liu,Zhi Wang,Runyuan Ma,Guangyu Wang,Wei Li,Conghui He,Dahua Lin,Kai Chen<br>
<strong>机构</strong>: Shanghai AI Laboratory(上海人工智能实验室); MMLab, The Chinese University of Hong Kong(多媒体实验室，香港中文大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the Outcome-based Process Verifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV’s superior performance and broad applicability. It achieves new state-of-the-art results on our held-out OPV-Bench, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2% to 73.3% on AIME2025 as the compute budget scales.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-12] RIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage</p>
<p>【速读】： 该论文旨在解决紧急语音识别系统在非标准英语变体（特别是加勒比口音）上表现系统性退化的问题，从而导致加勒比地区人群无法平等获得国家既定的分诊协议（如ESI和START）。其解决方案的核心是提出TRIDENT架构——一种三层调度员支持系统，通过融合针对加勒比口音优化的自动语音识别（ASR）、基于大语言模型的本地实体抽取以及生物声学应激检测，向调度员提供三种互补信号：转录置信度、结构化临床实体和声音应激指标。关键创新在于将低ASR置信度重新定义为一种有价值的队列优先级信号，尤其当与高应激标记结合时，可识别处于危机状态且可能使用底层方言（basilectal registers）的来电者；同时，通过语义分析弥补仅依赖副语言特征（paralinguistic features）可能遗漏的生命威胁信息，确保即使在自动识别失败或呼叫者无明显应激反应的情况下，仍能准确提取临床关键信息。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10741">https://arxiv.org/abs/2512.10741</a><br>
<strong>作者</strong>: Elroy Galbraith,Chadwick Sutherland,Donahue Morgan<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Emergency speech recognition systems exhibit systematic performance degradation on non-standard English varieties, creating a critical gap in services for Caribbean populations. We present TRIDENT (Transcription and Routing Intelligence for Dispatcher-Empowered National Triage), a three-layer dispatcher-support architecture designed to structure emergency call inputs for human application of established triage protocols (the ESI for routine operations and START for mass casualty events), even when automatic speech recognition fails. The system combines Caribbean-accent-tuned ASR, local entity extraction via large language models, and bio-acoustic distress detection to provide dispatchers with three complementary signals: transcription confidence, structured clinical entities, and vocal stress indicators. Our key insight is that low ASR confidence, rather than representing system failure, serves as a valuable queue prioritization signal – particularly when combined with elevated vocal distress markers indicating a caller in crisis whose speech may have shifted toward basilectal registers. A complementary insight drives the entity extraction layer: trained responders and composed bystanders may report life-threatening emergencies without elevated vocal stress, requiring semantic analysis to capture clinical indicators that paralinguistic features miss. We describe the architectural design, theoretical grounding in psycholinguistic research on stress-induced code-switching, and deployment considerations for offline operation during disaster scenarios. This work establishes a framework for accent-resilient emergency AI that ensures Caribbean voices receive equitable access to established national triage protocols. Empirical validation on Caribbean emergency calls remains future work.         Subjects:  Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)  Cite as: arXiv:2512.10741 [<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>]    (or  arXiv:2512.10741v1 [<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10741">https://doi.org/10.48550/arXiv.2512.10741</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-13] Long-horizon <mark class="hl-label green">Reasoning</mark>  <mark class="hl-label green">Agent</mark>  for Olympiad-Level Mathematical Problem Solving</p>
<p>【速读】： 该论文旨在解决当前验证机制在长链思维（Chain-of-Thought, CoT）推理过程中存在的两大局限：一是基于结果的验证器（Outcome-based Verifier, OV）无法有效检查中间步骤的可靠性；二是基于过程的验证器（Process-based Verifier, PV）受限于高质量标注数据稀缺，难以准确识别复杂长CoT中的错误。解决方案的关键在于提出一种新型验证框架——<strong>基于结果的过程验证器（Outcome-based Process Verifier, OPV）</strong>，其通过分析从长CoT中总结出的结果来验证推理过程，从而兼顾准确性与效率，并支持大规模自动化标注。为提升OPV性能，作者进一步设计了一种迭代式主动学习框架，结合专家标注与拒绝微调（Rejection Fine-Tuning, RFT）和强化学习带可验证奖励（Reinforcement Learning with Verifiable Rewards, RLVR），以低标注成本持续优化验证能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10739">https://arxiv.org/abs/2512.10739</a><br>
<strong>作者</strong>: Songyang Gao,Yuzhe Gu,Zijian Wu,Lingkai Kong,Wenwei Zhang,Zhongrui Cai,Fan Zheng,Tianyou Ma,Junhao Shen,Haiteng Zhao,Duanyang Zhang,Huilun Zhang,Kuikun Liu,Chengqi Lyu,Yanhui Duan,Chiyu Chen,Ningsheng Ma,Jianfei Gao,Han Lyu,Dahua Lin,Kai Chen<br>
<strong>机构</strong>: Shanghai AI Laboratory (上海人工智能实验室); Shanghai Jiao Tong University (上海交通大学); MMLab (多媒体实验室); The Chinese University of Hong Kong (香港中文大学); ICMAT (西班牙国家研究委员会); The High School Affiliated to Renmin University of China (中国人民大学附属中学); Ren Hui Academy of Beijing (北京仁慧学院)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the \textbfOutcome-based \textbfProcess \textbfVerifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV’s superior performance and broad applicability. It achieves new state-of-the-art results on our held-out \textsc\thisbench, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2% to 73.3% on AIME2025 as the compute budget scales.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-14] xtual Data Bias Detection and Mitigation - An Extensible Pipeline with Experimental Evaluation</p>
<p>【速读】： 该论文旨在解决大规模语言模型（Large Language Models, LLMs）训练数据中存在的多维度偏见问题，包括有害语言和人口统计分布失衡等表现形式，尤其关注对受保护群体的不公平影响。其核心挑战在于现有法规（如欧盟《人工智能法案》）要求识别并缓解数据中的偏见，但缺乏可操作的实践指导。解决方案的关键在于提出一个包含四个模块的系统性数据偏见检测与缓解流程：首先利用基于质量标准生成的LLM词表识别相关群体标签；其次通过“人口代表性得分”量化表示偏见；第三采用社会语言学启发的过滤方法检测并缓解显式刻板印象；最后借助语法与上下文感知的反事实数据增强技术补偿表示偏见。该框架在性别、宗教和年龄三个敏感属性上验证了有效性，尽管能显著降低数据层面的偏见，但发现经去偏数据微调后的模型在偏见基准测试中并未一致提升性能，揭示了当前评估方法的局限性，并强调需针对模型表现偏见进行更精准的数据干预。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10734">https://arxiv.org/abs/2512.10734</a><br>
<strong>作者</strong>: Rebekka Görge,Sujan Sai Gannamaneni,Tabea Naeven,Hammam Abdelwahab,Héctor Allende-Cid,Armin B. Cremers,Lennard Helmer,Michael Mock,Anna Schmitz,Songkai Xue,Elif Yildirir,Maximilian Poretschkin,Stefan Wrobel<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Textual data used to train large language models (LLMs) exhibits multifaceted bias manifestations encompassing harmful language and skewed demographic distributions. Regulations such as the European AI Act require identifying and mitigating biases against protected groups in data, with the ultimate goal of preventing unfair model outputs. However, practical guidance and operationalization are lacking. We propose a comprehensive data bias detection and mitigation pipeline comprising four components that address two data bias types, namely representation bias and (explicit) stereotypes for a configurable sensitive attribute. First, we leverage LLM-generated word lists created based on quality criteria to detect relevant group labels. Second, representation bias is quantified using the Demographic Representation Score. Third, we detect and mitigate stereotypes using sociolinguistically informed filtering. Finally, we compensate representation bias through Grammar- and Context-Aware Counterfactual Data Augmentation. We conduct a two-fold evaluation using the examples of gender, religion and age. First, the effectiveness of each individual component on data debiasing is evaluated through human validation and baseline comparison. The findings demonstrate that we successfully reduce representation bias and (explicit) stereotypes in a text dataset. Second, the effect of data debiasing on model bias reduction is evaluated by bias benchmarking of several models (0.6B-8B parameters), fine-tuned on the debiased text dataset. This evaluation reveals that LLMs fine-tuned on debiased data do not consistently show improved performance on bias benchmarks, exposing critical gaps in current evaluation methodologies and highlighting the need for targeted data manipulation to address manifested model bias.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-15] Remember Me Refine Me: A Dynamic Procedural Memory Framework for Experience-Driven <mark class="hl-label green">Agent</mark>  Evolution</p>
<p>【速读】： 该论文旨在解决大语言模型（Large Language Model, LLM）代理在长期任务执行中因记忆机制静态化而导致的效率低下问题，即现有框架多采用“被动积累”模式，将记忆视为仅可追加的静态存储库，无法实现动态推理与持续优化。其解决方案的关键在于提出ReMe（Remember Me, Refine Me）框架，通过三个核心机制重构记忆生命周期：1）多维度提炼（multi-faceted distillation），从成功模式识别、失败触发分析和对比洞察中提取细粒度经验；2）上下文自适应重用（context-adaptive reuse），基于场景感知索引适配历史知识至新情境；3）基于效用的精炼（utility-based refinement），自动保留有效记忆并剔除过时内容以维持高质量、紧凑的经验池。实验证明，该框架显著提升了代理的自我演化能力，并在BFCL-V3和AppWorld上达到新SOTA性能，且展现出显著的记忆扩展效应——具备ReMe的Qwen3-8B优于无记忆的大模型Qwen3-14B，验证了自进化记忆对计算高效终身学习的价值。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10696">https://arxiv.org/abs/2512.10696</a><br>
<strong>作者</strong>: Zouying Cao,Jiaji Deng,Li Yu,Weikang Zhou,Zhaoyang Liu,Bolin Ding,Hai Zhao<br>
<strong>机构</strong>: Shanghai Jiao Tong University (上海交通大学); Tongyi Lab (通义实验室); Alibaba Group (阿里巴巴集团)<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  16 pages, 9 figures, 9 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Procedural memory enables large language model (LLM) agents to internalize “how-to” knowledge, theoretically reducing redundant trial-and-error. However, existing frameworks predominantly suffer from a “passive accumulation” paradigm, treating memory as a static append-only archive. To bridge the gap between static storage and dynamic reasoning, we propose  \textbfReMe  ( \textitRemember Me, Refine Me ), a comprehensive framework for experience-driven agent evolution. ReMe innovates across the memory lifecycle via three mechanisms: 1)  \textitmulti-faceted distillation , which extracts fine-grained experiences by recognizing success patterns, analyzing failure triggers and generating comparative insights; 2)  \textitcontext-adaptive reuse , which tailors historical insights to new contexts via scenario-aware indexing; and 3)  \textitutility-based refinement , which autonomously adds valid memories and prunes outdated ones to maintain a compact, high-quality experience pool. Extensive experiments on BFCL-V3 and AppWorld demonstrate that ReMe establishes a new state-of-the-art in agent memory system. Crucially, we observe a significant memory-scaling effect: Qwen3-8B equipped with ReMe outperforms larger, memoryless Qwen3-14B, suggesting that self-evolving memory provides a computation-efficient pathway for lifelong learning. We release our code and the  \textttthis http URL  dataset to facilitate further research.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-16] From Data Scarcity to Data Care: Reimagining Language Technologies for Serbian and other Low-Resource Languages</p>
<p>【速读】： 该论文旨在解决低资源语言（如塞尔维亚语）在生成式 AI（Generative AI）时代面临的技术发展不平等与文化偏见问题，其根源在于历史文本遗产的破坏、当代工程导向的简化方法以及数据集构建中缺乏文化特异性。解决方案的关键在于提出“Data Care”框架，该框架以CARE原则（集体受益、控制权、责任与伦理）为基础，将偏见缓解从事后技术修正转变为语料库设计、标注与治理中的核心组成部分，从而推动更具包容性、可持续性和文化根基的语言技术建设。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10630">https://arxiv.org/abs/2512.10630</a><br>
<strong>作者</strong>: Smiljana Antonijevic Ubois<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language models are commonly trained on dominant languages like English, and their representation of low resource languages typically reflects cultural and linguistic biases present in the source language materials. Using the Serbian language as a case, this study examines the structural, historical, and sociotechnical factors shaping language technology development for low resource languages in the AI age. Drawing on semi structured interviews with ten scholars and practitioners, including linguists, digital humanists, and AI developers, it traces challenges rooted in historical destruction of Serbian textual heritage, intensified by contemporary issues that drive reductive, engineering first approaches prioritizing functionality over linguistic nuance. These include superficial transliteration, reliance on English-trained models, data bias, and dataset curation lacking cultural specificity. To address these challenges, the study proposes Data Care, a framework grounded in CARE principles (Collective Benefit, Authority to Control, Responsibility, and Ethics), that reframes bias mitigation from a post hoc technical fix to an integral component of corpus design, annotation, and governance, and positions Data Care as a replicable model for building inclusive, sustainable, and culturally grounded language technologies in contexts where traditional LLM development reproduces existing power imbalances and cultural blind spots.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-17] Agri<mark class="hl-label green">GPT</mark> -Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence</p>
<p>【速读】： 该论文旨在解决农业领域中多模态大语言模型应用受限的问题，具体包括多语言语音数据匮乏、统一的多模态架构缺失以及缺乏全面的评估基准。其解决方案的关键在于提出AgriGPT-Omni框架：首先构建可扩展的数据合成与采集管道，生成包含492K合成和1.4K真实语音样本的多语言农业语音数据集；其次通过三阶段训练范式（文本知识注入、渐进式多模态对齐、基于GRPO的强化学习）训练首个农业多模态模型，实现跨语言和跨模态的统一推理；最后设计AgriBench-Omni-2K这一首个农业三模态基准，涵盖多样化的语音-视觉-文本任务及多语言子集，提供标准化协议与可复现工具。实验证明，AgriGPT-Omni在多语言和多模态推理及真实语音理解上显著优于通用基线模型。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10624">https://arxiv.org/abs/2512.10624</a><br>
<strong>作者</strong>: Bo Yang,Lanfei Feng,Yunkui Chen,Yu Zhang,Jianyu Zhang,Xiao Xu,Nueraili Aierken,Shijian Li<br>
<strong>机构</strong>: Zhejiang University (浙江大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Despite rapid advances in multimodal large language models, agricultural applications remain constrained by the lack of multilingual speech data, unified multimodal architectures, and comprehensive evaluation benchmarks. To address these challenges, we present AgriGPT-Omni, an agricultural omni-framework that integrates speech, vision, and text in a unified framework. First, we construct a scalable data synthesis and collection pipeline that converts agricultural texts and images into training data, resulting in the largest agricultural speech dataset to date, including 492K synthetic and 1.4K real speech samples across six languages. Second, based on this, we train the first agricultural omni-model via a three-stage paradigm: textual knowledge injection, progressive multimodal alignment, and GRPO-based reinforcement learning, enabling unified reasoning across languages and modalities. Third, we propose AgriBench-Omni-2K, the first tri-modal benchmark for agriculture, covering diverse speech-vision-text tasks and multilingual slices, with standardized protocols and reproducible tools. Experiments show that AgriGPT-Omni significantly outperforms general-purpose baselines on multilingual and multimodal reasoning as well as real-world speech understanding. All models, data, benchmarks, and code will be released to promote reproducible research, inclusive agricultural intelligence, and sustainable AI development for low-resource regions.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-18] RoleRMBench  RoleRM: Towards Reward Modeling for Profile-Based Role Play in Dialogue Systems</p>
<p>【速读】： 该论文旨在解决当前奖励模型（Reward Modeling）在主观性与开放性场景（如角色扮演对话）中表现严重退化的问题，尤其在捕捉叙事连贯性和角色一致性等细粒度人类判断方面存在显著不足。其解决方案的关键在于提出一种基于连续隐式偏好（Continuous Implicit Preferences, CIP）的新训练范式，将主观评估重构为多结构策略下的连续一致成对监督信号，从而提升模型对角色扮演场景中叙事逻辑和风格一致性的建模能力。实验表明，所提出的RoleRM模型在RoleRMBench基准上相较主流开源与闭源奖励模型平均性能提升超过24%，验证了连续偏好表示与标注一致性对主观对齐的重要性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10575">https://arxiv.org/abs/2512.10575</a><br>
<strong>作者</strong>: Hang Ding,Qiming Feng,Dongqi Liu,Qi Zhao,Tao Yao,Shuo Wang,Dongsheng Chen,Jian Li,Zhenye Gan,Jiangning Zhang,Chengjie Wang,Yabiao Wang<br>
<strong>机构</strong>: Shanghai Jiao Tong University (上海交通大学); Fudan University (复旦大学); Saarland University (萨尔兰大学); Tencent Youtu Lab (腾讯优图实验室)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Reward modeling has become a cornerstone of aligning large language models (LLMs) with human preferences. Yet, when extended to subjective and open-ended domains such as role play, existing reward models exhibit severe degradation, struggling to capture nuanced and persona-grounded human judgments. To address this gap, we introduce RoleRMBench, the first systematic benchmark for reward modeling in role-playing dialogue, covering seven fine-grained capabilities from narrative management to role consistency and engagement. Evaluation on RoleRMBench reveals large and consistent gaps between general-purpose reward models and human judgment, particularly in narrative and stylistic dimensions. We further propose RoleRM, a reward model trained with Continuous Implicit Preferences (CIP), which reformulates subjective evaluation as continuous consistent pairwise supervision under multiple structuring strategies. Comprehensive experiments show that RoleRM surpasses strong open- and closed-source reward models by over 24% on average, demonstrating substantial gains in narrative coherence and stylistic fidelity. Our findings highlight the importance of continuous preference representation and annotation consistency, establishing a foundation for subjective alignment in human-centered dialogue systems.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-19] Causal <mark class="hl-label green">Reasoning</mark>  Favors Encoders: On The Limits of Decoder-Only Models</p>
<p>【速读】： 该论文旨在解决大语言模型（Large Language Models, LLMs）在因果推理任务中依赖上下文学习（In-Context Learning, ICL）时表现不稳定的问题，尤其是当输入存在伪词汇关联（spurious lexical relations）时可能导致错误推理。其核心挑战在于因果推理需要多跳组合（multihop composition）和严格的合取控制（conjunctive control），而现有仅解码器架构的模型在分布外泛化能力上表现脆弱。解决方案的关键在于采用编码器（encoder）或编码器-解码器（encoder-decoder）架构，并通过针对性微调（targeted fine-tuning），使其能更有效地将输入映射到潜在空间（latent space），从而实现更鲁棒的因果推理，尤其在自然语言与非自然语言场景下均表现出优于仅解码器模型的稳定性，且在小规模场景下更具成本效益。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10561">https://arxiv.org/abs/2512.10561</a><br>
<strong>作者</strong>: Amartya Roy,Elamparithy M,Kripabandhu Ghosh,Ponnurangam Kumaraguru,Adrian de Wynter<br>
<strong>机构</strong>: SIRE, IIT Delhi and Robert Bosch GmbH, India; IIIT Hyderabad; IISER Kolkata; Microsoft and the University of York<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In context learning (ICL) underpins recent advances in large language models (LLMs), although its role and performance in causal reasoning remains unclear. Causal reasoning demands multihop composition and strict conjunctive control, and reliance on spurious lexical relations of the input could provide misleading results. We hypothesize that, due to their ability to project the input into a latent space, encoder and encoder decoder architectures are better suited for said multihop conjunctive reasoning versus decoder only models. To do this, we compare fine-tuned versions of all the aforementioned architectures with zero and few shot ICL in both natural language and non natural language scenarios. We find that ICL alone is insufficient for reliable causal reasoning, often overfocusing on irrelevant input features. In particular, decoder only models are noticeably brittle to distributional shifts, while finetuned encoder and encoder decoder models can generalize more robustly across our tests, including the non natural language split. Both architectures are only matched or surpassed by decoder only architectures at large scales. We conclude by noting that for cost effective, short horizon robust causal reasoning, encoder or encoder decoder architectures with targeted finetuning are preferable.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-20] XDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in <mark class="hl-label green">LLM</mark> s</p>
<p>【速读】： 该论文旨在解决当前大语言模型（Large Language Models, LLMs）在训练过程中过度依赖高资源语言（如英语）而导致中低资源语言（如加利西亚语、巴斯克语等）性能显著下降的问题。其解决方案的关键在于：首先，通过扩展域重加权算法（DoGE）为多语言场景下的XDoGE算法，训练一个小型代理模型以优化语言分布；其次，基于所得语言权重对训练数据进行再缩放，并在此基础上从头预训练或在持续预训练（Continual Pre-Training, CPT）阶段微调全尺寸模型，从而实现对低资源语言的更好支持。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10545">https://arxiv.org/abs/2512.10545</a><br>
<strong>作者</strong>: Iñaki Lacunza,José Javier Saiz,Alexander Shvets,Aitor Gonzalez-Agirre,Marta Villegas<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  Accepted and presented at the LLMs4All workshop at the IEEE BigData 2025 Conference, Macau - December 8-11, 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Current large language models (LLMs) are trained on massive amounts of text data, primarily from a few dominant languages. Studies suggest that this over-reliance on high-resource languages, such as English, hampers LLM performance in mid- and low-resource languages. To mitigate this problem, we propose to (i) optimize the language distribution by training a small proxy model within a domain-reweighing DoGE algorithm that we extend to XDoGE for a multilingual setup, and (ii) rescale the data and train a full-size model with the established language weights either from scratch or within a continual pre-training phase (CPT). We target six languages possessing a variety of geographic and intra- and inter-language-family relations, namely, English and Spanish (high-resource), Portuguese and Catalan (mid-resource), Galician and Basque (low-resource). We experiment with Salamandra-2b, which is a promising model for these languages. We investigate the effects of substantial data repetition on minor languages and under-sampling on dominant languages using the IberoBench framework for quantitative evaluation. Finally, we release a new promising IberianLLM-7B-Instruct model centering on Iberian languages and English that we pretrained from scratch and further improved using CPT with the XDoGE weights.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-21] Grammaticality Judgments in Humans and Language Models: Revisiting Generative Grammar with <mark class="hl-label green">LLM</mark> s</p>
<p>【速读】： 该论文旨在解决一个核心语法哲学问题：在缺乏显式结构标注的情况下，大型语言模型（LLMs）是否能够通过仅学习表层形式的预测训练，捕捉到句法结构的内在规律性证据。传统生成语法认为，诸如主语-助动词倒装和寄生空位许可等系统性语法判断差异是句法结构存在的关键证据。论文通过设计针对这两个经典句法现象的可接受性评分实验，发现GPT-4和LLaMA-3等模型能可靠地区分合法与非法变体，表明其对句法结构具有功能性敏感性，而不仅仅是对线性顺序的依赖。解决方案的关键在于：即使没有显式的句法知识编码，基于表层文本的预测训练也能促使模型自发习得抽象的句法结构特征，从而在行为层面表现出对深层语法结构的识别能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10453">https://arxiv.org/abs/2512.10453</a><br>
<strong>作者</strong>: Lars G.B. Johnsen<br>
<strong>机构</strong>: National Library of Norway (挪威国家图书馆)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  2 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:What counts as evidence for syntactic structure? In traditional generative grammar, systematic contrasts in grammaticality such as subject-auxiliary inversion and the licensing of parasitic gaps are taken as evidence for an internal, hierarchical grammar. In this paper, we test whether large language models (LLMs), trained only on surface forms, reproduce these contrasts in ways that imply an underlying structural representation. We focus on two classic constructions: subject-auxiliary inversion (testing recognition of the subject boundary) and parasitic gap licensing (testing abstract dependency structure). We evaluate models including GPT-4 and LLaMA-3 using prompts eliciting acceptability ratings. Results show that LLMs reliably distinguish between grammatical and ungrammatical variants in both constructions, and as such support that they are sensitive to structure and not just linear order. Structural generalizations, distinct from cognitive knowledge, emerge from predictive training on surface forms, suggesting functional sensitivity to syntax without explicit encoding.          Comments: 2 figures   Subjects:  Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)  Cite as: arXiv:2512.10453 [<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>]    (or  arXiv:2512.10453v1 [<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10453">https://doi.org/10.48550/arXiv.2512.10453</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-22] When Reject Turns into Accept: Quantifying the Vulnerability of <mark class="hl-label green">LLM</mark> -Based Scientific Reviewers to Indirect Prompt Injection</p>
<p>【速读】： 该论文旨在解决生成式 AI（Generative AI）在科学同行评审中作为“评委”（LLM-as-a-Judge）时面临的对抗性攻击脆弱性问题，尤其是针对将“拒稿”（Reject）决策篡改为“接收”（Accept）的恶意操作。其解决方案的关键在于提出了一种新的评估指标——加权对抗脆弱性评分（WAVS），并构建了一个包含200篇科学论文的数据集与15种领域特定的PDF篡改攻击策略，系统性地评估了13种主流语言模型（包括GPT-5、Claude Haiku和DeepSeek）在面对此类攻击时的鲁棒性表现，发现如“Maximum Mark Magyk”等混淆策略可在大模型中实现高成功率的决策翻转，揭示了当前AI评审系统存在的严重安全风险。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10449">https://arxiv.org/abs/2512.10449</a><br>
<strong>作者</strong>: Devanshu Sahoo,Manish Prasad,Vasudev Majhi,Jahnvi Singh,Vinay Chamola,Yash Sinha,Murari Mandal,Dhruv Kumar<br>
<strong>机构</strong>: BITS Pilani(比特理工学院); KIIT University(基伊特大学)<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The landscape of scientific peer review is rapidly evolving with the integration of Large Language Models (LLMs). This shift is driven by two parallel trends: the widespread individual adoption of LLMs by reviewers to manage workload (the “Lazy Reviewer” hypothesis) and the formal institutional deployment of AI-powered assessment systems by conferences like AAAI and Stanford’s Agents4Science. This study investigates the robustness of these “LLM-as-a-Judge” systems (both illicit and sanctioned) to adversarial PDF manipulation. Unlike general jailbreaks, we focus on a distinct incentive: flipping “Reject” decisions to “Accept,” for which we develop a novel evaluation metric which we term as WAVS (Weighted Adversarial Vulnerability Score). We curated a dataset of 200 scientific papers and adapted 15 domain-specific attack strategies to this task, evaluating them across 13 Language Models, including GPT-5, Claude Haiku, and DeepSeek. Our results demonstrate that obfuscation strategies like “Maximum Mark Magyk” successfully manipulate scores, achieving alarming decision flip rates even in large-scale models. We will release our complete dataset and injection framework to facilitate more research on this topic.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-23] Decoding Student Minds: Leve<mark class="hl-label green">rag</mark> ing Conversational <mark class="hl-label green">Agents</mark>  for Psychological and Learning Analysis</p>
<p>【速读】： 该论文旨在解决传统教育聊天机器人在学习支持与情感关怀方面功能单一的问题，即多数系统仅专注于知识传授或情绪安抚中的某一方面，难以实现对学生认知状态（如理解程度）与情感状态（如压力、参与度）的协同感知与动态响应。解决方案的关键在于构建一个心理感知型对话代理，其核心由三部分组成：一是利用知识图谱增强的BERT（KG-BERT）进行语义推理以识别概念掌握水平；二是通过带注意力机制的双向长短期记忆网络（bidirectional LSTM with attention）建模时间序列行为趋势；三是融合文本语义、语音韵律特征等多模态数据，实现实时分类学生的认知与情感状态（cognitive and affective states）。该架构使系统能够同时提升学习效果与心理福祉，从而支持个性化、自适应的教学干预。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10441">https://arxiv.org/abs/2512.10441</a><br>
<strong>作者</strong>: Nour El Houda Ben Chaabene,Hamza Hammami,Laid Kahloul<br>
<strong>机构</strong>: Sorbonne University (索邦大学); ENIT (国立电信工程学院); University of Biskra (比斯克拉大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  This manuscript is currently under peer review in Expert Systems with Applications</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper presents a psychologically-aware conversational agent designed to enhance both learning performance and emotional well-being in educational settings. The system combines Large Language Models (LLMs), a knowledge graph-enhanced BERT (KG-BERT), and a bidirectional Long Short-Term Memory (LSTM) with attention to classify students’ cognitive and affective states in real time. Unlike prior chatbots limited to either tutoring or affective support, our approach leverages multimodal data-including textual semantics, prosodic speech features, and temporal behavioral trends-to infer engagement, stress, and conceptual understanding. A pilot study with university students demonstrated improved motivation, reduced stress, and moderate academic gains compared to baseline methods. These results underline the promise of integrating semantic reasoning, multimodal fusion, and temporal modeling to support adaptive, student-centered educational interventions.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-24] Enhancing Next-Generation Language Models with Knowledge Graphs: Extending Claude Mistral IA and <mark class="hl-label green">GPT</mark> -4 via KG-BERT <mark class="hl-label red">ALT</mark> <mark class="hl-label red">ALT2025</mark></p>
<p>【速读】： 该论文旨在解决大型语言模型（Large Language Models, LLMs）在自然语言处理任务中因缺乏结构化知识而导致的事实性不一致问题。其解决方案的关键在于通过引入知识图谱（Knowledge Graphs, KGs）并结合KG-BERT框架，增强模型的常识 grounding 和推理能力，从而显著提升在问答和实体链接等知识密集型任务中的表现，提高事实可靠性与上下文感知能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10440">https://arxiv.org/abs/2512.10440</a><br>
<strong>作者</strong>: Nour El Houda Ben Chaabene,Hamza Hammami<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  This paper was accepted and scheduled for inclusion in the ICALT 2025 proceedings but was ultimately not published due to absence from the conference presentation. It appears in the official program booklet. Conference: 2025 IEEE International Conference on Advanced Learning Technologies (ICALT)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language models (LLMs) like Claude, Mistral IA, and GPT-4 excel in NLP but lack structured knowledge, leading to factual inconsistencies. We address this by integrating Knowledge Graphs (KGs) via KG-BERT to enhance grounding and reasoning. Experiments show significant gains in knowledge-intensive tasks such as question answering and entity linking. This approach improves factual reliability and enables more context-aware next-generation LLMs.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-25] Semantic Reconstruction of Adversarial Plagiarism: A Context-Aware Framework for Detecting and Restoring “Tortured Phrases” in Scientific Literature</p>
<p>【速读】： 该论文旨在解决由对抗性文本生成技术（如自动化改写工具）对科学文献完整性与可靠性造成的威胁，特别是通过生成“扭曲短语”（tortured phrases）来掩盖抄袭行为的问题。这类短语在局部语法上合理但语义异常（例如用“counterfeit consciousness”替代“artificial intelligence”），导致现有检测方法因依赖静态黑名单或通用领域语言模型而出现高假阴性率，且无法追溯原文来源。解决方案的关键在于提出Semantic Reconstruction of Adversarial Plagiarism (SRAP)框架，采用两阶段架构：第一阶段利用领域特定的掩码语言模型（SciBERT）基于token级伪困惑度进行统计异常检测；第二阶段结合密集向量检索（FAISS）与句子级对齐（SBERT）实现源文档驱动的语义重建，从而数学还原被混淆的原始术语。实验表明，该方法在平行对抗文本语料上的恢复准确率达23.67%，显著优于零样本基线（0.00%），并验证了静态决策边界对于高专业术语密度文本中稳健检测的重要性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10435">https://arxiv.org/abs/2512.10435</a><br>
<strong>作者</strong>: Agniva Maiti,Prajwal Panth,Suresh Chandra Satapathy<br>
<strong>机构</strong>: KIIT University (KIIT 大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:  10 pages, 5 figures; unpublished manuscript; submitted to arXiv for dissemination</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The integrity and reliability of scientific literature is facing a serious threat by adversarial text generation techniques, specifically from the use of automated paraphrasing tools to mask plagiarism. These tools generate “tortured phrases”, statistically improbable synonyms (e.g. “counterfeit consciousness” for “artificial intelligence”), that preserve the local grammar while obscuring the original source. Most existing detection methods depend heavily on static blocklists or general-domain language models, which suffer from high false-negative rates for novel obfuscations and cannot determine the source of the plagiarized content. In this paper, we propose Semantic Reconstruction of Adversarial Plagiarism (SRAP), a framework designed not only to detect these anomalies but to mathematically recover the original terminology. We use a two-stage architecture: (1) statistical anomaly detection with a domain-specific masked language model (SciBERT) using token-level pseudo-perplexity, and (2) source-based semantic reconstruction using dense vector retrieval (FAISS) and sentence-level alignment (SBERT). Experiments on a parallel corpus of adversarial scientific text show that while zero-shot baselines fail completely (0.00 percent restoration accuracy), our retrieval-augmented approach achieves 23.67 percent restoration accuracy, significantly outperforming baseline methods. We also show that static decision boundaries are necessary for robust detection in jargon-heavy scientific text, since dynamic thresholding fails under high variance. SRAP enables forensic analysis by linking obfuscated expressions back to their most probable source documents.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-26] -pro 2.0: An Efficient Russian Hybrid-<mark class="hl-label green">Reasoning</mark>  Model and Playground</p>
<p>【速读】： 该论文旨在解决俄罗斯语大语言模型（Large Language Model, LLM）在推理效率与可复现性方面的挑战，特别是针对生成式 AI (Generative AI) 在俄语场景下缺乏高效推理机制和开放资源的问题。解决方案的关键在于：构建 T-pro 2.0 模型，其采用 Cyrillic 密集分词器（Cyrillic-dense tokenizer）以优化俄语表示，并集成改进的 EAGLE 推理加速流水线（EAGLE speculative-decoding pipeline），从而实现低延迟的直接回答与推理轨迹生成；同时开源模型权重、T-Wix 500k 指令语料库、T-Math 推理基准及 EAGLE 权重，支持研究可复现性和应用扩展，使俄语生成式 AI 的高效部署成为可能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10430">https://arxiv.org/abs/2512.10430</a><br>
<strong>作者</strong>: Dmitrii Stoianov,Danil Taranets,Olga Tsymboi,Ramil Latypov,Almaz Dautov,Vladislav Kruglikov,Nikita Surkov,German Abramov,Pavel Gein,Dmitry Abulkhanov,Mikhail Gashkov,Viktor Zelenkovskiy,Artem Batalov,Aleksandr Medvedev,Anatolii Potapov<br>
<strong>机构</strong>: T-Tech(科技公司)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce T-pro 2.0, an open-weight Russian LLM for hybrid reasoning and efficient inference. The model supports direct answering and reasoning-trace generation, using a Cyrillic-dense tokenizer and an adapted EAGLE speculative-decoding pipeline to reduce latency. To enable reproducible and extensible research, we release the model weights, the T-Wix 500k instruction corpus, the T-Math reasoning benchmark, and the EAGLE weights on Hugging Face. These resources allow users to study Russian-language reasoning and to extend or adapt both the model and the inference pipeline. A public web demo exposes reasoning and non-reasoning modes and illustrates the speedups achieved by our inference stack across domains. T-pro 2.0 thus serves as an accessible open system for building and evaluating efficient, practical Russian LLM applications.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-27] Cooperative Retrieval-Augmented Generation for Question Answering: Mutual Information Exchange and Ranking by Contrasting Layers <mark class="hl-label red">NEURIPS2025</mark></p>
<p>【速读】： 该论文旨在解决大型语言模型（Large Language Models, LLMs）在问答（Question Answering, QA）任务中因仅依赖自身知识而产生事实性错误（即幻觉）的问题，尤其针对现有检索增强生成（Retrieval-Augmented Generation, RAG）方法在简单和多跳QA场景下仍存在检索不准确与推理错误的问题。其解决方案的关键在于提出一种协同式RAG框架（CoopRAG），该框架通过检索器与LLM之间的信息交互实现协同推理：首先将问题分解为子问题和带掩码的推理链，利用增强后的查询进行文档检索；其次通过对比检索器不同层的表示对结果进行重排序；最后由LLM填充掩码位置以重构完整推理链，从而提升检索精度与问答准确性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10422">https://arxiv.org/abs/2512.10422</a><br>
<strong>作者</strong>: Youmin Ko,Sungjong Seo,Hyunjoon Kim<br>
<strong>机构</strong>: Hanyang University (汉阳大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Accepted to NeurIPS 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Since large language models (LLMs) have a tendency to generate factually inaccurate output, retrieval-augmented generation (RAG) has gained significant attention as a key means to mitigate this downside of harnessing only LLMs. However, existing RAG methods for simple and multi-hop question answering (QA) are still prone to incorrect retrievals and hallucinations. To address these limitations, we propose CoopRAG, a novel RAG framework for the question answering task in which a retriever and an LLM work cooperatively with each other by exchanging informative knowledge, and the earlier and later layers of the retriever model work cooperatively with each other to accurately rank the retrieved documents relevant to a given query. In this framework, we (i) unroll a question into sub-questions and a reasoning chain in which uncertain positions are masked, (ii) retrieve the documents relevant to the question augmented with the sub-questions and the reasoning chain, (iii) rerank the documents by contrasting layers of the retriever, and (iv) reconstruct the reasoning chain by filling the masked positions via the LLM. Our experiments demonstrate that CoopRAG consistently outperforms state-of-the-art QA methods on three multi-hop QA datasets as well as a simple QA dataset in terms of both the retrieval and QA performances. Our code is available.\footnotethis https URL<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-28] Sliding Window Attention Adaptation</p>
<p>【速读】： 该论文旨在解决基于Transformer的大语言模型（Large Language Models, LLMs）在长文本推理时因自注意力机制（self-attention mechanism）复杂度随输入长度呈二次增长而导致的计算成本高昂的问题。尽管滑动窗口注意力（Sliding Window Attention, SWA）可将复杂度降至线性，但直接在推理阶段对预训练时使用全注意力（Full Attention, FA）的模型启用SWA会导致严重的长文本性能下降，这是由于训练与推理不一致所引发的“训练-推理失配”（training-inference mismatch）。论文提出滑动窗口注意力适应方法（Sliding Window Attention Adaptation, SWAA），其关键在于通过五种协同策略的组合实现有效适配：仅在预填充阶段应用SWA、保留“sink”令牌、交错FA/SWA层结构、引入思维链（Chain-of-Thought, CoT）提示以及微调（fine-tuning）。实验表明，单一方法不足以恢复原始性能，而特定组合能显著提升长上下文能力，从而在效率与性能之间达成平衡。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10411">https://arxiv.org/abs/2512.10411</a><br>
<strong>作者</strong>: Yijiong Yu,Jiale Liu,Qingyun Wu,Huazheng Wang,Ji Pei<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The self-attention mechanism in Transformer-based Large Language Models (LLMs) scales quadratically with input length, making long-context inference expensive. Sliding window attention (SWA) reduces this cost to linear complexity, but naively enabling complete SWA at inference-time for models pretrained with full attention (FA) causes severe long-context performance degradation due to training-inference mismatch. This makes us wonder: Can FA-pretrained LLMs be well adapted to SWA without pretraining? We investigate this by proposing Sliding Window Attention Adaptation (SWAA), a set of practical recipes that combine five methods for better adaptation: (1) applying SWA only during prefilling; (2) preserving “sink” tokens; (3) interleaving FA/SWA layers; (4) chain-of-thought (CoT); and (5) fine-tuning. Our experiments show that SWA adaptation is feasible while non-trivial: no single method suffices, yet specific synergistic combinations effectively recover the original long-context performance. We further analyze the performance-efficiency trade-offs of different SWAA configurations and provide recommended recipes for diverse scenarios. Our code is available at this https URL<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-29] BRACE: A Benchmark for Robust Audio Caption Quality Evaluation</p>
<p>【速读】： 该论文旨在解决参考-free（无参考）音频字幕评估中缺乏系统性验证的问题，尤其是当前广泛使用的CLAPScore指标在多样场景下的鲁棒性尚未得到充分检验。其解决方案的关键在于提出BRACE基准，这是一个专门用于评估音频字幕对齐质量的参考-free评测框架，包含两个子基准：BRACE-Main用于细粒度字幕对比，BRACE-Hallucination用于检测细微的幻觉内容；该基准通过高质量过滤、LLM驱动的扰动和人工标注构建数据集，并首次系统性地评估了CLAPScore与大型音频语言模型（Large Audio Language Model, LALM）在真实复杂场景中的表现，揭示了现有方法在精度上的显著局限，为未来研究提供了明确方向。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10403">https://arxiv.org/abs/2512.10403</a><br>
<strong>作者</strong>: Tianyu Guo,Hongyu Chen,Hao Liang,Meiyi Qiang,Bohan Zeng,Linzhuang Sun,Bin Cui,Wentao Zhang<br>
<strong>机构</strong>: Peking University (北京大学); University of Chinese Academy of Sciences (中国科学院大学)<br>
<strong>类目</strong>: ound (<a target="_blank" rel="noopener" href="http://cs.SD">cs.SD</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Automatic audio captioning is essential for audio understanding, enabling applications such as accessibility and content indexing. However, evaluating the quality of audio captions remains a major challenge, especially in reference-free settings where high-quality ground-truth captions are unavailable. While CLAPScore is currently the most widely used reference-free Audio Caption Evaluation Metric(ACEM), its robustness under diverse conditions has not been systematically validated. To address this gap, we introduce BRACE, a new benchmark designed to evaluate audio caption alignment quality in a reference-free setting. BRACE is primarily designed for assessing ACEMs, and can also be extended to measure the modality alignment abilities of Large Audio Language Model(LALM). BRACE consists of two sub-benchmarks: BRACE-Main for fine-grained caption comparison and BRACE-Hallucination for detecting subtle hallucinated content. We construct these datasets through high-quality filtering, LLM-based corruption, and human annotation. Given the widespread adoption of CLAPScore as a reference-free ACEM and the increasing application of LALMs in audio-language tasks, we evaluate both approaches using the BRACE benchmark, testing CLAPScore across various CLAP model variants and assessing multiple LALMs. Notably, even the best-performing CLAP-based ACEM achieves only a 70.01 F1-score on the BRACE-Main benchmark, while the best LALM reaches just 63.19. By revealing the limitations of CLAP models and LALMs, our BRACE benchmark offers valuable insights into the direction of future research.         Subjects:  Sound (<a target="_blank" rel="noopener" href="http://cs.SD">cs.SD</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)  Cite as: arXiv:2512.10403 [<a target="_blank" rel="noopener" href="http://cs.SD">cs.SD</a>]    (or  arXiv:2512.10403v1 [<a target="_blank" rel="noopener" href="http://cs.SD">cs.SD</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10403">https://doi.org/10.48550/arXiv.2512.10403</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)        Submission history From: Hao Liang [view email]       [v1]         Thu, 11 Dec 2025 08:09:24 UTC (1,311 KB)       Full-text links: Access Paper:   View a PDF of the paper titled BRACE: A Benchmark for Robust Audio Caption Quality Evaluation, by Tianyu Guo and 7 other authorsView PDFHTML (experimental)TeX Source     view license         Current browse context: <a target="_blank" rel="noopener" href="http://cs.SD">cs.SD</a>   prev   |   next   new  |  recent  | 2025-12      Change to browse by:      cs <a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>     References  Citations  NASA ADSGoogle Scholar Semantic Scholar     export BibTeX citation Loading…     BibTeX formatted citation    loading…   Data provided by:      Bookmark           checked=“checked”&gt;     Bibliographic Tools  Bibliographic and Citation Tools       Bibliographic Explorer Toggle    Bibliographic Explorer (What is the Explorer?)        Connected Papers Toggle    Connected Papers (What is Connected Papers?)       Litmaps Toggle    Litmaps (What is Litmaps?)        <a target="_blank" rel="noopener" href="http://scite.ai">scite.ai</a> Toggle    scite Smart Citations (What are Smart Citations?)          Code, Data, Media  Code, Data and Media Associated with this Article       alphaXiv Toggle    alphaXiv (What is alphaXiv?)        Links to Code Toggle    CatalyzeX Code Finder for Papers (What is CatalyzeX?)        DagsHub Toggle    DagsHub (What is DagsHub?)        GotitPub Toggle    Gotit.pub (What is GotitPub?)        Huggingface Toggle    Hugging Face (What is Huggingface?)        Links to Code Toggle    Papers with Code (What is Papers with Code?)        ScienceCast Toggle    ScienceCast (What is ScienceCast?)              Demos  Demos       Replicate Toggle    Replicate (What is Replicate?)        Spaces Toggle    Hugging Face Spaces (What is Spaces?)        Spaces Toggle    <a target="_blank" rel="noopener" href="http://TXYZ.AI">TXYZ.AI</a> (What is <a target="_blank" rel="noopener" href="http://TXYZ.AI">TXYZ.AI</a>?)         Related Papers  Recommenders and Search Tools       Link to Influence Flower    Influence Flower (What are Influence Flowers?)        Core recommender toggle    CORE Recommender (What is CORE?)      Author Venue Institution Topic                      About arXivLabs           arXivLabs: experimental projects with community collaborators arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website. Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them. Have an idea for a project that will add value for arXiv’s community? Learn more about arXivLabs.           Which authors of this paper are endorsers? |     Disable MathJax (What is MathJax?)       mathjaxToggle();           About Help      contact arXivClick here to contact arXiv  Contact   subscribe to arXiv mailingsClick here to subscribe  Subscribe            Copyright Privacy Policy     Web Accessibility Assistance   arXiv Operational Status<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-30] Confucius Code <mark class="hl-label green">Agent</mark> : An Open-sourced AI Software Engineer at Industrial Scale</p>
<p>【速读】： 该论文旨在解决当前AI软件工程中编码代理（coding agent）在工业规模应用下的三大核心挑战：一是对大规模代码库的推理能力不足，二是跨会话与会话内长期记忆维护困难，三是复杂工具链在测试时的鲁棒协调能力弱。现有开源代理虽具透明性但性能受限，而专有代理虽表现优异却缺乏可扩展性、可解释性和可控性。解决方案的关键在于提出Confucius Code Agent（CCA）及其底层开发平台Confucius SDK，该平台从Agent Experience（AX）、User Experience（UX）和Developer Experience（DX）三方面协同设计：引入具有分层工作内存的统一编排器以支持长上下文推理，构建持久化笔记系统实现跨会话持续学习，以及通过模块化扩展模块保障工具调用的鲁棒性；此外，元代理（meta-agent）通过“构建-测试-改进”循环自动化配置合成与优化，显著提升新任务、环境和工具栈上的开发效率。这一架构使CCA在SWE-Bench-Pro上达到54.3%的Resolve@1最优性能，为AI代理提供了一个可透明、可扩展、可复现且适用于工业级部署的基础。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10398">https://arxiv.org/abs/2512.10398</a><br>
<strong>作者</strong>: Zhaodong Wang,Zhenting Qi,Sherman Wong,Nathan Hu,Samuel Lin,Jun Ge,Erwin Gao,Yining Yang,Ben Maurer,Wenlin Chen,David Recordon,Yilun Du,Minlan Yu,Ying Zhang<br>
<strong>机构</strong>: Harvard University (哈佛大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG); Software Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Real-world AI software engineering demands coding agents that can reason over massive repositories, maintain durable memory across and within long sessions, and robustly coordinate complex toolchains at test time. Existing open-source coding agents provide transparency but frequently fall short when pushed to these industrial-scale workloads, while proprietary coding agents offer strong practical performance but limited extensibility, interpretability, and controllability. We present the Confucius Code Agent (CCA), an open-sourced AI software engineer that can operate at an industrial scale. CCA is built atop the Confucius SDK, an open-sourced agent development platform designed around three complementary perspectives: Agent Experience (AX), User Experience (UX), and Developer Experience (DX). The SDK introduces a unified orchestrator with hierarchical working memory for long-context reasoning, a persistent note-taking system for cross-session continual learning, and a modular extension module for robust tool use. Moreover, a meta-agent automates the synthesis, evaluation, and refinement of agent configurations through a build-test-improve loop, enabling rapid agent development on new tasks, environments, and tool stacks. Instantiated on Confucius SDK with these mechanisms, CCA delivers strong performance on real-world software engineering tasks. On SWE-Bench-Pro, CCA achieves a state-of-the-art Resolve@1 performance of 54.3%, substantially improving over prior coding agents. Together, the Confucius SDK and CCA provide a transparent, extensible, and reproducible foundation for AI agents, bridge gaps between research prototypes and production-grade systems, and support agent development and deployment at industrial scale.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-31] GPG: Generalized Policy Gradient Theorem for Transformer-based Policies</p>
<p>【速读】： 该论文旨在解决基于Transformer架构的策略优化问题，特别是在大型语言模型（LLM）训练中如何实现高效且稳定的策略更新。其核心贡献在于提出了广义策略梯度（Generalized Policy Gradient, GPG）定理，该定理统一了标准策略梯度定理与GRPO（Generalized Reward Policy Optimization）方法，使其成为GPG框架下的特例。解决方案的关键在于构建一个适用于Transformer-based策略的通用数学框架，从而为复杂神经网络结构下的策略优化提供理论支持和实践指导，显著提升了在LLM训练中的策略学习效率与稳定性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10365">https://arxiv.org/abs/2512.10365</a><br>
<strong>作者</strong>: Hangyu Mao,Guangting Dong,Zhicheng Dou<br>
<strong>机构</strong>: Peking University (北京大学); Renmin University of China (中国人民大学)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present the Generalized Policy Gradient (GPG) Theorem, specifically designed for Transformer-based policies. Notably, we demonstrate that both standard Policy Gradient Theorem and GRPO emerge as special cases within our GPG framework. Furthermore, we explore its practical applications in training Large Language Models (LLMs), offering new insights into efficient policy optimization.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-32] Multilingual VLM Training: Adapting an English-Trained VLM to French</p>
<p>【速读】： 该论文旨在解决当前视觉-语言模型（Vision-Language Models, VLMs）主要局限于英语环境、难以有效支持多语言应用的问题。其核心挑战在于如何将已训练于英语数据的VLM适配至其他语言，同时平衡性能提升与计算成本。论文提出并比较了三种解决方案：基于翻译的流水线方法、LoRA微调（Low-Rank Adaptation Fine-tuning）以及分阶段微调策略（先适应视觉模态、再适应语言模态）。关键发现是：尽管不同方法在技术路径上各有优势，但数据质量仍是限制多语言VLM性能的主要瓶颈，尤其体现在翻译后的数据集在训练和评估中的有效性不足。因此，研究强调未来工作应优先聚焦于原生语言数据集的构建与更高质量的翻译策略优化。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10336">https://arxiv.org/abs/2512.10336</a><br>
<strong>作者</strong>: Jules Lahmi,Alexis Roger<br>
<strong>机构</strong>: Ecole Polytechnique (巴黎综合理工学院); Mila - Quebec AI Institute (魁北克人工智能研究所); McGill University (麦吉尔大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Artificial intelligence has made great progress in recent years, particularly in the development of Vision–Language Models (VLMs) that understand both visual and textual data. However, these advancements remain largely limited to English, reducing their accessibility for non–English speakers. It is essential to extend these capabilities to a broader range of languages. This paper explores the challenges of adapting an English-trained VLM to different languages. To this end, we will explore and compare different methods for their performance and computational cost. We consider a translation-based pipeline, LoRA finetuning, and a two-stage finetuning strategy that separates vision adaptation from language adaptation. To evaluate these methods, we use a combination of standard multimodal benchmarks translated into the target language and manual assessments by native experts. The results reveal that dataset translation remains a major bottleneck in multilingual VLM performance, with data quality limiting the effectiveness of training and evaluation. These findings suggest that future efforts should focus on native-language dataset collection and improved translation strategies.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-33] MotionEdit: Benchmarking and Learning Motion-Centric Image Editing</p>
<p>【速读】： 该论文旨在解决**运动导向的图像编辑（motion-centric image editing）**问题，即在保持主体身份、结构和物理合理性不变的前提下，精确修改目标对象的动作与交互行为。现有图像编辑数据集多聚焦于静态外观变化或仅提供稀疏且低质量的运动编辑样本，难以支撑高质量视频生成与动画等下游应用。为此，作者构建了MotionEdit数据集，包含从连续视频中提取并验证的高保真图像对，用于真实运动变换的建模；同时提出MotionNFT（Motion-guided Negative-aware Fine Tuning）框架，其核心在于通过计算输入图像与模型编辑结果之间的运动流一致性来生成运动对齐奖励信号，从而引导扩散模型实现更准确的运动转换，显著提升运动保真度而不牺牲通用编辑能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10284">https://arxiv.org/abs/2512.10284</a><br>
<strong>作者</strong>: Yixin Wan,Lei Ke,Wenhao Yu,Kai-Wei Chang,Dong Yu<br>
<strong>机构</strong>: Tencent AI (腾讯AI); University of California, Los Angeles (加州大学洛杉矶分校)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce MotionEdit, a novel dataset for motion-centric image editing-the task of modifying subject actions and interactions while preserving identity, structure, and physical plausibility. Unlike existing image editing datasets that focus on static appearance changes or contain only sparse, low-quality motion edits, MotionEdit provides high-fidelity image pairs depicting realistic motion transformations extracted and verified from continuous videos. This new task is not only scientifically challenging but also practically significant, powering downstream applications such as frame-controlled video synthesis and animation. To evaluate model performance on the novel task, we introduce MotionEdit-Bench, a benchmark that challenges models on motion-centric edits and measures model performance with generative, discriminative, and preference-based metrics. Benchmark results reveal that motion editing remains highly challenging for existing state-of-the-art diffusion-based editing models. To address this gap, we propose MotionNFT (Motion-guided Negative-aware Fine Tuning), a post-training framework that computes motion alignment rewards based on how well the motion flow between input and model-edited images matches the ground-truth motion, guiding models toward accurate motion transformations. Extensive experiments on FLUX.1 Kontext and Qwen-Image-Edit show that MotionNFT consistently improves editing quality and motion fidelity of both base models on the motion editing task without sacrificing general editing ability, demonstrating its effectiveness.         Subjects:  Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)  Cite as: arXiv:2512.10284 [<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>]    (or  arXiv:2512.10284v1 [<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10284">https://doi.org/10.48550/arXiv.2512.10284</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-34] AutoMedic: An Automated Evaluation Framework for Clinical Conversational <mark class="hl-label green">Agents</mark>  with Medical Dataset Grounding</p>
<p>【速读】： 该论文旨在解决当前大型语言模型（Large Language Models, LLMs）在医疗领域应用中，缺乏对动态、交互式临床多轮对话场景下性能的有效评估问题。现有静态医学问答（Question-Answering, QA）基准难以覆盖真实临床交互的复杂性，且评价维度单一，无法全面衡量LLMs在临床对话中的准确性、效率、共情能力与鲁棒性。解决方案的关键在于提出AutoMedic——一个基于多智能体（multi-agent）的模拟框架，可将通用静态QA数据集转化为虚拟患者档案，从而生成具有临床真实性的多轮对话场景，并通过CARE指标（Clinical Conversational Accuracy, Efficiency/Strategy, Empathy, Robustness）实现多维量化评估，验证了其作为自动化评估工具的有效性和实用性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10195">https://arxiv.org/abs/2512.10195</a><br>
<strong>作者</strong>: Gyutaek Oh,Sangjoon Park,Byung-Hoon Kim<br>
<strong>机构</strong>: Yonsei University College of Medicine (延世大学医学院); Yonsei Institute for Digital Health (延世数字健康研究所)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Machine Learning (cs.LG); Multiagent Systems (<a target="_blank" rel="noopener" href="http://cs.MA">cs.MA</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Evaluating large language models (LLMs) has recently emerged as a critical issue for safe and trustworthy application of LLMs in the medical domain. Although a variety of static medical question-answering (QA) benchmarks have been proposed, many aspects remain underexplored, such as the effectiveness of LLMs in generating responses in dynamic, interactive clinical multi-turn conversation situations and the identification of multi-faceted evaluation strategies beyond simple accuracy. However, formally evaluating a dynamic, interactive clinical situation is hindered by its vast combinatorial space of possible patient states and interaction trajectories, making it difficult to standardize and quantitatively measure such scenarios. Here, we introduce AutoMedic, a multi-agent simulation framework that enables automated evaluation of LLMs as clinical conversational agents. AutoMedic transforms off-the-shelf static QA datasets into virtual patient profiles, enabling realistic and clinically grounded multi-turn clinical dialogues between LLM agents. The performance of various clinical conversational agents is then assessed based on our CARE metric, which provides a multi-faceted evaluation standard of clinical conversational accuracy, efficiency/strategy, empathy, and robustness. Our findings, validated by human experts, demonstrate the validity of AutoMedic as an automated evaluation framework for clinical conversational agents, offering practical guidelines for the effective development of LLMs in conversational medical applications.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-35] Watermarks for Language Models via Probabilistic Automata</p>
<p>【速读】： 该论文旨在解决现有语言模型水印方案中存在的两个关键问题：一是生成多样性受限，导致水印嵌入后模型输出缺乏自然性和丰富性；二是检测开销较高，难以在实际部署中高效运行。此外，传统方法在面对编辑距离攻击时虽具鲁棒性，但未充分考虑对抗者对水印的检测与伪造能力，即缺乏“不可检测性”（undetectability）。解决方案的核心在于引入基于概率自动机（probabilistic automata）的新水印构造框架，该框架可实现两类实例化：其一为实用型方案，具备指数级生成多样性和计算效率；其二为理论型构造，在密码学假设下提供形式化的不可检测性保障。实验验证表明，所提方案在LLaMA-3B和Mistral-7B模型上显著优于现有方法，在鲁棒性与效率之间取得更好平衡。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10185">https://arxiv.org/abs/2512.10185</a><br>
<strong>作者</strong>: Yangkun Wang,Jingbo Shang<br>
<strong>机构</strong>: University of California, San Diego (加州大学圣地亚哥分校)<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:A recent watermarking scheme for language models achieves distortion-free embedding and robustness to edit-distance attacks. However, it suffers from limited generation diversity and high detection overhead. In parallel, recent research has focused on undetectability, a property ensuring that watermarks remain difficult for adversaries to detect and spoof. In this work, we introduce a new class of watermarking schemes constructed through probabilistic automata. We present two instantiations: (i) a practical scheme with exponential generation diversity and computational efficiency, and (ii) a theoretical construction with formal undetectability guarantees under cryptographic assumptions. Extensive experiments on LLaMA-3B and Mistral-7B validate the superior performance of our scheme in terms of robustness and efficiency.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-36] CIEGAD: Cluster-Conditioned Interpolative and Extrapolative Framework for Geometry-Aware and Domain-Aligned Data Augmentation</p>
<p>【速读】： 该论文旨在解决深度学习部署中因数据稀缺和标签分布不平衡导致的语义未覆盖区域问题，这些问题会阻碍模型训练，并在类别边界附近引发误分类及外围区域行为不稳定。其解决方案的关键在于提出一种几何感知且域对齐的数据增强框架CIEGAD（Cluster-conditioned Interpolative and Extrapolative framework for Geometry-Aware and Domain-aligned data augmentation），该框架通过聚类条件构建域特征画像，采用融合类别频率与几何指标的分层分配策略进行生成控制，并利用插值与外推协同合成机制实现生成方向的精确调控；同时结合几何约束过滤与LLM-as-a-Judge的质量控制机制，从而系统性地补全分布内与分布外的语义空白区域，在保持生成数据与真实数据高对齐度的同时提升语义多样性与质量，尤其在长尾和多分类任务中显著改善F1和召回率，验证了分布一致性、多样性和质量三者的协同优化效果。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10178">https://arxiv.org/abs/2512.10178</a><br>
<strong>作者</strong>: Keito Inoshita,Xiaokang Zhou,Akira Kawai,Katsutoshi Yada<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In practical deep learning deployment, the scarcity of data and the imbalance of label distributions often lead to semantically uncovered regions within the real-world data distribution, hindering model training and causing misclassification near class boundaries as well as unstable behaviors in peripheral areas. Although recent large language models (LLMs) show promise for data augmentation, an integrated framework that simultaneously achieves directional control of generation, domain alignment, and quality control has not yet been fully established. To address these challenges, we propose a Cluster-conditioned Interpolative and Extrapolative framework for Geometry-Aware and Domain-aligned data augmentation (CIEGAD), which systematically complements both in-distribution and out-of-distribution semantically uncovered regions. CIEGAD constructs domain profiles through cluster conditioning, allocates generation with a hierarchical frequency-geometric allocation integrating class frequency and geometric indicators, and finely controls generation directions via the coexistence of interpolative and extrapolative synthesis. It further performs quality control through geometry-constrained filtering combined with an LLM-as-a-Judge mechanism. Experiments on multiple classification tasks demonstrate that CIEGAD effectively extends the periphery of real-world data distributions while maintaining high alignment between generated and real-world data as well as semantic diversity. In particular, for long-tailed and multi-class classification tasks, CIEGAD consistently improves F1 and recall, validating the triple harmony of distributional consistency, diversity, and quality. These results indicate that CIEGAD serves as a practically oriented data augmentation framework that complements underrepresented regions while preserving alignment with real-world data.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-37] Offscript: Automated Auditing of Instruction Adherence in <mark class="hl-label green">LLM</mark> s</p>
<p>【速读】： 该论文试图解决的问题是：当前大型语言模型（Large Language Models, LLMs）在信息检索场景中被广泛用于满足不同用户对知识来源和呈现方式的个性化需求，但缺乏有效的机制来评估用户通过自定义指令（custom instructions）设定的行为规范是否被模型准确遵循。解决方案的关键在于提出并实现了一个名为 Offscript 的自动化审计工具，该工具能够高效识别 LLM 在对话中潜在的指令违背行为；其核心创新在于利用自动化方法对大量用户生成的定制指令进行系统性检测，并结合人工验证确认违规比例，从而为评估 LLM 对行为指令的合规性提供可扩展、可量化的技术路径。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10172">https://arxiv.org/abs/2512.10172</a><br>
<strong>作者</strong>: Nicholas Clark,Ryan Bai,Tanu Mitra<br>
<strong>机构</strong>: University of Washington Information School (华盛顿大学信息学院); University of Washington Paul G. Allen School of Computer Science &amp; Engineering (华盛顿大学保罗·G·艾伦计算机科学与工程学院)<br>
<strong>类目</strong>: Human-Computer Interaction (cs.HC); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) and generative search systems are increasingly used for information seeking by diverse populations with varying preferences for knowledge sourcing and presentation. While users can customize LLM behavior through custom instructions and behavioral prompts, no mechanism exists to evaluate whether these instructions are being followed effectively. We present Offscript, an automated auditing tool that efficiently identifies potential instruction following failures in LLMs. In a pilot study analyzing custom instructions sourced from Reddit, Offscript detected potential deviations from instructed behavior in 86.4% of conversations, 22.2% of which were confirmed as material violations through human review. Our findings suggest that automated auditing serves as a viable approach for evaluating compliance to behavioral instructions related to information seeking.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-38] Unforgotten Safety: Preserving Safety Alignment of <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  with Continual Learning</p>
<p>【速读】： 该论文旨在解决大型语言模型（Large Language Models, LLMs）在适应新任务时出现的安全性退化问题，其核心归因于灾难性遗忘（catastrophic forgetting）。为应对这一挑战，作者将安全保护问题建模为持续学习（Continual Learning, CL）任务，并提出通过引入多种CL方法来维持模型在微调过程中的安全性。关键解决方案在于采用正则化、记忆回放与模型合并等CL策略，在用户数据上传至服务端进行定制化微调的场景下，有效降低攻击成功率，同时保持任务性能；其中，DER方法表现最优，在多种下游任务（GSM8K、SST2、Code）和模型架构（LLaMA2-7B、Mistral-7B、Gemma-2B）上均展现出稳定的安全性保护能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10150">https://arxiv.org/abs/2512.10150</a><br>
<strong>作者</strong>: Lama Alssum,Hani Itani,Hasan Abed Al Kader Hammoud,Philip Torr,Adel Bibi,Bernard Ghanem<br>
<strong>机构</strong>: 1. King Abdullah University of Science and Technology (KAUST); 2. University of Oxford (牛津大学)<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The safety alignment of large language models (LLMs) is becoming increasingly important with their democratization. In this paper, we study the safety degradation that comes with adapting LLMs to new tasks. We attribute this safety compromise to catastrophic forgetting and frame the problem of preserving safety when fine-tuning as a continual learning (CL) problem. We consider the fine-tuning-as-a-service setup where the user uploads their data to a service provider to get a customized model that excels on the user’s selected task. We adapt several CL approaches from the literature and systematically evaluate their ability to mitigate safety degradation. These include regularization-based, memory-based, and model merging approaches. We consider two scenarios, (1) benign user data and (2) poisoned user data. Our results demonstrate that CL approaches consistently achieve lower attack success rates than standard fine-tuning. Among these, DER outperforms both other CL methods and existing safety-preserving baselines while maintaining task utility. These findings generalize across three downstream tasks (GSM8K, SST2, Code) and three model families (LLaMA2-7B, Mistral-7B, Gemma-2B), establishing CL as a practical solution to preserve safety.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-39] PARAN: Persona-Augmented Review ANswering system on Food Delivery Review Dataset</p>
<p>【速读】： 该论文旨在解决在用户信息有限的场景下（如外卖平台），生成式 AI (Generative AI) 在个性化评论回复生成中因缺乏上下文数据而导致回复泛化、互动性与有效性下降的问题。其解决方案的关键在于提出一种两阶段提示（prompting）框架：首先从简短的用户评论文本中推断显式（如用户明确表达的偏好）和隐式（如人口统计或风格线索）的人物画像（persona）特征，随后将这些推断出的属性嵌入到生成提示中，以引导模型生成更贴合用户的定制化回复；同时，在推理阶段通过调整解码温度（decoding temperature）来平衡生成结果的多样性与语义忠实度，从而在无需微调模型的前提下显著提升回复的相关性和个性化水平。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10148">https://arxiv.org/abs/2512.10148</a><br>
<strong>作者</strong>: Moonsoo Park,Jeongseok Yun,Bohyung Kim<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Personalized review response generation presents a significant challenge in domains where user information is limited, such as food delivery platforms. While large language models (LLMs) offer powerful text generation capabilities, they often produce generic responses when lacking contextual user data, reducing engagement and effectiveness. In this work, we propose a two-stage prompting framework that infers both explicit (e.g., user-stated preferences) and implicit (e.g., demographic or stylistic cues) personas directly from short review texts. These inferred persona attributes are then incorporated into the response generation prompt to produce user-tailored replies. To encourage diverse yet faithful generations, we adjust decoding temperature during inference. We evaluate our method using a real-world dataset collected from a Korean food delivery app, and assess its impact on precision, diversity, and semantic consistency. Our findings highlight the effectiveness of persona-augmented prompting in enhancing the relevance and personalization of automated responses without requiring model fine-tuning.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-40] Workflow is All You Need: Escaping the “Statistical Smoothing Trap” via High-Entropy Information Fo<mark class="hl-label green">rag</mark> ing and Adversarial Pacing</p>
<p>【速读】： 该论文旨在解决垂直领域长文本生成中“不可能三角”问题，即如何同时实现低幻觉（low hallucination）、深层次逻辑连贯性（deep logical coherence）与个性化表达（personalized expression）。研究表明，当前大语言模型（LLMs）受限于统计平滑陷阱（Statistical Smoothing Trap），忽视了专家写作中高熵信息获取与结构化认知过程。解决方案的关键在于提出DeepNews框架，其核心创新为：1）基于信息觅食理论的双粒度检索机制，通过控制10:1的信息输入饱和比以抑制幻觉；2）基于叙事模板（narrative schemas）和原子块（Atomic Blocks）的策略规划模块，构建强逻辑骨架；3）对抗约束提示技术（adversarial constraint prompting），采用节奏打断（Rhythm Break）与逻辑雾化（Logic Fog）等策略破坏模型输出的概率平滑特性。实验验证了知识悬崖效应（Knowledge Cliff）的存在，并在真实场景下显著提升稿件接受率，证明该框架可有效突破现有生成范式的瓶颈。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10121">https://arxiv.org/abs/2512.10121</a><br>
<strong>作者</strong>: Zhongjie Jiang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>); General Finance (<a target="_blank" rel="noopener" href="http://q-fin.GN">q-fin.GN</a>)<br>
<strong>备注</strong>:  22 pages, 8 figures. Includes an ecological validity blind test where the Agentic Workflow achieved a 25% acceptance rate in top-tier media, decisively outperforming the SOTA Zero-shot baseline (0%). Features the DNFO-v5 ontology</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Central to long-form text generation in vertical domains is the “impossible trinity” confronting current large language models (LLMs): the simultaneous achievement of low hallucination, deep logical coherence, and personalized expression. This study establishes that this bottleneck arises from existing generative paradigms succumbing to the Statistical Smoothing Trap, a phenomenon that overlooks the high-entropy information acquisition and structured cognitive processes integral to expert-level writing. To address this limitation, we propose the DeepNews Framework, an agentic workflow that explicitly models the implicit cognitive processes of seasoned financial journalists. The framework integrates three core modules: first, a dual-granularity retrieval mechanism grounded in information foraging theory, which enforces a 10:1 saturated information input ratio to mitigate hallucinatory outputs; second, schema-guided strategic planning, a process leveraging domain expert knowledge bases (narrative schemas) and Atomic Blocks to forge a robust logical skeleton; third, adversarial constraint prompting, a technique deploying tactics including Rhythm Break and Logic Fog to disrupt the probabilistic smoothness inherent in model-generated text. Experiments delineate a salient Knowledge Cliff in deep financial reporting: content truthfulness collapses when retrieved context falls below 15,000 characters, while a high-redundancy input exceeding 30,000 characters stabilizes the Hallucination-Free Rate (HFR) above 85%. In an ecological validity blind test conducted with a top-tier Chinese technology media outlet, the DeepNews system–built on a previous-generation model (DeepSeek-V3-0324)-achieved a 25% submission acceptance rate, significantly outperforming the 0% acceptance rate of zero-shot generation by a state-of-the-art (SOTA) model (GPT-5).<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-41] Generate-Then-Validate: A Novel Question Generation Approach Using Small Language Models</p>
<p>【速读】： 该论文旨在解决当前学习分析研究中普遍依赖大型语言模型（Large Language Models, LLMs）进行自动问题生成（Automatic Question Generation, AQG）所面临的计算资源消耗高、部署成本大等问题，探索小型语言模型（Small Language Models, SLMs）在该任务中的可行性与有效性。其解决方案的关键在于提出了一种新颖的“生成-验证”（generate-then-validate）流水线：首先利用SLM强大的文本生成能力生成大量候选问题，随后通过基于概率推理的新颖验证机制对候选问题进行筛选和优化，从而在不牺牲问题质量的前提下显著降低资源开销。实证评估表明，该方法生成的问题在语义清晰性和目标对齐度上均获得人类专家与LLM评委的一致认可。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10110">https://arxiv.org/abs/2512.10110</a><br>
<strong>作者</strong>: Yumou Wei,John Stamper,Paulo F. Carvalho<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Human-Computer Interaction (cs.HC)<br>
<strong>备注</strong>:  Accepted as a full research paper for the 16th International Conference on Learning Analytics and Knowledge (LAK’26)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We explore the use of small language models (SLMs) for automatic question generation as a complement to the prevalent use of their large counterparts in learning analytics research. We present a novel question generation pipeline that leverages both the text generation and the probabilistic reasoning abilities of SLMs to generate high-quality questions. Adopting a “generate-then-validate” strategy, our pipeline first performs expansive generation to create an abundance of candidate questions and refine them through selective validation based on novel probabilistic reasoning. We conducted two evaluation studies, one with seven human experts and the other with a large language model (LLM), to assess the quality of the generated questions. Most judges (humans or LLMs) agreed that the generated questions had clear answers and generally aligned well with the intended learning objectives. Our findings suggest that an SLM can effectively generate high-quality questions when guided by a well-designed pipeline that leverages its strengths.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-42] What Kind of <mark class="hl-label green">Reasoning</mark>  (if any) is an <mark class="hl-label green">LLM</mark>  actually doing? On the Stochastic Nature and Abductive Appearance of <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark></p>
<p>【速读】： 该论文试图解决的问题是：当前基于token补全机制的大型语言模型（Large Language Models, LLMs）是否真正具备推理能力，尤其是能否进行类比推理（abductive reasoning）。论文指出，尽管LLMs在输出中常表现出类似人类的推理行为，如生成合理解释或模拟常识推理，但其本质并非基于真实的逻辑推理或语义理解，而是依赖于从人类文本中学习到的模式。解决方案的关键在于揭示LLMs的“随机性基础”（stochastic nature）与其表面“类比推理”表现之间的矛盾——即模型的输出看似合理，实则缺乏对真理的识别、验证和语义理解能力。因此，评估和应用LLMs时必须认识到其生成内容的潜在误导性，并强调对其输出进行批判性审查的重要性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10080">https://arxiv.org/abs/2512.10080</a><br>
<strong>作者</strong>: Luciano Floridi,Jessica Morley,Claudio Novelli,David Watson<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This article looks at how reasoning works in current Large Language Models (LLMs) that function using the token-completion method. It examines their stochastic nature and their similarity to human abductive reasoning. The argument is that these LLMs create text based on learned patterns rather than performing actual abductive reasoning. When their output seems abductive, this is largely because they are trained on human-generated texts that include reasoning structures. Examples are used to show how LLMs can produce plausible ideas, mimic commonsense reasoning, and give explanatory answers without being grounded in truth, semantics, verification, or understanding, and without performing any real abductive reasoning. This dual nature, where the models have a stochastic base but appear abductive in use, has important consequences for how LLMs are evaluated and applied. They can assist with generating ideas and supporting human thinking, but their outputs must be critically assessed because they cannot identify truth or verify their explanations. The article concludes by addressing five objections to these points, noting some limitations in the analysis, and offering an overall evaluation.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-43] Parallel Decoder Transformer: Model-Internal Parallel Decoding with Speculative Invariance via Note Conditioning</p>
<p>【速读】： 该论文旨在解决大语言模型（Large Language Models, LLMs）自回归解码过程中固有的序列性导致的延迟瓶颈问题，该瓶颈随输出长度线性增长。现有并行化方法如“分解-填充”（Decomposition-and-Fill）策略虽尝试通过外部调度实现并行生成，但因缺乏跨流通信而产生语义连贯性漂移（coherence drift）。其解决方案的关键在于提出一种参数高效的架构——并行解码变压器（Parallel Decoder Transformer, PDT），它不需微调预训练主干模型，而是注入轻量级的推测性笔记条件适配器（Speculative Note Conditioning, SNC），使多个并行解码流能通过共享动态潜在空间进行同步。PDT将协调机制建模为一个推测性共识问题，其中子流通过学习到的验证头控制广播语义“笔记”至全局总线，从而实现有效自我修正，在50,000步课程中达到77.8%的覆盖率预测精度，并恢复近似串行语义，无需修改主干权重。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10054">https://arxiv.org/abs/2512.10054</a><br>
<strong>作者</strong>: Logan Robbins<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Autoregressive decoding in Large Language Models (LLMs) is inherently sequential, creating a latency bottleneck that scales linearly with output length. While <code>Decomposition-and-Fill'' methods like Skeleton-of-Thought attempt to parallelize generation via external orchestration, they suffer from \textitcoherence drift due to the lack of cross-stream communication. In this work, we introduce the \textbfParallel Decoder Transformer (PDT), a parameter-efficient architecture that embeds coordination primitives directly into the inference process of a frozen pre-trained model. Instead of retraining the base model, PDT injects lightweight \textitSpeculative Note Conditioning (SNC) adapters that allow parallel decoding streams to synchronize via a shared, dynamic latent space. We formulate coordination as a \textitspeculative consensus problem, where sibling streams broadcast semantic </code>notes’’ to a global bus, gated by a learned verification head. We validate our approach on a 50,000-step curriculum using a frozen 20B-parameter backbone. Our results demonstrate that PDT achieves effective self-correction, reaching \textbf77.8% precision in coverage prediction and recovering approximate serial semantics without modifying the trunk weights. This establishes PDT as a scalable, efficient alternative to full model fine-tuning for structured parallel generation.         Subjects:  Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)  Cite as: arXiv:2512.10054 [<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>]    (or  arXiv:2512.10054v1 [<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10054">https://doi.org/10.48550/arXiv.2512.10054</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-44] Diffusion Is Your Friend in Show Suggest and Tell</p>
<p>【速读】： 该论文旨在解决扩散去噪模型（Diffusion Denoising Models）在离散域生成任务中难以超越传统自回归模型（Autoregressive Models）性能的问题，尽管其在连续空间的生成任务中表现优异。解决方案的关键在于提出一种新范式：不直接用扩散模型替代自回归模型，而是将其作为建议模块（suggestion module），为自回归生成过程提供双向信息和精细化指导，从而融合扩散模型的全局优化能力与自回归模型的语言结构优势。实验表明，所提出的“Show, Suggest and Tell”（SST）模型在COCO数据集上达到125.1的CIDEr-D分数（无需强化学习），显著优于当前最优的自回归与扩散模型方法。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10038">https://arxiv.org/abs/2512.10038</a><br>
<strong>作者</strong>: Jia Cheng Hu,Roberto Cavicchioli,Alessandro Capotondi<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Diffusion Denoising models demonstrated impressive results across generative Computer Vision tasks, but they still fail to outperform standard autoregressive solutions in the discrete domain, and only match them at best. In this work, we propose a different paradigm by adopting diffusion models to provide suggestions to the autoregressive generation rather than replacing them. By doing so, we combine the bidirectional and refining capabilities of the former with the strong linguistic structure provided by the latter. To showcase its effectiveness, we present Show, Suggest and Tell (SST), which achieves State-of-the-Art results on COCO, among models in a similar setting. In particular, SST achieves 125.1 CIDEr-D on the COCO dataset without Reinforcement Learning, outperforming both autoregressive and diffusion model State-of-the-Art results by 1.5 and 2.5 points. On top of the strong results, we performed extensive experiments to validate the proposal and analyze the impact of the suggestion module. Results demonstrate a positive correlation between suggestion and caption quality, overall indicating a currently underexplored but promising research direction. Code will be available at: this https URL_suggest_tell.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-45] Exploring <mark class="hl-label green">LLM</mark> s for Scientific Information Extraction Using The SciEx Framework</p>
<p>【速读】： 该论文旨在解决当前基于大语言模型（Large Language Models, LLMs）的科学信息抽取系统在处理科学文献时面临的三大核心挑战：长文本上下文理解困难、多模态内容整合能力不足，以及跨多篇文献中细粒度信息的一致性对齐问题。此外，当数据模式或抽取本体（ontology）频繁变化时，现有系统难以快速重构或微调。解决方案的关键在于提出一个模块化且可组合的框架 SciEx，其通过解耦 PDF 解析、多模态检索、信息抽取与聚合等关键组件，实现了按需数据提取的高效性，并支持灵活集成新模型、提示策略和推理机制，从而提升系统的可扩展性和适应性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10004">https://arxiv.org/abs/2512.10004</a><br>
<strong>作者</strong>: Sha Li,Ayush Sadekar,Nathan Self,Yiqi Su,Lars Andersland,Mira Chaplin,Annabel Zhang,Hyoju Yang,James B Henderson,Krista Wigginton,Linsey Marr,T.M. Murali,Naren Ramakrishnan<br>
<strong>机构</strong>: Virginia Tech (弗吉尼亚理工学院); Virginia Polytechnic Institute and State University (弗吉尼亚理工学院); Virginia Tech (弗吉尼亚理工学院); Virginia Polytechnic Institute and State University (弗吉尼亚理工学院)<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language models (LLMs) are increasingly touted as powerful tools for automating scientific information extraction. However, existing methods and tools often struggle with the realities of scientific literature: long-context documents, multi-modal content, and reconciling varied and inconsistent fine-grained information across multiple publications into standardized formats. These challenges are further compounded when the desired data schema or extraction ontology changes rapidly, making it difficult to re-architect or fine-tune existing systems. We present SciEx, a modular and composable framework that decouples key components including PDF parsing, multi-modal retrieval, extraction, and aggregation. This design streamlines on-demand data extraction while enabling extensibility and flexible integration of new models, prompting strategies, and reasoning mechanisms. We evaluate SciEx on datasets spanning three scientific topics for its ability to extract fine-grained information accurately and consistently. Our findings provide practical insights into both the strengths and limitations of current LLM-based pipelines.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-46] BAMBO: Construct Ability and Efficiency <mark class="hl-label green">LLM</mark>  Pareto Set via Bayesian Adaptive Multi-objective Block-wise Optimization</p>
<p>【速读】： 该论文旨在解决大型语言模型（Large Language Models, LLMs）在能力与效率之间权衡时，难以有效构建帕累托前沿（Pareto set）的问题。现有合并技术存在两大局限：粗粒度的模型级方法仅能获得稀疏且次优的解，而细粒度的层级方法则因维度灾难导致搜索空间计算不可行。解决方案的关键在于提出 BAMBO（Bayesian Adaptive Multi-objective Block-wise Optimization）框架，其核心创新是引入一种混合最优块划分策略（Hybrid Optimal Block Partitioning），将高维优化问题转化为一维聚类问题，并通过动态规划实现块内同质性与块间信息分布的最优平衡，从而显著降低维度并保留关键粒度；整个过程由 q-期望超体积改进（qEHVI）采集函数驱动的进化循环自动化完成，最终实现更优且更全面的帕累托前沿发现。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09972">https://arxiv.org/abs/2512.09972</a><br>
<strong>作者</strong>: Kesheng Chen,Wenjian Luo,Zhenqian Zhu,Yamin Hu,Yiya Xi<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Neural and Evolutionary Computing (<a target="_blank" rel="noopener" href="http://cs.NE">cs.NE</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Constructing a Pareto set is pivotal for navigating the capability-efficiency trade-offs in Large Language Models (LLMs); however, existing merging techniques remain inadequate for this task. Coarse-grained, model-level methods yield only a sparse set of suboptimal solutions, while fine-grained, layer-wise approaches suffer from the “curse of dimensionality,” rendering the search space computationally intractable. To resolve this dichotomy, we propose BAMBO (Bayesian Adaptive Multi-objective Block-wise Optimization), a novel framework that automatically constructs the LLM Pareto set. BAMBO renders the search tractable by introducing a Hybrid Optimal Block Partitioning strategy. Formulated as a 1D clustering problem, this strategy leverages a dynamic programming approach to optimally balance intra-block homogeneity and inter-block information distribution, thereby dramatically reducing dimensionality without sacrificing critical granularity. The entire process is automated within an evolutionary loop driven by the q-Expected Hypervolume Improvement (qEHVI) acquisition function. Experiments demonstrate that BAMBO discovers a superior and more comprehensive Pareto frontier than baselines, enabling agile model selection tailored to diverse operational constraints. Code is available at: this https URL.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-47] Unsupervised Acquisition of Discrete Grammatical Categories</p>
<p>【速读】： 该论文旨在解决如何从无监督的输入数据中自动提取抽象的语法知识，从而模拟语言习得过程的问题。其核心挑战在于：学习者代理（daughter language model）无法访问母语代理（mother language model）的内部表征，仅能通过观察后者生成的语言样本进行学习。解决方案的关键在于利用层次聚类分析（hierarchical agglomerative cluster analysis）对母语代理连续输出的语句进行统计模式识别，从中发现与自然语言中语法范畴（grammatical categories）相对应的离散结构，并将这些结构作为规则注入到学习者的语法知识库中。实验表明，这种方法能够有效获取非平凡的语法类别，验证了该计算实验室环境在无监督语法习得中的可行性与有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2503.18702">https://arxiv.org/abs/2503.18702</a><br>
<strong>作者</strong>: David Ph. Shakouri,Crit Cremers,Niels O. Schiller<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG); Multiagent Systems (<a target="_blank" rel="noopener" href="http://cs.MA">cs.MA</a>)<br>
<strong>备注</strong>:  34 pages, 3 figures, 7 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This article presents experiments performed using a computational laboratory environment for language acquisition experiments. It implements a multi-agent system consisting of two agents: an adult language model and a daughter language model that aims to learn the mother language. Crucially, the daughter agent does not have access to the internal knowledge of the mother language model but only to the language exemplars the mother agent generates. These experiments illustrate how this system can be used to acquire abstract grammatical knowledge. We demonstrate how statistical analyses of patterns in the input data corresponding to grammatical categories yield discrete grammatical rules. These rules are subsequently added to the grammatical knowledge of the daughter language model. To this end, hierarchical agglomerative cluster analysis was applied to the utterances consecutively generated by the mother language model. It is argued that this procedure can be used to acquire structures resembling grammatical categories proposed by linguists for natural languages. Thus, it is established that non-trivial grammatical knowledge has been acquired. Moreover, the parameter configuration of this computational laboratory environment determined using training data generated by the mother language model is validated in a second experiment with a test set similarly resulting in the acquisition of non-trivial categories.<br>
zh</p>
</div></div>
<div class="note orange no-icon flat"><p>[NLP-48] <mark class="hl-label green">Planning</mark>  Living and Judging: A Multi-<mark class="hl-label green">agent</mark>  <mark class="hl-label green">LLM</mark> -based Framework for Cyclical Urban <mark class="hl-label green">Planning</mark>  <mark class="hl-label red">AAAI2025</mark></p>
<p>【速读】： 该论文旨在解决城市再生（Urban Regeneration）在快速城市化背景下所面临的动态适应性挑战，即传统静态规划方法难以持续响应不断变化的城市需求。其解决方案的关键在于提出了一种名为“循环城市规划”（Cyclical Urban Planning, CUP）的新范式，通过基于多智能体大语言模型（Multi-agent LLM-based Framework）的闭环机制，实现城市规划的持续生成、模拟与优化：具体包括三个核心组件——规划（Planning）、生活模拟（Living）和评估反馈（Judging），其中LLM代理依据上下文数据生成并迭代优化方案，同时模拟居民行为以真实反映城市运行状态，最终形成可自适应演进的城市设计流程。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2412.20505">https://arxiv.org/abs/2412.20505</a><br>
<strong>作者</strong>: Hang Ni,Yuzhi Wang,Hao Liu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computation and Language (<a target="_blank" rel="noopener" href="http://cs.CL">cs.CL</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  4 pages, 2 figures, accepted by The 1st Workshop on AI for Urban Planning (AAAI 2025’s Workshop)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Urban regeneration presents significant challenges within the context of urbanization, requiring adaptive approaches to tackle evolving needs. Leveraging advancements in large language models (LLMs), we propose Cyclical Urban Planning (CUP), a new paradigm that continuously generates, evaluates, and refines urban plans in a closed-loop. Specifically, our multi-agent LLM-based framework consists of three key components: (1) Planning, where LLM agents generate and refine urban plans based on contextual data; (2) Living, where agents simulate the behaviors and interactions of residents, modeling life in the urban environment; and (3) Judging, which involves evaluating plan effectiveness and providing iterative feedback for improvement. The cyclical process enables a dynamic and responsive planning approach. Experiments on the real-world dataset demonstrate the effectiveness of our framework as a continuous and adaptive planning process.<br>
zh</p>
</div></div>
<h3 id="计算机视觉">计算机视觉</h3>
<div class="note purple no-icon flat"><p>[CV-0] StereoSpace: Depth-Free Synthesis of Stereo Geometry via End-to-End Diffusion in a Canonical Space</p>
<p>【速读】：该论文旨在解决单目图像到立体图像（monocular-to-stereo synthesis）的生成问题，其核心挑战在于如何在不依赖显式深度图或视差图（disparity map）的情况下，准确建模几何结构并生成具有真实感视差（parallax）和几何一致性的立体图像。解决方案的关键在于提出一种基于扩散模型（diffusion-based framework）的框架 StereoSpace，它通过视角条件（viewpoint conditioning）隐式建模几何信息，无需显式估计深度或进行图像扭曲（warping），而是利用一个规范化的正交空间（canonical rectified space）作为参考，引导生成器端到端地推断像素对应关系（correspondences）并填补遮挡区域（disocclusions）。该方法在测试阶段采用无泄漏评估协议（leakage-free evaluation protocol），确保不使用任何真值或代理几何信息，从而更真实地反映下游任务性能（如感知舒适度 iSQoE 和几何一致性 MEt3R）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10959">https://arxiv.org/abs/2512.10959</a><br>
<strong>作者</strong>: Tjark Behrens,Anton Obukhov,Bingxin Ke,Fabio Tosi,Matteo Poggi,Konrad Schindler<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://hf.co/spaces/prs-eth/stereospace_web">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce StereoSpace, a diffusion-based framework for monocular-to-stereo synthesis that models geometry purely through viewpoint conditioning, without explicit depth or warping. A canonical rectified space and the conditioning guide the generator to infer correspondences and fill disocclusions end-to-end. To ensure fair and leakage-free evaluation, we introduce an end-to-end protocol that excludes any ground truth or proxy geometry estimates at test time. The protocol emphasizes metrics reflecting downstream relevance: iSQoE for perceptual comfort and MEt3R for geometric consistency. StereoSpace surpasses other methods from the warp  inpaint, latent-warping, and warped-conditioning categories, achieving sharp parallax and strong robustness on layered and non-Lambertian scenes. This establishes viewpoint-conditioned diffusion as a scalable, depth-free solution for stereo generation.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-1] WorldLens: Full-Spectrum Evaluations of Driving World Models in Real World</p>
<p>【速读】：该论文旨在解决当前生成式世界模型（Generative World Models）在评估标准上的碎片化问题，即缺乏统一指标来衡量其生成环境在几何一致性、物理合理性及行为可靠性等方面的综合表现。现有模型往往在视觉真实感与物理行为之间存在权衡：高纹理质量的模型常违背物理规律，而几何稳定的模型则难以实现行为上的真实性。解决方案的关键在于提出WorldLens基准测试体系，涵盖生成、重建、动作跟随、下游任务和人类偏好五个维度，全面覆盖视觉、几何、物理与功能层面；同时构建WorldLens-26K大规模人类标注数据集和WorldLens-Agent评分代理模型，以对齐客观指标与人类判断，从而形成一个标准化、可扩展且具备解释性的世界模型评估生态系统。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10958">https://arxiv.org/abs/2512.10958</a><br>
<strong>作者</strong>: Ao Liang,Lingdong Kong,Tianyi Yan,Hongsi Liu,Wesley Yang,Ziqi Huang,Wei Yin,Jialong Zuo,Yixuan Hu,Dekai Zhu,Dongyue Lu,Youquan Liu,Guangfeng Jiang,Linfeng Li,Xiangtai Li,Long Zhuo,Lai Xing Ng,Benoit R. Cottereau,Changxin Gao,Liang Pan,Wei Tsang Ooi,Ziwei Liu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Preprint; 80 pages, 37 figures, 29 tables; Project Page at <a target="_blank" rel="noopener" href="https://worldbench.github.io/worldlens">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Generative world models are reshaping embodied AI, enabling agents to synthesize realistic 4D driving environments that look convincing but often fail physically or behaviorally. Despite rapid progress, the field still lacks a unified way to assess whether generated worlds preserve geometry, obey physics, or support reliable control. We introduce WorldLens, a full-spectrum benchmark evaluating how well a model builds, understands, and behaves within its generated world. It spans five aspects – Generation, Reconstruction, Action-Following, Downstream Task, and Human Preference – jointly covering visual realism, geometric consistency, physical plausibility, and functional reliability. Across these dimensions, no existing world model excels universally: those with strong textures often violate physics, while geometry-stable ones lack behavioral fidelity. To align objective metrics with human judgment, we further construct WorldLens-26K, a large-scale dataset of human-annotated videos with numerical scores and textual rationales, and develop WorldLens-Agent, an evaluation model distilled from these annotations to enable scalable, explainable scoring. Together, the benchmark, dataset, and agent form a unified ecosystem for measuring world fidelity – standardizing how future models are judged not only by how real they look, but by how real they behave.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-2] SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model</p>
<p>【速读】：该论文旨在解决在严重遮挡和开放集（open-set）场景下，现有3D场景生成方法难以同时实现高质量几何重建与准确位姿估计的问题。其关键解决方案在于提出了一种解耦的3D场景生成框架SceneMaker：首先将去遮挡（de-occlusion）模型与3D物体生成模块分离，并利用图像数据集和自建的去遮挡数据集增强模型对多样化开放集遮挡模式的泛化能力；其次设计了一个统一的位姿估计模型，通过融合全局与局部机制的自注意力（self-attention）和交叉注意力（cross-attention）结构提升位姿估计精度；此外，构建了一个开放集3D场景数据集以进一步提升位姿估计模型的泛化性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10957">https://arxiv.org/abs/2512.10957</a><br>
<strong>作者</strong>: Yukai Shi,Weiyu Li,Zihao Wang,Hongyang Li,Xingyu Chen,Ping Tan,Lei Zhang<br>
<strong>机构</strong>: Tsinghua University (清华大学); HKUST (香港科技大学); IDEA Research (IDEA研究院); LightIllusions<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://idea-research.github.io/SceneMaker/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-3] Empowering Dynamic Urban Navigation with Stereo and Mid-Level Vision <mark class="hl-label red">WWW</mark></p>
<p>【速读】：该论文旨在解决当前基于单目视觉的机器人导航基础模型（Navigation Foundation Models, NFMs）在动态和非结构化环境中性能受限的问题，其核心挑战在于：单目视觉存在深度尺度模糊性（depth-scale ambiguity），且忽略中层视觉先验（如深度估计、密集像素跟踪等）导致几何与动态理解不足，从而难以实现鲁棒导航。解决方案的关键在于引入立体视觉输入（stereo inputs）并显式融合中层视觉模块（mid-level vision），包括深度估计和密集像素跟踪，以消除深度歧义并提供可靠的几何与运动结构信息；同时构建了一个大规模立体导航数据集，支持模型训练与未来研究。实验表明，该方法仅需1.5%的训练数据即可达到当前最优性能，并在完整数据下超越现有最先进水平。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10956">https://arxiv.org/abs/2512.10956</a><br>
<strong>作者</strong>: Wentao Zhou,Xuweiyi Chen,Vignesh Rajagopal,Jeffrey Chen,Rohan Chandra,Zezhou Cheng<br>
<strong>机构</strong>: University of Virginia (弗吉尼亚大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project Page: <a target="_blank" rel="noopener" href="https://www.cs.virginia.edu/~tsx4zn/stereowalk/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The success of foundation models in language and vision motivated research in fully end-to-end robot navigation foundation models (NFMs). NFMs directly map monocular visual input to control actions and ignore mid-level vision modules (tracking, depth estimation, etc) entirely. While the assumption that vision capabilities will emerge implicitly is compelling, it requires large amounts of pixel-to-action supervision that are difficult to obtain. The challenge is especially pronounced in dynamic and unstructured settings, where robust navigation requires precise geometric and dynamic understanding, while the depth-scale ambiguity in monocular views further limits accurate spatial reasoning. In this paper, we show that relying on monocular vision and ignoring mid-level vision priors is inefficient. We present StereoWalker, which augments NFMs with stereo inputs and explicit mid-level vision such as depth estimation and dense pixel tracking. Our intuition is straightforward: stereo inputs resolve the depth-scale ambiguity, and modern mid-level vision models provide reliable geometric and motion structure in dynamic scenes. We also curate a large stereo navigation dataset with automatic action annotation from Internet stereo videos to support training of StereoWalker and to facilitate future research. Through our experiments, we find that mid-level vision enables StereoWalker to achieve a comparable performance as the state-of-the-art using only 1.5% of the training data, and surpasses the state-of-the-art using the full data. We also observe that stereo vision yields higher navigation performance than monocular input.          Comments: Project Page: this https URL   Subjects:  Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)  Cite as: arXiv:2512.10956 [<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>]    (or  arXiv:2512.10956v1 [<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10956">https://doi.org/10.48550/arXiv.2512.10956</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-4] Omni-Attribute: Open-vocabulary Attribute Encoder for Visual Concept Personalization</p>
<p>【速读】：该论文旨在解决视觉概念个性化（Visual Concept Personalization）中因依赖通用图像编码器生成的全局嵌入而导致的多属性纠缠问题，从而引发的信息泄露与合成不一致现象。其解决方案的关键在于提出首个开放词汇的图像属性编码器 Omni-Attribute，通过两个核心设计实现：一是构建语义关联的图像对数据集，并标注正负属性以明确指导编码器保留或抑制特定属性；二是采用生成保真度与对比解耦双重目标联合训练策略，在保证图像质量的同时实现属性间的解耦表征。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10955">https://arxiv.org/abs/2512.10955</a><br>
<strong>作者</strong>: Tsai-Shien Chen,Aliaksandr Siarohin,Guocheng Gordon Qian,Kuan-Chieh Jackson Wang,Egor Nemchinov,Moayed Haji-Ali,Riza Alp Guler,Willi Menapace,Ivan Skorokhodov,Anil Kag,Jun-Yan Zhu,Sergey Tulyakov<br>
<strong>机构</strong>: Snap Inc.; UC Merced (加州大学默塞德分校); CMU (卡内基梅隆大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://snap-research.github.io/omni-attribute">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Visual concept personalization aims to transfer only specific image attributes, such as identity, expression, lighting, and style, into unseen contexts. However, existing methods rely on holistic embeddings from general-purpose image encoders, which entangle multiple visual factors and make it difficult to isolate a single attribute. This often leads to information leakage and incoherent synthesis. To address this limitation, we introduce Omni-Attribute, the first open-vocabulary image attribute encoder designed to learn high-fidelity, attribute-specific representations. Our approach jointly designs the data and model: (i) we curate semantically linked image pairs annotated with positive and negative attributes to explicitly teach the encoder what to preserve or suppress; and (ii) we adopt a dual-objective training paradigm that balances generative fidelity with contrastive disentanglement. The resulting embeddings prove effective for open-vocabulary attribute retrieval, personalization, and compositional generation, achieving state-of-the-art performance across multiple benchmarks.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-5] Group Diffusion: Enhancing Image Generation by Unlocking Cross-Sample Collaboration</p>
<p>【速读】：该论文旨在解决扩散模型（Diffusion Model）在推理阶段仅独立生成图像、未能利用样本间潜在关联的问题。传统方法中，每张图像的去噪过程完全独立，忽略了跨样本之间的结构与语义对应关系。为解决此问题，作者提出Group Diffusion，其关键在于将注意力机制从单张图像内部的patch间扩展至多张图像之间，实现图像间的协同去噪（joint denoising），从而同时学习图像内（intra-image）和图像间（inter-image）的对应关系。实验表明，组规模越大，跨样本注意力越强，生成质量提升显著，最终在ImageNet-256x256数据集上实现最高达32.2%的FID改进。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10954">https://arxiv.org/abs/2512.10954</a><br>
<strong>作者</strong>: Sicheng Mo,Thao Nguyen,Richard Zhang,Nick Kolkin,Siddharth Srinivasan Iyer,Eli Shechtman,Krishna Kumar Singh,Yong Jae Lee,Bolei Zhou,Yuheng Li<br>
<strong>机构</strong>: University of California, Los Angeles (加州大学洛杉矶分校); University of Wisconsin–Madison (威斯康星大学麦迪逊分校); Adobe Research (Adobe 研究院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project Page: <a target="_blank" rel="noopener" href="https://sichengmo.github.io/GroupDiff/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In this work, we explore an untapped signal in diffusion model inference. While all previous methods generate images independently at inference, we instead ask if samples can be generated collaboratively. We propose Group Diffusion, unlocking the attention mechanism to be shared across images, rather than limited to just the patches within an image. This enables images to be jointly denoised at inference time, learning both intra and inter-image correspondence. We observe a clear scaling effect - larger group sizes yield stronger cross-sample attention and better generation quality. Furthermore, we introduce a qualitative measure to capture this behavior and show that its strength closely correlates with FID. Built on standard diffusion transformers, our GroupDiff achieves up to 32.2% FID improvement on ImageNet-256x256. Our work reveals cross-sample inference as an effective, previously unexplored mechanism for generative modeling.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-6] Bidirectional Normalizing Flow: From Data to Noise and Back</p>
<p>【速读】：该论文旨在解决传统归一化流（Normalizing Flows, NFs）中因果解码（causal decoding）带来的计算瓶颈问题，尤其是在基于Transformer和自回归流（autoregressive flows）的最新方法（如TARFlow）中，其严格的显式可逆性约束限制了模型灵活性与采样效率。解决方案的关键在于提出双向归一化流（Bidirectional Normalizing Flow, BiFlow），该框架摒弃了对精确解析逆映射的依赖，转而学习一个近似数据到噪声逆映射的反向模型，从而允许更灵活的损失函数设计和网络架构选择。实验表明，BiFlow在ImageNet上显著提升了生成质量，并将采样速度加快高达两个数量级，同时在单次前向传播评估（1-NFE）指标下达到与当前最优NF方法相当甚至更优的性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10953">https://arxiv.org/abs/2512.10953</a><br>
<strong>作者</strong>: Yiyang Lu,Qiao Sun,Xianbang Wang,Zhicheng Jiang,Hanhong Zhao,Kaiming He<br>
<strong>机构</strong>: MIT(麻省理工学院); Tsinghua University(清华大学)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Tech report</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations are constrained by explicit invertibility, ensuring that the reverse process can serve as their exact analytic inverse. Recent developments in TARFlow and its variants have revitalized NF methods by combining Transformers and autoregressive flows, but have also exposed causal decoding as a major bottleneck. In this work, we introduce Bidirectional Normalizing Flow ( \textbfBiFlow ), a framework that removes the need for an exact analytic inverse. BiFlow learns a reverse model that approximates the underlying noise-to-data inverse mapping, enabling more flexible loss functions and architectures. Experiments on ImageNet demonstrate that BiFlow, compared to its causal decoding counterpart, improves generation quality while accelerating sampling by up to two orders of magnitude. BiFlow yields state-of-the-art results among NF-based methods and competitive performance among single-evaluation (“1-NFE”) methods. Following recent encouraging progress on NFs, we hope our work will draw further attention to this classical paradigm.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-7] E-RayZer: Self-supervised 3D Reconstruction as Spatial Visual Pre-training</p>
<p>【速读】：该论文旨在解决当前自监督学习方法在从多视角图像中学习真正三维感知表示（3D-aware representations）方面的局限性，尤其是现有方法如RayZer通过潜在空间视图合成间接推断3D结构所导致的几何不准确问题。其解决方案的关键在于提出E-RayZer模型，该模型直接在3D空间中进行自监督三维重建，并引入显式几何约束（Explicit geometry），从而避免了捷径解（shortcut solutions），确保学习到的表示具有几何基础。此外，为保障训练收敛与可扩展性，作者设计了一种细粒度的学习课程（fine-grained learning curriculum），以无监督方式组织样本难度并融合异构数据源，最终在姿态估计和下游3D任务中显著优于现有方法，包括完全监督模型。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10950">https://arxiv.org/abs/2512.10950</a><br>
<strong>作者</strong>: Qitao Zhao,Hao Tan,Qianqian Wang,Sai Bi,Kai Zhang,Kalyan Sunkavalli,Shubham Tulsiani,Hanwen Jiang<br>
<strong>机构</strong>: Carnegie Mellon University (卡内基梅隆大学); Adobe Research (Adobe 研究院); Harvard University (哈佛大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project website: <a target="_blank" rel="noopener" href="https://qitaozhao.github.io/E-RayZer">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Self-supervised pre-training has revolutionized foundation models for languages, individual 2D images and videos, but remains largely unexplored for learning 3D-aware representations from multi-view images. In this paper, we present E-RayZer, a self-supervised large 3D Vision model that learns truly 3D-aware representations directly from unlabeled images. Unlike prior self-supervised methods such as RayZer that infer 3D indirectly through latent-space view synthesis, E-RayZer operates directly in 3D space, performing self-supervised 3D reconstruction with Explicit geometry. This formulation eliminates shortcut solutions and yields representations that are geometrically grounded. To ensure convergence and scalability, we introduce a novel fine-grained learning curriculum that organizes training from easy to hard samples and harmonizes heterogeneous data sources in an entirely unsupervised manner. Experiments demonstrate that E-RayZer significantly outperforms RayZer on pose estimation, matches or sometimes surpasses fully supervised reconstruction models such as VGGT. Furthermore, its learned representations outperform leading visual pre-training models (e.g., DINOv3, CroCo v2, VideoMAE V2, and RayZer) when transferring to 3D downstream tasks, establishing E-RayZer as a new paradigm for 3D-aware visual pre-training.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-8] ClusIR: Towards Cluster-Guided All-in-One Image Restoration</p>
<p>【速读】：该论文旨在解决现有全合一图像复原（All-in-One Image Restoration, AiOIR）方法在处理多样或混合退化类型时，难以显式建模退化语义且缺乏自适应恢复能力的问题。其核心解决方案是提出ClusIR框架，关键在于引入两个创新模块：一是概率聚类引导路由机制（Probabilistic Cluster-Guided Routing Mechanism, PCGRM），实现退化识别与专家激活的解耦，从而提升退化感知的判别性和专家路由的稳定性；二是退化感知频域调制模块（Degradation-Aware Frequency Modulation Module, DAFMM），利用聚类引导先验进行自适应频域分解与定向调制，协同优化结构与纹理表征以增强复原保真度。该方案通过聚类引导的语义线索与频域调制的协同作用，显著提升了对复杂退化场景的适应性与复原性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10948">https://arxiv.org/abs/2512.10948</a><br>
<strong>作者</strong>: Shengkai Hu,Jiaqi Ma,Jun Wan,Wenwen Min,Yongcheng Jing,Lefei Zhang,Dacheng Tao<br>
<strong>机构</strong>: Zhongnan University of Economics and Law (中南财经政法大学); Mohamed bin Zayed University of Artificial Intelligence (穆罕默德·本·扎耶德人工智能大学); Yunnan University (云南大学); Nanyang Technological University (南洋理工大学); Wuhan University (武汉大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:All-in-One Image Restoration (AiOIR) aims to recover high-quality images from diverse degradations within a unified framework. However, existing methods often fail to explicitly model degradation types and struggle to adapt their restoration behavior to complex or mixed degradations. To address these issues, we propose ClusIR, a Cluster-Guided Image Restoration framework that explicitly models degradation semantics through learnable clustering and propagates cluster-aware cues across spatial and frequency domains for adaptive restoration. Specifically, ClusIR comprises two key components: a Probabilistic Cluster-Guided Routing Mechanism (PCGRM) and a Degradation-Aware Frequency Modulation Module (DAFMM). The proposed PCGRM disentangles degradation recognition from expert activation, enabling discriminative degradation perception and stable expert routing. Meanwhile, DAFMM leverages the cluster-guided priors to perform adaptive frequency decomposition and targeted modulation, collaboratively refining structural and textural representations for higher restoration fidelity. The cluster-guided synergy seamlessly bridges semantic cues with frequency-domain modulation, empowering ClusIR to attain remarkable restoration results across a wide range of degradations. Extensive experiments on diverse benchmarks validate that ClusIR reaches competitive performance under several scenarios.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-9] owards Efficient and Effective Multi-Camera Encoding for End-to-End Driving</p>
<p>【速读】：该论文旨在解决端到端自动驾驶系统中处理多摄像头高体积数据时存在的计算瓶颈问题。其解决方案的关键在于提出了一种名为Flex的高效场景编码器，通过一组可学习的场景标记（scene tokens）联合编码来自不同摄像头和时间步的所有图像标记信息，从而实现对视觉输入的高效压缩。该方法不依赖于显式的三维先验知识（如鸟瞰图（Bird-Eye-View, BEV）、占据表示或三平面表示），而是直接从数据中学习紧凑的场景表征，具备几何无关性（geometry-agnostic）。这种联合编码策略显著提升了下游基于大语言模型（Large Language Model, LLM）的策略模型的推理吞吐量，并在大规模驾驶数据集上实现了性能提升与无需监督的场景分解能力的涌现。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10947">https://arxiv.org/abs/2512.10947</a><br>
<strong>作者</strong>: Jiawei Yang,Ziyu Chen,Yurong You,Yan Wang,Yiming Li,Yuxiao Chen,Boyi Li,Boris Ivanovic,Marco Pavone,Yue Wang<br>
<strong>机构</strong>: University of Southern California (南加州大学); Stanford University (斯坦福大学); NVIDIA Research (英伟达研究)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project Page: <a target="_blank" rel="noopener" href="https://jiawei-yang.github.io/Flex/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present Flex, an efficient and effective scene encoder that addresses the computational bottleneck of processing high-volume multi-camera data in end-to-end autonomous driving. Flex employs a small set of learnable scene tokens to jointly encode information from all image tokens across different cameras and timesteps. By design, our approach is geometry-agnostic, learning a compact scene representation directly from data without relying on the explicit 3D inductive biases, such as Bird-Eye-View (BEV), occupancy or tri-plane representations, which are common in prior work. This holistic encoding strategy aggressively compresses the visual input for the downstream Large Language Model (LLM) based policy model. Evaluated on a large-scale proprietary dataset of 20,000 driving hours, our Flex achieves 2.2x greater inference throughput while improving driving performance by a large margin compared to state-of-the-art methods. Furthermore, we show that these compact scene tokens develop an emergent capability for scene decomposition without any explicit supervision. Our findings challenge the prevailing assumption that 3D priors are necessary, demonstrating that a data-driven, joint encoding strategy offers a more scalable, efficient and effective path for future autonomous driving systems.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-10] MeViS: A Multi-Modal Dataset for Referring Motion Expression Video Segmentation</p>
<p>【速读】：该论文旨在解决现有视频理解方法在处理基于运动描述（motion expression）的像素级视频理解任务时存在的不足，尤其是当前数据集多聚焦于静态属性丰富的显著目标，忽视了运动信息在语言和视频中的关键作用。为填补这一空白，作者提出了MeViS数据集，包含33,072条人工标注的文本与语音形式的运动表达，覆盖2,006个复杂场景中8,171个目标对象，并支持4类任务：指代表达视频对象分割（RVOS）、音频引导视频对象分割（AVOS）、指代多目标跟踪（RMOT）以及新提出的指代运动表达生成（RMEG）。实验表明，现有方法在运动表达驱动的视频理解任务中存在明显局限性；为此，作者进一步提出LMPM++方法，在RVOS/AVOS/RMOT任务上取得新的最先进性能，其关键在于融合运动语义推理与跨模态对齐机制，从而增强模型对动态目标的精准定位与跟踪能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10945">https://arxiv.org/abs/2512.10945</a><br>
<strong>作者</strong>: Henghui Ding,Chang Liu,Shuting He,Kaining Ying,Xudong Jiang,Chen Change Loy,Yu-Gang Jiang<br>
<strong>机构</strong>: Fudan University (复旦大学); Shanghai University of Finance and Economics (上海财经大学); Nanyang Technological University (南洋理工大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  IEEE TPAMI, Project Page: <a target="_blank" rel="noopener" href="https://henghuiding.com/MeViS/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper proposes a large-scale multi-modal dataset for referring motion expression video segmentation, focusing on segmenting and tracking target objects in videos based on language description of objects’ motions. Existing referring video segmentation datasets often focus on salient objects and use language expressions rich in static attributes, potentially allowing the target object to be identified in a single frame. Such datasets underemphasize the role of motion in both videos and languages. To explore the feasibility of using motion expressions and motion reasoning clues for pixel-level video understanding, we introduce MeViS, a dataset containing 33,072 human-annotated motion expressions in both text and audio, covering 8,171 objects in 2,006 videos of complex scenarios. We benchmark 15 existing methods across 4 tasks supported by MeViS, including 6 referring video object segmentation (RVOS) methods, 3 audio-guided video object segmentation (AVOS) methods, 2 referring multi-object tracking (RMOT) methods, and 4 video captioning methods for the newly introduced referring motion expression generation (RMEG) task. The results demonstrate weaknesses and limitations of existing methods in addressing motion expression-guided video understanding. We further analyze the challenges and propose an approach LMPM++ for RVOS/AVOS/RMOT that achieves new state-of-the-art results. Our dataset provides a platform that facilitates the development of motion expression-guided video understanding algorithms in complex video scenes. The proposed MeViS dataset and the method’s source code are publicly available at this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-11] AlcheMinT: Fine-grained Temporal Control for Multi-Reference Consistent Video Generation</p>
<p>【速读】：该论文旨在解决当前基于大型扩散模型的主体驱动视频生成方法在主体出现与消失时间控制上的细粒度缺失问题，这限制了其在组合视频合成、故事板设计及可控动画等应用中的实用性。解决方案的关键在于提出AlcheMinT框架，通过引入显式的时间戳条件机制，结合一种新颖的位置编码方式以解码时间区间信息（即主体身份关联的时间段），并无缝集成到预训练视频生成模型的位置嵌入中；同时引入主体描述性文本标记以强化视觉身份与视频字幕之间的绑定关系，从而减少生成过程中的歧义。该方法采用标记级拼接策略，避免了额外的交叉注意力模块，参数开销可忽略不计，首次实现了多主体视频生成中精确的时间控制能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10943">https://arxiv.org/abs/2512.10943</a><br>
<strong>作者</strong>: Sharath Girish,Viacheslav Ivanov,Tsai-Shien Chen,Hao Chen,Aliaksandr Siarohin,Sergey Tulyakov<br>
<strong>机构</strong>: Snap Inc.; UC Merced<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://snap-research.github.io/Video-AlcheMinT/snap-research.github.io/Video-AlcheMinT">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advances in subject-driven video generation with large diffusion models have enabled personalized content synthesis conditioned on user-provided subjects. However, existing methods lack fine-grained temporal control over subject appearance and disappearance, which are essential for applications such as compositional video synthesis, storyboarding, and controllable animation. We propose AlcheMinT, a unified framework that introduces explicit timestamps conditioning for subject-driven video generation. Our approach introduces a novel positional encoding mechanism that unlocks the encoding of temporal intervals, associated in our case with subject identities, while seamlessly integrating with the pretrained video generation model positional embeddings. Additionally, we incorporate subject-descriptive text tokens to strengthen binding between visual identity and video captions, mitigating ambiguity during generation. Through token-wise concatenation, AlcheMinT avoids any additional cross-attention modules and incurs negligible parameter overhead. We establish a benchmark evaluating multiple subject identity preservation, video fidelity, and temporal adherence. Experimental results demonstrate that AlcheMinT achieves visual quality matching state-of-the-art video personalization methods, while, for the first time, enabling precise temporal control over multi-subject generation within videos. Project page is at this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-12] VL-JEPA: Joint Embedding Predictive Architecture for Vision-language</p>
<p>【速读】：该论文旨在解决传统视觉语言模型（Vision-Language Models, VLMs）在训练效率和推理灵活性方面的局限性，尤其是其依赖自回归生成文本令牌（token）导致参数冗余与计算开销大、难以实现高效选择性解码的问题。解决方案的关键在于提出VL-JEPA，一种基于联合嵌入预测架构（Joint Embedding Predictive Architecture, JEPA）的新范式：模型不再直接预测离散文本令牌，而是预测目标文本的连续嵌入表示（continuous embeddings），从而在抽象表示空间中学习任务相关的语义信息，同时忽略表层语言变异性。这一设计使得模型在保持高性能的同时，参数量减少50%，且支持原生的选择性解码机制，在不显著牺牲性能的前提下将解码操作次数降低2.85倍。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10942">https://arxiv.org/abs/2512.10942</a><br>
<strong>作者</strong>: Delong Chen,Mustafa Shukor,Theo Moutakanni,Willy Chung,Jade Yu,Tejaswi Kasarla,Allen Bolourchi,Yann LeCun,Pascale Fung<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce VL-JEPA, a vision-language model built on a Joint Embedding Predictive Architecture (JEPA). Instead of autoregressively generating tokens as in classical VLMs, VL-JEPA predicts continuous embeddings of the target texts. By learning in an abstract representation space, the model focuses on task-relevant semantics while abstracting away surface-level linguistic variability. In a strictly controlled comparison against standard token-space VLM training with the same vision encoder and training data, VL-JEPA achieves stronger performance while having 50% fewer trainable parameters. At inference time, a lightweight text decoder is invoked only when needed to translate VL-JEPA predicted embeddings into text. We show that VL-JEPA natively supports selective decoding that reduces the number of decoding operations by 2.85x while maintaining similar performance compared to non-adaptive uniform decoding. Beyond generation, the VL-JEPA’s embedding space naturally supports open-vocabulary classification, text-to-video retrieval, and discriminative VQA without any architecture modification. On eight video classification and eight video retrieval datasets, the average performance VL-JEPA surpasses that of CLIP, SigLIP2, and Perception Encoder. At the same time, the model achieves comparable performance as classical VLMs (InstructBLIP, QwenVL) on four VQA datasets: GQA, TallyQA, POPE and POPEv2, despite only having 1.6B parameters.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-13] Mull-Tokens: Modality-Agnostic Latent Thinking</p>
<p>【速读】：该论文旨在解决现有多模态模型在空间推理等复杂任务中表现脆弱且难以扩展的问题，这些问题通常源于对专用工具的依赖、高成本的图像生成或手工设计的推理数据，导致模型在文本与图像思维之间切换效率低下。其解决方案的关键在于提出了一种称为Mull-Tokens的通用潜在标记机制，这些标记在训练过程中被预训练以在图像或文本模态中存储中间信息，从而支持模型自由形式地进行跨模态思考，无需显式调用外部工具或大量标注数据。通过利用交错文本-图像轨迹进行监督训练，并进一步无监督微调仅基于最终答案，Mull-Tokens显著提升了多模态空间推理性能，在四个基准测试中平均提升3%，在拼图类任务上最高达16%。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10941">https://arxiv.org/abs/2512.10941</a><br>
<strong>作者</strong>: Arijit Ray,Ahmed Abdelkader,Chengzhi Mao,Bryan A. Plummer,Kate Saenko,Ranjay Krishna,Leonidas Guibas,Wen-Sheng Chu<br>
<strong>机构</strong>: Google(谷歌); University of Washington (华盛顿大学); Stanford University (斯坦福大学); Boston University (波士顿大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Project webpage: <a target="_blank" rel="noopener" href="https://arijitray.com/multimodal_thinking/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Reasoning goes beyond language; the real world requires reasoning about space, time, affordances, and much more that words alone cannot convey. Existing multimodal models exploring the potential of reasoning with images are brittle and do not scale. They rely on calling specialist tools, costly generation of images, or handcrafted reasoning data to switch between text and image thoughts. Instead, we offer a simpler alternative – Mull-Tokens – modality-agnostic latent tokens pre-trained to hold intermediate information in either image or text modalities to let the model think free-form towards the correct answer. We investigate best practices to train Mull-Tokens inspired by latent reasoning frameworks. We first train Mull-Tokens using supervision from interleaved text-image traces, and then fine-tune without any supervision by only using the final answers. Across four challenging spatial reasoning benchmarks involving tasks such as solving puzzles and taking different perspectives, we demonstrate that Mull-Tokens improve upon several baselines utilizing text-only reasoning or interleaved image-text reasoning, achieving a +3% average improvement and up to +16% on a puzzle solving reasoning-heavy split compared to our strongest baseline. Adding to conversations around challenges in grounding textual and visual reasoning, Mull-Tokens offers a simple solution to abstractly think in multiple modalities.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-14] OmniView: An All-Seeing Diffusion Model for 3D and 4D View Synthesis</p>
<p>【速读】：该论文旨在解决当前扩散模型中相机控制（camera control）任务碎片化的问题，即现有方法仅针对特定的4D一致性任务（如新视角合成、带相机控制的文生视频、图像到视频等）进行训练，导致模型缺乏通用性且依赖于不连续的数据子集。解决方案的关键在于提出OmniView框架，通过将空间（space）、时间（time）和视角（view）条件分别建模，实现三者的灵活组合，从而统一处理包括静态/动态场景的新视角合成、轨迹外推以及文本或图像驱动的视频生成等多种4D一致性任务。该设计显著提升了模型在多个基准上的性能，例如在多视角新视角合成（multiview NVS）任务中图像质量提升达33%，并大幅降低文本引导视频生成中的相机轨迹误差（减少4倍），验证了单一模型实现通用4D视频生成的可行性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10940">https://arxiv.org/abs/2512.10940</a><br>
<strong>作者</strong>: Xiang Fan,Sharath Girish,Vivek Ramanujan,Chaoyang Wang,Ashkan Mirzaei,Petr Sushko,Aliaksandr Siarohin,Sergey Tulyakov,Ranjay Krishna<br>
<strong>机构</strong>: University of Washington (华盛顿大学); Snap Inc. (Snap Inc.)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://snap-research.github.io/OmniView/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Prior approaches injecting camera control into diffusion models have focused on specific subsets of 4D consistency tasks: novel view synthesis, text-to-video with camera control, image-to-video, amongst others. Therefore, these fragmented approaches are trained on disjoint slices of available 3D/4D data. We introduce OmniView, a unified framework that generalizes across a wide range of 4D consistency tasks. Our method separately represents space, time, and view conditions, enabling flexible combinations of these inputs. For example, OmniView can synthesize novel views from static, dynamic, and multiview inputs, extrapolate trajectories forward and backward in time, and create videos from text or image prompts with full camera control. OmniView is competitive with task-specific models across diverse benchmarks and metrics, improving image quality scores among camera-conditioned diffusion models by up to 33% in multiview NVS LLFF dataset, 60% in dynamic NVS Neural 3D Video benchmark, 20% in static camera control on RE-10K, and reducing camera trajectory errors by 4x in text-conditioned video generation. With strong generalizability in one model, OmniView demonstrates the feasibility of a generalist 4D video model. Project page is available at this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-15] GaussianHeadTalk: Wobble-Free 3D Talking Heads with Audio Driven Gaussian Splatting</p>
<p>【速读】：该论文旨在解决当前语音驱动人脸动画（speech-driven talking heads）在实际应用中面临的两大核心问题：一是现有方法在视觉保真度与时间稳定性之间难以平衡，即高保真方法往往速度慢或存在时序不稳定；二是扩散模型（diffusion methods）虽能生成逼真图像，但在单次输入（one-shot setting）场景下表现不佳，而基于高斯点阵（Gaussian Splatting）的方法虽可实现实时渲染，却因面部追踪不准确或高斯映射不一致导致输出不稳定和视频伪影。解决方案的关键在于：引入3D可变形模型（3D Morphable Models, 3DMM）对高斯点阵进行结构化映射，从而提升几何一致性；并设计基于Transformer的参数预测机制，直接从音频输入中预测3DMM参数，以实现时序一致性驱动，最终仅需单目视频和独立音频即可实时生成高质量、稳定的人脸说话视频。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10939">https://arxiv.org/abs/2512.10939</a><br>
<strong>作者</strong>: Madhav Agarwal,Mingtian Zhang,Laura Sevilla-Lara,Steven McDonagh<br>
<strong>机构</strong>: University of Edinburgh (爱丁堡大学); University College London (伦敦大学学院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  IEEE/CVF Winter Conference on Applications of Computer Vision 2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Speech-driven talking heads have recently emerged and enable interactive avatars. However, real-world applications are limited, as current methods achieve high visual fidelity but slow or fast yet temporally unstable. Diffusion methods provide realistic image generation, yet struggle with oneshot settings. Gaussian Splatting approaches are real-time, yet inaccuracies in facial tracking, or inconsistent Gaussian mappings, lead to unstable outputs and video artifacts that are detrimental to realistic use cases. We address this problem by mapping Gaussian Splatting using 3D Morphable Models to generate person-specific avatars. We introduce transformer-based prediction of model parameters, directly from audio, to drive temporal consistency. From monocular video and independent audio speech inputs, our method enables generation of real-time talking head videos where we report competitive quantitative and qualitative performance.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-16] Any4D: Unified Feed-Forward Metric 4D Reconstruction</p>
<p>【速读】：该论文旨在解决大规模、密集的4D场景重建问题，即从多视角RGB视频中同时估计动态场景的几何结构与像素级运动（scene flow），并支持多模态输入（如RGB-D、IMU和雷达数据）。传统方法通常局限于两帧之间的稠密场景光流或稀疏3D点跟踪，难以实现高效且灵活的4D重建。其解决方案的关键在于提出了一种模块化的4D场景表示机制：将每帧的预测分解为以局部相机坐标系表示的自主因素（egocentric factors，如深度图和相机内参）以及以全局世界坐标系表示的他主因素（allocentric factors，如相机外参和场景光流），从而构建一个可扩展的多视角Transformer架构Any4D。该设计不仅提升了精度（误差降低2–3倍）和计算效率（快15倍），还增强了对多传感器输入的适应能力，为下游应用提供了通用且高效的4D重建框架。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10935">https://arxiv.org/abs/2512.10935</a><br>
<strong>作者</strong>: Jay Karhade,Nikhil Keetha,Yuchen Zhang,Tanisha Gupta,Akash Sharma,Sebastian Scherer,Deva Ramanan<br>
<strong>机构</strong>: Carnegie Mellon University (卡内基梅隆大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
<strong>备注</strong>:  Project Website: <a target="_blank" rel="noopener" href="https://any-4d.github.io/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present Any4D, a scalable multi-view transformer for metric-scale, dense feed-forward 4D reconstruction. Any4D directly generates per-pixel motion and geometry predictions for N frames, in contrast to prior work that typically focuses on either 2-view dense scene flow or sparse 3D point tracking. Moreover, unlike other recent methods for 4D reconstruction from monocular RGB videos, Any4D can process additional modalities and sensors such as RGB-D frames, IMU-based egomotion, and Radar Doppler measurements, when available. One of the key innovations that allows for such a flexible framework is a modular representation of a 4D scene; specifically, per-view 4D predictions are encoded using a variety of egocentric factors (depthmaps and camera intrinsics) represented in local camera coordinates, and allocentric factors (camera extrinsics and scene flow) represented in global world coordinates. We achieve superior performance across diverse setups - both in terms of accuracy (2-3X lower error) and compute efficiency (15X faster), opening avenues for multiple downstream applications.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-17] BabyVLM-V2: Toward Developmentally Grounded Pretraining and Benchmarking of Vision Foundation Models</p>
<p>【速读】：该论文旨在解决视觉基础模型（Vision Foundation Models）在预训练阶段缺乏发展合理性与样本效率的问题，尤其是如何借鉴婴儿早期认知发展的自然轨迹来设计更高效、更具可解释性的预训练框架。其解决方案的关键在于提出BabyVLM-V2框架，该框架通过三个核心要素实现突破：一是构建覆盖范围广且人工标注最少的纵向婴儿中心音频视频语料库，生成符合婴儿经验的多模态数据（如视频-话语对、图像-话语对及多轮对话数据）；二是开发一个灵活的模型架构；三是引入DevCV Toolbox，将NIH Baby Toolbox中的全部视觉相关认知评估指标转化为涵盖空间推理、记忆和词汇理解等能力的十项多模态基准任务，从而实现对模型认知能力的系统性评测。实验表明，从零开始预训练的小型模型即可在DevCV上达到竞争性表现，甚至在部分任务上优于GPT-4o，验证了该框架在发展合理预训练中的有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10932">https://arxiv.org/abs/2512.10932</a><br>
<strong>作者</strong>: Shengao Wang,Wenqi Wang,Zecheng Wang,Max Whitton,Michael Wakeham,Arjun Chandra,Joey Huang,Pengyue Zhu,Helen Chen,David Li,Jeffrey Li,Shawn Li,Andrew Zagula,Amy Zhao,Andrew Zhu,Sayaka Nakamura,Yuki Yamamoto,Jerry Jun Yokono,Aaron Mueller,Bryan A. Plummer,Kate Saenko,Venkatesh Saligrama,Boqing Gong<br>
<strong>机构</strong>: Boston University (波士顿大学); Sony Group Corporation (索尼集团)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Early children’s developmental trajectories set up a natural goal for sample-efficient pretraining of vision foundation models. We introduce BabyVLM-V2, a developmentally grounded framework for infant-inspired vision-language modeling that extensively improves upon BabyVLM-V1 through a longitudinal, multifaceted pretraining set, a versatile model, and, most importantly, DevCV Toolbox for cognitive evaluation. The pretraining set maximizes coverage while minimizing curation of a longitudinal, infant-centric audiovisual corpus, yielding video-utterance, image-utterance, and multi-turn conversational data that mirror infant experiences. DevCV Toolbox adapts all vision-related measures of the recently released NIH Baby Toolbox into a benchmark suite of ten multimodal tasks, covering spatial reasoning, memory, and vocabulary understanding aligned with early children’s capabilities. Experimental results show that a compact model pretrained from scratch can achieve competitive performance on DevCV Toolbox, outperforming GPT-4o on some tasks. We hope the principled, unified BabyVLM-V2 framework will accelerate research in developmentally plausible pretraining of vision foundation models.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-18] FoundationMotion: Auto-Labeling and <mark class="hl-label green">Reasoning</mark>  about Spatial Movement in Videos</p>
<p>【速读】：该论文旨在解决当前生成式AI模型在运动理解（motion understanding）任务中表现不佳的问题，其根本原因在于缺乏大规模、细粒度的运动数据集。现有数据集多依赖人工标注，成本高且难以扩展。解决方案的关键在于提出FoundationMotion——一个全自动的数据整理管道，通过视频中目标物体的检测与跟踪提取轨迹，并结合大语言模型（Large Language Models, LLMs）自动生成细粒度描述和多样化的问答对，从而构建高质量、可扩展的运动理解数据集。基于此数据集微调的开源模型（如NVILA-Video-15B和Qwen2.5-7B）在多个基准测试中显著优于封闭源模型（如Gemini-2.5 Flash）和大型开源模型（如Qwen2.5-VL-72B），验证了该方案的有效性与通用性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10927">https://arxiv.org/abs/2512.10927</a><br>
<strong>作者</strong>: Yulu Gan,Ligeng Zhu,Dandan Shan,Baifeng Shi,Hongxu Yin,Boris Ivanovic,Song Han,Trevor Darrell,Jitendra Malik,Marco Pavone,Boyi Li<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Code is available at <a target="_blank" rel="noopener" href="https://github.com/Wolfv0/FoundationMotion/tree/main">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Motion understanding is fundamental to physical reasoning, enabling models to infer dynamics and predict future states. However, state-of-the-art models still struggle on recent motion benchmarks, primarily due to the scarcity of large-scale, fine-grained motion datasets. Existing motion datasets are often constructed from costly manual annotation, severely limiting scalability. To address this challenge, we introduce FoundationMotion, a fully automated data curation pipeline that constructs large-scale motion datasets. Our approach first detects and tracks objects in videos to extract their trajectories, then leverages these trajectories and video frames with Large Language Models (LLMs) to generate fine-grained captions and diverse question-answer pairs about motion and spatial reasoning. Using datasets produced by this pipeline, we fine-tune open-source models including NVILA-Video-15B and Qwen2.5-7B, achieving substantial improvements in motion understanding without compromising performance on other tasks. Notably, our models outperform strong closed-source baselines like Gemini-2.5 Flash and large open-source models such as Qwen2.5-VL-72B across diverse motion understanding datasets and benchmarks. FoundationMotion thus provides a scalable solution for curating fine-grained motion datasets that enable effective fine-tuning of diverse models to enhance motion understanding and spatial reasoning capabilities.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-19] DuetSVG: Unified Multimodal SVG Generation with Internal Visual Guidance</p>
<p>【速读】：该论文旨在解决当前基于视觉语言模型（Vision-Language Model, VLM）的可缩放矢量图形（SVG）生成方法在解码过程中仅依赖文本信号、缺乏视觉反馈而导致的复杂语义理解不足和图形几何不一致性问题。解决方案的关键在于提出DuetSVG，这是一种统一的多模态模型，能够端到端地联合生成图像令牌（image tokens）与对应的SVG令牌（SVG tokens），并通过引入一种新颖的推理时缩放策略，利用模型原生的视觉预测作为引导来提升SVG解码质量，从而实现视觉忠实性、语义对齐性和语法清洁性的综合优化。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10894">https://arxiv.org/abs/2512.10894</a><br>
<strong>作者</strong>: Peiying Zhang,Nanxuan Zhao,Matthew Fisher,Yiran Xu,Jing Liao,Difan Liu<br>
<strong>机构</strong>: City University of Hong Kong (香港城市大学); Adobe Research (Adobe 研究院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://intchous.github.io/DuetSVG-site">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent vision-language model (VLM)-based approaches have achieved impressive results on SVG generation. However, because they generate only text and lack visual signals during decoding, they often struggle with complex semantics and fail to produce visually appealing or geometrically coherent SVGs. We introduce DuetSVG, a unified multimodal model that jointly generates image tokens and corresponding SVG tokens in an end-to-end manner. DuetSVG is trained on both image and SVG datasets. At inference, we apply a novel test-time scaling strategy that leverages the model’s native visual predictions as guidance to improve SVG decoding quality. Extensive experiments show that our method outperforms existing methods, producing visually faithful, semantically aligned, and syntactically clean SVGs across a wide range of applications.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-20] PubTables-v2: A new large-scale dataset for full-page and multi-page table extraction</p>
<p>【速读】：该论文旨在解决视觉文档理解中的表格提取（Table Extraction, TE）难题，特别是针对现有方法在多页文档中难以准确识别和结构化表格的问题。传统方法通常分两步进行：先检测表格区域，再识别其结构；而新兴的视觉语言模型（Vision-Language Models, VLMs）虽能直接在整页或文档上下文中提取表格，但受限于缺乏大规模标注数据，进展难以量化评估。解决方案的关键在于构建了一个新的大规模数据集 PubTables-v2，这是首个支持多页表格结构识别的大规模基准数据集，同时基于此数据集开发了 Page-Object Table Transformer (POTATR)，一种将 Table Transformer 扩展为图像到图结构的端到端页面级表格提取模型，从而显著提升了复杂文档场景下的表格结构建模能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10888">https://arxiv.org/abs/2512.10888</a><br>
<strong>作者</strong>: Brandon Smock,Valerie Faucon-Morin,Max Sokolov,Libin Liang,Tayyibah Khanam,Maury Courtland<br>
<strong>机构</strong>: Kensho Technologies<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  15 pages, 7 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Table extraction (TE) is a key challenge in visual document understanding. Traditional approaches detect tables first, then recognize their structure. Recently, interest has surged in developing methods, such as vision-language models (VLMs), that can extract tables directly in their full page or document context. However, progress has been difficult to demonstrate due to a lack of annotated data. To address this, we create a new large-scale dataset, PubTables-v2. PubTables-v2 supports a number of current challenging table extraction tasks. Notably, it is the first large-scale benchmark for multi-page table structure recognition. We demonstrate its usefulness by evaluating domain-specialized VLMs on these tasks and highlighting current progress. Finally, we use PubTables-v2 to create the Page-Object Table Transformer (POTATR), an image-to-graph extension of the Table Transformer to comprehensive page-level TE. Data, code, and trained models will be released.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-21] MoCapAnything: Unified 3D Motion Capture for Arbitrary Skeletons from Monocular Videos</p>
<p>【速读】：该论文旨在解决现有动作捕捉（Motion Capture, MoCap）系统在跨物种或跨模板场景下适应性差的问题，即大多数现有流程依赖于特定物种或预定义模板，难以直接应用于任意3D资产（如不同骨骼结构或网格形态的模型）。为应对这一挑战，作者提出Category-Agnostic Motion Capture (CAMoCap) 的形式化定义，并设计了MoCapAnything框架：其核心在于通过参考引导的因子化建模，将运动重建解耦为两个阶段——首先预测通用的3D关节轨迹，再利用约束感知的逆向运动学（Inverse Kinematics, IK）恢复适配特定资产的旋转动画（如BVH格式）。关键创新包括：(1) 参考提示编码器从资产的骨架、网格及渲染图像中提取关节级查询；(2) 视频特征提取器生成密集视觉描述符并重建粗粒度4D变形网格以弥合视频与关节空间的鸿沟；(3) 统一运动解码器融合多源线索生成时序一致的关节轨迹。该方案实现了对任意3D资产的高质量驱动动画生成，具备显著的跨物种迁移能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10881">https://arxiv.org/abs/2512.10881</a><br>
<strong>作者</strong>: Kehong Gong,Zhengyu Wen,Weixia He,Mingxi Xu,Qi Wang,Ning Zhang,Zhengyu Li,Dongze Lian,Wei Zhao,Xiaoyu He,Mingyuan Zhang<br>
<strong>机构</strong>: Huawei Technologies Co., Ltd.(华为技术有限公司); Huawei Central Media Technology Institute(华为中央媒体技术研究院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://animotionlab.github.io/MoCapAnything/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Motion capture now underpins content creation far beyond digital humans, yet most existing pipelines remain species- or template-specific. We formalize this gap as Category-Agnostic Motion Capture (CAMoCap): given a monocular video and an arbitrary rigged 3D asset as a prompt, the goal is to reconstruct a rotation-based animation such as BVH that directly drives the specific asset. We present MoCapAnything, a reference-guided, factorized framework that first predicts 3D joint trajectories and then recovers asset-specific rotations via constraint-aware inverse kinematics. The system contains three learnable modules and a lightweight IK stage: (1) a Reference Prompt Encoder that extracts per-joint queries from the asset’s skeleton, mesh, and rendered images; (2) a Video Feature Extractor that computes dense visual descriptors and reconstructs a coarse 4D deforming mesh to bridge the gap between video and joint space; and (3) a Unified Motion Decoder that fuses these cues to produce temporally coherent trajectories. We also curate Truebones Zoo with 1038 motion clips, each providing a standardized skeleton-mesh-render triad. Experiments on both in-domain benchmarks and in-the-wild videos show that MoCapAnything delivers high-quality skeletal animations and exhibits meaningful cross-species retargeting across heterogeneous rigs, enabling scalable, prompt-driven 3D motion capture for arbitrary assets. Project page: this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-22] From Macro to Micro: Benchmarking Microscopic Spatial Intelligence on Molecules via Vision-Language Models</p>
<p>【速读】：该论文旨在解决当前视觉语言模型（Vision-Language Models, VLMs）在微观空间智能（Microscopic Spatial Intelligence, MiSI）领域中对不可见微观实体的空间关系感知与推理能力不足的问题。MiSI是指对分子等微观结构中空间关系的理解能力，是科学发现的核心基础。为系统评估VLMs在此领域的潜力，作者提出了MiSI-Bench基准框架，其关键创新在于构建了一个包含超过16.3万条问答对和58.7万张图像的数据集，覆盖约4000个分子结构及九类互补任务，从基础的空间变换到复杂的关联识别全面衡量模型性能。实验表明，现有最先进VLMs在该基准上表现远低于人类水平，但经过微调的7B参数模型在空间变换任务中已超越人类，而其在氢键识别等需科学知识支撑的任务中表现不佳，凸显了将显式领域知识融入模型以推动科学通用人工智能（Scientific AGI）发展的必要性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10867">https://arxiv.org/abs/2512.10867</a><br>
<strong>作者</strong>: Zongzhao Li,Xiangzhe Kong,Jiahui Su,Zongyang Ma,Mingze Li,Songyou Li,Yuelin Zhang,Yu Rong,Tingyang Xu,Deli Zhao,Wenbing Huang<br>
<strong>机构</strong>: Gaoling School of Artificial Intelligence, Renmin University of China (中国人民大学高瓴人工智能学院); Dept. of Comp. Sci. &amp; Tech., Tsinghua University (清华大学计算机科学与技术系); Institute for AI Industry Research (AIR), Tsinghua University (清华大学人工智能产业研究院); SKL-ESPC &amp; SEPKL-AERM, College of Environmental Sciences and Engineering, Peking University (北京大学环境科学与工程学院重点实验室); MAIS, Institute of Automation, Chinese Academy of Sciences (中国科学院自动化研究所); DAMO Academy, Alibaba Group, Hangzhou, China (阿里巴巴达摩院); Hupan Lab, Hangzhou, China (湖畔实验室)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper introduces the concept of Microscopic Spatial Intelligence (MiSI), the capability to perceive and reason about the spatial relationships of invisible microscopic entities, which is fundamental to scientific discovery. To assess the potential of Vision-Language Models (VLMs) in this domain, we propose a systematic benchmark framework MiSI-Bench. This framework features over 163,000 question-answer pairs and 587,000 images derived from approximately 4,000 molecular structures, covering nine complementary tasks that evaluate abilities ranging from elementary spatial transformations to complex relational identifications. Experimental results reveal that current state-of-the-art VLMs perform significantly below human level on this benchmark. However, a fine-tuned 7B model demonstrates substantial potential, even surpassing humans in spatial transformation tasks, while its poor performance in scientifically-grounded tasks like hydrogen bond recognition underscores the necessity of integrating explicit domain knowledge for progress toward scientific AGI. The datasets are available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-23] MMSI-Video-Bench: A Holistic Benchmark for Video-Based Spatial Intelligence</p>
<p>【速读】：该论文旨在解决多模态大语言模型（Multimodal Large Language Models, MLLMs）在连续视觉输入下缺乏系统性空间智能评估标准的问题，从而推动其向物理环境中通用助手的演进。解决方案的关键在于构建了一个全人工标注的视频空间智能基准测试集——MMSI-Video-Bench，该基准基于感知（Perception）、规划（Planning）、预测（Prediction）与跨视频推理（Cross-Video Reasoning）四层框架设计了1,106个问题，覆盖25个公开数据集及自建视频片段（共1,278个clip），并通过三位三维视觉专家严格审核确保语义精确性和无歧义性。此基准不仅支持整体能力评估，还可细分为室内场景感知、机器人任务和空间定位三个子基准，实现针对性分析。实验表明当前主流MLLMs在该基准上表现远低于人类水平（最佳模型落后约60%），且现有空间微调策略难以泛化，揭示出几何推理、运动定位、长时预测和跨视频对应等系统性缺陷，为后续研究提供了明确的方向和统一的评测平台。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10863">https://arxiv.org/abs/2512.10863</a><br>
<strong>作者</strong>: Jingli Lin,Runsen Xu,Shaohao Zhu,Sihan Yang,Peizhou Cao,Yunlong Ran,Miao Hu,Chenming Zhu,Yiman Xie,Yilin Long,Wenbo Hu,Dahua Lin,Tai Wang,Jiangmiao Pang<br>
<strong>机构</strong>: Shanghai AI Laboratory (上海人工智能实验室); Shanghai Jiaotong University (上海交通大学); The Chinese University of Hong Kong (香港中文大学); Zhejiang University (浙江大学); Beihang University (北京航空航天大学); Xi’an Jiaotong University (西安交通大学); University of Hong Kong (香港大学); Fudan University (复旦大学); University of California, Los Angeles (加州大学洛杉矶分校)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Spatial understanding over continuous visual input is crucial for MLLMs to evolve into general-purpose assistants in physical environments. Yet there is still no comprehensive benchmark that holistically assesses the progress toward this goal. In this work, we introduce MMSI-Video-Bench, a fully human-annotated benchmark for video-based spatial intelligence in MLLMs. It operationalizes a four-level framework, Perception, Planning, Prediction, and Cross-Video Reasoning, through 1,106 questions grounded in 1,278 clips from 25 datasets and in-house videos. Each item is carefully designed and reviewed by 3DV experts with explanatory rationales to ensure precise, unambiguous grounding. Leveraging its diverse data sources and holistic task coverage, MMSI-Video-Bench also supports three domain-oriented sub-benchmarks (Indoor Scene Perception Bench, Robot Bench and Grounding Bench) for targeted capability assessment. We evaluate 25 strong open-source and proprietary MLLMs, revealing a striking human–AI gap: many models perform near chance, and the best reasoning model lags humans by nearly 60%. We further find that spatially fine-tuned models still fail to generalize effectively on our benchmark. Fine-grained error analysis exposes systematic failures in geometric reasoning, motion grounding, long-horizon prediction, and cross-video correspondence. We also show that typical frame-sampling strategies transfer poorly to our reasoning-intensive benchmark, and that neither 3D spatial cues nor chain-of-thought prompting yields meaningful gains. We expect our benchmark to establish a solid testbed for advancing video-based spatial intelligence.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-24] SWiT-4D: Sliding-Window Transformer for Lossless and Parameter-Free Temporal 4D Generation</p>
<p>【速读】：该论文旨在解决从单目视频到高质量显式4D网格（4D mesh）的生成难题，尤其是在缺乏大规模自然采集的4D网格数据集情况下，如何实现高保真且时序稳定的3D动画资产重建。其核心解决方案是提出SWiT-4D（Sliding-Window Transformer），该方法无需额外参数即可实现无损的时间维度建模，通过与任意基于Diffusion Transformer（DiT）的图像到3D生成器无缝集成，在保持原始单帧前向过程的基础上引入跨帧空间-时间建模能力，从而支持任意长度视频的4D网格重建；同时，为恢复全局平移运动，设计了一个针对静态相机单目视频优化的轨迹模块。实验表明，仅需一段10秒短视频微调，SWiT-4D即可实现几何精度高、时序一致性稳定的结果，展现出极强的数据效率和实际部署潜力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10860">https://arxiv.org/abs/2512.10860</a><br>
<strong>作者</strong>: Kehong Gong,Zhengyu Wen,Mingxi Xu,Weixia He,Qi Wang,Ning Zhang,Zhengyu Li,Chenbin Li,Dongze Lian,Wei Zhao,Xiaoyu He,Mingyuan Zhang<br>
<strong>机构</strong>: Huawei Technologies Co., Ltd.(华为技术有限公司); Huawei Central Media Technology Institute(华为中央媒体技术研究院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://animotionlab.github.io/SWIT4D/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Despite significant progress in 4D content generation, the conversion of monocular videos into high-quality animated 3D assets with explicit 4D meshes remains considerably challenging. The scarcity of large-scale, naturally captured 4D mesh datasets further limits the ability to train generalizable video-to-4D models from scratch in a purely data-driven manner. Meanwhile, advances in image-to-3D generation, supported by extensive datasets, offer powerful prior models that can be leveraged. To better utilize these priors while minimizing reliance on 4D supervision, we introduce SWiT-4D, a Sliding-Window Transformer for lossless, parameter-free temporal 4D mesh generation. SWiT-4D integrates seamlessly with any Diffusion Transformer (DiT)-based image-to-3D generator, adding spatial-temporal modeling across video frames while preserving the original single-image forward process, enabling 4D mesh reconstruction from videos of arbitrary length. To recover global translation, we further introduce an optimization-based trajectory module tailored for static-camera monocular videos. SWiT-4D demonstrates strong data efficiency: with only a single short (10s) video for fine-tuning, it achieves high-fidelity geometry and stable temporal consistency, indicating practical deployability under extremely limited 4D supervision. Comprehensive experiments on both in-domain zoo-test sets and challenging out-of-domain benchmarks (C4D, Objaverse, and in-the-wild videos) show that SWiT-4D consistently outperforms existing baselines in temporal smoothness. Project page: this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-25] PoseGAM: Robust Unseen Object Pose Estimation via Geometry-Aware Multi-View <mark class="hl-label green">Reasoning</mark></p>
<p>【速读】：该论文旨在解决6D物体位姿估计（6D object pose estimation）中对未见过物体的泛化能力不足的问题。现有方法通常依赖于在查询图像与物体模型或模板图像之间显式构建特征对应关系，这限制了其在未知场景下的鲁棒性。解决方案的关键在于提出PoseGAM，一种几何感知的多视角框架，能够直接从查询图像和多个模板图像中预测物体位姿，无需显式匹配；该方法通过两种互补机制融合物体几何信息：基于点的显式几何结构与几何表示网络学习到的特征，从而显著提升对未见物体的泛化性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10840">https://arxiv.org/abs/2512.10840</a><br>
<strong>作者</strong>: Jianqi Chen,Biao Zhang,Xiangjun Tang,Peter Wonka<br>
<strong>机构</strong>: King Abdullah University of Science and Technology (KAUST)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://windvchen.github.io/PoseGAM/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:6D object pose estimation, which predicts the transformation of an object relative to the camera, remains challenging for unseen objects. Existing approaches typically rely on explicitly constructing feature correspondences between the query image and either the object model or template images. In this work, we propose PoseGAM, a geometry-aware multi-view framework that directly predicts object pose from a query image and multiple template images, eliminating the need for explicit matching. Built upon recent multi-view-based foundation model architectures, the method integrates object geometry information through two complementary mechanisms: explicit point-based geometry and learned features from geometry representation networks. In addition, we construct a large-scale synthetic dataset containing more than 190k objects under diverse environmental conditions to enhance robustness and generalization. Extensive evaluations across multiple benchmarks demonstrate our state-of-the-art performance, yielding an average AR improvement of 5.1% over prior methods and achieving up to 17.6% gains on individual datasets, indicating strong generalization to unseen objects. Project page: this https URL .<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-26] Agile Deliberation: Concept Deliberation for Subjective Visual Classification</p>
<p>【速读】：该论文旨在解决视觉概念分类任务中用户初始概念模糊、难以提供高质量标注数据的问题，尤其是在内容审核与内容推荐等场景下，传统的人机协同（human-in-the-loop）方法往往假设用户具备明确且稳定的概念理解，这与实际操作中用户需通过反复思考和反馈逐步厘清概念的“概念 deliberation”（概念思辨）过程相悖。解决方案的关键在于提出一种名为“敏捷思辨”（Agile Deliberation）的人机协同框架，其核心机制包括两个阶段：一是“概念界定”（concept scoping），将初始模糊概念分解为结构化的子概念层次；二是“概念迭代”（concept iteration），通过呈现语义边界案例（semantically borderline examples）引导用户反思并反馈，从而持续调整图像分类器以贴合用户不断演进的意图。该框架强调主观性与交互性，显著提升了模型性能（F1提升7.5%以上）与用户体验（认知负荷降低）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10821">https://arxiv.org/abs/2512.10821</a><br>
<strong>作者</strong>: Leijie Wang,Otilia Stretcu,Wei Qiao,Thomas Denby,Krishnamurthy Viswanathan,Enming Luo,Chun-Ta Lu,Tushar Dogra,Ranjay Krishna,Ariel Fuxman<br>
<strong>机构</strong>: Google Research(谷歌研究); University of Washington(华盛顿大学)<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Human-Computer Interaction (cs.HC); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:From content moderation to content curation, applications requiring vision classifiers for visual concepts are rapidly expanding. Existing human-in-the-loop approaches typically assume users begin with a clear, stable concept understanding to be able to provide high-quality supervision. In reality, users often start with a vague idea and must iteratively refine it through “concept deliberation”, a practice we uncovered through structured interviews with content moderation experts. We operationalize the common strategies in deliberation used by real content moderators into a human-in-the-loop framework called “Agile Deliberation” that explicitly supports evolving and subjective concepts. The system supports users in defining the concept for themselves by exposing them to borderline cases. The system does this with two deliberation stages: (1) concept scoping, which decomposes the initial concept into a structured hierarchy of sub-concepts, and (2) concept iteration, which surfaces semantically borderline examples for user reflection and feedback to iteratively align an image classifier with the user’s evolving intent. Since concept deliberation is inherently subjective and interactive, we painstakingly evaluate the framework through 18 user sessions, each 1.5h long, rather than standard benchmarking datasets. We find that Agile Deliberation achieves 7.5% higher F1 scores than automated decomposition baselines and more than 3% higher than manual deliberation, while participants reported clearer conceptual understanding and lower cognitive effort.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-27] Self-Ensemble Post Learning for Noisy Domain Generalization</p>
<p>【速读】：该论文旨在解决域泛化（Domain Generalization, DG）在面对标签噪声时性能下降的问题，尤其是噪声标签会加剧深层特征中的虚假特征放大（spurious feature enlargement），从而导致模型性能退化。解决方案的关键在于提出一种自集成后学习方法（Self-Ensemble Post Learning, SEPL），其核心思想是利用预训练模型内部中间特征表示的多样性：通过特征探测训练（feature probing training）阶段训练多个探测分类器以挖掘不同潜在特征的空间判别能力，并在预测集成推理（prediction ensemble inference）阶段采用众包式集成策略融合这些多样化分类头的输出，从而提升模型对标签噪声的鲁棒性与泛化能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10818">https://arxiv.org/abs/2512.10818</a><br>
<strong>作者</strong>: Wang Lu,Jindong Wang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  18 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:While computer vision and machine learning have made great progress, their robustness is still challenged by two key issues: data distribution shift and label noise. When domain generalization (DG) encounters noise, noisy labels further exacerbate the emergence of spurious features in deep layers, i.e. spurious feature enlargement, leading to a degradation in the performance of existing algorithms. This paper, starting from domain generalization, explores how to make existing methods rework when meeting noise. We find that the latent features inside the model have certain discriminative capabilities, and different latent features focus on different parts of the image. Based on these observations, we propose the Self-Ensemble Post Learning approach (SEPL) to diversify features which can be leveraged. Specifically, SEPL consists of two parts: feature probing training and prediction ensemble inference. It leverages intermediate feature representations within the model architecture, training multiple probing classifiers to fully exploit the capabilities of pre-trained models, while the final predictions are obtained through the integration of outputs from these diverse classification heads. Considering the presence of noisy labels, we employ semi-supervised algorithms to train probing classifiers. Given that different probing classifiers focus on different areas, we integrate their predictions using a crowdsourcing inference approach. Extensive experimental evaluations demonstrate that the proposed method not only enhances the robustness of existing methods but also exhibits significant potential for real-world applications with high flexibility.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-28] Extrapolation of Periodic Functions Using Binary Encoding of Continuous Numerical Values</p>
<p>【速读】：该论文旨在解决神经网络在处理周期性函数时难以超越训练数据范围进行外推的问题。传统方法通常依赖于对函数形式的先验知识或复杂架构设计，而本文提出的关键解决方案是采用归一化二进制编码（Normalized Base-2 Encoding, NB2E）对连续数值输入进行编码。该编码方式促使多层感知机（MLP）在内部激活中形成比特相位表示（bit-phase representations），从而使得模型能够在不依赖目标函数具体形式的前提下，自主学习并准确外推多样化的周期信号。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10817">https://arxiv.org/abs/2512.10817</a><br>
<strong>作者</strong>: Brian P. Powell,Jordan A. Caraballo-Vega,Mark L. Carroll,Thomas Maxwell,Andrew Ptak,Greg Olmschenk,Jorge Martinez-Palomera<br>
<strong>机构</strong>: NASA(美国国家航空航天局)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
<strong>备注</strong>:  Submitted to JMLR, under review</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We report the discovery that binary encoding allows neural networks to extrapolate periodic functions beyond their training bounds. We introduce Normalized Base-2 Encoding (NB2E) as a method for encoding continuous numerical values and demonstrate that, using this input encoding, vanilla multi-layer perceptrons (MLP) successfully extrapolate diverse periodic signals without prior knowledge of their functional form. Internal activation analysis reveals that NB2E induces bit-phase representations, enabling MLPs to learn and extrapolate signal structure independently of position.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-29] Graph Laplacian Transformer with Progressive Sampling for Prostate Cancer Grading <mark class="hl-label red">MICCAI</mark></p>
<p>【速读】：该论文旨在解决前列腺癌病理图像（Whole-Slide Images, WSIs）分级中因图像尺度大、组织结构异质性强以及难以选取诊断相关区域而导致的性能瓶颈问题。现有方法多依赖随机或静态的图像块（patch）选择策略，易引入冗余或非信息性区域，影响模型判别能力。其解决方案的关键在于提出一种基于图拉普拉斯注意力机制的Transformer（Graph Laplacian Attention-Based Transformer, GLAT）与迭代精化模块（Iterative Refinement Module, IRM）相结合的框架：IRM通过预训练ResNet50提取局部特征并利用无梯度模式的基础模型进行重要性评分，实现对诊断相关区域的动态筛选；GLAT则构建以patch为节点的图结构，借助图拉普拉斯约束保障空间一致性，并通过可学习滤波机制增强组织学特征的判别性表示；此外，采用凸聚合机制自适应调整patch权重，生成鲁棒的WSI级表征。该方法在五个公开和一个私有数据集上验证了优越性，兼具高准确率、强空间一致性与计算效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10808">https://arxiv.org/abs/2512.10808</a><br>
<strong>作者</strong>: Masum Shah Junayed,John Derek Van Vessem,Qian Wan,Gahie Nam,Sheida Nabavi<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI) 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Prostate cancer grading from whole-slide images (WSIs) remains a challenging task due to the large-scale nature of WSIs, the presence of heterogeneous tissue structures, and difficulty of selecting diagnostically relevant regions. Existing approaches often rely on random or static patch selection, leading to the inclusion of redundant or non-informative regions that degrade performance. To address this, we propose a Graph Laplacian Attention-Based Transformer (GLAT) integrated with an Iterative Refinement Module (IRM) to enhance both feature learning and spatial consistency. The IRM iteratively refines patch selection by leveraging a pretrained ResNet50 for local feature extraction and a foundation model in no-gradient mode for importance scoring, ensuring only the most relevant tissue regions are preserved. The GLAT models tissue-level connectivity by constructing a graph where patches serve as nodes, ensuring spatial consistency through graph Laplacian constraints and refining feature representations via a learnable filtering mechanism that enhances discriminative histological structures. Additionally, a convex aggregation mechanism dynamically adjusts patch importance to generate a robust WSI-level representation. Extensive experiments on five public and one private dataset demonstrate that our model outperforms state-of-the-art methods, achieving higher performance and spatial consistency while maintaining computational efficiency.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-30] Interpretable and Steerable Concept Bottleneck Sparse Autoencoders</p>
<p>【速读】：该论文旨在解决稀疏自编码器（Sparse Autoencoders, SAEs）在大语言模型（LLMs）和视觉语言模型（LVLMs）中应用时存在的两大核心问题：一是多数SAE神经元缺乏可解释性或可控性（steerability），导致其在下游任务中效用有限；二是由于SAEs的无监督特性，用户期望的概念往往无法在学习到的特征字典中体现，限制了实际应用价值。解决方案的关键在于提出一种新的后处理框架——概念瓶颈稀疏自编码器（Concept Bottleneck Sparse Autoencoders, CB-SAE），该框架通过两个步骤实现改进：首先剪枝低效神经元以提升整体质量，其次引入轻量级概念瓶颈模块，将潜在空间与用户定义的概念集对齐，从而显著增强模型的可解释性和可控性，在LVLMs和图像生成任务中分别实现了可解释性提升32.1%和可控性提升14.5%。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10805">https://arxiv.org/abs/2512.10805</a><br>
<strong>作者</strong>: Akshay Kulkarni,Tsui-Wei Weng,Vivek Narayanaswamy,Shusen Liu,Wesam A. Sakla,Kowshik Thopalli<br>
<strong>机构</strong>: University of California, San Diego (加州大学圣地亚哥分校); Lawrence Livermore National Laboratory (劳伦斯利弗莫尔国家实验室)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Sparse autoencoders (SAEs) promise a unified approach for mechanistic interpretability, concept discovery, and model steering in LLMs and LVLMs. However, realizing this potential requires that the learned features be both interpretable and steerable. To that end, we introduce two new computationally inexpensive interpretability and steerability metrics and conduct a systematic analysis on LVLMs. Our analysis uncovers two observations; (i) a majority of SAE neurons exhibit either low interpretability or low steerability or both, rendering them ineffective for downstream use; and (ii) due to the unsupervised nature of SAEs, user-desired concepts are often absent in the learned dictionary, thus limiting their practical utility. To address these limitations, we propose Concept Bottleneck Sparse Autoencoders (CB-SAE) - a novel post-hoc framework that prunes low-utility neurons and augments the latent space with a lightweight concept bottleneck aligned to a user-defined concept set. The resulting CB-SAE improves interpretability by +32.1% and steerability by +14.5% across LVLMs and image generation tasks. We will make our code and model weights available.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-31] What matters for Representation Alignment: Global Information or Spatial Structure?</p>
<p>【速读】：该论文旨在解决生成式模型训练中表示对齐（Representation Alignment, REPA）机制的核心作用机制不明确的问题，即目标表示中何种特性对生成质量更为关键：全局语义信息（如ImageNet-1K准确率衡量的）还是空间结构（patch token之间的成对余弦相似度）。传统观点认为更强的全局语义性能有助于生成效果，但本文通过大规模实证分析（涵盖27种视觉编码器和多种模型规模）发现，空间结构才是决定生成性能的关键因素。解决方案的关键在于提出一种简单而有效的改进方法iREPA，其核心是将REPA中的标准MLP投影层替换为卷积层，并引入空间归一化层以增强空间信息的传递，仅需4行代码即可显著提升不同视觉编码器、模型规模及训练变体（如REPA、REPA-E、Meanflow、JiT等）下的收敛速度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10794">https://arxiv.org/abs/2512.10794</a><br>
<strong>作者</strong>: Jaskirat Singh,Xingjian Leng,Zongze Wu,Liang Zheng,Richard Zhang,Eli Shechtman,Saining Xie<br>
<strong>机构</strong>: Adobe Research(Adobe 研究院); ANU(澳大利亚国立大学); New York University(纽约大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Graphics (<a target="_blank" rel="noopener" href="http://cs.GR">cs.GR</a>); Machine Learning (cs.LG); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://end2end-diffusion.github.io/irepa">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Representation alignment (REPA) guides generative training by distilling representations from a strong, pretrained vision encoder to intermediate diffusion features. We investigate a fundamental question: what aspect of the target representation matters for generation, its \textitglobal \revisionsemantic information (e.g., measured by ImageNet-1K accuracy) or its spatial structure (i.e. pairwise cosine similarity between patch tokens)? Prevalent wisdom holds that stronger global semantic performance leads to better generation as a target representation. To study this, we first perform a large-scale empirical analysis across 27 different vision encoders and different model scales. The results are surprising; spatial structure, rather than global performance, drives the generation performance of a target representation. To further study this, we introduce two straightforward modifications, which specifically accentuate the transfer of \emphspatial information. We replace the standard MLP projection layer in REPA with a simple convolution layer and introduce a spatial normalization layer for the external representation. Surprisingly, our simple method (implemented in   4 lines of code), termed iREPA, consistently improves convergence speed of REPA, across a diverse set of vision encoders, model sizes, and training variants (such as REPA, REPA-E, Meanflow, JiT etc). %, etc. Our work motivates revisiting the fundamental working mechanism of representational alignment and how it can be leveraged for improved training of generative models. The code and project page are available at this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-32] Metaphor-based Jailbreaking Attacks on Text-to-Image Models</p>
<p>【速读】：该论文旨在解决生成式 AI（Generative AI）中的文本到图像（Text-to-Image, T2I）模型在面对未知或多样化防御机制时，难以有效实施越狱攻击（jailbreaking attack）的问题。现有方法通常假设攻击者已知目标模型所部署的防御类型，这限制了其在复杂多变的实际场景中的适用性。为应对这一挑战，作者提出了一种基于隐喻的越狱攻击方法（Metaphor-based Jailbreaking Attack, MJA），其核心创新在于通过隐喻引导生成对抗性提示，从而绕过不同类型的防御机制而无需事先了解其具体形式。MJA的关键组件包括：一个基于大语言模型（LLM）的多智能体生成模块（MLAG），用于分解并协同生成多样化的隐喻类对抗提示；以及一个对抗提示优化模块（APO），通过训练代理模型预测攻击效果并设计自适应采集策略以高效识别最优对抗提示。实验表明，MJA在多种外部与内部防御机制下均优于六种基线方法，在显著减少查询次数的同时实现了更强的攻击成功率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10766">https://arxiv.org/abs/2512.10766</a><br>
<strong>作者</strong>: Chenyu Zhang,Yiwen Ma,Lanjun Wang,Wenhui Li,Yi Tu,An-An Liu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  This paper includes model-generated content that may contain offensive or distressing material</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Text-to-image~(T2I) models commonly incorporate defense mechanisms to prevent the generation of sensitive images. Unfortunately, recent jailbreaking attacks have shown that adversarial prompts can effectively bypass these mechanisms and induce T2I models to produce sensitive content, revealing critical safety vulnerabilities. However, existing attack methods implicitly assume that the attacker knows the type of deployed defenses, which limits their effectiveness against unknown or diverse defense mechanisms. In this work, we introduce \textbfMJA, a \textbfmetaphor-based \textbfjailbreaking \textbfattack method inspired by the Taboo game, aiming to effectively and efficiently attack diverse defense mechanisms without prior knowledge of their type by generating metaphor-based adversarial prompts. Specifically, MJA consists of two modules: an LLM-based multi-agent generation module~(MLAG) and an adversarial prompt optimization module~(APO). MLAG decomposes the generation of metaphor-based adversarial prompts into three subtasks: metaphor retrieval, context matching, and adversarial prompt generation. Subsequently, MLAG coordinates three LLM-based agents to generate diverse adversarial prompts by exploring various metaphors and contexts. To enhance attack efficiency, APO first trains a surrogate model to predict the attack results of adversarial prompts and then designs an acquisition strategy to adaptively identify optimal adversarial prompts. Extensive experiments on T2I models with various external and internal defense mechanisms demonstrate that MJA outperforms six baseline methods, achieving stronger attack performance while using fewer queries. Code is available in this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-33] Blood Pressure Prediction for Coronary Artery Disease Diagnosis using Coronary Computed Tomography Angiography</p>
<p>【速读】：该论文旨在解决冠状动脉血流计算流体动力学（Computational Fluid Dynamics, CFD）模拟在临床应用中因计算成本高、耗时长及难以集成到大规模诊疗流程而导致的瓶颈问题，从而限制了基于生理学的冠状动脉疾病（Coronary Artery Disease, CAD）非侵入性评估的推广。其解决方案的关键在于构建一个端到端自动化流程：首先从冠状动脉计算机断层扫描血管成像（Coronary Computed Tomography Angiography, CCTA）自动提取冠状动脉几何结构，继而高效生成仿真数据，并引入一种基于扩散模型的回归方法，直接从CCTA特征预测冠状动脉血压分布，从而在推理阶段绕过耗时的CFD计算。该方案显著降低了人工干预需求并确保训练数据一致性，实现了快速、可扩展的非侵入性血压预测框架。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10765">https://arxiv.org/abs/2512.10765</a><br>
<strong>作者</strong>: Rene Lisasi,Michele Esposito,Chen Zhao<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  19 pages, 9 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Computational fluid dynamics (CFD) based simulation of coronary blood flow provides valuable hemodynamic markers, such as pressure gradients, for diagnosing coronary artery disease (CAD). However, CFD is computationally expensive, time-consuming, and difficult to integrate into large-scale clinical workflows. These limitations restrict the availability of labeled hemodynamic data for training AI models and hinder broad adoption of non-invasive, physiology based CAD assessment. To address these challenges, we develop an end to end pipeline that automates coronary geometry extraction from coronary computed tomography angiography (CCTA), streamlines simulation data generation, and enables efficient learning of coronary blood pressure distributions. The pipeline reduces the manual burden associated with traditional CFD workflows while producing consistent training data. We further introduce a diffusion-based regression model designed to predict coronary blood pressure directly from CCTA derived features, bypassing the need for slow CFD computation during inference. Evaluated on a dataset of simulated coronary hemodynamics, the proposed model achieves state of the art performance, with an R2 of 64.42%, a root mean squared error of 0.0974, and a normalized RMSE of 0.154, outperforming several baseline approaches. This work provides a scalable and accessible framework for rapid, non-invasive blood pressure prediction to support CAD diagnosis.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-34] LDP: Parameter-Efficient Fine-Tuning of Multimodal <mark class="hl-label green">LLM</mark>  for Medical Report Generation</p>
<p>【速读】：该论文旨在解决结肠镜息肉诊断报告生成中因高质量多模态医学数据稀缺而导致的自动化报告一致性差和幻觉问题。解决方案的关键在于提出LDP框架，其核心包括：构建包含专家标注的结肠镜图像-文本对的多模态数据集MMEndo，并基于Qwen2-VL-7B大模型采用参数高效微调（LoRA）方法进行训练，同时通过直接偏好优化（DPO）对齐临床标准，从而在保证诊断准确性（医师评分达7.2/10）的同时，将训练计算成本降低833倍。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10750">https://arxiv.org/abs/2512.10750</a><br>
<strong>作者</strong>: Tianyu Zhou,Junyi Tang,Zehui Li,Dahong Qian,Suncheng Xiang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Work in progress</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Colonoscopic polyp diagnosis is pivotal for early colorectal cancer detection, yet traditional automated reporting suffers from inconsistencies and hallucinations due to the scarcity of high-quality multimodal medical data. To bridge this gap, we propose LDP, a novel framework leveraging multimodal large language models (MLLMs) for professional polyp diagnosis report generation. Specifically, we curate MMEndo, a multimodal endoscopic dataset comprising expert-annotated colonoscopy image-text pairs. We fine-tune the Qwen2-VL-7B backbone using Parameter-Efficient Fine-Tuning (LoRA) and align it with clinical standards via Direct Preference Optimization (DPO). Extensive experiments show that our LDP outperforms existing baselines on both automated metrics and rigorous clinical expert evaluations (achieving a Physician Score of 7.2/10), significantly reducing training computational costs by 833x compared to full fine-tuning. The proposed solution offers a scalable, clinically viable path for primary healthcare, with additional validation on the IU-XRay dataset confirming its robustness.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-35] IRG-Motion<mark class="hl-label green">LLM</mark> : Interleaving Motion Generation Assessment and Refinement for Text-to-Motion Generation</p>
<p>【速读】：该论文旨在解决当前运动理解与生成任务在大型语言模型中通常被独立处理的问题，这种分离限制了两任务间通过交互反馈实现的知识共享与协同优化。其解决方案的关键在于提出一种称为“运动生成的交错推理”（Interleaved Reasoning for Motion Generation, IRMoGen）的新范式，该范式通过迭代式的文本-运动对话，将运动生成、评估与精炼步骤紧密耦合，从而实现双向知识流动。为此，作者构建了首个能无缝交织这三个步骤的模型IRG-MotionLLM，并设计了一个三阶段训练方案及自动化数据引擎以合成交错推理标注，显著提升了文本到运动生成任务的对齐效果和整体性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10730">https://arxiv.org/abs/2512.10730</a><br>
<strong>作者</strong>: Yuan-Ming Li,Qize Yang,Nan Lei,Shenghao Fu,Ling-An Zeng,Jian-Fang Hu,Xihan Wei,Wei-Shi Zheng<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  25 pages, 16 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advances in motion-aware large language models have shown remarkable promise for unifying motion understanding and generation tasks. However, these models typically treat understanding and generation separately, limiting the mutual benefits that could arise from interactive feedback between tasks. In this work, we reveal that motion assessment and refinement tasks act as crucial bridges to enable bidirectional knowledge flow between understanding and generation. Leveraging this insight, we propose Interleaved Reasoning for Motion Generation (IRMoGen), a novel paradigm that tightly couples motion generation with assessment and refinement through iterative text-motion dialogue. To realize this, we introduce IRG-MotionLLM, the first model that seamlessly interleaves motion generation, assessment, and refinement to improve generation performance. IRG-MotionLLM is developed progressively with a novel three-stage training scheme, initializing and subsequently enhancing native IRMoGen capabilities. To facilitate this development, we construct an automated data engine to synthesize interleaved reasoning annotations from existing text-motion datasets. Extensive experiments demonstrate that: (i) Assessment and refinement tasks significantly improve text-motion alignment; (ii) Interleaving motion generation, assessment, and refinement steps yields consistent performance gains across training stages; and (iii) IRG-MotionLLM clearly outperforms the baseline model and achieves advanced performance on standard text-to-motion generation benchmarks. Cross-evaluator testing further validates its effectiveness. Code  Data: this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-36] Video Depth Propagation</p>
<p>【速读】：该论文旨在解决视频深度估计中普遍存在的时序不一致性与计算效率低下的问题。现有方法要么采用简单的单帧单目模型，导致深度预测在时间维度上不稳定；要么依赖复杂的时序建模机制，难以满足实时应用需求。为应对这一挑战，作者提出VeloDepth，其核心创新在于设计了一个新颖的传播模块（Propagation Module），通过光流引导的特征扭曲（flow-based warping）结合学习到的残差修正机制，实现深度特征与预测结果的有效传递与优化。该模块不仅结构化地强化了时序一致性，还显著提升了推理速度，从而在多个基准测试中实现了优于现有方法的时序稳定性和竞争力的精度，同时具备高效的实时处理能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10725">https://arxiv.org/abs/2512.10725</a><br>
<strong>作者</strong>: Luigi Piccinelli,Thiemo Wandel,Christos Sakaridis,Wim Abbeloos,Luc Van Gool<br>
<strong>机构</strong>: ETH Zürich; Toyota Motor Europe; INSAIT, Sofia University St. Kliment Ohridski<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Depth estimation in videos is essential for visual perception in real-world applications. However, existing methods either rely on simple frame-by-frame monocular models, leading to temporal inconsistencies and inaccuracies, or use computationally demanding temporal modeling, unsuitable for real-time applications. These limitations significantly restrict general applicability and performance in practical settings. To address this, we propose VeloDepth, an efficient and robust online video depth estimation pipeline that effectively leverages spatiotemporal priors from previous depth predictions and performs deep feature propagation. Our method introduces a novel Propagation Module that refines and propagates depth features and predictions using flow-based warping coupled with learned residual corrections. In addition, our design structurally enforces temporal consistency, resulting in stable depth predictions across consecutive frames with improved efficiency. Comprehensive zero-shot evaluation on multiple benchmarks demonstrates the state-of-the-art temporal consistency and competitive accuracy of VeloDepth, alongside its significantly faster inference compared to existing video-based depth estimators. VeloDepth thus provides a practical, efficient, and accurate solution for real-time depth estimation suitable for diverse perception tasks. Code and models are available at this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-37] SpaceDrive: Infusing Spatial Awareness into VLM-based Autonomous Driving</p>
<p>【速读】：该论文旨在解决当前视觉语言模型（Vision Language Models, VLMs）在端到端自动驾驶系统中对细粒度三维空间关系理解能力不足的问题，这是影响模型与物理世界交互的关键瓶颈。其解决方案的核心在于提出SpaceDrive框架，通过将空间信息显式建模为位置编码（Positional Encodings, PEs），而非传统依赖文本数字 token 的方式，从而实现语义与空间表征的联合推理。具体而言，SpaceDrive利用一个通用的位置编码器处理来自多视角深度估计、历史自车状态和文本提示的3D坐标，并将其叠加至对应的2D视觉token上，同时作为任务无关的坐标表示替代数值型token作为VLM的输入和输出，使模型能够更精准地索引特定视觉语义并直接回归轨迹坐标，显著提升规划精度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10719">https://arxiv.org/abs/2512.10719</a><br>
<strong>作者</strong>: Peizheng Li,Zhenghao Zhang,David Holtz,Hang Yu,Yutong Yang,Yuzhi Lai,Rui Song,Andreas Geiger,Andreas Zell<br>
<strong>机构</strong>: Mercedes-Benz AG; University of Tübingen (图宾根大学); Tübingen AI Center; TU Munich (慕尼黑工业大学); Karlsruhe Institute of Technology (卡尔斯鲁厄理工学院); University of Stuttgart (斯图加特大学); UCLA<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:End-to-end autonomous driving methods built on vision language models (VLMs) have undergone rapid development driven by their universal visual understanding and strong reasoning capabilities obtained from the large-scale pretraining. However, we find that current VLMs struggle to understand fine-grained 3D spatial relationships which is a fundamental requirement for systems interacting with the physical world. To address this issue, we propose SpaceDrive, a spatial-aware VLM-based driving framework that treats spatial information as explicit positional encodings (PEs) instead of textual digit tokens, enabling joint reasoning over semantic and spatial representations. SpaceDrive employs a universal positional encoder to all 3D coordinates derived from multi-view depth estimation, historical ego-states, and text prompts. These 3D PEs are first superimposed to augment the corresponding 2D visual tokens. Meanwhile, they serve as a task-agnostic coordinate representation, replacing the digit-wise numerical tokens as both inputs and outputs for the VLM. This mechanism enables the model to better index specific visual semantics in spatial reasoning and directly regress trajectory coordinates rather than generating digit-by-digit, thereby enhancing planning accuracy. Extensive experiments validate that SpaceDrive achieves state-of-the-art open-loop performance on the nuScenes dataset and the second-best Driving Score of 78.02 on the Bench2Drive closed-loop benchmark over existing VLM-based methods.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-38] CheXmask-U: Quantifying uncertainty in landmark-based anatomical segmentation for X-ray images</p>
<p>【速读】：该论文旨在解决医学图像分割系统在临床部署中的不确定性估计问题，尤其是针对基于解剖标志点（anatomical landmark）的胸部X光片分割方法，以提升其鲁棒性和安全性。现有研究多聚焦于像素级不确定性，而忽略了标志点分割固有的拓扑约束优势。解决方案的关键在于借鉴混合神经网络架构（结合标准图像卷积编码器与图结构生成解码器），利用其变分潜在空间，提出两种互补的不确定性度量：(i) 潜在不确定性（latent uncertainty），直接从学习到的分布参数中获取；(ii) 预测不确定性（predictive uncertainty），通过从潜在空间采样生成多个随机输出预测来计算。实验表明，这两种度量均能随扰动强度增加而上升，有效反映全局与局部退化，并可识别不可靠预测及支持分布外检测，从而为标志点分割提供空间异质性的质量评估依据。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10715">https://arxiv.org/abs/2512.10715</a><br>
<strong>作者</strong>: Matias Cosarinsky,Nicolas Gaggion,Rodrigo Echeveste,Enzo Ferrante<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Uncertainty estimation is essential for the safe clinical deployment of medical image segmentation systems, enabling the identification of unreliable predictions and supporting human oversight. While prior work has largely focused on pixel-level uncertainty, landmark-based segmentation offers inherent topological guarantees yet remains underexplored from an uncertainty perspective. In this work, we study uncertainty estimation for anatomical landmark-based segmentation on chest X-rays. Inspired by hybrid neural network architectures that combine standard image convolutional encoders with graph-based generative decoders, and leveraging their variational latent space, we derive two complementary measures: (i) latent uncertainty, captured directly from the learned distribution parameters, and (ii) predictive uncertainty, obtained by generating multiple stochastic output predictions from latent samples. Through controlled corruption experiments we show that both uncertainty measures increase with perturbation severity, reflecting both global and local degradation. We demonstrate that these uncertainty signals can identify unreliable predictions by comparing with manual ground-truth, and support out-of-distribution detection on the CheXmask dataset. More importantly, we release CheXmask-U (this http URL), a large scale dataset of 657,566 chest X-ray landmark segmentations with per-node uncertainty estimates, enabling researchers to account for spatial variations in segmentation quality when using these anatomical masks. Our findings establish uncertainty estimation as a promising direction to enhance robustness and safe deployment of landmark-based anatomical segmentation methods in chest X-ray. A fully working interactive demo of the method is available at this http URL and the source code at this http URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-39] Enhancing Radiology Report Generation and Visual Grounding using Reinforcement Learning</p>
<p>【速读】：该论文旨在解决当前医学视觉语言模型（Medical Vision-Language Models, VLMs）在胸部X光片（CXR）解读中依赖监督微调（Supervised Fine-Tuning, SFT）所带来的局限性，即SFT仅优化下一个词的预测概率，而无法有效评估生成答案的质量。为此，作者提出将强化学习（Reinforcement Learning, RL）与显式中间推理（explicit thinking）相结合的方法，以引入临床任务特定的反馈机制。关键解决方案在于：首先通过大规模SFT构建基础模型RadVLM（基于Qwen3-VL），随后引入冷启动微调阶段赋予模型基本推理能力；接着采用组相对策略优化（Group Relative Policy Optimization, GRPO）并设计临床对齐的奖励函数用于报告生成和视觉定位任务，同时对比分析是否启用“思考”机制在域特定和通用版本Qwen3-VL上的效果。实验表明，虽然强SFT是高性能的基础，但RL能进一步提升两个任务的表现，而显式思考并未带来额外增益，验证了临床对齐的强化学习作为SFT有效补充的潜力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10691">https://arxiv.org/abs/2512.10691</a><br>
<strong>作者</strong>: Benjamin Gundersen,Nicolas Deperrois,Samuel Ruiperez-Campillo,Thomas M. Sutter,Julia E. Vogt,Michael Moor,Farhad Nooralahzadeh,Michael Krauthammer<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  10 pages main text (3 figures, 3 tables), 31 pages in total</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advances in vision-language models (VLMs) have improved Chest X-ray (CXR) interpretation in multiple aspects. However, many medical VLMs rely solely on supervised fine-tuning (SFT), which optimizes next-token prediction without evaluating answer quality. In contrast, reinforcement learning (RL) can incorporate task-specific feedback, and its combination with explicit intermediate reasoning (“thinking”) has demonstrated substantial gains on verifiable math and coding tasks. To investigate the effects of RL and thinking in a CXR VLM, we perform large-scale SFT on CXR data to build an updated RadVLM based on Qwen3-VL, followed by a cold-start SFT stage that equips the model with basic thinking ability. We then apply Group Relative Policy Optimization (GRPO) with clinically grounded, task-specific rewards for report generation and visual grounding, and run matched RL experiments on both domain-specific and general-domain Qwen3-VL variants, with and without thinking. Across these settings, we find that while strong SFT remains crucial for high base performance, RL provides additional gains on both tasks, whereas explicit thinking does not appear to further improve results. Under a unified evaluation pipeline, the RL-optimized RadVLM models outperform their baseline counterparts and reach state-of-the-art performance on both report generation and grounding, highlighting clinically aligned RL as a powerful complement to SFT for medical VLMs.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-40] Sharp Monocular View Synthesis in Less Than a Second</p>
<p>【速读】：该论文旨在解决从单张图像中实现高保真度视角合成（photorealistic view synthesis）的问题，即如何仅凭一张照片重建出可支持任意视角渲染的3D场景表示。其解决方案的关键在于提出SHARP方法，通过一个神经网络直接回归出场景的3D高斯表示（3D Gaussian representation），该表示具备绝对尺度且支持度量相机运动，能够在标准GPU上以不到一秒的时间完成推理，并实现实时渲染的高质量图像输出。此方法在多个数据集上展现出卓越的零样本泛化能力，显著优于现有最优模型，在感知图像相似性指标（如LPIPS和DISTS）上提升25–43%，同时将合成时间降低三个数量级。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10685">https://arxiv.org/abs/2512.10685</a><br>
<strong>作者</strong>: Lars Mescheder,Wei Dong,Shiwei Li,Xuyang Bai,Marcel Santos,Peiyun Hu,Bruno Lecouat,Mingmin Zhen,Amaël Delaunoy,Tian Fang,Yanghai Tsin,Stephan R. Richter,Vladlen Koltun<br>
<strong>机构</strong>: Apple(苹果)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  Code and weights available at <a target="_blank" rel="noopener" href="https://github.com/apple/ml-sharp">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present SHARP, an approach to photorealistic view synthesis from a single image. Given a single photograph, SHARP regresses the parameters of a 3D Gaussian representation of the depicted scene. This is done in less than a second on a standard GPU via a single feedforward pass through a neural network. The 3D Gaussian representation produced by SHARP can then be rendered in real time, yielding high-resolution photorealistic images for nearby views. The representation is metric, with absolute scale, supporting metric camera movements. Experimental results demonstrate that SHARP delivers robust zero-shot generalization across datasets. It sets a new state of the art on multiple datasets, reducing LPIPS by 25-34% and DISTS by 21-43% versus the best prior model, while lowering the synthesis time by three orders of magnitude. Code and weights are provided at this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-41] Optimal transport unlocks end-to-end learning for single-molecule localization</p>
<p>【速读】：该论文旨在解决单分子定位显微镜（Single-molecule localization microscopy, SMLM）在高荧光标记密度下成像效率低的问题，尤其是在活细胞成像中因传统方法要求非重叠发射体而导致的采集时间过长。其核心解决方案是将SMLM的训练目标重新建模为集合匹配问题，并引入基于最优传输（optimal transport）的损失函数，从而避免在推理阶段依赖非可微的非极大值抑制（non-maximum suppression, NMS）策略，实现端到端可微训练；同时提出一种融合显微光学系统先验知识的迭代神经网络架构，在合成基准和真实生物数据上均验证了该方法在中高发射体密度下优于当前最先进水平。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10683">https://arxiv.org/abs/2512.10683</a><br>
<strong>作者</strong>: Romain Seailles(DI-ENS),Jean-Baptiste Masson(IP, CNRS, UPCité),Jean Ponce(DI-ENS, CDS),Julien Mairal(LJK)<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Single-molecule localization microscopy (SMLM) allows reconstructing biology-relevant structures beyond the diffraction limit by detecting and localizing individual fluorophores – fluorescent molecules stained onto the observed specimen – over time to reconstruct super-resolved images. Currently, efficient SMLM requires non-overlapping emitting fluorophores, leading to long acquisition times that hinders live-cell imaging. Recent deep-learning approaches can handle denser emissions, but they rely on variants of non-maximum suppression (NMS) layers, which are unfortunately non-differentiable and may discard true positives with their local fusion strategy. In this presentation, we reformulate the SMLM training objective as a set-matching problem, deriving an optimal-transport loss that eliminates the need for NMS during inference and enables end-to-end training. Additionally, we propose an iterative neural network that integrates knowledge of the microscope’s optical system inside our model. Experiments on synthetic benchmarks and real biological data show that both our new loss function and architecture surpass the state of the art at moderate and high emitter densities. Code is available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-42] Evaluating Gemini Robotics Policies in a Veo World Simulator</p>
<p>【速读】：该论文旨在解决当前生成式视频模型在机器人领域应用受限的问题，即现有方法主要局限于分布内（in-distribution）评估，难以支持对策略在分布外（out-of-distribution, OOD）场景下的泛化能力、物理与语义安全性等复杂评估任务。其解决方案的关键在于构建一个基于前沿视频基础模型（Veo）的生成式评估系统，该系统通过优化机器人动作条件控制（robot action conditioning）和多视角一致性（multi-view consistency），并融合生成式图像编辑与多视角补全技术，实现对真实世界场景在多个泛化维度上的高保真模拟。该方法能够准确预测不同策略在名义和分布外条件下的相对性能，并用于红队测试以识别违反物理或语义安全约束的行为，从而全面支持机器人政策的多维评估需求。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10675">https://arxiv.org/abs/2512.10675</a><br>
<strong>作者</strong>: Gemini Robotics Team,Coline Devin,Yilun Du,Debidatta Dwibedi,Ruiqi Gao,Abhishek Jindal,Thomas Kipf,Sean Kirmani,Fangchen Liu,Anirudha Majumdar,Andrew Marmon,Carolina Parada,Yulia Rubanova,Dhruv Shah,Vikas Sindhwani,Jie Tan,Fei Xia,Ted Xiao,Sherry Yang,Wenhao Yu,Allan Zhou<br>
<strong>机构</strong>: Google DeepMind(谷歌深度思维)<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Generative world models hold significant potential for simulating interactions with visuomotor policies in varied environments. Frontier video models can enable generation of realistic observations and environment interactions in a scalable and general manner. However, the use of video models in robotics has been limited primarily to in-distribution evaluations, i.e., scenarios that are similar to ones used to train the policy or fine-tune the base video model. In this report, we demonstrate that video models can be used for the entire spectrum of policy evaluation use cases in robotics: from assessing nominal performance to out-of-distribution (OOD) generalization, and probing physical and semantic safety. We introduce a generative evaluation system built upon a frontier video foundation model (Veo). The system is optimized to support robot action conditioning and multi-view consistency, while integrating generative image-editing and multi-view completion to synthesize realistic variations of real-world scenes along multiple axes of generalization. We demonstrate that the system preserves the base capabilities of the video model to enable accurate simulation of scenes that have been edited to include novel interaction objects, novel visual backgrounds, and novel distractor objects. This fidelity enables accurately predicting the relative performance of different policies in both nominal and OOD conditions, determining the relative impact of different axes of generalization on policy performance, and performing red teaming of policies to expose behaviors that violate physical or semantic safety constraints. We validate these capabilities through 1600+ real-world evaluations of eight Gemini Robotics policy checkpoints and five tasks for a bimanual manipulator.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-43] Geo6DPose: Fast Zero-Shot 6D Object Pose Estimation via Geometry-Filtered Feature Matching</p>
<p>【速读】：该论文旨在解决当前零样本6D物体位姿估计（6D object pose estimation）方法依赖大规模模型和云端推理所导致的高延迟、高能耗及部署风险问题，这些问题与实际机器人应用中计算资源受限、需本地化推理的需求相冲突。解决方案的关键在于提出Geo6DPose，一种轻量级、全本地化且无需训练的流水线：通过融合基础模型的视觉特征与几何过滤策略，利用模板DINO描述符与场景图像块之间的相似性映射建立对应关系，并结合投影到3D空间的场景块中心与模板描述符到物体模型坐标系的映射，最终通过基于对应关系的RANSAC恢复位姿，并采用联合考虑重投影一致性与空间支持的加权几何对齐指标进行排序，从而提升对噪声、杂波和部分遮挡的鲁棒性。该方法在单个消费级GPU上实现亚秒级推理，且性能媲美更大规模的零样本基线模型（53.7 AR, 1.08 FPS），同时无需训练、微调或网络连接，具备良好的可扩展性和对新兴基础模型的兼容性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10674">https://arxiv.org/abs/2512.10674</a><br>
<strong>作者</strong>: Javier Villena Toro,Mehdi Tarkian<br>
<strong>机构</strong>: Linköping University (林雪平大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent progress in zero-shot 6D object pose estimation has been driven largely by large-scale models and cloud-based inference. However, these approaches often introduce high latency, elevated energy consumption, and deployment risks related to connectivity, cost, and data governance; factors that conflict with the practical constraints of real-world robotics, where compute is limited and on-device inference is frequently required. We introduce Geo6DPose, a lightweight, fully local, and training-free pipeline for zero-shot 6D pose estimation that trades model scale for geometric reliability. Our method combines foundation model visual features with a geometric filtering strategy: Similarity maps are computed between onboarded template DINO descriptors and scene patches, and mutual correspondences are established by projecting scene patch centers to 3D and template descriptors to the object model coordinate system. Final poses are recovered via correspondence-driven RANSAC and ranked using a weighted geometric alignment metric that jointly accounts for reprojection consistency and spatial support, improving robustness to noise, clutter, and partial visibility. Geo6DPose achieves sub-second inference on a single commodity GPU while matching the average recall of significantly larger zero-shot baselines (53.7 AR, 1.08 FPS). It requires no training, fine-tuning, or network access, and remains compatible with evolving foundation backbones, advancing practical, fully local 6D perception for robotic deployment.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-44] XDen-1K: A Density Field Dataset of Real-World Objects</p>
<p>【速读】：该论文旨在解决当前 embodied AI 和物理仿真中对物体内部物理属性（尤其是体积密度）建模不足的问题，这一缺失限制了机器人操作和物理模拟中对质心、稳定性及交互动力学的准确预测。解决方案的关键在于构建首个大规模、多模态的真实世界物理属性估计数据集 XDen-1K，其中包含 1,000 个真实物体的高分辨率 3D 几何模型与对应的双平面 X 射线扫描图像，并提出一种新颖的优化框架，从稀疏 X 射线视图中恢复高保真体积密度场。该方法显著提升了质心估计精度与机器人抓取成功率，为基于物理约束的视觉推理研究提供了基础资源与基准测试平台。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10668">https://arxiv.org/abs/2512.10668</a><br>
<strong>作者</strong>: Jingxuan Zhang,Tianqi Yu,Yatu Zhang,Jinze Wu,Kaixin Yao,Jingyang Liu,Yuyao Zhang,Jiayuan Gu,Jingyi Yu<br>
<strong>机构</strong>: ShanghaiTech University (上海科技大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  10 pages, 7 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:A deep understanding of the physical world is a central goal for embodied AI and realistic simulation. While current models excel at capturing an object’s surface geometry and appearance, they largely neglect its internal physical properties. This omission is critical, as properties like volumetric density are fundamental for predicting an object’s center of mass, stability, and interaction dynamics in applications ranging from robotic manipulation to physical simulation. The primary bottleneck has been the absence of large-scale, real-world data. To bridge this gap, we introduce XDen-1K, the first large-scale, multi-modal dataset designed for real-world physical property estimation, with a particular focus on volumetric density. The core of this dataset consists of 1,000 real-world objects across 148 categories, for which we provide comprehensive multi-modal data, including a high-resolution 3D geometric model with part-level annotations and a corresponding set of real-world biplanar X-ray scans. Building upon this data, we introduce a novel optimization framework that recovers a high-fidelity volumetric density field of each object from its sparse X-ray views. To demonstrate its practical value, we add X-ray images as a conditioning signal to an existing segmentation network and perform volumetric segmentation. Furthermore, we conduct experiments on downstream robotics tasks. The results show that leveraging the dataset can effectively improve the accuracy of center-of-mass estimation and the success rate of robotic manipulation. We believe XDen-1K will serve as a foundational resource and a challenging new benchmark, catalyzing future research in physically grounded visual inference and embodied AI.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-45] NaviHydra: Controllable Navigation-guided End-to-end Autonomous Driving with Hydra-distillation</p>
<p>【速读】：该论文旨在解决自动驾驶场景中模型对高阶导航指令理解与执行能力不足的问题，尤其是在动态环境中传统规则系统响应受限、端到端方法难以遵循明确导航指令的挑战。解决方案的关键在于提出NaviHydra——一个从现有规则模拟器蒸馏而来的可控导航引导式端到端模型，通过将高阶导航命令作为控制信号输入，生成与意图一致的安全轨迹；其核心技术包括基于鸟瞰图（Bird’s Eye View, BEV）的轨迹特征提取方法和一种新的导航合规度量指标，从而显著提升模型在复杂场景下的可控性与导航安全性，在NAVSIM基准测试中达到当前最优性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10660">https://arxiv.org/abs/2512.10660</a><br>
<strong>作者</strong>: Hanfeng Wu,Marlon Steiner,Michael Schmidt,Alvaro Marcos-Ramiro,Christoph Stiller<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The complexity of autonomous driving scenarios requires robust models that can interpret high-level navigation commands and generate safe trajectories. While traditional rule-based systems can react to these commands, they often struggle in dynamic environments, and end-to-end methods face challenges in complying with explicit navigation commands. To address this, we present NaviHydra, a controllable navigation-guided end-to-end model distilled from an existing rule-based simulator. Our framework accepts high-level navigation commands as control signals, generating trajectories that align with specified intentions. We utilize a Bird’s Eye View (BEV) based trajectory gathering method to enhance the trajectory feature extraction. Additionally, we introduce a novel navigation compliance metric to evaluate adherence to intended route, improving controllability and navigation safety. To comprehensively assess our model’s controllability, we design a test that evaluates its response to various navigation commands. Our method significantly outperforms baseline models, achieving state-of-the-art results in the NAVSIM benchmark, demonstrating its effectiveness in advancing autonomous driving.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-46] riDF: Evaluating Perception Detection and Hallucination for Interpretable DeepFake Detection</p>
<p>【速读】：该论文旨在解决生成式 AI (Generative AI) 伪造内容（如 DeepFake）对安全、通信和公众信任带来的严重威胁，其核心问题是现有检测系统缺乏可解释性与可靠性，难以在复杂多模态场景下准确识别伪造内容并提供可信的推理依据。解决方案的关键在于提出 TriDF 基准，该基准从三个维度系统评估检测模型：感知（Perception）——识别细粒度篡改痕迹的能力；检测（Detection）——跨伪造类型与生成器的分类性能；以及幻觉（Hallucination）——模型解释的可靠性。实验表明，精准的感知是可靠检测的前提，但若解释存在幻觉则会显著干扰决策过程，揭示了三者间的强耦合关系，从而为构建可信赖的合成媒体检测系统提供了统一框架。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10652">https://arxiv.org/abs/2512.10652</a><br>
<strong>作者</strong>: Jian-Yu Jiang-Lin,Kang-Yang Huang,Ling Zou,Ling Lo,Sheng-Ping Yang,Yu-Wen Tseng,Kun-Hsiang Lin,Chia-Ling Chen,Yu-Ting Ta,Yan-Tsung Wang,Po-Ching Chen,Hongxia Xie,Hong-Han Shuai,Wen-Huang Cheng<br>
<strong>机构</strong>: National Taiwan University (国立台湾大学); National Yang Ming Chiao Tung University (国立阳明交通大学); Jilin University (吉林大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Advances in generative modeling have made it increasingly easy to fabricate realistic portrayals of individuals, creating serious risks for security, communication, and public trust. Detecting such person-driven manipulations requires systems that not only distinguish altered content from authentic media but also provide clear and reliable reasoning. In this paper, we introduce TriDF, a comprehensive benchmark for interpretable DeepFake detection. TriDF contains high-quality forgeries from advanced synthesis models, covering 16 DeepFake types across image, video, and audio modalities. The benchmark evaluates three key aspects: Perception, which measures the ability of a model to identify fine-grained manipulation artifacts using human-annotated evidence; Detection, which assesses classification performance across diverse forgery families and generators; and Hallucination, which quantifies the reliability of model-generated explanations. Experiments on state-of-the-art multimodal large language models show that accurate perception is essential for reliable detection, but hallucination can severely disrupt decision-making, revealing the interdependence of these three aspects. TriDF provides a unified framework for understanding the interaction between detection accuracy, evidence identification, and explanation reliability, offering a foundation for building trustworthy systems that address real-world synthetic media threats.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-47] K-Track: Kalman-Enhanced Tracking for Accelerating Deep Point Trackers on Edge Devices</p>
<p>【速读】：该论文旨在解决当前基于深度学习的点跟踪（Point Tracking）算法在资源受限边缘设备上部署困难的问题。现有方法虽在基准测试中表现优异，但依赖每帧进行GPU推理，导致计算、功耗和连接性受限的边缘平台难以实时运行。解决方案的关键在于提出K-Track（Kalman-enhanced Tracking）框架，其核心是将稀疏的深度学习关键帧更新与轻量级卡尔曼滤波（Kalman Filtering）相结合，利用贝叶斯不确定性传播实现中间帧预测，从而在保持85%以上原始跟踪精度的同时，实现5–10倍的速度提升。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10628">https://arxiv.org/abs/2512.10628</a><br>
<strong>作者</strong>: Bishoy Galoaa,Pau Closas,Sarah Ostadabbas<br>
<strong>机构</strong>: Northeastern University (东北大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Point tracking in video sequences is a foundational capability for real-world computer vision applications, including robotics, autonomous systems, augmented reality, and video analysis. While recent deep learning-based trackers achieve state-of-the-art accuracy on challenging benchmarks, their reliance on per-frame GPU inference poses a major barrier to deployment on resource-constrained edge devices, where compute, power, and connectivity are limited. We introduce K-Track (Kalman-enhanced Tracking), a general-purpose, tracker-agnostic acceleration framework designed to bridge this deployment gap. K-Track reduces inference cost by combining sparse deep learning keyframe updates with lightweight Kalman filtering for intermediate frame prediction, using principled Bayesian uncertainty propagation to maintain temporal coherence. This hybrid strategy enables 5-10X speedup while retaining over 85% of the original trackers’ accuracy. We evaluate K-Track across multiple state-of-the-art point trackers and demonstrate real-time performance on edge platforms such as the NVIDIA Jetson Nano and RTX Titan. By preserving accuracy while dramatically lowering computational requirements, K-Track provides a practical path toward deploying high-quality point tracking in real-world, resource-limited settings, closing the gap between modern tracking algorithms and deployable vision systems.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-48] DOCR-Inspector: Fine-Grained and Automated Evaluation of Document Parsing with VLM</p>
<p>【速读】：该论文旨在解决真实场景下文档解析（Document Parsing）质量评估不可靠、不全面的问题。现有方法依赖标准基准测试的总体得分，但这些基准常存在数据集特异性偏差，导致模型排名与实际性能相关性弱，且无法揭示具体的错误模式。为应对这一挑战，作者提出DOCR-Inspector，其核心在于将文档解析评估形式化为细粒度错误检测与分析任务：利用视觉语言模型作为评判者（VLM-as-a-Judge），对文档图像及其解析输出进行逐项比对，识别并分类28种预定义类型的错误，从而生成全面的质量评估报告。关键技术包括构建包含20万样本的DOCRcase-200K训练数据集，以及提出Chain-of-Checklist推理范式以支持分层结构化的评估逻辑。实证表明，DOCR-Inspector-7B在882个真实世界案例组成的DOCRcaseBench上优于Gemini 2.5 Pro等商用模型及主流开源模型，并能有效指导解析结果优化，兼具评估与改进双重价值。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10619">https://arxiv.org/abs/2512.10619</a><br>
<strong>作者</strong>: Qintong Zhang,Junyuan Zhang,Zhifei Ren,Linke Ouyang,Zichen Wen,Junbo Niu,Yuan Qu,Bin Wang,Ka-Ho Chow,Conghui He,Wentao Zhang<br>
<strong>机构</strong>: Peking University (北京大学); Shanghai AI Laboratory (上海人工智能实验室); The University of HongKong (香港大学); Shanghai Jiaotong University (上海交通大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Document parsing aims to transform unstructured PDF images into semi-structured data, facilitating the digitization and utilization of information in diverse domains. While vision language models (VLMs) have significantly advanced this task, achieving reliable, high-quality parsing in real-world scenarios remains challenging. Common practice often selects the top-performing model on standard benchmarks. However, these benchmarks may carry dataset-specific biases, leading to inconsistent model rankings and limited correlation with real-world performance. Moreover, benchmark metrics typically provide only overall scores, which can obscure distinct error patterns in output. This raises a key challenge: how can we reliably and comprehensively assess document parsing quality in the wild? We address this problem with DOCR-Inspector, which formalizes document parsing assessment as fine-grained error detection and analysis. Leveraging VLM-as-a-Judge, DOCR-Inspector analyzes a document image and its parsed output, identifies all errors, assigns them to one of 28 predefined types, and produces a comprehensive quality assessment. To enable this capability, we construct DOCRcase-200K for training and propose the Chain-of-Checklist reasoning paradigm to enable the hierarchical structure of parsing quality assessment. For empirical validation, we introduce DOCRcaseBench, a set of 882 real-world document parsing cases with manual annotations. On this benchmark, DOCR-Inspector-7B outperforms commercial models like Gemini 2.5 Pro, as well as leading open-source models. Further experiments demonstrate that its quality assessments provide valuable guidance for parsing results refinement, making DOCR-Inspector both a practical evaluator and a driver for advancing document parsing systems at scale. Model and code are released at: this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-49] Lang2Motion: Bridging Language and Motion through Joint Embedding Spaces</p>
<p>【速读】：该论文旨在解决如何基于自然语言描述生成任意物体在三维空间中的显式点轨迹问题，传统方法多集中于人类动作或视频合成，难以精确控制物体运动路径。其核心解决方案是提出Lang2Motion框架，通过将运动流形（motion manifold）与联合嵌入空间（joint embedding space）对齐，利用基于Transformer的自编码器学习轨迹表示，并采用双监督机制：文本运动描述和渲染轨迹可视化均通过冻结的CLIP编码器映射至同一语义空间，从而实现语言到轨迹的精准映射。此方法显著提升了文本到轨迹检索的召回率（Recall@1达34.2%），并大幅改善了轨迹预测精度（平均位移误差从18.3–25.3降至12.4 ADE）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10617">https://arxiv.org/abs/2512.10617</a><br>
<strong>作者</strong>: Bishoy Galoaa,Xiangyu Bai,Sarah Ostadabbas<br>
<strong>机构</strong>: Northeastern University (东北大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present Lang2Motion, a framework for language-guided point trajectory generation by aligning motion manifolds with joint embedding spaces. Unlike prior work focusing on human motion or video synthesis, we generate explicit trajectories for arbitrary objects using motion extracted from real-world videos via point tracking. Our transformer-based auto-encoder learns trajectory representations through dual supervision: textual motion descriptions and rendered trajectory visualizations, both mapped through CLIP’s frozen encoders. Lang2Motion achieves 34.2% Recall@1 on text-to-trajectory retrieval, outperforming video-based methods by 12.5 points, and improves motion accuracy by 33-52% (12.4 ADE vs 18.3-25.3) compared to video generation baselines. We demonstrate 88.3% Top-1 accuracy on human action recognition despite training only on diverse object motions, showing effective transfer across motion domains. Lang2Motion supports style transfer, semantic interpolation, and latent-space editing through CLIP-aligned trajectory representations.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-50] Robust Multi-Disease Retinal Classification via Xception-Based Transfer Learning and W-Net Vessel Segmentation</p>
<p>【速读】：该论文旨在解决当前视力威胁性眼病筛查中对可扩展且高精度诊断方案的需求，尤其针对标准卷积神经网络（Convolutional Neural Networks, CNNs）存在的“黑箱”问题。其解决方案的关键在于构建一个融合深度特征提取与可解释图像处理模块的流水线，通过将高保真视网膜血管分割作为辅助任务来引导分类过程，从而基于临床相关的形态学特征提升模型预测的可信度，降低假阳性率，并增强在临床环境中的部署可行性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10608">https://arxiv.org/abs/2512.10608</a><br>
<strong>作者</strong>: Mohammad Sadegh Gholizadeh,Amir Arsalan Rezapour<br>
<strong>机构</strong>: Shahid Rajaee University (沙希德·拉吉大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In recent years, the incidence of vision-threatening eye diseases has risen dramatically, necessitating scalable and accurate screening solutions. This paper presents a comprehensive study on deep learning architectures for the automated diagnosis of ocular conditions. To mitigate the “black-box” limitations of standard convolutional neural networks (CNNs), we implement a pipeline that combines deep feature extraction with interpretable image processing modules. Specifically, we focus on high-fidelity retinal vessel segmentation as an auxiliary task to guide the classification process. By grounding the model’s predictions in clinically relevant morphological features, we aim to bridge the gap between algorithmic output and expert medical validation, thereby reducing false positives and improving deployment viability in clinical settings.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-51] rack and Caption Any Motion: Query-Free Motion Discovery and Description in Videos</p>
<p>【速读】：该论文旨在解决复杂场景下视频理解的挑战，尤其是当视频中存在遮挡、伪装或快速运动时，仅依赖静态外观特征难以准确识别和描述动作的问题。传统方法通常需要用户查询才能定位特定动作，而TCAM提出了一种无查询的运动中心框架，能够自主发现并描述视频中的多种运动模式。其解决方案的关键在于将运动模式与对比视觉-语言表示对齐，利用运动场注意力机制（motion-field attention mechanism）实现自然语言描述与对应轨迹的空间对齐，并通过统一训练结合全局视频-文本对齐与细粒度空间对应关系，借助多头交叉注意力机制实现无需查询的多运动表达发现。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10607">https://arxiv.org/abs/2512.10607</a><br>
<strong>作者</strong>: Bishoy Galoaa,Sarah Ostadabbas<br>
<strong>机构</strong>: Northeastern University (东北大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We propose Track and Caption Any Motion (TCAM), a motion-centric framework for automatic video understanding that discovers and describes motion patterns without user queries. Understanding videos in challenging conditions like occlusion, camouflage, or rapid movement often depends more on motion dynamics than static appearance. TCAM autonomously observes a video, identifies multiple motion activities, and spatially grounds each natural language description to its corresponding trajectory through a motion-field attention mechanism. Our key insight is that motion patterns, when aligned with contrastive vision-language representations, provide powerful semantic signals for recognizing and describing actions. Through unified training that combines global video-text alignment with fine-grained spatial correspondence, TCAM enables query-free discovery of multiple motion expressions via multi-head cross-attention. On the MeViS benchmark, TCAM achieves 58.4% video-to-text retrieval, 64.9 JF for spatial grounding, and discovers 4.8 relevant expressions per video with 84.7% precision, demonstrating strong cross-task generalization.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-52] Beyond Pixels: A Training-Free Text-to-Text Framework for Remote Sensing Image Retrieval</p>
<p>【速读】：该论文旨在解决遥感（Remote Sensing, RS）图像语义检索中的“语义鸿沟”问题，即模型低层视觉特征与高层人类概念之间的不匹配。现有方法通常依赖于昂贵且领域特定的训练，且缺乏在零样本检索场景下评估视觉语言模型（Vision-Language Models, VLMs）生成文本实用性的基准。解决方案的关键在于提出一个完全无需训练的文本检索参考方法 TRSLLaVA，其核心创新是将跨模态检索重构为文本到文本（Text-to-Text, T2T）匹配任务：利用结构化文本描述作为查询，在统一的文本嵌入空间中与VLM生成的图像描述进行匹配，从而绕过模型训练或微调过程。实验表明，该方法在RSITMD和RSICD基准上性能优于多个监督模型，验证了高质量结构化文本作为语义表示的有效性与成本效益。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10596">https://arxiv.org/abs/2512.10596</a><br>
<strong>作者</strong>: J. Xiao,Y. Guo,X. Zi,K. Thiyagarajan,C. Moreira,M. Prasad<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  6 pages, 1 figure</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Semantic retrieval of remote sensing (RS) images is a critical task fundamentally challenged by the \textquotesemantic gap, the discrepancy between a model’s low-level visual features and high-level human concepts. While large Vision-Language Models (VLMs) offer a promising path to bridge this gap, existing methods often rely on costly, domain-specific training, and there is a lack of benchmarks to evaluate the practical utility of VLM-generated text in a zero-shot retrieval context. To address this research gap, we introduce the Remote Sensing Rich Text (RSRT) dataset, a new benchmark featuring multiple structured captions per image. Based on this dataset, we propose a fully training-free, text-only retrieval reference called TRSLLaVA. Our methodology reformulates cross-modal retrieval as a text-to-text (T2T) matching problem, leveraging rich text descriptions as queries against a database of VLM-generated captions within a unified textual embedding space. This approach completely bypasses model training or fine-tuning. Experiments on the RSITMD and RSICD benchmarks show our training-free method is highly competitive with state-of-the-art supervised models. For instance, on RSITMD, our method achieves a mean Recall of 42.62%, nearly doubling the 23.86% of the standard zero-shot CLIP baseline and surpassing several top supervised models. This validates that high-quality semantic representation through structured text provides a powerful and cost-effective paradigm for remote sensing image retrieval.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-53] Salient Object Detection in Complex Weather Conditions via Noise Indicators</p>
<p>【速读】：该论文旨在解决现有显著性目标检测（Salient Object Detection, SOD）方法在真实复杂天气条件下因天气诱导噪声导致分割精度下降的问题。当前大多数SOD模型假设视觉条件为低噪声环境，忽视了实际场景中雨、雾、雪等天气因素对检测性能的影响。解决方案的关键在于提出一个针对多天气条件的SOD框架，其核心创新是引入一个“噪声指示符（Noise Indicator Fusion Module, NIFM）”，该模块以one-hot向量形式表示不同天气类型，并将天气信息作为先验嵌入到编码器中——通过双输入机制（语义特征与噪声指示符）实现自适应特征调制，在编码器的不同阶段动态融合天气感知信息，从而提升模型在多样化天气下的鲁棒性和分割准确性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10592">https://arxiv.org/abs/2512.10592</a><br>
<strong>作者</strong>: Quan Chen,Xiaokai Yang,Tingyu Wang,Rongfeng Lu,Xichun Sheng,Yaoqi Sun,Chenggang Yan<br>
<strong>机构</strong>: Hangzhou Dianzi University (杭州电子科技大学); Jiaxing University (嘉兴大学); Macao Polytechnic University (澳门理工大学); Lishui University (丽水学院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Salient object detection (SOD), a foundational task in computer vision, has advanced from single-modal to multi-modal paradigms to enhance generalization. However, most existing SOD methods assume low-noise visual conditions, overlooking the degradation of segmentation accuracy caused by weather-induced noise in real-world scenarios. In this paper, we propose a SOD framework tailored for diverse weather conditions, encompassing a specific encoder and a replaceable decoder. To enable handling of varying weather noises, we introduce a one-hot vector as a noise indicator to represent different weather types and design a Noise Indicator Fusion Module (NIFM). The NIFM takes both semantic features and the noise indicator as dual inputs and is inserted between consecutive stages of the encoder to embed weather-aware priors via adaptive feature modulation. Critically, the proposed specific encoder retains compatibility with mainstream SOD decoders. Extensive experiments are conducted on the WXSOD dataset under varying training data scales (100%, 50%, 30% of the full training set), three encoder and seven decoder configurations. Results show that the proposed SOD framework (particularly the NIFM-enhanced specific encoder) improves segmentation accuracy under complex weather conditions compared to a vanilla encoder.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-54] Unleashing Degradation-Carrying Features in Symmetric U-Net: Simpler and Stronger Baselines for All-in-One Image Restoration</p>
<p>【速读】：该论文旨在解决**全合一图像复原（all-in-one image restoration）**中因复杂架构和繁琐退化提示策略导致的计算开销高、模型设计冗余的问题。现有方法通常依赖于Mixture-of-Experts或扩散模型等复杂结构，且需精心设计退化提示以区分不同类型的退化（如噪声、模糊、恶劣天气）。论文的关键洞察在于：<strong>经过精心设计的特征提取机制本身已蕴含退化信息，而对称U-Net架构足以有效挖掘并利用这些内在退化线索</strong>。通过在编码器与解码器之间对齐特征尺度并实现跨尺度的简洁传播，该对称设计能稳健保留退化信号，从而仅用简单的加法融合即可在跳跃连接中取得最优性能。基于此，作者提出两个基线模型——SymUNet及其语义增强版本SE-SymUNet，后者通过引入冻结CLIP的语义特征进行交叉注意力注入，进一步强化退化先验，实验表明二者均在多个基准上优于现有方法，同时显著降低计算成本。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10581">https://arxiv.org/abs/2512.10581</a><br>
<strong>作者</strong>: Wenlong Jiao,Heyang Lee,Ping Wang,Pengfei Zhu,Qinghua Hu,Dongwei Ren<br>
<strong>机构</strong>: Tianjin University (天津大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:All-in-one image restoration aims to handle diverse degradations (e.g., noise, blur, adverse weather) within a unified framework, yet existing methods increasingly rely on complex architectures (e.g., Mixture-of-Experts, diffusion models) and elaborate degradation prompt strategies. In this work, we reveal a critical insight: well-crafted feature extraction inherently encodes degradation-carrying information, and a symmetric U-Net architecture is sufficient to unleash these cues effectively. By aligning feature scales across encoder-decoder and enabling streamlined cross-scale propagation, our symmetric design preserves intrinsic degradation signals robustly, rendering simple additive fusion in skip connections sufficient for state-of-the-art performance. Our primary baseline, SymUNet, is built on this symmetric U-Net and achieves better results across benchmark datasets than existing approaches while reducing computational cost. We further propose a semantic enhanced variant, SE-SymUNet, which integrates direct semantic injection from frozen CLIP features via simple cross-attention to explicitly amplify degradation priors. Extensive experiments on several benchmarks validate the superiority of our methods. Both baselines SymUNet and SE-SymUNet establish simpler and stronger foundations for future advancements in all-in-one image restoration. The source code is available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-55] Audio-sync Video Instance Editing with Granularity-Aware Mask Refiner</p>
<p>【速读】：该论文旨在解决视频编辑中音频-视觉同步（audio-visual synchronization）不足及缺乏细粒度时空可控性的问题，尤其针对实例级（instance-level）编辑需求。现有方法通常忽略音画一致性，且难以实现对特定对象在空间和时间维度上的精确控制。解决方案的关键在于提出AVI-Edit框架：首先设计了一个粒度感知的掩码精修模块（granularity-aware mask refiner），可将用户提供的粗略掩码迭代优化为精确的实例级区域；其次引入自反馈音频代理（self-feedback audio agent），用于生成高质量音频引导信号，从而实现细粒度的时间控制能力。此外，研究构建了一个大规模实例中心的数据集，包含详尽标注，有效支撑了上述技术的训练与验证。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10571">https://arxiv.org/abs/2512.10571</a><br>
<strong>作者</strong>: Haojie Zheng,Shuchen Weng,Jingqi Liu,Siqi Yang,Boxin Shi,Xinlong Wang<br>
<strong>机构</strong>: Peking University (北京大学); Beijing Academy of Artificial Intelligence (北京人工智能研究院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advancements in video generation highlight that realistic audio-visual synchronization is crucial for engaging content creation. However, existing video editing methods largely overlook audio-visual synchronization and lack the fine-grained spatial and temporal controllability required for precise instance-level edits. In this paper, we propose AVI-Edit, a framework for audio-sync video instance editing. We propose a granularity-aware mask refiner that iteratively refines coarse user-provided masks into precise instance-level regions. We further design a self-feedback audio agent to curate high-quality audio guidance, providing fine-grained temporal control. To facilitate this task, we additionally construct a large-scale dataset with instance-centric correspondence and comprehensive annotations. Extensive experiments demonstrate that AVI-Edit outperforms state-of-the-art methods in visual quality, condition following, and audio-visual synchronization. Project page: this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-56] Data-Efficient American Sign Language Recognition via Few-Shot Prototypical Networks</p>
<p>【速读】：该论文旨在解决孤立手语识别（Isolated Sign Language Recognition, ISLR）中因数据稀缺和词汇分布长尾特性导致的模型泛化能力差的问题，尤其在少量样本情况下难以有效识别罕见手语符号。其核心解决方案是提出一种基于骨架信息的少样本原型网络（Few-Shot Prototypical Network）框架，通过引入基于时空图卷积网络（Spatiotemporal Graph Convolutional Network, ST-GCN）与新颖的多尺度时间聚合模块（Multi-Scale Temporal Aggregation, MSTA），构建一个度量学习驱动的语义空间，在该空间中手语符号依据其与动态类别原型的距离进行分类，而非依赖固定决策边界。此策略显著提升了在低资源场景下的识别性能，并展现出强大的零样本迁移能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10562">https://arxiv.org/abs/2512.10562</a><br>
<strong>作者</strong>: Meher Md Saad<br>
<strong>机构</strong>: NYUAD(纽约大学阿布扎比分校)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Isolated Sign Language Recognition (ISLR) is critical for bridging the communication gap between the Deaf and Hard-of-Hearing (DHH) community and the hearing world. However, robust ISLR is fundamentally constrained by data scarcity and the long-tail distribution of sign vocabulary, where gathering sufficient examples for thousands of unique signs is prohibitively expensive. Standard classification approaches struggle under these conditions, often overfitting to frequent classes while failing to generalize to rare ones. To address this bottleneck, we propose a Few-Shot Prototypical Network framework adapted for a skeleton based encoder. Unlike traditional classifiers that learn fixed decision boundaries, our approach utilizes episodic training to learn a semantic metric space where signs are classified based on their proximity to dynamic class prototypes. We integrate a Spatiotemporal Graph Convolutional Network (ST-GCN) with a novel Multi-Scale Temporal Aggregation (MSTA) module to capture both rapid and fluid motion dynamics. Experimental results on the WLASL dataset demonstrate the superiority of this metric learning paradigm: our model achieves 43.75% Top-1 and 77.10% Top-5 accuracy on the test set. Crucially, this outperforms a standard classification baseline sharing the identical backbone architecture by over 13%, proving that the prototypical training strategy effectively outperforms in a data scarce situation where standard classification fails. Furthermore, the model exhibits strong zero-shot generalization, achieving nearly 30% accuracy on the unseen SignASL dataset without fine-tuning, offering a scalable pathway for recognizing extensive sign vocabularies with limited data.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-57] Grounding Everything in Tokens for Multimodal <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark></p>
<p>【速读】：该论文旨在解决多模态大语言模型（Multimodal Large Language Models, MLLMs）在视觉理解与推理中因采用自回归Transformer架构而导致的图像空间定位不准确问题，即输入图像被离散化为语言令牌后难以精确锚定二维图像空间中的目标对象。解决方案的关键在于提出一种名为GETok的空间表示方法，其核心是将可学习的专用令牌嵌入MLLMs中：首先通过网格令牌（grid tokens）对图像平面进行结构化空间划分以建立锚点，再利用偏移令牌（offset tokens）实现定位预测的精细化迭代修正，从而在不改变自回归架构的前提下，将空间关系直接编码至令牌中，显著提升模型在原生2D空间推理能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10554">https://arxiv.org/abs/2512.10554</a><br>
<strong>作者</strong>: Xiangxuan Ren,Zhongdao Wang,Liping Hou,Pin Tang,Guoqing Wang,Chao Ma<br>
<strong>机构</strong>: MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University (上海交通大学人工智能重点实验室); Huawei Noah’s Ark Lab (华为诺亚方舟实验室)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  19 pages, 16 figures, 12 Tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multimodal large language models (MLLMs) have made significant advancements in vision understanding and reasoning. However, the autoregressive Transformer architecture used by MLLMs requries tokenization on input images, which limits their ability to accurately ground objects within the 2D image space. This raises an important question: how can sequential language tokens be improved to better ground objects in 2D spatial space for MLLMs? To address this, we present a spatial representation method for grounding objects, namely GETok, that integrates a specialized vocabulary of learnable tokens into MLLMs. GETok first uses grid tokens to partition the image plane into structured spatial anchors, and then exploits offset tokens to enable precise and iterative refinement of localization predictions. By embedding spatial relationships directly into tokens, GETok significantly advances MLLMs in native 2D space reasoning without modifying the autoregressive architecture. Extensive experiments demonstrate that GETok achieves superior performance over the state-of-the-art methods across various referring tasks in both supervised fine-tuning and reinforcement learning settings.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-58] Blink: Dynamic Visual Token Resolution for Enhanced Multimodal Understanding</p>
<p>【速读】：该论文旨在解决多模态大语言模型（Multimodal Large Language Models, MLLMs）在视觉感知能力上的局限性问题，即现有模型难以像人类一样通过动态扫描和聚焦显著区域来高效理解复杂场景。其解决方案的关键在于提出一种名为Blink的动态视觉标记分辨率框架，该框架模拟人类“眨眼式”的注意力机制，在单次前向传播中实现视觉标记的自适应聚焦与扩展：首先基于注意力图估计各层视觉标记的显著性，并通过插件式的标记超分辨率（TokenSR）模块增强重要标记；随后在下一层中丢弃失去关注的扩展标记，从而在广域探索与细粒度聚焦之间取得平衡，显著提升视觉感知能力和多模态理解性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10548">https://arxiv.org/abs/2512.10548</a><br>
<strong>作者</strong>: Yuchen Feng,Zhenyu Zhang,Naibin Gu,Yilong Chen,Peng Fu,Zheng Lin,Shuohuan Wang,Yu Sun,Hua Wu,Weiping Wang,Haifeng Wang<br>
<strong>机构</strong>: Institute of Information Engineering, Chinese Academy of Sciences (中国科学院信息工程研究所); School of Cyber Security, University of Chinese Academy of Sciences (中国科学院大学网络空间安全学院); Baidu Inc. (百度公司)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multimodal large language models (MLLMs) have achieved remarkable progress on various vision-language tasks, yet their visual perception remains limited. Humans, in comparison, perceive complex scenes efficiently by dynamically scanning and focusing on salient regions in a sequential “blink-like” process. Motivated by this strategy, we first investigate whether MLLMs exhibit similar behavior. Our pilot analysis reveals that MLLMs naturally attend to different visual regions across layers and that selectively allocating more computation to salient tokens can enhance visual perception. Building on this insight, we propose Blink, a dynamic visual token resolution framework that emulates the human-inspired process within a single forward pass. Specifically, Blink includes two modules: saliency-guided scanning and dynamic token resolution. It first estimates the saliency of visual tokens in each layer based on the attention map, and extends important tokens through a plug-and-play token super-resolution (TokenSR) module. In the next layer, it drops the extended tokens when they lose focus. This dynamic mechanism balances broad exploration and fine-grained focus, thereby enhancing visual perception adaptively and efficiently. Extensive experiments validate Blink, demonstrating its effectiveness in enhancing visual perception and multimodal understanding.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-59] Mode-Seeking for Inverse Problems with Diffusion Models</p>
<p>【速读】：该论文旨在解决生成式 AI（Generative AI）在求解任意逆问题（inverse problems）时，传统后验采样（posterior sampling）与最大后验估计（Maximum a Posteriori, MAP）方法依赖模型近似且计算成本高的问题。其解决方案的关键在于提出变分模态搜索损失（Variational Mode-Seeking Loss, VML），该损失函数通过在每一步反向扩散过程中最小化，引导生成样本逼近MAP估计；VML源自一种新视角，即最小化扩散后验 $ p(\mathbf{x}_0|\mathbf{x}_t) $ 与观测后验 $ p(\mathbf{x}_0|\mathbf{y}) $ 之间的KL散度，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">y</mi></mrow><annotation encoding="application/x-tex">\mathbf{y}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6389em;vertical-align:-0.1944em;"></span><span class="mord mathbf" style="margin-right:0.01597em;">y</span></span></span></span> 表示观测数据。对于线性逆问题，VML可解析推导而无需近似，从而显著提升效率与精度。基于此理论，作者进一步提出 VML-MAP 算法，在多个图像恢复任务中验证了其优于现有方法的性能和计算效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10524">https://arxiv.org/abs/2512.10524</a><br>
<strong>作者</strong>: Sai Bharath Chandra Gutha,Ricardo Vinuesa,Hossein Azizpour<br>
<strong>机构</strong>: KTH, Sweden; University of Michigan, USA<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:A pre-trained unconditional diffusion model, combined with posterior sampling or maximum a posteriori (MAP) estimation techniques, can solve arbitrary inverse problems without task-specific training or fine-tuning. However, existing posterior sampling and MAP estimation methods often rely on modeling approximations and can be computationally demanding. In this work, we propose the variational mode-seeking loss (VML), which, when minimized during each reverse diffusion step, guides the generated sample towards the MAP estimate. VML arises from a novel perspective of minimizing the Kullback-Leibler (KL) divergence between the diffusion posterior  p(\mathbfx_0|\mathbfx_t)  and the measurement posterior  p(\mathbfx_0|\mathbfy) , where  \mathbfy  denotes the measurement. Importantly, for linear inverse problems, VML can be analytically derived and need not be approximated. Based on further theoretical insights, we propose VML-MAP, an empirically effective algorithm for solving inverse problems, and validate its efficacy over existing methods in both performance and computational time, through extensive experiments on diverse image-restoration tasks across multiple datasets.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-60] ake a Peek: Efficient Encoder Adaptation for Few-Shot Semantic Segmentation via LoRA</p>
<p>【速读】：该论文旨在解决少样本语义分割（Few-shot Semantic Segmentation, FSS）中编码器对未见类别特征提取能力不足的问题，这一局限性成为制约模型泛化性能的关键瓶颈。解决方案的核心在于提出一种名为“Take a Peek”（TaP）的简单而有效的方法，其关键创新是利用低秩适应（Low-Rank Adaptation, LoRA）技术，在支持集上对编码器进行轻量级微调，从而在极小计算开销下实现快速适应新类别，并缓解灾难性遗忘问题。该方法具有模型无关性，可无缝集成至现有FSS框架中，在多个基准数据集（如COCO、Pascal、DeepGlobe等）上验证了其在不同模型和样本设置下的稳定性能提升，尤其在复杂多类场景中表现显著，证明了其在真实应用中的有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10521">https://arxiv.org/abs/2512.10521</a><br>
<strong>作者</strong>: Pasquale De Marinis,Gennaro Vessio,Giovanna Castellano<br>
<strong>机构</strong>: University of Bari Aldo Moro (巴里阿尔多·莫罗大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Few-shot semantic segmentation (FSS) aims to segment novel classes in query images using only a small annotated support set. While prior research has mainly focused on improving decoders, the encoder’s limited ability to extract meaningful features for unseen classes remains a key bottleneck. In this work, we introduce \textitTake a Peek (TaP), a simple yet effective method that enhances encoder adaptability for both FSS and cross-domain FSS (CD-FSS). TaP leverages Low-Rank Adaptation (LoRA) to fine-tune the encoder on the support set with minimal computational overhead, enabling fast adaptation to novel classes while mitigating catastrophic forgetting. Our method is model-agnostic and can be seamlessly integrated into existing FSS pipelines. Extensive experiments across multiple benchmarks–including COCO  20^i , Pascal  5^i , and cross-domain datasets such as DeepGlobe, ISIC, and Chest X-ray–demonstrate that TaP consistently improves segmentation performance across diverse models and shot settings. Notably, TaP delivers significant gains in complex multi-class scenarios, highlighting its practical effectiveness in realistic settings. A rank sensitivity analysis also shows that strong performance can be achieved even with low-rank adaptations, ensuring computational efficiency. By addressing a critical limitation in FSS–the encoder’s generalization to novel classes–TaP paves the way toward more robust, efficient, and generalizable segmentation systems. The code is available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-61] 3D Blood Pulsation Maps</p>
<p>【速读】：该论文旨在解决远程脉搏估计中缺乏高质量、多视角3D血流波动数据的问题，从而限制了基于光电容积脉搏波描记法（photoplethysmography, PPG）的模型训练与验证。解决方案的关键在于构建首个用于估计3D血流波动图（3D blood pulsation maps）的数据集Pulse3DFace，其包含15名受试者在23个视角下以30 Hz采集的RGB视频、同步血流参考测量值及通过单目结构光恢复（monocular structure-from-motion）生成的面部三维扫描，并进一步处理得到与FLAME三维头部模型纹理空间兼容的3D脉动映射结果，提供信噪比、局部脉动幅度和相位等生理可解释特征，为开发更鲁棒的多视角血流分析方法和合成视频数据生成提供了基础支撑。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10517">https://arxiv.org/abs/2512.10517</a><br>
<strong>作者</strong>: Maurice Rohr,Tobias Reinhardt,Tizian Dege,Justus Thies,Christoph Hoog Antink<br>
<strong>机构</strong>: Technical University of Darmstadt (达姆施塔特工业大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  9 pages (without references), supplementals attached, waiting for publication. In order to access the dataset,see <a target="_blank" rel="noopener" href="https://github.com/KISMED-TUDa/pulse3dface">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present Pulse3DFace, the first dataset of its kind for estimating 3D blood pulsation maps. These maps can be used to develop models of dynamic facial blood pulsation, enabling the creation of synthetic video data to improve and validate remote pulse estimation methods via photoplethysmography imaging. Additionally, the dataset facilitates research into novel multi-view-based approaches for mitigating illumination effects in blood pulsation analysis. Pulse3DFace consists of raw videos from 15 subjects recorded at 30 Hz with an RGB camera from 23 viewpoints, blood pulse reference measurements, and facial 3D scans generated using monocular structure-from-motion techniques. It also includes processed 3D pulsation maps compatible with the texture space of the 3D head model FLAME. These maps provide signal-to-noise ratio, local pulse amplitude, phase information, and supplementary data. We offer a comprehensive evaluation of the dataset’s illumination conditions, map consistency, and its ability to capture physiologically meaningful features in the facial and neck skin regions.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-62] Robust Shape from Focus via Multiscale Directional Dilated Laplacian and Recurrent Network</p>
<p>【速读】：该论文旨在解决基于深度学习的形状恢复聚焦（Shape-from-Focus, SFF）方法中存在的两个关键问题：一是现有方法通常依赖复杂的特征编码器提取焦点体积（focus volume），导致计算开销大；二是后续采用简单的单步聚合技术进行深度估计，易引入伪影并放大噪声，影响深度图质量。其解决方案的关键在于提出一种混合框架：首先利用手工设计的定向扩张拉普拉斯（Directional Dilated Laplacian, DDL）核在多尺度上高效构建鲁棒的焦点体积，以捕捉长距离和方向性焦点变化；随后通过轻量级、多尺度的门控循环单元（GRU）模块迭代优化低分辨率初始深度估计，提升计算效率与精度；最终借助网络内嵌的可学习凸插值模块实现高分辨率深度图重建，同时保持细节清晰度与边界锐度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10498">https://arxiv.org/abs/2512.10498</a><br>
<strong>作者</strong>: Khurram Ashfaq,Muhammad Tariq Mahmood<br>
<strong>机构</strong>: Korea University of Science and Technology (韩国科学技术院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Accepted to IJCV</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Shape-from-Focus (SFF) is a passive depth estimation technique that infers scene depth by analyzing focus variations in a focal stack. Most recent deep learning-based SFF methods typically operate in two stages: first, they extract focus volumes (a per pixel representation of focus likelihood across the focal stack) using heavy feature encoders; then, they estimate depth via a simple one-step aggregation technique that often introduces artifacts and amplifies noise in the depth map. To address these issues, we propose a hybrid framework. Our method computes multi-scale focus volumes traditionally using handcrafted Directional Dilated Laplacian (DDL) kernels, which capture long-range and directional focus variations to form robust focus volumes. These focus volumes are then fed into a lightweight, multi-scale GRU-based depth extraction module that iteratively refines an initial depth estimate at a lower resolution for computational efficiency. Finally, a learned convex upsampling module within our recurrent network reconstructs high-resolution depth maps while preserving fine scene details and sharp boundaries. Extensive experiments on both synthetic and real-world datasets demonstrate that our approach outperforms state-of-the-art deep learning and traditional methods, achieving superior accuracy and generalization across diverse focal conditions.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-63] Error-Propagation-Free Learned Video Compression With Dual-Domain Progressive Temporal Alignment</p>
<p>【速读】：该论文旨在解决现有学习型视频压缩框架中因运动估计与补偿（Motion Estimation and Compensation, ME/MC）导致的时序对齐不准确与误差传播之间的矛盾问题。具体而言，分离变换框架虽能实现优异的率失真（Rate-Distortion, R-D）性能，但存在明显的误差传播；而统一变换框架虽可消除误差传播，却在共享潜在域中的ME/MC表现不佳。解决方案的关键在于提出一种新型统一变换框架，其核心包括两个创新模块：一是双域渐进式时序对齐机制，通过粗粒度像素域对齐与精化潜空间对齐相结合，在粗到细的层次上显著增强时序上下文建模能力；二是质量条件混合专家（Quality-Conditioned Mixture-of-Experts, QCMoE）模块，实现连续比特率自适应控制，动态分配不同专家调整每像素的量化步长，从而在保持高质量一致性的同时实现无误差传播的流媒体传输。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10450">https://arxiv.org/abs/2512.10450</a><br>
<strong>作者</strong>: Han Li,Shaohui Li,Wenrui Dai,Chenglin Li,Xinlong Pan,Haipeng Wang,Junni Zou,Hongkai Xiong<br>
<strong>机构</strong>: Shanghai Jiao Tong University (上海交通大学); Zhejiang University (浙江大学); Naval Aviation University (海军航空大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Existing frameworks for learned video compression suffer from a dilemma between inaccurate temporal alignment and error propagation for motion estimation and compensation (ME/MC). The separate-transform framework employs distinct transforms for intra-frame and inter-frame compression to yield impressive rate-distortion (R-D) performance but causes evident error propagation, while the unified-transform framework eliminates error propagation via shared transforms but is inferior in ME/MC in shared latent domains. To address this limitation, in this paper, we propose a novel unifiedtransform framework with dual-domain progressive temporal alignment and quality-conditioned mixture-of-expert (QCMoE) to enable quality-consistent and error-propagation-free streaming for learned video compression. Specifically, we propose dualdomain progressive temporal alignment for ME/MC that leverages coarse pixel-domain alignment and refined latent-domain alignment to significantly enhance temporal context modeling in a coarse-to-fine fashion. The coarse pixel-domain alignment efficiently handles simple motion patterns with optical flow estimated from a single reference frame, while the refined latent-domain alignment develops a Flow-Guided Deformable Transformer (FGDT) over latents from multiple reference frames to achieve long-term motion refinement (LTMR) for complex motion patterns. Furthermore, we design a QCMoE module for continuous bit-rate adaptation that dynamically assigns different experts to adjust quantization steps per pixel based on target quality and content rather than relies on a single quantization step. QCMoE allows continuous and consistent rate control with appealing R-D performance. Experimental results show that the proposed method achieves competitive R-D performance compared with the state-of-the-arts, while successfully eliminating error propagation.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-64] An M-Health Algorithmic Approach to Identify and Assess Physiotherapy Exercises in Real Time</p>
<p>【速读】：该论文旨在解决远程物理治疗监督中运动识别与评估的实时性与准确性问题，特别是在移动设备上实现对患者执行动作的自动识别、分类及质量评价。其核心解决方案是将动态运动分解为一系列静态姿态（pose），通过轻量级监督模型从摄像头输入中提取关键点并转换为基于三角函数的角度特征进行帧级分类，再利用改进的莱文斯坦距离（Levenshtein distance）动态规划算法实现完整动作序列的匹配与偏差定位，从而在客户端完成端到端的实时分析，具备良好的可扩展性和实用性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10437">https://arxiv.org/abs/2512.10437</a><br>
<strong>作者</strong>: Stylianos Kandylakis,Christos Orfanopoulos,Georgios Siolas,Panayiotis Tsanakas<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  11 pages, 5 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This work presents an efficient algorithmic framework for real-time identification, classification, and evaluation of human physiotherapy exercises using mobile devices. The proposed method interprets a kinetic movement as a sequence of static poses, which are estimated from camera input using a pose-estimation neural network. Extracted body keypoints are transformed into trigonometric angle-based features and classified with lightweight supervised models to generate frame-level pose predictions and accuracy scores. To recognize full exercise movements and detect deviations from prescribed patterns, we employ a dynamic-programming scheme based on a modified Levenshtein distance algorithm, enabling robust sequence matching and localization of inaccuracies. The system operates entirely on the client side, ensuring scalability and real-time performance. Experimental evaluation demonstrates the effectiveness of the methodology and highlights its applicability to remote physiotherapy supervision and m-health applications.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-65] Neural Collapse in Test-Time Adaptation</p>
<p>【速读】：该论文旨在解决测试时适应（Test-Time Adaptation, TTA）在面对分布偏移（domain shift）时性能下降的问题，其根本原因在于样本级特征嵌入与分类器权重之间的对齐失效。通过扩展神经坍缩（Neural Collapse, NC）至样本层面，作者发现了一种新的现象——样本级对齐坍缩（Sample-wise Alignment Collapse, NC3+），即训练好的模型中每个样本的特征嵌入会紧密对齐于对应的分类器权重；然而，在域偏移下，这种对齐关系被破坏，导致伪标签不可靠，进而损害模型性能。解决方案的关键在于提出NCTTA方法，该方法基于特征-分类器对齐机制，引入混合目标（hybrid targets）来缓解不可靠伪标签的影响，融合几何邻近性与预测置信度以实现更稳定的在线适应，从而显著提升模型在分布外数据上的鲁棒性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10421">https://arxiv.org/abs/2512.10421</a><br>
<strong>作者</strong>: Xiao Chen,Zhongjing Du,Jiazhen Huang,Xu Jiang,Li Lu,Jingyan Jiang,Zhi Wang<br>
<strong>机构</strong>: Tsinghua University (清华大学); Peking University (北京大学); Sichuan University (四川大学); Shenzhen Technology University (深圳技术大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  10 pages, 8 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Test-Time Adaptation (TTA) enhances model robustness to out-of-distribution (OOD) data by updating the model online during inference, yet existing methods lack theoretical insights into the fundamental causes of performance degradation under domain shifts. Recently, Neural Collapse (NC) has been proposed as an emergent geometric property of deep neural networks (DNNs), providing valuable insights for TTA. In this work, we extend NC to the sample-wise level and discover a novel phenomenon termed Sample-wise Alignment Collapse (NC3+), demonstrating that a sample’s feature embedding, obtained by a trained model, aligns closely with the corresponding classifier weight. Building on NC3+, we identify that the performance degradation stems from sample-wise misalignment in adaptation which exacerbates under larger distribution shifts. This indicates the necessity of realigning the feature embeddings with their corresponding classifier weights. However, the misalignment makes pseudo-labels unreliable under domain shifts. To address this challenge, we propose NCTTA, a novel feature-classifier alignment method with hybrid targets to mitigate the impact of unreliable pseudo-labels, which blends geometric proximity with predictive confidence. Extensive experiments demonstrate the effectiveness of NCTTA in enhancing robustness to domain shifts. For example, NCTTA outperforms Tent by 14.52% on ImageNet-C.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-66] ransLocNet: Cross-Modal Attention for Aerial-Ground Vehicle Localization with Contrastive Learning</p>
<p>【速读】：该论文旨在解决航空与地面传感器之间的视角差异（viewpoint gap）和模态差异（modality gap）导致的定位难题，尤其是在使用地面激光雷达（LiDAR）与航拍影像进行联合定位时。其核心解决方案是提出TransLocNet框架，该框架通过双向交叉注意力机制将LiDAR几何信息与航拍图像语义特征对齐，并引入对比学习模块构建共享嵌入空间以增强跨模态一致性；随后通过 likelihood map 解码器输出位置与姿态的概率分布，从而实现高精度、鲁棒的空中-地面协同定位。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10419">https://arxiv.org/abs/2512.10419</a><br>
<strong>作者</strong>: Phu Pham,Damon Conover,Aniket Bera<br>
<strong>机构</strong>: Purdue University (普渡大学); DEVCOM Army Research Laboratory (美国陆军研究实验室)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  8 pages, 4 figures, 4 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Aerial-ground localization is difficult due to large viewpoint and modality gaps between ground-level LiDAR and overhead imagery. We propose TransLocNet, a cross-modal attention framework that fuses LiDAR geometry with aerial semantic context. LiDAR scans are projected into a bird’s-eye-view representation and aligned with aerial features through bidirectional attention, followed by a likelihood map decoder that outputs spatial probability distributions over position and orientation. A contrastive learning module enforces a shared embedding space to improve cross-modal alignment. Experiments on CARLA and KITTI show that TransLocNet outperforms state-of-the-art baselines, reducing localization error by up to 63% and achieving sub-meter, sub-degree accuracy. These results demonstrate that TransLocNet provides robust and generalizable aerial-ground localization in both synthetic and real-world settings.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-67] Beyond Endpoints: Path-Centric <mark class="hl-label green">Reasoning</mark>  for Vectorized Off-Road Network Extraction</p>
<p>【速读】：该论文旨在解决离道路（off-road）环境中矢量道路提取的挑战，主要受限于两大问题：缺乏大规模矢量数据集以及现有方法在结构上的脆弱性。具体而言，当前主流模型如SAM-Road采用以节点为中心的范式，在离道路场景中因遮挡和模糊交汇处导致拓扑错误，难以稳定推理。解决方案的关键在于两个互补方面：一是发布WildRoad数据集，该数据集通过专用交互式标注工具高效构建，填补了离道路场景下高质量矢量道路数据的空白；二是提出MaGRoad（Mask-aware Geodesic Road network extractor），一种路径中心的框架，通过沿候选路径聚合多尺度视觉证据来推断连通性，从而增强对复杂环境的鲁棒性。实验表明，MaGRoad在WildRoad基准上达到最先进性能，并能良好泛化至城市数据集，同时推理速度提升约2.5倍，显著改善实际应用可行性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10416">https://arxiv.org/abs/2512.10416</a><br>
<strong>作者</strong>: Wenfei Guan,Jilin Mei,Tong Shen,Xumin Wu,Shuo Wang,Cheng Min,Yu Hu<br>
<strong>机构</strong>: Institute of Computing Technology, Chinese Academy of Sciences (中国科学院计算技术研究所); Hangzhou Institute for Advanced Study, University of Chinese Academy of Sciences (中国科学院大学杭州高等研究院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Deep learning has advanced vectorized road extraction in urban settings, yet off-road environments remain underexplored and challenging. A significant domain gap causes advanced models to fail in wild terrains due to two key issues: lack of large-scale vectorized datasets and structural weakness in prevailing methods. Models such as SAM-Road employ a node-centric paradigm that reasons at sparse endpoints, making them fragile to occlusions and ambiguous junctions in off-road scenes, leading to topological this http URL work addresses these limitations in two complementary ways. First, we release WildRoad, a gloabal off-road road network dataset constructed efficiently with a dedicated interactive annotation tool tailored for road-network labeling. Second, we introduce MaGRoad (Mask-aware Geodesic Road network extractor), a path-centric framework that aggregates multi-scale visual evidence along candidate paths to infer connectivity this http URL experiments show that MaGRoad achieves state-of-the-art performance on our challenging WildRoad benchmark while generalizing well to urban datasets. A streamlined pipeline also yields roughly 2.5x faster inference, improving practical applicability. Together, the dataset and path-centric paradigm provide a stronger foundation for mapping roads in the wild.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-68] MultiHateLoc: Towards Temporal Localisation of Multimodal Hate Content in Online Videos</p>
<p>【速读】：该论文旨在解决弱监督环境下多模态仇恨内容（multimodal hate speech）的时间定位问题，即在仅有视频级别标签的情况下，精准识别出仇恨言论在时间轴上的具体发生段落。现有方法主要集中在视频级分类，难以捕捉跨模态（视觉、音频、文本）和时序动态特征，尤其在弱监督场景下表现不佳。解决方案的关键在于提出MultiHateLoc框架：其核心包括（1）模态感知的时序编码器以建模异构序列模式，并引入针对文本的预处理模块增强特征；（2）动态跨模态融合机制与跨模态对比对齐策略，实现时变的信息模态权重调整和多模态特征一致性强化；（3）模态感知的MIL（Multiple Instance Learning）目标函数，在视频级监督下识别判别性片段。该方法仅依赖粗粒度标签即可生成细粒度、可解释的帧级预测，显著提升了定位精度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10408">https://arxiv.org/abs/2512.10408</a><br>
<strong>作者</strong>: Qiyue Sun,Tailin Chen,Yinghui Zhang,Yuchen Zhang,Jiangbei Yue,Jianbo Jiao,Zeyu Fu<br>
<strong>机构</strong>: Multimodal Intelligence Lab, Department of Computer Science, University of Exeter, UK; The MIx Group, School of Computer Science, University of Birmingham, UK; School of Information Science and Engineering, Shandong University, China; Institute for Analytics and Data Science, University of Essex, UK<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The rapid growth of video content on platforms such as TikTok and YouTube has intensified the spread of multimodal hate speech, where harmful cues emerge subtly and asynchronously across visual, acoustic, and textual streams. Existing research primarily focuses on video-level classification, leaving the practically crucial task of temporal localisation, identifying when hateful segments occur, largely unaddressed. This challenge is even more noticeable under weak supervision, where only video-level labels are available, and static fusion or classification-based architectures struggle to capture cross-modal and temporal dynamics. To address these challenges, we propose MultiHateLoc, the first framework designed for weakly-supervised multimodal hate localisation. MultiHateLoc incorporates (1) modality-aware temporal encoders to model heterogeneous sequential patterns, including a tailored text-based preprocessing module for feature enhancement; (2) dynamic cross-modal fusion to adaptively emphasise the most informative modality at each moment and a cross-modal contrastive alignment strategy to enhance multimodal feature consistency; (3) a modality-aware MIL objective to identify discriminative segments under video-level supervision. Despite relying solely on coarse labels, MultiHateLoc produces fine-grained, interpretable frame-level predictions. Experiments on HateMM and MultiHateClip show that our method achieves state-of-the-art performance in the localisation task.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-69] Adaptive Dual-Weighted Gravitational Point Cloud Denoising Method</p>
<p>【速读】：该论文旨在解决LiDAR点云数据在获取过程中受多种干扰影响而引入大量噪声点的问题，这些问题会显著降低后续点云目标检测与识别的准确性。现有去噪方法往往难以兼顾高去噪精度、强边缘保持能力和实时性能。其解决方案的关键在于提出一种自适应双权重引力机制点云去噪方法：首先利用八叉树（octree）对全局点云进行空间分区以实现并行加速；其次，在每个叶节点内结合自适应体素占用统计与k近邻（kNN）密度估计快速剔除明显孤立和低密度噪声点，缩小候选集；最后构建融合密度权重与自适应距离权重的引力评分函数，精细区分噪声点与物体点，从而在多噪声场景下实现高精度、强鲁棒性和实时性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10386">https://arxiv.org/abs/2512.10386</a><br>
<strong>作者</strong>: Ge Zhang,Chunyang Wang,Bo Xiao,Xuelian Liu,Bin Liu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:High-quality point cloud data is a critical foundation for tasks such as autonomous driving and 3D reconstruction. However, LiDAR-based point cloud acquisition is often affected by various disturbances, resulting in a large number of noise points that degrade the accuracy of subsequent point cloud object detection and recognition. Moreover, existing point cloud denoising methods typically sacrifice computational efficiency in pursuit of higher denoising accuracy, or, conversely, improve processing speed at the expense of preserving object boundaries and fine structural details, making it difficult to simultaneously achieve high denoising accuracy, strong edge preservation, and real-time performance. To address these limitations, this paper proposes an adaptive dual-weight gravitational-based point cloud denoising method. First, an octree is employed to perform spatial partitioning of the global point cloud, enabling parallel acceleration. Then, within each leaf node, adaptive voxel-based occupancy statistics and k-nearest neighbor (kNN) density estimation are applied to rapidly remove clearly isolated and low-density noise points, thereby reducing the effective candidate set. Finally, a gravitational scoring function that combines density weights with adaptive distance weights is constructed to finely distinguish noise points from object points. Experiments conducted on the Stanford 3D Scanning Repository, the Canadian Adverse Driving Conditions (CADC) dataset, and in-house FMCW LiDAR point clouds acquired in our laboratory demonstrate that, compared with existing methods, the proposed approach achieves consistent improvements in F1, PSNR, and Chamfer Distance (CD) across various noise conditions while reducing the single-frame processing time, thereby validating its high accuracy, robustness, and real-time performance in multi-noise scenarios.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-70] owards Fine-Grained Recognition with Large Visual Language Models: Benchmark and Optimization Strategies</p>
<p>【速读】：该论文旨在解决当前大型视觉语言模型（Large Vision Language Models, LVLMs）在细粒度识别（fine-grained recognition）能力上的评估与提升不足的问题，尤其针对现有基准测试多集中于推理任务而忽视实际应用场景中对细节识别的需求。其解决方案的关键在于构建一个名为Fine-grained Recognition Open World (FROW)的新型基准，并提出从数据构造和训练过程两个维度优化LVLM性能的新策略：一方面引入拼贴数据（mosaic data）和开放世界数据（open-world data），其中后者基于GPT-4o生成真实问题与答案，显著提升了模型在类别识别和内容准确性方面的表现；另一方面，在预训练阶段融入细粒度数据可使类别识别准确率最高提升10%，从而系统性增强LVLM在复杂现实场景中的细粒度理解能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10384">https://arxiv.org/abs/2512.10384</a><br>
<strong>作者</strong>: Cong Pang,Hongtao Yu,Zixuan Chen,Lewei Lu,Xin Lou<br>
<strong>机构</strong>: ShanghaiTech University (上海科技大学); Southeast University (东南大学); SenseTime Research (商汤科技研究院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Vision Language Models (LVLMs) have made remarkable progress, enabling sophisticated vision-language interaction and dialogue applications. However, existing benchmarks primarily focus on reasoning tasks, often neglecting fine-grained recognition, which is crucial for practical application scenarios. To address this gap, we introduce the Fine-grained Recognition Open World (FROW) benchmark, designed for detailed evaluation of LVLMs with GPT-4o. On the basis of that, we propose a novel optimization strategy from two perspectives: \textitdata construction and \textittraining process, to improve the performance of LVLMs. Our dataset includes mosaic data, which combines multiple short-answer responses, and open-world data, generated from real-world questions and answers using GPT-4o, creating a comprehensive framework for evaluating fine-grained recognition in LVLMs. Experiments show that mosaic data improves category recognition accuracy by 1% and open-world data boosts FROW benchmark accuracy by 10%-20% and content accuracy by 6%-12%. Meanwhile, incorporating fine-grained data into the pre-training phase can improve the model’s category recognition accuracy by up to 10%. The benchmark will be available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-71] Self-Supervised Contrastive Embedding Adaptation for Endoscopic Image Matching</p>
<p>【速读】：该论文旨在解决微创手术中内窥镜图像像素级对应关系建立的难题，其核心挑战在于弱透视线索、非朗伯体组织反射及复杂可变形解剖结构导致传统计算机视觉方法性能下降。解决方案的关键在于提出了一种新颖的深度学习流水线与自监督优化框架：通过新视角合成生成真值内点对应关系，并在对比学习范式下挖掘三元组样本；在此基础上，对DINOv2骨干网络增加一个专用Transformer层，优化嵌入表示以支持基于余弦相似度阈值的直接匹配。实验表明，该方法在SCARED数据集上实现了更高的匹配精度和更低的极线误差，显著优于现有先进方法。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10379">https://arxiv.org/abs/2512.10379</a><br>
<strong>作者</strong>: Alberto Rota,Elena De Momi<br>
<strong>机构</strong>: Politecnico di Milano (米兰理工大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Accurate spatial understanding is essential for image-guided surgery, augmented reality integration and context awareness. In minimally invasive procedures, where visual input is the sole intraoperative modality, establishing precise pixel-level correspondences between endoscopic frames is critical for 3D reconstruction, camera tracking, and scene interpretation. However, the surgical domain presents distinct challenges: weak perspective cues, non-Lambertian tissue reflections, and complex, deformable anatomy degrade the performance of conventional computer vision techniques. While Deep Learning models have shown strong performance in natural scenes, their features are not inherently suited for fine-grained matching in surgical images and require targeted adaptation to meet the demands of this domain. This research presents a novel Deep Learning pipeline for establishing feature correspondences in endoscopic image pairs, alongside a self-supervised optimization framework for model training. The proposed methodology leverages a novel-view synthesis pipeline to generate ground-truth inlier correspondences, subsequently utilized for mining triplets within a contrastive learning paradigm. Through this self-supervised approach, we augment the DINOv2 backbone with an additional Transformer layer, specifically optimized to produce embeddings that facilitate direct matching through cosine similarity thresholding. Experimental evaluation demonstrates that our pipeline surpasses state-of-the-art methodologies on the SCARED datasets improved matching precision and lower epipolar error compared to the related work. The proposed framework constitutes a valuable contribution toward enabling more accurate high-level computer vision applications in surgical endoscopy.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-72] RaLiFlow: Scene Flow Estimation with 4D Radar and LiDAR Point Clouds <mark class="hl-label red">AAAI</mark></p>
<p>【速读】：该论文旨在解决4D毫米波雷达与激光雷达（LiDAR）在场景流估计中的联合建模问题，填补当前多模态融合方法中缺乏雷达-LiDAR协同学习的研究空白。现有方法主要依赖图像与LiDAR融合，而雷达因成本低、抗恶劣天气能力强且具备点云级速度信息，成为LiDAR的重要补充，但其噪声大、分辨率低和稀疏性带来挑战，同时缺乏专门用于场景流估计的雷达-LiDAR数据集。解决方案的关键在于：首先构建首个雷达-LiDAR场景流数据集，并提出针对雷达去噪及场景流标签生成的有效预处理策略；其次设计RaLiFlow框架，通过动态感知的双向跨模态融合（Dynamic-aware Bidirectional Cross-modal Fusion, DBCF）模块，将雷达动态信息嵌入局部交叉注意力机制以实现跨模态上下文传播；同时引入精心设计的损失函数，在训练中缓解不可靠雷达数据的影响并增强两模态在实例层面的场景流一致性，尤其在动态前景区域表现显著提升。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10376">https://arxiv.org/abs/2512.10376</a><br>
<strong>作者</strong>: Jingyun Fu,Zhiyu Xiang,Na Zhao<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Accepted by AAAI</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent multimodal fusion methods, integrating images with LiDAR point clouds, have shown promise in scene flow estimation. However, the fusion of 4D millimeter wave radar and LiDAR remains unexplored. Unlike LiDAR, radar is cheaper, more robust in various weather conditions and can detect point-wise velocity, making it a valuable complement to LiDAR. However, radar inputs pose challenges due to noise, low resolution, and sparsity. Moreover, there is currently no dataset that combines LiDAR and radar data specifically for scene flow estimation. To address this gap, we construct a Radar-LiDAR scene flow dataset based on a public real-world automotive dataset. We propose an effective preprocessing strategy for radar denoising and scene flow label generation, deriving more reliable flow ground truth for radar points out of the object boundaries. Additionally, we introduce RaLiFlow, the first joint scene flow learning framework for 4D radar and LiDAR, which achieves effective radar-LiDAR fusion through a novel Dynamic-aware Bidirectional Cross-modal Fusion (DBCF) module and a carefully designed set of loss functions. The DBCF module integrates dynamic cues from radar into the local cross-attention mechanism, enabling the propagation of contextual information across modalities. Meanwhile, the proposed loss functions mitigate the adverse effects of unreliable radar data during training and enhance the instance-level consistency in scene flow predictions from both modalities, particularly for dynamic foreground areas. Extensive experiments on the repurposed scene flow dataset demonstrate that our method outperforms existing LiDAR-based and radar-based single-modal methods by a significant margin.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-73] Breaking the Vicious Cycle: Coherent 3D Gaussian Splatting from Sparse and Motion-Blurred Views</p>
<p>【速读】：该论文旨在解决3D Gaussian Splatting (3DGS)在真实场景下因输入图像稀疏且存在运动模糊而导致重建失败的问题。此类退化因素形成恶性循环：稀疏视图无法提供多视角约束以消除运动模糊，而运动模糊又会丢失高频细节，进而阻碍有限视图间的对齐。为打破这一循环，论文提出CoherentGS框架，其核心在于采用双先验策略——融合一个专用去模糊网络（提供光度引导）与一个扩散模型（提供几何先验），从而同时恢复清晰细节并填补未观测区域。关键技术包括一致性引导的相机探索模块和深度正则化损失，确保生成过程的几何合理性与视觉一致性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10369">https://arxiv.org/abs/2512.10369</a><br>
<strong>作者</strong>: Zhankuo Xu,Chaoran Feng,Yingtao Li,Jianbin Zhao,Jiashu Yang,Wangbo Yu,Li Yuan,Yonghong Tian<br>
<strong>机构</strong>: Peking University (北京大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  20 pages, 14 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:3D Gaussian Splatting (3DGS) has emerged as a state-of-the-art method for novel view synthesis. However, its performance heavily relies on dense, high-quality input imagery, an assumption that is often violated in real-world applications, where data is typically sparse and motion-blurred. These two issues create a vicious cycle: sparse views ignore the multi-view constraints necessary to resolve motion blur, while motion blur erases high-frequency details crucial for aligning the limited views. Thus, reconstruction often fails catastrophically, with fragmented views and a low-frequency bias. To break this cycle, we introduce CoherentGS, a novel framework for high-fidelity 3D reconstruction from sparse and blurry images. Our key insight is to address these compound degradations using a dual-prior strategy. Specifically, we combine two pre-trained generative models: a specialized deblurring network for restoring sharp details and providing photometric guidance, and a diffusion model that offers geometric priors to fill in unobserved regions of the scene. This dual-prior strategy is supported by several key techniques, including a consistency-guided camera exploration module that adaptively guides the generative process, and a depth regularization loss that ensures geometric plausibility. We evaluate CoherentGS through both quantitative and qualitative experiments on synthetic and real-world scenes, using as few as 3, 6, and 9 input views. Our results demonstrate that CoherentGS significantly outperforms existing methods, setting a new state-of-the-art for this challenging task. The code and video demos are available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-74] Point to Span: Zero-Shot Moment Retrieval for Navigating Unseen Hour-Long Videos</p>
<p>【速读】：该论文旨在解决零样本长视频时段检索（Zero-shot Long Video Moment Retrieval, ZLVMR）中的两大核心挑战：一是“搜索-精炼”范式下搜索阶段因启发式策略导致候选片段爆炸，二是精炼阶段受语义差异影响，需依赖高成本视觉语言模型（Visual Language Model, VLM）进行验证，造成显著计算开销。解决方案的关键在于提出一种无需训练的框架Point-to-Span (P2S)，其核心创新为：(1) 自适应区间生成器（Adaptive Span Generator），有效抑制搜索阶段的候选爆炸；(2) 查询分解（Query Decomposition），在不依赖高成本VLM的前提下实现高效精炼，从而首次实现对小时级长视频的零样本时序定位，并显著超越现有监督方法性能（如在MAD数据集上R5@0.1指标提升3.7%）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10363">https://arxiv.org/abs/2512.10363</a><br>
<strong>作者</strong>: Mingyu Jeon,Jisoo Yang,Sungjin Han,Jinkwon Hwang,Sunjae Yoon,Jonghee Kim,Junyeoung Kim<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Zero-shot Long Video Moment Retrieval (ZLVMR) is the task of identifying temporal segments in hour-long videos using a natural language query without task-specific training. The core technical challenge of LVMR stems from the computational infeasibility of processing entire lengthy videos in a single pass. This limitation has established a ‘Search-then-Refine’ approach, where candidates are rapidly narrowed down, and only those portions are analyzed, as the dominant paradigm for LVMR. However, existing approaches to this paradigm face severe limitations. Conventional supervised learning suffers from limited scalability and poor generalization, despite substantial resource consumption. Yet, existing zero-shot methods also fail, facing a dual challenge: (1) their heuristic strategies cause a ‘search’ phase candidate explosion, and (2) the ‘refine’ phase, which is vulnerable to semantic discrepancy, requires high-cost VLMs for verification, incurring significant computational overhead. We propose \textbfPoint-\textbfto-\textbfSpan (P2S), a novel training-free framework to overcome this challenge of inefficient ‘search’ and costly ‘refine’ phases. P2S overcomes these challenges with two key innovations: an ‘Adaptive Span Generator’ to prevent the search phase candidate explosion, and ‘Query Decomposition’ to refine candidates without relying on high-cost VLM verification. To our knowledge, P2S is the first zero-shot framework capable of temporal grounding in hour-long videos, outperforming supervised state-of-the-art methods by a significant margin (e.g., +3.7% on R5@0.1 on MAD).<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-75] Visual Funnel: Resolving Contextual Blindness in Multimodal <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark></p>
<p>【速读】：该论文旨在解决多模态大语言模型（Multimodal Large Language Models, MLLMs）在处理高精度任务时因无法感知细粒度视觉细节而导致的“上下文盲区”（Contextual Blindness）问题。这一现象源于高保真细节区域（来自图像裁剪）与原始图像全局语境之间存在的结构断层，即便所有必要视觉信息均存在。作者指出，问题根源并非信息量不足，而是输入中缺乏结构多样性（Structural Diversity）。解决方案的关键在于提出一种无需训练的两步方法——Visual Funnel：首先通过单次前向传播实现上下文锚定（Contextual Anchoring），精准定位感兴趣区域；随后构建基于注意力熵动态调节裁剪尺寸和中心的熵缩放组合（Entropy-Scaled Portfolio），以保留从焦点细节到周边环境的层次化语境结构，从而有效缓解上下文盲区，显著优于简单单裁剪或多裁剪基线方法。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10362">https://arxiv.org/abs/2512.10362</a><br>
<strong>作者</strong>: Woojun Jung,Jaehoon Go,Mingyu Jeon,Sunjae Yoon,Junyeong Kim<br>
<strong>机构</strong>: Chung-Ang University (中央大学); KAIST (韩国科学技术院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multimodal Large Language Models (MLLMs) demonstrate impressive reasoning capabilities, but often fail to perceive fine-grained visual details, limiting their applicability in precision-demanding tasks. While methods that crop salient regions of an image offer a partial solution, we identify a critical limitation they introduce: “Contextual Blindness”. This failure occurs due to structural disconnect between high-fidelity details (from the crop) and the broader global context (from the original image), even when all necessary visual information is present. We argue that this limitation stems not from a lack of information ‘Quantity’, but from a lack of ‘Structural Diversity’ in the model’s input. To resolve this, we propose Visual Funnel, a training-free, two-step approach. Visual Funnel first performs Contextual Anchoring to identify the region of interest in a single forward pass. It then constructs an Entropy-Scaled Portfolio that preserves the hierarchical context - ranging from focal detail to broader surroundings - by dynamically determining crop sizes based on attention entropy and refining crop centers. Through extensive experiments, we demonstrate that Visual Funnel significantly outperforms naive single-crop and unstructured multi-crop baselines. Our results further validate that simply adding more unstructured crops provides limited or even detrimental benefits, confirming that the hierarchical structure of our portfolio is key to resolving Contextual Blindness.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-76] ool-Augmented Spatiotemporal <mark class="hl-label green">Reasoning</mark>  for Streamlining Video Question Answering Task <mark class="hl-label red">NEURIPS2025</mark></p>
<p>【速读】：该论文旨在解决当前多模态大语言模型（Multimodal Large Language Models, MLLMs）在视频问答（Video Question Answering, VideoQA）任务中难以同时建模视频帧内的空间关系与理解时间演化的因果动态问题，尤其是在复杂且需要深度推理的场景下表现不足。解决方案的关键在于提出一个可扩展的视频工具集（Video Toolkit）与一种时空推理框架（Spatiotemporal Reasoning Framework, STAR），其中STAR通过策略性调度时空工具，逐步定位视频中的关键区域，从而有效控制工具调用顺序并避免工具链捷径（toolchain shortcut）问题。该方法在GPT-4o基础上引入轻量级工具，显著提升了模型在VideoMME和LongVideoBench两个基准上的性能，分别获得8.2%和4.6%的准确率提升。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10359">https://arxiv.org/abs/2512.10359</a><br>
<strong>作者</strong>: Sunqi Fan,Jiashuo Cui,Meng-Hao Guo,Shuojin Yang<br>
<strong>机构</strong>: Tsinghua University (清华大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Accepted by NeurIPS 2025 main track</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Video Question Answering (VideoQA) task serves as a critical playground for evaluating whether foundation models can effectively perceive, understand, and reason about dynamic real-world scenarios. However, existing Multimodal Large Language Models (MLLMs) struggle with simultaneously modeling spatial relationships within video frames and understanding the causal dynamics of temporal evolution on complex and reasoning-intensive VideoQA task. In this work, we equip MLLM with a comprehensive and extensible Video Toolkit, to enhance MLLM’s spatiotemporal reasoning capabilities and ensure the harmony between the quantity and diversity of tools. To better control the tool invocation sequence and avoid toolchain shortcut issues, we propose a Spatiotemporal Reasoning Framework (STAR) that strategically schedules temporal and spatial tools, thereby progressively localizing the key area in the video. Our STAR framework enhances GPT-4o using lightweight tools, achieving an 8.2% gain on VideoMME and 4.6% on LongVideoBench. We believe that our proposed Video Toolkit and STAR framework make an important step towards building autonomous and intelligent video analysis assistants. The code is publicly available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-77] mmCounter: Static People Counting in Dense Indoor Scenarios Using mmWave Radar</p>
<p>【速读】：该论文旨在解决毫米波雷达（mmWave radar）在密集静态人群环境中难以准确检测或计数个体的问题，其核心挑战在于空间分辨率有限且传统方法依赖人体运动进行目标识别。解决方案的关键在于提出mmCounter系统，通过提取超低频（&lt;1 Hz）生理信号（如呼吸和微尺度躯干移动），并结合创新的多阶段信号处理流程，从背景噪声和静态物体中分离出与个体相关的低频源，并将其空间信息映射至具体人员，从而实现高精度计数。该方法突破了现有呼吸率估计研究需预先知道人数的限制，可在无间距排列的三平方米区域内对最多七名静止人员进行有效计数。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10357">https://arxiv.org/abs/2512.10357</a><br>
<strong>作者</strong>: Tarik Reza Toha,Shao-Jung(Louie)Lu,Shahriar Nirjon<br>
<strong>机构</strong>: University of North CarolinaChapel HillNCUSA<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Accepted at the 22nd International Conference on Embedded Wireless Systems and Networks (EWSN 2025)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:mmWave radars struggle to detect or count individuals in dense, static (non-moving) groups due to limitations in spatial resolution and reliance on movement for detection. We present mmCounter, which accurately counts static people in dense indoor spaces (up to three people per square meter). mmCounter achieves this by extracting ultra-low frequency ( 1 Hz) signals, primarily from breathing and micro-scale body movements such as slight torso shifts, and applying novel signal processing techniques to differentiate these subtle signals from background noise and nearby static objects. Our problem differs significantly from existing studies on breathing rate estimation, which assume the number of people is known a priori. In contrast, mmCounter utilizes a novel multi-stage signal processing pipeline to extract relevant low-frequency sources along with their spatial information and map these sources to individual people, enabling accurate counting. Extensive evaluations in various environments demonstrate that mmCounter delivers an 87% average F1 score and 0.6 mean absolute error in familiar environments, and a 60% average F1 score and 1.1 mean absolute error in previously untested environments. It can count up to seven individuals in a three square meter space, such that there is no side-by-side spacing and only a one-meter front-to-back distance.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-78] Hybrid Transformer-Mamba Architecture for Weakly Supervised Volumetric Medical Segmentation</p>
<p>【速读】：该论文旨在解决弱监督语义分割（Weakly Supervised Semantic Segmentation）在三维医学影像（volumetric medical imaging）中因依赖二维编码器而忽略数据固有三维结构的问题。现有方法难以有效建模跨切片的上下文信息，导致分割精度受限。解决方案的关键在于提出一种混合Transformer-Mamba架构——TranSamba，其通过在标准Vision Transformer主干网络中引入Cross-Plane Mamba模块，利用状态空间模型（State Space Model, SSM）的线性复杂度特性，实现相邻切片间的高效信息交换；该机制增强了Transformer块内单切片的成对自注意力机制，从而提升目标定位的注意力图质量，最终实现时间复杂度与输入体积深度呈线性关系、批量处理内存恒定的高效三维建模，显著优于现有方法。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10353">https://arxiv.org/abs/2512.10353</a><br>
<strong>作者</strong>: Yiheng Lyu,Lian Xu,Mohammed Bennamoun,Farid Boussaid,Coen Arrow,Girish Dwivedi<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Weakly supervised semantic segmentation offers a label-efficient solution to train segmentation models for volumetric medical imaging. However, existing approaches often rely on 2D encoders that neglect the inherent volumetric nature of the data. We propose TranSamba, a hybrid Transformer-Mamba architecture designed to capture 3D context for weakly supervised volumetric medical segmentation. TranSamba augments a standard Vision Transformer backbone with Cross-Plane Mamba blocks, which leverage the linear complexity of state space models for efficient information exchange across neighboring slices. The information exchange enhances the pairwise self-attention within slices computed by the Transformer blocks, directly contributing to the attention maps for object localization. TranSamba achieves effective volumetric modeling with time complexity that scales linearly with the input volume depth and maintains constant memory usage for batch processing. Extensive experiments on three datasets demonstrate that TranSamba establishes new state-of-the-art performance, consistently outperforming existing methods across diverse modalities and pathologies. Our source code and trained models are openly accessible at: this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-79] opology-Agnostic Animal Motion Generation from Text Prompt</p>
<p>【速读】：该论文旨在解决当前运动生成方法在处理不同或扰动拓扑结构的骨骼时缺乏泛化能力的问题，其核心挑战在于缺少大规模异构动物运动数据集以及能够联合建模任意骨骼拓扑和文本条件的统一生成框架。解决方案的关键是提出了OmniZoo数据集和一个广义自回归运动生成框架：其中OmniZoo包含140个物种、32,979条序列的多模态标注动物运动数据；而模型的核心创新在于引入了拓扑感知的骨骼嵌入模块（Topology-aware Skeleton Embedding Module），该模块将任意骨骼的几何与结构特性编码到共享标记空间中，实现与文本语义的无缝融合，从而支持基于文本提示生成针对任意骨骼拓扑的时序连贯、物理合理且语义一致的运动，并进一步实现跨物种运动风格迁移。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10352">https://arxiv.org/abs/2512.10352</a><br>
<strong>作者</strong>: Keyi Chen,Mingze Sun,Zhenyu Liu,Zhangquan Chen,Ruqi Huang<br>
<strong>机构</strong>: Tsinghua Shenzhen International Graduate School (清华大学深圳国际研究生院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  10 pages, 7 <a target="_blank" rel="noopener" href="http://figures.Conference">this http URL</a> submission</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Motion generation is fundamental to computer animation and widely used across entertainment, robotics, and virtual environments. While recent methods achieve impressive results, most rely on fixed skeletal templates, which prevent them from generalizing to skeletons with different or perturbed topologies. We address the core limitation of current motion generation methods - the combined lack of large-scale heterogeneous animal motion data and unified generative frameworks capable of jointly modeling arbitrary skeletal topologies and textual conditions. To this end, we introduce OmniZoo, a large-scale animal motion dataset spanning 140 species and 32,979 sequences, enriched with multimodal annotations. Building on OmniZoo, we propose a generalized autoregressive motion generation framework capable of producing text-driven motions for arbitrary skeletal topologies. Central to our model is a Topology-aware Skeleton Embedding Module that encodes geometric and structural properties of any skeleton into a shared token space, enabling seamless fusion with textual semantics. Given a text prompt and a target skeleton, our method generates temporally coherent, physically plausible, and semantically aligned motions, and further enables cross-species motion style transfer.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-80] CoSPlan: Corrective Sequential <mark class="hl-label green">Planning</mark>  via Scene Graph Incremental Updates</p>
<p>【速读】：该论文旨在解决大型视觉语言模型（Large-scale Vision-Language Models, VLMs）在视觉序列规划（visual sequential planning）任务中表现不佳的问题，尤其是面对包含错误步骤的非最优动作序列时，VLMs难以识别并纠正这些错误以达成目标。其核心挑战在于现有VLMs缺乏对上下文线索的有效利用能力，导致无法完成复杂的多步规划任务。解决方案的关键在于提出一种无需训练的新型方法——场景图增量更新（Scene Graph Incremental updates, SGI），该方法通过在初始状态与目标状态之间引入中间推理步骤，增强VLMs对动作序列的理解与纠错能力，从而显著提升其在错误容忍环境下的规划可靠性，并展现出良好的泛化性能至传统规划任务（如Plan-Bench和VQA）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10342">https://arxiv.org/abs/2512.10342</a><br>
<strong>作者</strong>: Shresth Grover,Priyank Pathak,Akash Kumar,Vibhav Vineet,Yogesh S Rawat<br>
<strong>机构</strong>: University of California San Diego (加州大学圣地亚哥分校); University of Central Florida (中佛罗里达大学); Microsoft Research (微软研究院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large-scale Vision-Language Models (VLMs) exhibit impressive complex reasoning capabilities but remain largely unexplored in visual sequential planning, i.e., executing multi-step actions towards a goal. Additionally, practical sequential planning often involves non-optimal (erroneous) steps, challenging VLMs to detect and correct such steps. We propose Corrective Sequential Planning Benchmark (CoSPlan) to evaluate VLMs in error-prone, vision-based sequential planning tasks across 4 domains: maze navigation, block rearrangement, image reconstruction,and object reorganization. CoSPlan assesses two key abilities: Error Detection (identifying non-optimal action) and Step Completion (correcting and completing action sequences to reach the goal). Despite using state-of-the-art reasoning techniques such as Chain-of-Thought and Scene Graphs, VLMs (e.g. Intern-VLM and Qwen2) struggle on CoSPlan, failing to leverage contextual cues to reach goals. Addressing this, we propose a novel training-free method, Scene Graph Incremental updates (SGI), which introduces intermediate reasoning steps between the initial and goal states. SGI helps VLMs reason about sequences, yielding an average performance gain of 5.2%. In addition to enhancing reliability in corrective sequential planning, SGI generalizes to traditional planning tasks such as Plan-Bench and VQA.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-81] Zero-shot Adaptation of Stable Diffusion via Plug-in Hierarchical Degradation Representation for Real-World Super-Resolution</p>
<p>【速读】：该论文旨在解决真实世界图像超分辨率（Real-World Image Super-Resolution, Real-ISR）中因未知且复杂的退化因素导致的重建质量下降问题，尤其针对现有方法在退化严重程度未知、依赖CLIP文本编码器无法量化退化强度以及泛化能力受限等挑战。其解决方案的关键在于提出一种层次化退化CLIP（Hierarchical Degradation CLIP, HD-CLIP）模块，该模块将低质量图像分解为语义嵌入和序数退化嵌入（ordinal degradation embedding），后者能捕捉退化等级间的有序关系并支持未见退化水平的插值；同时结合无分类器引导（Classifier-Free Guidance, CFG）与提出的无分类器投影引导（Classifier-Free Projection Guidance, CFPG），使扩散模型在生成过程中既能利用语义信息提升细节保真度，又能通过退化信息抑制幻觉与伪影，从而显著增强重建图像的感知真实性和细节 fidelity。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10340">https://arxiv.org/abs/2512.10340</a><br>
<strong>作者</strong>: Yi-Cheng Liao,Shyang-En Weng,Yu-Syuan Xu,Chi-Wei Hsiao,Wei-Chen Chiu,Ching-Chun Huang<br>
<strong>机构</strong>: National Yang Ming Chiao Tung University (国立阳明交通大学); MediaTek Inc. (联发科技)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Real-World Image Super-Resolution (Real-ISR) aims to recover high-quality images from low-quality inputs degraded by unknown and complex real-world factors. Real-world scenarios involve diverse and coupled degradations, making it necessary to provide diffusion models with richer and more informative guidance. However, existing methods often assume known degradation severity and rely on CLIP text encoders that cannot capture numerical severity, limiting their generalization ability. To address this, we propose \textbfHD-CLIP (\textbfHierarchical \textbfDegradation CLIP), which decomposes a low-quality image into a semantic embedding and an ordinal degradation embedding that captures ordered relationships and allows interpolation across unseen levels. Furthermore, we integrated it into diffusion models via classifier-free guidance (CFG) and proposed classifier-free projection guidance (CFPG). HD-CLIP leverages semantic cues to guide generative restoration while using degradation cues to suppress undesired hallucinations and artifacts. As a \textbfplug-and-play module, HD-CLIP can be seamlessly integrated into various super-resolution frameworks without training, significantly improving detail fidelity and perceptual realism across diverse real-world datasets.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-82] A Conditional Generative Framework for Synthetic Data Augmentation in Segmenting Thin and Elongated Structures in Biological Images</p>
<p>【速读】：该论文旨在解决生物图像中细长丝状结构（如微管和肌动蛋白丝）的像素级标注数据稀缺问题，这一问题限制了深度学习模型在丝状结构分割任务中的性能提升。其解决方案的关键在于提出一种基于Pix2Pix架构的条件生成框架，能够从二值掩码（binary masks）生成逼真的显微图像中的丝状结构，并引入一种丝状结构感知的结构损失函数（filament-aware structural loss），以增强合成图像与真实图像在几何结构上的相似性，从而有效提升模型训练的数据质量和分割性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10334">https://arxiv.org/abs/2512.10334</a><br>
<strong>作者</strong>: Yi Liu,Yichi Zhang<br>
<strong>机构</strong>: University of Delaware (特拉华大学); University of Virginia (弗吉尼亚大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Thin and elongated filamentous structures, such as microtubules and actin filaments, often play important roles in biological systems. Segmenting these filaments in biological images is a fundamental step for quantitative analysis. Recent advances in deep learning have significantly improved the performance of filament segmentation. However, there is a big challenge in acquiring high quality pixel-level annotated dataset for filamentous structures, as the dense distribution and geometric properties of filaments making manual annotation extremely laborious and time-consuming. To address the data shortage problem, we propose a conditional generative framework based on the Pix2Pix architecture to generate realistic filaments in microscopy images from binary masks. We also propose a filament-aware structural loss to improve the structure similarity when generating synthetic images. Our experiments have demonstrated the effectiveness of our approach and outperformed existing model trained without synthetic data.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-83] Simple Yet Effective Selective Imputation for Incomplete Multi-view Clustering</p>
<p>【速读】：该论文旨在解决不完整多视图数据（incomplete multi-view data）在聚类任务中的挑战，特别是当不同视图存在缺失和不平衡观测时，传统基于填补（imputation-based）的方法因盲目填补引入噪声与偏差，而无填补（imputation-free）方法则因缺乏跨视图互补性在严重缺失情况下性能受限。其解决方案的关键在于提出一种基于信息量的有选择性填补方法（Informativeness-based Selective imputation Multi-View Clustering, ISMVC）：首先通过视图内相似性和跨视图一致性评估每个缺失位置的信息相关性，仅在支持充分时才进行填补；其次将此选择机制与带有高斯混合先验的变分自编码器（variational autoencoder）结合，学习具有聚类友好性的潜在表示，并通过分布级填补稳定后验聚合、显式建模填补不确定性，从而实现鲁棒融合并避免过度自信的重建。该方法轻量、数据驱动且模型无关，可作为插件模块集成至现有多视图聚类模型中。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10327">https://arxiv.org/abs/2512.10327</a><br>
<strong>作者</strong>: Cai Xu,Jinlong Liu,Yilin Zhang,Ziyu Guan,Wei Zhao<br>
<strong>机构</strong>: Xidian University (西安电子科技大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Multimedia (<a target="_blank" rel="noopener" href="http://cs.MM">cs.MM</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Incomplete multi-view data, where different views suffer from missing and unbalanced observations, pose significant challenges for clustering. Existing imputation-based methods attempt to estimate missing views to restore data associations, but indiscriminate imputation often introduces noise and bias, especially when the available information is insufficient. Imputation-free methods avoid this risk by relying solely on observed data, but struggle under severe incompleteness due to the lack of cross-view complementarity. To address this issue, we propose Informativeness-based Selective imputation Multi-View Clustering (ISMVC). Our method evaluates the imputation-relevant informativeness of each missing position based on intra-view similarity and cross-view consistency, and selectively imputes only when sufficient support is available. Furthermore, we integrate this selection with a variational autoencoder equipped with a mixture-of-Gaussians prior to learn clustering-friendly latent representations. By performing distribution-level imputation, ISMVC not only stabilizes the aggregation of posterior distributions but also explicitly models imputation uncertainty, enabling robust fusion and preventing overconfident reconstructions. Compared with existing cautious imputation strategies that depend on training dynamics or model feedback, our method is lightweight, data-driven, and model-agnostic. It can be readily integrated into existing IMC models as a plug-in module. Extensive experiments on multiple benchmark datasets under a more realistic and challenging unbalanced missing scenario demonstrate that our method outperforms both imputation-based and imputation-free approaches.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-84] StainNet: A Special Staining Self-Supervised Vision Transformer for Computational Pathology</p>
<p>【速读】：该论文旨在解决当前病理学基础模型（Pathology Foundation Models, PFMs）主要基于苏木精-伊红（Hematoxylin-Eosin, HE）染色图像预训练，导致在临床实践中广泛应用的特殊染色（如免疫组化）图像上性能受限的问题。解决方案的关键在于提出 StainNet，一个专为特殊染色设计的基础模型，其采用基于视觉Transformer（Vision Transformer, ViT）架构并结合自蒸馏（self-distillation）的自监督学习（Self-Supervised Learning, SSL）方法，在包含超过140万张切片图像的HISTAI数据库上进行训练，从而实现对特殊染色图像的高效特征提取与迁移学习能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10326">https://arxiv.org/abs/2512.10326</a><br>
<strong>作者</strong>: Jiawen Li,Jiali Hu,Xitong Ling,Yongqiang Lv,Yuxuan Chen,Yizhi Wang,Tian Guan,Yifei Liu,Yonghong He<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  15 pages, 6 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Foundation models trained with self-supervised learning (SSL) on large-scale histological images have significantly accelerated the development of computational pathology. These models can serve as backbones for region-of-interest (ROI) image analysis or patch-level feature extractors in whole-slide images (WSIs) based on multiple instance learning (MIL). Existing pathology foundation models (PFMs) are typically pre-trained on Hematoxylin-Eosin (HE) stained pathology images. However, images with special stains, such as immunohistochemistry, are also frequently used in clinical practice. PFMs pre-trained mainly on H\E-stained images may be limited in clinical applications involving special stains. To address this issue, we propose StainNet, a specialized foundation model for special stains based on the vision transformer (ViT) architecture. StainNet adopts a self-distillation SSL approach and is trained on over 1.4 million patch images cropping from 20,231 publicly available special staining WSIs in the HISTAI database. To evaluate StainNet, we conduct experiments on an in-house slide-level liver malignancy classification task and two public ROI-level datasets to demonstrate its strong ability. We also perform few-ratio learning and retrieval evaluations, and compare StainNet with recently larger PFMs to further highlight its strengths. We have released the StainNet model weights at: this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-85] EchoingPixels: Cross-Modal Adaptive Token Reduction for Efficient Audio-Visual <mark class="hl-label green">LLM</mark> s</p>
<p>【速读】：该论文旨在解决音频-视觉大语言模型（Audio-Visual Large Language Models, AV-LLMs）在处理大规模音视频标记时面临的计算开销过高的问题。现有针对纯视频的标记压缩方法无法有效利用音视频之间的跨模态协同效应，且静态分配每模态固定标记预算难以适应音频与视频信息密度差异显著的特点，导致标记减少效率低下。解决方案的关键在于提出 EchoingPixels 框架，其核心是 Cross-Modal Semantic Sieve (CS2) 模块，该模块通过早期音视频交互机制，在联合多模态流中对音视频标记池进行统一筛选，而非独立压缩各模态；CS2 能动态识别并自适应分配标记预算至音视频两模态，从而实现更高效的标记削减。此外，为保障稀疏选择后的关键时间关系不被破坏，作者还设计了 Synchronization-Augmented RoPE (Sync-RoPE)，以维持时序建模能力。实验表明，该方法仅需原始标记的 5–20% 即可达到强基线性能，同时实现 2–3 倍的速度提升和内存节省。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10324">https://arxiv.org/abs/2512.10324</a><br>
<strong>作者</strong>: Chao Gong,Depeng Wang,Zhipeng Wei,Ya Guo,Huijia Zhu,Jingjing Chen<br>
<strong>机构</strong>: Fudan University (复旦大学); Ant Group (蚂蚁集团); UC Berkeley (加州大学伯克利分校)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Audio-Visual Large Language Models (AV-LLMs) face prohibitive computational overhead from massive audio and video tokens. Token reduction, while extensively explored for video-only LLMs, is insufficient for the audio-visual domain, as these unimodal methods cannot leverage audio-visual cross-modal synergies. Furthermore, the distinct and dynamic information densities of audio and video render static budgets per modality suboptimal. How to perform token reduction on a joint audio-visual stream thus remains an unaddressed bottleneck. To fill this gap, we introduce EchoingPixels, a framework inspired by the coexistence and interaction of visuals and sound in real-world scenes. The core of our framework is the Cross-Modal Semantic Sieve (CS2), a module enabling early audio-visual interaction. Instead of compressing modalities independently, CS2 co-attends to the joint multimodal stream and reduces tokens from an entire combined pool of audio-visual tokens rather than using fixed budgets per modality. This single-pool approach allows it to adaptively allocate the token budget across both modalities and dynamically identify salient tokens in concert. To ensure this aggressive reduction preserves the vital temporal modeling capability, we co-design a Synchronization-Augmented RoPE (Sync-RoPE) to maintain critical temporal relationships for the sparsely selected tokens. Extensive experiments demonstrate that EchoingPixels achieves performance comparable to strong baselines using only 5-20% of the original tokens, with a 2-3x speedup and memory reduction.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-86] Point2Pose: A Generative Framework for 3D Human Pose Estimation with Multi-View Point Cloud Dataset <mark class="hl-label red">WACV2026</mark></p>
<p>【速读】：该论文旨在解决3D人体姿态估计（3D human pose estimation）中的关键挑战，包括人体复杂的几何结构、关节自遮挡以及对大规模真实世界运动数据集的依赖。其解决方案的核心是提出Point2Pose框架，该框架通过联合建模点云序列和历史姿态信息来有效捕捉人体姿态分布；具体而言，采用时空点云编码器与姿态特征编码器提取关节级特征，并引入基于注意力机制的生成式回归器，从而实现更精确的姿态预测。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10321">https://arxiv.org/abs/2512.10321</a><br>
<strong>作者</strong>: Hyunsoo Lee,Daeum Jeon,Hyeokjae Oh<br>
<strong>机构</strong>: Seoul National University (首尔国立大学); KAIST (韩国科学技术院); Soulart Inc.<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  WACV 2026 camera ready</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We propose a novel generative approach for 3D human pose estimation. 3D human pose estimation poses several key challenges due to the complex geometry of the human body, self-occluding joints, and the requirement for large-scale real-world motion datasets. To address these challenges, we introduce Point2Pose, a framework that effectively models the distribution of human poses conditioned on sequential point cloud and pose history. Specifically, we employ a spatio-temporal point cloud encoder and a pose feature encoder to extract joint-wise features, followed by an attention-based generative regressor. Additionally, we present a large-scale indoor dataset MVPose3D, which contains multiple modalities, including IMU data of non-trivial human motions, dense multi-view point clouds, and RGB images. Experimental results show that the proposed method outperforms the baseline models, demonstrating its superior performance across various datasets.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-87] Design of a six wheel suspension and a three-axis linear actuation mechanism for a laser weeding robot</p>
<p>【速读】：该论文旨在解决农业中传统除草方式存在的效率低和生态破坏问题，尤其是机械除草在大面积农田中效率低下，而化学除草剂会对土壤生态系统造成负面影响。其解决方案的关键在于开发一种基于低能量激光的自主除草机器人，通过高精度定位与控制实现对杂草的精准清除：该机器人采用六轮结构及创新的双四连杆悬架系统以提升田间稳定性，配合三维线性驱动机构引导激光束精确作用于目标杂草，实现在42.5 cm/s最优速度下86.2%的杂草检测率和97%的命中率，同时保持平均位置误差仅为1.54 mm，从而显著提高除草作业的自动化水平、环境友好性和作业效率，推动精准农业（precision farming）的发展。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10319">https://arxiv.org/abs/2512.10319</a><br>
<strong>作者</strong>: Muhammad Usama,Muhammad Ibrahim Khan,Ahmad Hasan,Muhammad Shaaf Nadeem,Khawaja Fahad Iqbal,Jawad Aslam,Mian Ashfaq Ali,Asad Nisar Awan<br>
<strong>机构</strong>: National University of Sciences and Technology (NUST) (巴基斯坦国立科技大学)<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Systems and Control (<a target="_blank" rel="noopener" href="http://eess.SY">eess.SY</a>)<br>
<strong>备注</strong>:  15 Pages, 10 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Mobile robots are increasingly utilized in agriculture to automate labor-intensive tasks such as weeding, sowing, harvesting and soil analysis. Recently, agricultural robots have been developed to detect and remove weeds using mechanical tools or precise herbicide sprays. Mechanical weeding is inefficient over large fields, and herbicides harm the soil ecosystem. Laser weeding with mobile robots has emerged as a sustainable alternative in precision farming. In this paper, we present an autonomous weeding robot that uses controlled exposure to a low energy laser beam for weed removal. The proposed robot is six-wheeled with a novel double four-bar suspension for higher stability. The laser is guided towards the detected weeds by a three-dimensional linear actuation mechanism. Field tests have demonstrated the robot’s capability to navigate agricultural terrains effectively by overcoming obstacles up to 15 cm in height. At an optimal speed of 42.5 cm/s, the robot achieves a weed detection rate of 86.2% and operating time of 87 seconds per meter. The laser actuation mechanism maintains a minimal mean positional error of 1.54 mm, combined with a high hit rate of 97%, ensuring effective and accurate weed removal. This combination of speed, accuracy, and efficiency highlights the robot’s potential for significantly enhancing precision farming practices.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-88] ConStruct: Structural Distillation of Foundation Models for Prototype-Based Weakly Supervised Histopathology Segmentation</p>
<p>【速读】：该论文旨在解决弱监督语义分割（Weakly Supervised Semantic Segmentation, WSSS）在组织病理学图像中面临的两大挑战：一是分类主干网络通常仅定位最具判别性的区域，难以捕获组织结构的完整空间范围；二是现有方法在缺乏像素级标注的情况下难以生成高质量的伪掩码（pseudo-masks），导致分割结果不完整且语义一致性差。解决方案的关键在于提出一种原型学习框架，融合来自CONCH模型的形态感知表示（morphology-aware representations）、SegFormer主干的多尺度结构线索（multi-scale structural cues）以及文本引导的语义对齐机制，从而生成兼具语义判别性和空间一致性的原型。具体而言，通过文本引导的原型初始化策略引入病理描述以生成更完整准确的伪掩码，并设计结构蒸馏机制将SegFormer的空间知识迁移至原型学习过程，有效保留细粒度形态模式和局部组织边界，最终在BCSS-WSSS数据集上显著优于现有方法，同时保持计算效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10316">https://arxiv.org/abs/2512.10316</a><br>
<strong>作者</strong>: Khang Le(equal contribution),Ha Thach(equal contribution),Anh M. Vu(equal contribution),Trang T. K. Vo,Han H. Huynh,David Yang,Minh H. N. Le,Thanh-Huy Nguyen,Akash Awasthi,Chandra Mohan,Zhu Han,Hien Van Nguyen<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Weakly supervised semantic segmentation (WSSS) in histopathology relies heavily on classification backbones, yet these models often localize only the most discriminative regions and struggle to capture the full spatial extent of tissue structures. Vision-language models such as CONCH offer rich semantic alignment and morphology-aware representations, while modern segmentation backbones like SegFormer preserve fine-grained spatial cues. However, combining these complementary strengths remains challenging, especially under weak supervision and without dense annotations. We propose a prototype learning framework for WSSS in histopathological images that integrates morphology-aware representations from CONCH, multi-scale structural cues from SegFormer, and text-guided semantic alignment to produce prototypes that are simultaneously semantically discriminative and spatially coherent. To effectively leverage these heterogeneous sources, we introduce text-guided prototype initialization that incorporates pathology descriptions to generate more complete and semantically accurate pseudo-masks. A structural distillation mechanism transfers spatial knowledge from SegFormer to preserve fine-grained morphological patterns and local tissue boundaries during prototype learning. Our approach produces high-quality pseudo masks without pixel-level annotations, improves localization completeness, and enhances semantic consistency across tissue types. Experiments on BCSS-WSSS datasets demonstrate that our prototype learning framework outperforms existing WSSS methods while remaining computationally efficient through frozen foundation model backbones and lightweight trainable adapters.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-89] DualProtoSeg: Simple and Efficient Design with Text- and Image-Guided Prototype Learning for Weakly Supervised Histopathology Image Segmentation</p>
<p>【速读】：该论文旨在解决组织病理学图像中弱监督语义分割（Weakly Supervised Semantic Segmentation, WSSS）面临的三大挑战：类间同质性（inter-class homogeneity）、类内异质性（intra-class heterogeneity）以及基于类别激活图（Class Activation Map, CAM）监督导致的区域收缩效应（region-shrinkage effect）。为应对这些问题，其解决方案的关键在于提出一种基于原型驱动（prototype-driven）的框架，通过视觉-语言对齐（vision-language alignment）增强弱监督下的区域发现能力。具体而言，该方法结合CoOp风格的可学习提示调优（prompt tuning）生成文本原型，并与可学习图像原型共同构建双模态原型库（dual-modal prototype bank），从而融合语义信息与外观特征；同时引入多尺度金字塔模块缓解ViT表示中的过平滑问题，提升空间定位精度。实验表明，该方法在BCSS-WSSS基准上优于现有最先进方法，验证了文本描述多样性、上下文长度及文本与图像原型互补性的有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10314">https://arxiv.org/abs/2512.10314</a><br>
<strong>作者</strong>: Anh M. Vu(equal contribution),Khang P. Le(equal contribution),Trang T. K. Vo(equal contribution),Ha Thach,Huy Hung Nguyen,David Yang,Han H. Huynh,Quynh Nguyen,Tuan M. Pham,Tuan-Anh Le,Minh H. N. Le,Thanh-Huy Nguyen,Akash Awasthi,Chandra Mohan,Zhu Han,Hien Van Nguyen<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Weakly supervised semantic segmentation (WSSS) in histopathology seeks to reduce annotation cost by learning from image-level labels, yet it remains limited by inter-class homogeneity, intra-class heterogeneity, and the region-shrinkage effect of CAM-based supervision. We propose a simple and effective prototype-driven framework that leverages vision-language alignment to improve region discovery under weak supervision. Our method integrates CoOp-style learnable prompt tuning to generate text-based prototypes and combines them with learnable image prototypes, forming a dual-modal prototype bank that captures both semantic and appearance cues. To address oversmoothing in ViT representations, we incorporate a multi-scale pyramid module that enhances spatial precision and improves localization quality. Experiments on the BCSS-WSSS benchmark show that our approach surpasses existing state-of-the-art methods, and detailed analyses demonstrate the benefits of text description diversity, context length, and the complementary behavior of text and image prototypes. These results highlight the effectiveness of jointly leveraging textual semantics and visual prototype learning for WSSS in digital pathology.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-90] Efficient-VLN: A Training-Efficient Vision-Language Navigation Model</p>
<p>【速读】：该论文针对多模态大语言模型（Multimodal Large Language Models, MLLMs）在视觉-语言导航（Vision-Language Navigation, VLN）任务中训练开销过大的问题展开研究，识别出两个核心瓶颈：一是处理长时历史观测时因序列token数量呈二次增长带来的计算负担；二是DAgger数据聚合过程中探索效率之间的权衡问题，即增加探索虽能提升错误恢复能力以应对测试分布偏移，但会显著延长训练与推理轨迹长度。解决方案的关键在于提出Efficient-VLN框架：首先设计两种高效记忆机制——渐进式记忆（progressive memory）动态分配更多token给近期观测，以及可学习递归记忆（learnable recursive memory）利用可学习token的键值缓存作为记忆状态，从而缓解token处理压力；其次引入动态混合策略（dynamic mixed policy）以平衡探索与效率，最终在R2R-CE和RxR-CE基准上分别达到64.2%和67.0%的成功率，同时仅需282 H800 GPU小时训练时间，大幅降低训练成本。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10310">https://arxiv.org/abs/2512.10310</a><br>
<strong>作者</strong>: Duo Zheng,Shijia Huang,Yanyang Li,Liwei Wang<br>
<strong>机构</strong>: The Chinese University of Hong Kong (香港中文大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multimodal large language models (MLLMs) have shown promising potential in Vision-Language Navigation (VLN). However, their practical development is severely hindered by the substantial training overhead. We recognize two key issues that contribute to the overhead: (1) the quadratic computational burden from processing long-horizon historical observations as massive sequences of tokens, and (2) the exploration-efficiency trade-off in DAgger, i.e., a data aggregation process of collecting agent-explored trajectories. While more exploration yields effective error-recovery trajectories for handling test-time distribution shifts, it comes at the cost of longer trajectory lengths for both training and inference. To address these challenges, we propose Efficient-VLN, a training-efficient VLN model. Specifically, to mitigate the token processing burden, we design two efficient memory mechanisms: a progressive memory that dynamically allocates more tokens to recent observations, and a learnable recursive memory that utilizes the key-value cache of learnable tokens as the memory state. Moreover, we introduce a dynamic mixed policy to balance the exploration-efficiency trade-off. Extensive experiments show that Efficient-VLN achieves state-of-the-art performance on R2R-CE (64.2% SR) and RxR-CE (67.0% SR). Critically, our model consumes merely 282 H800 GPU hours, demonstrating a dramatic reduction in training overhead compared to state-of-the-art methods.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-91] Physically Aware 360circ View Generation from a Single Image using Disentangled Scene Embeddings</p>
<p>【速读】：该论文旨在解决现有3D重建与视图合成技术中对各向同性（isotropic）与各向异性（anisotropic）光行为建模不足、跨场景泛化能力弱以及缺乏方向感知能力的问题。其核心解决方案在于提出Disentangled360框架，通过在高斯点绘（Gaussian Splatting）主干网络中显式解耦各向同性与各向异性光照贡献，并引入双分支条件机制：一分支针对CT强度驱动的散射特性优化医学图像体积数据处理，另一分支利用归一化相机嵌入（normalized camera embeddings）适配真实RGB场景；同时设计了一种混合姿态无关锚定方法（hybrid pose agnostic anchoring），以自适应采样场景深度和材质过渡作为稳定参考点，从而缓解尺度模糊并保持结构真实性。此方案实现了无需场景特定微调即可快速生成具有方向感知的逼真360°视图，在医疗影像模拟与自然场景重建中均展现出优越性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10293">https://arxiv.org/abs/2512.10293</a><br>
<strong>作者</strong>: Karthikeya KV,Narendra Bandaru<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We introduce Disentangled360, an innovative 3D-aware technology that integrates the advantages of direction disentangled volume rendering with single-image 360° unique view synthesis for applications in medical imaging and natural scene reconstruction. In contrast to current techniques that either oversimplify anisotropic light behavior or lack generalizability across various contexts, our framework distinctly differentiates between isotropic and anisotropic contributions inside a Gaussian Splatting backbone. We implement a dual-branch conditioning framework, one optimized for CT intensity driven scattering in volumetric data and the other for real-world RGB scenes through normalized camera embeddings. To address scale ambiguity and maintain structural realism, we present a hybrid pose agnostic anchoring method that adaptively samples scene depth and material transitions, functioning as stable pivots during scene distillation. Our design integrates preoperative radiography simulation and consumer-grade 360° rendering into a singular inference pipeline, facilitating rapid, photorealistic view synthesis with inherent directionality. Evaluations on the Mip-NeRF 360, RealEstate10K, and DeepDRR datasets indicate superior SSIM and LPIPS performance, while runtime assessments confirm its viability for interactive applications. Disentangled360 facilitates mixed-reality medical supervision, robotic perception, and immersive content creation, eliminating the necessity for scene-specific finetuning or expensive photon simulations.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-92] ShotDirector: Directorially Controllable Multi-Shot Video Generation with Cinematographic Transitions</p>
<p>【速读】：该论文旨在解决多镜头视频生成中shot transitions（镜头切换）缺乏叙事一致性与导演式设计的问题，现有方法多关注低层次视觉连续性，忽视了电影剪辑语言对整体叙事表达的影响，导致镜头切换仅表现为机械的序列变化而非有意识的影视编辑模式。解决方案的关键在于提出ShotDirector框架，其核心创新包括：1）引入参数级相机控制模块，整合6-DoF位姿和内参设置，实现精确的相机信息注入；2）设计shot-aware mask机制，结合分层编辑模式感知提示（editing-pattern-aware prompting），使模型能够根据专业剪辑规律进行细粒度内容控制。通过将参数级条件与高层语义引导相结合，该框架实现了类电影风格的可控镜头切换。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10286">https://arxiv.org/abs/2512.10286</a><br>
<strong>作者</strong>: Xiaoxue Wu,Xinyuan Chen,Yaohui Wang,Yu Qiao<br>
<strong>机构</strong>: Fudan University (复旦大学); Shanghai Artificial Intelligence Laboratory<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Project Page: <a target="_blank" rel="noopener" href="https://uknowsth.github.io/ShotDirector/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Shot transitions play a pivotal role in multi-shot video generation, as they determine the overall narrative expression and the directorial design of visual storytelling. However, recent progress has primarily focused on low-level visual consistency across shots, neglecting how transitions are designed and how cinematographic language contributes to coherent narrative expression. This often leads to mere sequential shot changes without intentional film-editing patterns. To address this limitation, we propose ShotDirector, an efficient framework that integrates parameter-level camera control and hierarchical editing-pattern-aware prompting. Specifically, we adopt a camera control module that incorporates 6-DoF poses and intrinsic settings to enable precise camera information injection. In addition, a shot-aware mask mechanism is employed to introduce hierarchical prompts aware of professional editing patterns, allowing fine-grained control over shot content. Through this design, our framework effectively combines parameter-level conditions with high-level semantic guidance, achieving film-like controllable shot transitions. To facilitate training and evaluation, we construct ShotWeaver40K, a dataset that captures the priors of film-like editing patterns, and develop a set of evaluation metrics for controllable multi-shot video generation. Extensive experiments demonstrate the effectiveness of our framework.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-93] Sample-wise Adaptive Weighting for Transfer Consistency in Adversarial Distillation</p>
<p>【速读】：该论文旨在解决标准最小-最大对抗训练框架中，将鲁棒性从大型强健的教师网络（robust teacher network）迁移至紧凑学生网络（compact student network）时存在的效率瓶颈问题。研究表明，更强的教师模型并不必然带来更鲁棒的学生模型，这种现象称为鲁棒饱和（robust saturation），而传统归因于容量差距的解释并不充分。论文的核心发现是：对抗迁移性（adversarial transferability，即学生生成的对抗样本在教师模型上仍有效的比例）是决定鲁棒性迁移成功与否的关键因素。基于此洞察，作者提出样本级自适应对抗蒸馏（Sample-wise Adaptive Adversarial Distillation, SAAD），通过无额外计算开销的方式对训练样本按其迁移性进行重加权，从而显著提升学生模型在AutoAttack下的鲁棒性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10275">https://arxiv.org/abs/2512.10275</a><br>
<strong>作者</strong>: Hongsin Lee,Hye Won Chung<br>
<strong>机构</strong>: KAIST(韩国科学技术院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Adversarial distillation in the standard min-max adversarial training framework aims to transfer adversarial robustness from a large, robust teacher network to a compact student. However, existing work often neglects to incorporate state-of-the-art robust teachers. Through extensive analysis, we find that stronger teachers do not necessarily yield more robust students-a phenomenon known as robust saturation. While typically attributed to capacity gaps, we show that such explanations are incomplete. Instead, we identify adversarial transferability-the fraction of student-crafted adversarial examples that remain effective against the teacher-as a key factor in successful robustness transfer. Based on this insight, we propose Sample-wise Adaptive Adversarial Distillation (SAAD), which reweights training examples by their measured transferability without incurring additional computational cost. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet show that SAAD consistently improves AutoAttack robustness over prior methods. Our code is available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-94] Long-LRM: Preserving Fine Details in Feed-Forward Wide-Cove<mark class="hl-label green">rag</mark> e Reconstruction</p>
<p>【速读】：该论文旨在解决当前基于高斯溅射（Gaussian Splatting, GS）方法在大规模输入场景下易受误差敏感导致图像模糊，以及隐式表示方法（如LaCT）虽渲染质量高但计算复杂度大难以实现实时渲染的问题。其核心挑战在于如何在保持隐式表示高保真度的同时实现高效推理。解决方案的关键在于提出Long-LRM++模型，采用半显式场景表示与轻量级解码器相结合的架构：通过将场景信息压缩到模型权重中以保留隐式表示的优势，同时设计轻量化解码结构避免逐帧深度解压缩过程，从而在保证渲染质量（达到LaCT在DL3DV上的水平）的前提下实现14 FPS的实时渲染性能（A100 GPU），且支持扩展至64张输入图像，显著提升了泛化能力和新视角深度预测精度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10267">https://arxiv.org/abs/2512.10267</a><br>
<strong>作者</strong>: Chen Ziwen,Hao Tan,Peng Wang,Zexiang Xu,Li Fuxin<br>
<strong>机构</strong>: Adobe Research; Tripo AI; Hillbot; Oregon State University<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advances in generalizable Gaussian splatting (GS) have enabled feed-forward reconstruction of scenes from tens of input views. Long-LRM notably scales this paradigm to 32 input images at  950\times540  resolution, achieving 360° scene-level reconstruction in a single forward pass. However, directly predicting millions of Gaussian parameters at once remains highly error-sensitive: small inaccuracies in positions or other attributes lead to noticeable blurring, particularly in fine structures such as text. In parallel, implicit representation methods such as LVSM and LaCT have demonstrated significantly higher rendering fidelity by compressing scene information into model weights rather than explicit Gaussians, and decoding RGB frames using the full transformer or TTT backbone. However, this computationally intensive decompression process for every rendered frame makes real-time rendering infeasible. These observations raise key questions: Is the deep, sequential “decompression” process necessary? Can we retain the benefits of implicit representations while enabling real-time performance? We address these questions with Long-LRM++, a model that adopts a semi-explicit scene representation combined with a lightweight decoder. Long-LRM++ matches the rendering quality of LaCT on DL3DV while achieving real-time 14 FPS rendering on an A100 GPU, overcoming the speed limitations of prior implicit methods. Our design also scales to 64 input views at the  950\times540  resolution, demonstrating strong generalization to increased input lengths. Additionally, Long-LRM++ delivers superior novel-view depth prediction on ScanNetv2 compared to direct depth rendering from Gaussians. Extensive ablation studies validate the effectiveness of each component in the proposed framework.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-95] VLM-NCD:Novel Class Discovery with Vision-Based <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark></p>
<p>【速读】：该论文旨在解决图像领域中新型类发现（Novel Class Discovery, NCD）任务面临的两大挑战：一是现有方法主要依赖视觉特征，导致特征判别能力不足；二是数据长尾分布问题严重影响模型性能。其解决方案的核心在于提出一种多模态框架 LLM-NCD，通过融合视觉-文本语义信息并引入原型引导聚类机制，关键创新点包括：1）联合优化已知类图像与文本特征，构建更具语义一致性的类别中心和原型；2）设计双阶段发现机制，利用语义亲和度阈值动态区分已知或未知样本，并结合自适应聚类实现更精准的新型类识别。实验表明，该方法在CIFAR-100数据集上对未知类别的准确率提升达25.3%，且首次展现出对长尾分布的独特鲁棒性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10262">https://arxiv.org/abs/2512.10262</a><br>
<strong>作者</strong>: Yuetong Su,Baoguo Wei,Xinyu Wang,Xu Li,Lixin Li<br>
<strong>机构</strong>: Northwestern Polytechnical University (西北工业大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  8 pages, 5 figures, conference</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Novel Class Discovery aims to utilise prior knowledge of known classes to classify and discover unknown classes from unlabelled data. Existing NCD methods for images primarily rely on visual features, which suffer from limitations such as insufficient feature discriminability and the long-tail distribution of data. We propose LLM-NCD, a multimodal framework that breaks this bottleneck by fusing visual-textual semantics and prototype guided clustering. Our key innovation lies in modelling cluster centres and semantic prototypes of known classes by jointly optimising known class image and text features, and a dualphase discovery mechanism that dynamically separates known or novel samples via semantic affinity thresholds and adaptive clustering. Experiments on the CIFAR-100 dataset show that compared to the current methods, this method achieves up to 25.3% improvement in accuracy for unknown classes. Notably, our method shows unique resilience to long tail distributions, a first in NCD literature.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-96] GDKVM: Echocardiography Video Segmentation via Spatiotemporal Key-Value Memory with Gated Delta Rule <mark class="hl-label red">ICCV2025</mark></p>
<p>【速读】：该论文旨在解决超声心动图视频中心脏腔室精准分割的问题，尤其针对成像噪声、伪影以及心脏形变与运动带来的挑战。现有基于卷积神经网络（Convolutional Neural Networks, CNNs）、Transformer 和时空记忆网络的方法虽提升了分割精度，但在捕捉长程时空依赖关系与保持细粒度特征表示的计算效率之间存在权衡。其解决方案的关键在于提出一种名为 GDKVM 的新架构：通过线性键值关联（Linear Key-Value Association, LKVA）高效建模帧间相关性，引入门控增量规则（Gated Delta Rule, GDR）以低开销存储中间记忆状态，并设计关键像素特征融合（Key-Pixel Feature Fusion, KPFF）模块实现多尺度局部与全局特征整合，从而显著增强对边界模糊和噪声干扰的鲁棒性，同时保障实时性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10252">https://arxiv.org/abs/2512.10252</a><br>
<strong>作者</strong>: Rui Wang,Yimu Sun,Jingxing Guo,Huisi Wu,Jing Qin<br>
<strong>机构</strong>: Shenzhen University (深圳大学); The Hong Kong Polytechnic University (香港理工大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Accepted to ICCV 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Accurate segmentation of cardiac chambers in echocardiography sequences is crucial for the quantitative analysis of cardiac function, aiding in clinical diagnosis and treatment. The imaging noise, artifacts, and the deformation and motion of the heart pose challenges to segmentation algorithms. While existing methods based on convolutional neural networks, Transformers, and space-time memory networks have improved segmentation accuracy, they often struggle with the trade-off between capturing long-range spatiotemporal dependencies and maintaining computational efficiency with fine-grained feature representation. In this paper, we introduce GDKVM, a novel architecture for echocardiography video segmentation. The model employs Linear Key-Value Association (LKVA) to effectively model inter-frame correlations, and introduces Gated Delta Rule (GDR) to efficiently store intermediate memory states. Key-Pixel Feature Fusion (KPFF) module is designed to integrate local and global features at multiple scales, enhancing robustness against boundary blurring and noise interference. We validated GDKVM on two mainstream echocardiography video datasets (CAMUS and EchoNet-Dynamic) and compared it with various state-of-the-art methods. Experimental results show that GDKVM outperforms existing approaches in terms of segmentation accuracy and robustness, while ensuring real-time performance. Code is available at this https URL.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-97] HE-Pose: Topological Prior with Hybrid Graph Fusion for Estimating Category-Level 6D Object Pose</p>
<p>【速读】：该论文旨在解决类别级6D姿态估计（category-level 6D pose estimation）中因类内差异（intra-class variations）导致的鲁棒性不足问题，尤其是现有基于3D图卷积（3D graph convolution, 3D-GC）的方法仅依赖局部几何与深度信息，难以应对复杂物体和视觉模糊场景。解决方案的关键在于提出THE-Pose框架，其核心创新是引入拓扑先验（topological prior）并通过表面嵌入（surface embedding）提取图像域中一致且不变的拓扑特征，结合混合图融合模块（Hybrid Graph Fusion, HGF），自适应地将这些拓扑特征与点云特征融合，从而无缝衔接2D图像上下文与3D几何结构，显著提升对未见或复杂对象在严重遮挡下的姿态估计稳定性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10251">https://arxiv.org/abs/2512.10251</a><br>
<strong>作者</strong>: Eunho Lee,Chaehyeon Song,Seunghoon Jeong,Ayoung Kim<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Category-level object pose estimation requires both global context and local structure to ensure robustness against intra-class variations. However, 3D graph convolution (3D-GC) methods only focus on local geometry and depth information, making them vulnerable to complex objects and visual ambiguities. To address this, we present THE-Pose, a novel category-level 6D pose estimation framework that leverages a topological prior via surface embedding and hybrid graph fusion. Specifically, we extract consistent and invariant topological features from the image domain, effectively overcoming the limitations inherent in existing 3D-GC based methods. Our Hybrid Graph Fusion (HGF) module adaptively integrates the topological features with point-cloud features, seamlessly bridging 2D image context and 3D geometric structure. These fused features ensure stability for unseen or complicated objects, even under significant occlusions. Extensive experiments on the REAL275 dataset show that THE-Pose achieves a 35.8% improvement over the 3D-GC baseline (HS-Pose) and surpasses the previous state-of-the-art by 7.2% across all key metrics. The code is avaialbe on this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-98] RobustSora: De-Watermarked Benchmark for Robust AI-Generated Video Detection</p>
<p>【速读】：该论文旨在解决生成式 AI 视频（AIGC video）检测模型在面对数字水印（digital watermark）干扰时的鲁棒性不足问题，即现有检测方法可能过度依赖水印特征而非内容真实性，导致在水印被移除或伪造时性能显著下降。解决方案的关键在于构建了 RobustSora 基准测试集，包含四类视频样本（真实干净视频、带伪造水印的真实视频、带水印的生成视频、去水印的生成视频），并通过两个任务（Task-I：检测去水印AI视频；Task-II：评估对带假水印真实视频的误报率）系统量化不同检测模型对水印的依赖程度。实验表明，Transformer 类模型表现出稳定的中度依赖（2–8pp 性能波动），而多模态大语言模型（MLLM）则呈现多样化响应，揭示了水印依赖是当前检测技术的重要漏洞，亟需引入水印感知训练策略以提升检测鲁棒性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10248">https://arxiv.org/abs/2512.10248</a><br>
<strong>作者</strong>: Zhuo Wang,Xiliang Liu,Ligang Sun<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The proliferation of AI-generated video technologies poses challenges to information integrity. While recent benchmarks advance AIGC video detection, they overlook a critical factor: many state-of-the-art generative models embed digital watermarks in outputs, and detectors may partially rely on these patterns. To evaluate this influence, we present RobustSora, the benchmark designed to assess watermark robustness in AIGC video detection. We systematically construct a dataset of 6,500 videos comprising four types: Authentic-Clean (A-C), Authentic-Spoofed with fake watermarks (A-S), Generated-Watermarked (G-W), and Generated-DeWatermarked (G-DeW). Our benchmark introduces two evaluation tasks: Task-I tests performance on watermark-removed AI videos, while Task-II assesses false alarm rates on authentic videos with fake watermarks. Experiments with ten models spanning specialized AIGC detectors, transformer architectures, and MLLM approaches reveal performance variations of 2-8pp under watermark manipulation. Transformer-based models show consistent moderate dependency (6-8pp), while MLLMs exhibit diverse patterns (2-8pp). These findings indicate partial watermark dependency and highlight the need for watermark-aware training strategies. RobustSora provides essential tools to advance robust AIGC detection research.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-99] Solving Semi-Supervised Few-Shot Learning from an Auto-Annotation Perspective</p>
<p>【速读】：该论文旨在解决半监督少样本学习（Semi-supervised Few-shot Learning, SSFSL）中如何有效利用大规模未标注数据与开源视觉语言模型（Vision-Language Models, VLMs）的问题，以实现真实场景下的自动标注（auto-annotation）。现有方法忽视了预训练VLM及其丰富预训练数据的价值，而本文发现直接应用经典自监督学习（SSL）方法微调VLM时性能显著低于少样本学习（FSL）基线，其根本原因在于VLM输出的softmax概率分布过于“平坦”，导致伪标签置信度低、未标注数据利用率不足且监督信号微弱。解决方案的关键在于两个简单但有效的技术：分类器初始化（classifier initialization）和温度缩放（temperature tuning），二者协同提升伪标签置信度，从而提高未标注数据的利用效率并强化监督信号。基于此，作者提出分阶段微调框架SWIFT（Stage-Wise Finetuning with Temperature Tuning），使现有SSL方法能在少量标注数据、大量未标注数据以及从VLM预训练集中检索到的任务相关噪声数据上高效微调VLM，实验表明SWIFT在五个SSFSL基准上较最新FSL和SSL方法提升约5个百分点，甚至可媲美使用真实标签进行微调的监督学习。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10244">https://arxiv.org/abs/2512.10244</a><br>
<strong>作者</strong>: Tian Liu,Anwesha Basu,James Caverlee,Shu Kong<br>
<strong>机构</strong>: Texas A&amp;M University (德州农工大学); University of Macau (澳门大学); Institute of Collaborative Innovation (协同创新研究院)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  website and code: <a target="_blank" rel="noopener" href="https://tian1327.github.io/SWIFT">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Semi-supervised few-shot learning (SSFSL) formulates real-world applications like ‘‘auto-annotation’’, as it aims to learn a model over a few labeled and abundant unlabeled examples to annotate the unlabeled ones. Despite the availability of powerful open-source Vision-Language Models (VLMs) and their pretraining data, the SSFSL literature largely neglects these open-source resources. In contrast, the related area few-shot learning (FSL) has already exploited them to boost performance. Arguably, to achieve auto-annotation in the real world, SSFSL should leverage such open-source resources. To this end, we start by applying established SSL methods to finetune a VLM. Counterintuitively, they significantly underperform FSL baselines. Our in-depth analysis reveals the root cause: VLMs produce rather ‘‘flat’’ distributions of softmax probabilities. This results in zero utilization of unlabeled data and weak supervision signals. We address this issue with embarrassingly simple techniques: classifier initialization and temperature tuning. They jointly increase the confidence scores of pseudo-labels, improving the utilization rate of unlabeled data, and strengthening supervision signals. Building on this, we propose: Stage-Wise Finetuning with Temperature Tuning (SWIFT), which enables existing SSL methods to effectively finetune a VLM on limited labeled data, abundant unlabeled data, and task-relevant but noisy data retrieved from the VLM’s pretraining set. Extensive experiments on five SSFSL benchmarks show that SWIFT outperforms recent FSL and SSL methods by  \sim 5 accuracy points. SWIFT even rivals supervised learning, which finetunes VLMs with the unlabeled data being labeled with ground truth!<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-100] Multi-dimensional Preference Alignment by Conditioning Reward Itself</p>
<p>【速读】：该论文旨在解决基于人类反馈的强化学习（Reinforcement Learning from Human Feedback, RLHF）在对齐扩散模型时存在的奖励冲突问题。标准的直接偏好优化（Direct Preference Optimization, DPO）方法依赖Bradley-Terry模型将美学质量、语义一致性等多维评价指标聚合为单一标量奖励，导致模型在优化过程中被迫舍弃某些维度中 desirable 的特征，从而引发性能下降。解决方案的关键在于提出多奖励条件DPO（Multi Reward Conditional DPO, MCDPO），其核心创新是引入解耦的Bradley-Terry目标函数，并在训练中显式注入偏好结果向量作为条件，使模型能够在单个网络中独立学习每个奖励维度的正确优化方向；同时通过维度奖励丢弃（dimensional reward dropout）机制保障各维度间的平衡优化，最终实现更稳定且可控的生成效果。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10237">https://arxiv.org/abs/2512.10237</a><br>
<strong>作者</strong>: Jiho Jang,Jinyoung Kim,Kyungjune Baek,Nojun Kwak<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Reinforcement Learning from Human Feedback has emerged as a standard for aligning diffusion models. However, we identify a fundamental limitation in the standard DPO formulation because it relies on the Bradley-Terry model to aggregate diverse evaluation axes like aesthetic quality and semantic alignment into a single scalar reward. This aggregation creates a reward conflict where the model is forced to unlearn desirable features of a specific dimension if they appear in a globally non-preferred sample. To address this issue, we propose Multi Reward Conditional DPO (MCDPO). This method resolves reward conflicts by introducing a disentangled Bradley-Terry objective. MCDPO explicitly injects a preference outcome vector as a condition during training, which allows the model to learn the correct optimization direction for each reward axis independently within a single network. We further introduce dimensional reward dropout to ensure balanced optimization across dimensions. Extensive experiments on Stable Diffusion 1.5 and SDXL demonstrate that MCDPO achieves superior performance on benchmarks. Notably, our conditional framework enables dynamic and multiple-axis control at inference time using Classifier Free Guidance to amplify specific reward dimensions without additional training or external reward models.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-101] Emerging Standards for Machine-to-Machine Video Coding</p>
<p>【速读】：该论文旨在解决机器间通信（Machine-to-Machine, M2M）中传统视频编码方式依赖面向人类感知的编解码器所导致的带宽消耗高、可扩展性差及隐私泄露问题。其核心解决方案是引入两个新标准：视频编码用于机器（Video Coding for Machines, VCM）和特征编码用于机器（Feature Coding for Machines, FCM），其中FCM通过压缩神经网络中间特征来降低比特率、保护隐私并支持计算卸载。实验表明，FCM可在保持接近边缘推理精度的同时显著减少传输数据量；进一步分析显示，在使用H.26X系列编解码器作为内部编码工具时，HEVC与VVC在机器任务性能上几乎相当，而AVC则明显劣于VVC，说明现有硬件部署的编解码器已能有效支撑M2M通信且不影响任务性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10230">https://arxiv.org/abs/2512.10230</a><br>
<strong>作者</strong>: Md Eimran Hossain Eimon,Velibor Adzic,Hari Kalva,Borko Furht<br>
<strong>机构</strong>: Florida Atlantic University (佛罗里达大西洋大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Machines are increasingly becoming the primary consumers of visual data, yet most deployments of machine-to-machine systems still rely on remote inference where pixel-based video is streamed using codecs optimized for human perception. Consequently, this paradigm is bandwidth intensive, scales poorly, and exposes raw images to third parties. Recent efforts in the Moving Picture Experts Group (MPEG) redesigned the pipeline for machine-to-machine communication: Video Coding for Machines (VCM) is designed to apply task-aware coding tools in the pixel domain, and Feature Coding for Machines (FCM) is designed to compress intermediate neural features to reduce bitrate, preserve privacy, and support compute offload. Experiments show that FCM is capable of maintaining accuracy close to edge inference while significantly reducing bitrate. Additional analysis of H.26X codecs used as inner codecs in FCM reveals that H.265/High Efficiency Video Coding (HEVC) and H.266/Versatile Video Coding (VVC) achieve almost identical machine task performance, with an average BD-Rate increase of 1.39% when VVC is replaced with HEVC. In contrast, H.264/Advanced Video Coding (AVC) yields an average BD-Rate increase of 32.28% compared to VVC. However, for the tracking task, the impact of codec choice is minimal, with HEVC outperforming VVC and achieving BD Rate of -1.81% and 8.79% for AVC, indicating that existing hardware for already deployed codecs can support machine-to-machine communication without degrading performance.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-102] Latent Chain-of-Thought World Modeling for End-to-End Driving</p>
<p>【速读】：该论文旨在解决当前视觉-语言-动作（Vision-Language-Action, VLA）模型在自动驾驶中推理效率与决策质量不足的问题，尤其是传统基于自然语言的链式思维（Chain-of-Thought, CoT）推理方式在复杂场景下存在表达冗余、与动作空间不一致等局限性。其解决方案的关键在于提出Latent-CoT-Drive（LCDrive）模型，通过将CoT推理与决策统一于一个动作对齐的潜在空间中：模型使用两类token进行推理——动作提议token（与输出动作词汇表一致）和世界模型token（基于学习到的潜在世界模型，表示动作可能带来的未来状态），从而实现更高效、更贴近实际驾驶行为的推理机制；此外，该方法通过监督预训练冷启动潜在推理，并利用闭环强化学习进一步优化推理能力，最终在大规模端到端驾驶基准上实现了更快推理速度、更优轨迹质量和更强的交互式强化学习增益。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10226">https://arxiv.org/abs/2512.10226</a><br>
<strong>作者</strong>: Shuhan Tan,Kashyap Chitta,Yuxiao Chen,Ran Tian,Yurong You,Yan Wang,Wenjie Luo,Yulong Cao,Philipp Krahenbuhl,Marco Pavone,Boris Ivanovic<br>
<strong>机构</strong>: UT Austin; NVIDIA; Stanford University<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
<strong>备注</strong>:  Technical Report</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent Vision-Language-Action (VLA) models for autonomous driving explore inference-time reasoning as a way to improve driving performance and safety in challenging scenarios. Most prior work uses natural language to express chain-of-thought (CoT) reasoning before producing driving actions. However, text may not be the most efficient representation for reasoning. In this work, we present Latent-CoT-Drive (LCDrive): a model that expresses CoT in a latent language that captures possible outcomes of the driving actions being considered. Our approach unifies CoT reasoning and decision making by representing both in an action-aligned latent space. Instead of natural language, the model reasons by interleaving (1) action-proposal tokens, which use the same vocabulary as the model’s output actions; and (2) world model tokens, which are grounded in a learned latent world model and express future outcomes of these actions. We cold start latent CoT by supervising the model’s action proposals and world model tokens based on ground-truth future rollouts of the scene. We then post-train with closed-loop reinforcement learning to strengthen reasoning capabilities. On a large-scale end-to-end driving benchmark, LCDrive achieves faster inference, better trajectory quality, and larger improvements from interactive reinforcement learning compared to both non-reasoning and text-reasoning baselines.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-103] Federated Domain Generalization with Latent Space Inversion <mark class="hl-label red">ICDM2025</mark></p>
<p>【速读】：该论文旨在解决联邦域泛化（Federated Domain Generalization, FedDG）中模型泛化能力与数据隐私保护之间的矛盾问题。现有方法在提升全局模型对未见客户端的泛化性能时，往往因共享客户端数据统计信息而损害隐私。其解决方案的关键在于两个方面：一是提出一种新颖的<strong>潜在空间反演（latent space inversion）<strong>技术，在本地客户端训练中引入域不变性约束，从而增强客户端隐私；二是设计一种</strong>重要权重聚合策略（important weight aggregation strategy）</strong>，在模型聚合阶段优先保留对本地预测影响显著的参数，避免因非独立同分布（non-i.i.d.）客户端间的局部适应性差异而导致信息丢失，进而实现更高效且隐私友好的联邦域泛化。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10224">https://arxiv.org/abs/2512.10224</a><br>
<strong>作者</strong>: Ragja Palakkadavath,Hung Le,Thanh Nguyen-Tang,Svetha Venkatesh,Sunil Gupta<br>
<strong>机构</strong>: 3: School of Engineering and Information Technology, University of New South Wales, Canberra, Australia (新南威尔士大学堪培拉分校); 2: Department of Computer Science, University of Auckland, New Zealand (奥克兰大学计算机科学系)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Accepted at ICDM 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Federated domain generalization (FedDG) addresses distribution shifts among clients in a federated learning framework. FedDG methods aggregate the parameters of locally trained client models to form a global model that generalizes to unseen clients while preserving data privacy. While improving the generalization capability of the global model, many existing approaches in FedDG jeopardize privacy by sharing statistics of client data between themselves. Our solution addresses this problem by contributing new ways to perform local client training and model aggregation. To improve local client training, we enforce (domain) invariance across local models with the help of a novel technique, \textbflatent space inversion, which enables better client privacy. When clients are not \emphi.i.d, aggregating their local models may discard certain local adaptations. To overcome this, we propose an \textbfimportant weight aggregation strategy to prioritize parameters that significantly influence predictions of local models during aggregation. Our extensive experiments show that our approach achieves superior results over state-of-the-art methods with less communication overhead.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-104] Feature Coding for Scalable Machine Vision</p>
<p>【速读】：该论文旨在解决深度神经网络（Deep Neural Networks, DNNs）在边缘设备上部署时面临的高计算需求与带宽限制之间的矛盾问题。传统方案要么在本地运行完整模型（受限于算力），要么将全部计算任务卸载至云端（受限于延迟、带宽和隐私），而通过将推理任务拆分到边缘与云端协同执行虽具潜力，却因传输中间特征（intermediate features）带来新的带宽压力。解决方案的关键在于引入由MPEG制定的面向机器的特征编码（Feature Coding for Machines, FCM）标准，其核心是设计了一种专门用于压缩中间特征的比特流语法与编解码流程。文中提出的特征编码测试模型（FCTM）验证了该方法的有效性：在多个视觉任务中平均压缩率高达85.14%，同时保持模型精度不变，从而为带宽受限且对隐私敏感的消费级应用提供了可扩展、互操作的智能特征高效部署路径。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10209">https://arxiv.org/abs/2512.10209</a><br>
<strong>作者</strong>: Md Eimran Hossain Eimon,Juan Merlos,Ashan Perera,Hari Kalva,Velibor Adzic,Borko Furht<br>
<strong>机构</strong>: Florida Atlantic University (佛罗里达大西洋大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  This article has been accepted for publication in IEEE Consumer Electronics Magazine</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Deep neural networks (DNNs) drive modern machine vision but are challenging to deploy on edge devices due to high compute demands. Traditional approaches-running the full model on-device or offloading to the cloud face trade-offs in latency, bandwidth, and privacy. Splitting the inference workload between the edge and the cloud offers a balanced solution, but transmitting intermediate features to enable such splitting introduces new bandwidth challenges. To address this, the Moving Picture Experts Group (MPEG) initiated the Feature Coding for Machines (FCM) standard, establishing a bitstream syntax and codec pipeline tailored for compressing intermediate features. This paper presents the design and performance of the Feature Coding Test Model (FCTM), showing significant bitrate reductions-averaging 85.14%-across multiple vision tasks while preserving accuracy. FCM offers a scalable path for efficient and interoperable deployment of intelligent features in bandwidth-limited and privacy-sensitive consumer applications.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-105] opological Conditioning for Mammography Models via a Stable Wavelet-Persistence Vectorization</p>
<p>【速读】：该论文旨在解决乳腺癌筛查中数字乳腺断层摄影（mammography）图像解读存在的高假阴性率和假阳性率问题，以及模型在跨设备、跨模态和跨人群部署时性能下降的挑战。其解决方案的关键在于引入一种基于小波变换的持久同调（persistent homology）向量化表示作为条件信号，通过拓扑数据分析提取在不同灰度阈值下保持稳定的图像结构信息，并将其转化为空间上多尺度的稳定映射；这些映射以通道拼接方式整合进两阶段检测流程中，从而显著提升模型在外部独立数据集上的泛化能力，例如在葡萄牙INbreast数据集上，使用ConvNeXt Tiny模型时患者层面AUC从0.55提升至0.75。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10151">https://arxiv.org/abs/2512.10151</a><br>
<strong>作者</strong>: Charles Fanning,Mehmet Emin Aktas<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  8 Pages, 2 Figures, submitted to IEEE Transactions on Medical Imaging</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Breast cancer is the most commonly diagnosed cancer in women and a leading cause of cancer death worldwide. Screening mammography reduces mortality, yet interpretation still suffers from substantial false negatives and false positives, and model accuracy often degrades when deployed across scanners, modalities, and patient populations. We propose a simple conditioning signal aimed at improving external performance based on a wavelet based vectorization of persistent homology. Using topological data analysis, we summarize image structure that persists across intensity thresholds and convert this information into spatial, multi scale maps that are provably stable to small intensity perturbations. These maps are integrated into a two stage detection pipeline through input level channel concatenation. The model is trained and validated on the CBIS DDSM digitized film mammography cohort from the United States and evaluated on two independent full field digital mammography cohorts from Portugal (INbreast) and China (CMMD), with performance reported at the patient level. On INbreast, augmenting ConvNeXt Tiny with wavelet persistence channels increases patient level AUC from 0.55 to 0.75 under a limited training budget.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-106] Hierarchical Instance Tracking to Balance Privacy Preservation with Accessible Information <mark class="hl-label red">WACV2026</mark></p>
<p>【速读】：该论文旨在解决传统实例跟踪（instance tracking）方法难以同时精确追踪预定义类别中物体及其组成部分，并保持其层级关系的问题。为应对这一挑战，研究者提出了“层次实例跟踪”（hierarchical instance tracking）这一新任务，并构建了首个支持该任务的基准数据集，包含552段视频中2,765个唯一实体，涵盖40个类别（含物体与部件）。解决方案的关键在于设计了一个结构化的数据集，能够刻画复杂场景中多层次对象间的语义与空间关联，从而推动模型在多粒度、跨层级实例追踪上的性能提升。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10102">https://arxiv.org/abs/2512.10102</a><br>
<strong>作者</strong>: Neelima Prasad,Jarek Reynolds,Neel Karsanbhai,Tanusree Sharma,Lotus Zhang,Abigale Stangl,Yang Wang,Leah Findlater,Danna Gurari<br>
<strong>机构</strong>: University of Colorado Boulder (科罗拉多大学博尔德分校); Pennsylvania State University (宾夕法尼亚州立大学); University of Washington (华盛顿大学); Georgia Institute of Technology (佐治亚理工学院); University of Illinois at Urbana-Champaign (伊利诺伊大学厄巴纳-香槟分校)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:  Accepted at WACV 2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We propose a novel task, hierarchical instance tracking, which entails tracking all instances of predefined categories of objects and parts, while maintaining their hierarchical relationships. We introduce the first benchmark dataset supporting this task, consisting of 2,765 unique entities that are tracked in 552 videos and belong to 40 categories (across objects and parts). Evaluation of seven variants of four models tailored to our novel task reveals the new dataset is challenging. Our dataset is available at this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-107] raceFlow: Dynamic 3D Reconstruction of Specular Scenes Driven by Ray Tracing</p>
<p>【速读】：该论文旨在解决动态镜面场景中高保真渲染的问题，核心挑战在于精确的反射方向估计与物理上准确的反射建模。解决方案的关键在于提出了一种残差材质增强的二维高斯点绘（Residual Material-Augmented 2D Gaussian Splatting）表示方法，用于建模动态几何与材质属性，从而实现精确的反射光线计算；同时引入动态环境高斯（Dynamic Environment Gaussian）和混合渲染管线，将渲染过程分解为漫反射与镜面反射两部分，通过光栅化与光线追踪结合的方式实现物理基础的镜面合成。此外，采用粗到精的训练策略提升优化稳定性并促进物理合理的分解。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10095">https://arxiv.org/abs/2512.10095</a><br>
<strong>作者</strong>: Jiachen Tao,Junyi Wu,Haoxuan Wang,Zongxin Yang,Dawen Cai,Yan Yan<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present TraceFlow, a novel framework for high-fidelity rendering of dynamic specular scenes by addressing two key challenges: precise reflection direction estimation and physically accurate reflection modeling. To achieve this, we propose a Residual Material-Augmented 2D Gaussian Splatting representation that models dynamic geometry and material properties, allowing accurate reflection ray computation. Furthermore, we introduce a Dynamic Environment Gaussian and a hybrid rendering pipeline that decomposes rendering into diffuse and specular components, enabling physically grounded specular synthesis via rasterization and ray tracing. Finally, we devise a coarse-to-fine training strategy to improve optimization stability and promote physically meaningful decomposition. Extensive experiments on dynamic scene benchmarks demonstrate that TraceFlow outperforms prior methods both quantitatively and qualitatively, producing sharper and more realistic specular reflections in complex dynamic environments.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-108] Independent Density Estimation</p>
<p>【速读】：该论文旨在解决大规模视觉-语言模型在实现人类水平的组合泛化（compositional generalization）方面存在的挑战，即模型在面对未见过的物体或属性组合时表现不佳的问题。解决方案的关键在于提出一种新的独立密度估计方法（Independent Density Estimation, IDE），其核心思想是学习句子中单个词汇与图像中对应特征之间的关联关系，从而支持对新组合的推理。为此，作者构建了两种基于IDE理念的模型：一种使用完全解耦的视觉表征作为输入，另一种则通过变分自编码器（Variational Auto-Encoder）从原始图像中提取部分解耦特征；同时引入基于熵的组合推理方法，用于融合句子中每个词的预测结果，显著提升了模型在未见组合场景下的泛化能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10067">https://arxiv.org/abs/2512.10067</a><br>
<strong>作者</strong>: Jiahao Liu<br>
<strong>机构</strong>: Brown University (布朗大学)<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  10 pages, 1 table, 4 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large-scale Vision-Language models have achieved remarkable results in various domains, such as image captioning and conditioned image generation. Neverthe- less, these models still encounter difficulties in achieving human-like composi- tional generalization. In this study, we propose a new method called Independent Density Estimation (IDE) to tackle this challenge. IDE aims to learn the connec- tion between individual words in a sentence and the corresponding features in an image, enabling compositional generalization. We build two models based on the philosophy of IDE. The first one utilizes fully disentangled visual representations as input, and the second leverages a Variational Auto-Encoder to obtain partially disentangled features from raw images. Additionally, we propose an entropy- based compositional inference method to combine predictions of each word in the sentence. Our models exhibit superior generalization to unseen compositions compared to current models when evaluated on various datasets.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-109] MetaVoxel: Joint Diffusion Modeling of Imaging and Clinical Metadata</p>
<p>【速读】：该论文旨在解决当前医学人工智能模型中任务割裂的问题，即不同任务（如疾病分类、连续生物标志物估计、图像生成等）通常依赖于独立训练的条件模型，缺乏统一建模能力且难以实现灵活的零样本推理。解决方案的关键在于提出MetaVoxel——一种基于扩散机制的联合生成建模框架，通过学习影像数据与临床元数据（clinical metadata）之间的联合分布，仅用单一扩散过程即可同时支持多种下游任务。该方法突破了传统条件建模的局限性，实现了无需针对特定任务重新训练即可利用任意输入子集进行灵活推理的能力，从而为构建通用化、可扩展的医学AI系统提供了新路径。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10041">https://arxiv.org/abs/2512.10041</a><br>
<strong>作者</strong>: Yihao Liu,Chenyu Gao,Lianrui Zuo,Michael E. Kim,Brian D. Boyd,Lisa L. Barnes,Walter A. Kukull,Lori L. Beason-Held,Susan M. Resnick,Timothy J. Hohman,Warren D. Taylor,Bennett A. Landman<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Modern deep learning methods have achieved impressive results across tasks from disease classification, estimating continuous biomarkers, to generating realistic medical images. Most of these approaches are trained to model conditional distributions defined by a specific predictive direction with a specific set of input variables. We introduce MetaVoxel, a generative joint diffusion modeling framework that models the joint distribution over imaging data and clinical metadata by learning a single diffusion process spanning all variables. By capturing the joint distribution, MetaVoxel unifies tasks that traditionally require separate conditional models and supports flexible zero-shot inference using arbitrary subsets of inputs without task-specific retraining. Using more than 10,000 T1-weighted MRI scans paired with clinical metadata from nine datasets, we show that a single MetaVoxel model can perform image generation, age estimation, and sex prediction, achieving performance comparable to established task-specific baselines. Additional experiments highlight its capabilities for flexible this http URL, these findings demonstrate that joint multimodal diffusion offers a promising direction for unifying medical AI models and enabling broader clinical applicability.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-110] ABBSPO: Adaptive Bounding Box Scaling and Symmetric Prior based Orientation Prediction for Detecting Aerial Image Objects <mark class="hl-label red">CVPR2025</mark></p>
<p>【速读】：该论文针对弱监督定向目标检测（Weakly Supervised Oriented Object Detection, WS-OOD）中基于水平边界框（Horizontal Bounding Box, HBox）监督的方法存在的精度不足问题展开研究，特别是传统方法直接将真实标注的HBox与预测的旋转边界框（Rotated BoundingBox, RBox）最小外接矩形进行比较，导致尺度估计不准确的问题。解决方案的关键在于提出两个核心模块：(i) 自适应边界框缩放（Adaptive Bounding Box Scaling, ABBS），通过动态调整GT HBox尺寸以匹配每个预测RBox的规模，提升尺度预测准确性；(ii) 对称先验角度损失（Symmetric Prior Angle, SPA），利用遥感图像中物体固有的对称性，在多视角增强（原始、旋转、翻转）下实现自监督学习，避免因三视图预测一致错误而导致的学习崩溃问题。该框架ABBSPO在多个数据集上达到当前最优性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10031">https://arxiv.org/abs/2512.10031</a><br>
<strong>作者</strong>: Woojin Lee,Hyugjae Chang,Jaeho Moon,Jaehyup Lee,Munchurl Kim<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  17 pages, 11 figures, 8 tables, supplementary included. Accepted to CVPR 2025. Please visit our project page at <a target="_blank" rel="noopener" href="https://kaist-viclab.github.io/ABBSPO_site/">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Weakly supervised oriented object detection (WS-OOD) has gained attention as a cost-effective alternative to fully supervised methods, providing both efficiency and high accuracy. Among weakly supervised approaches, horizontal bounding box (HBox)-supervised OOD stands out for its ability to directly leverage existing HBox annotations while achieving the highest accuracy under weak supervision settings. This paper introduces adaptive bounding box scaling and symmetry-prior-based orientation prediction, called ABBSPO, a framework for WS-OOD. Our ABBSPO addresses limitations of previous HBox-supervised OOD methods, which compare ground truth (GT) HBoxes directly with the minimum circumscribed rectangles of predicted RBoxes, often leading to inaccurate scale estimation. To overcome this, we propose: (i) Adaptive Bounding Box Scaling (ABBS), which appropriately scales GT HBoxes to optimize for the size of each predicted RBox, ensuring more accurate scale prediction; and (ii) a Symmetric Prior Angle (SPA) loss that exploits inherent symmetry of aerial objects for self-supervised learning, resolving issues in previous methods where learning collapses when predictions for all three augmented views (original, rotated, and flipped) are consistently incorrect. Extensive experimental results demonstrate that ABBSPO achieves state-of-the-art performance, outperforming existing methods.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-111] Neuromorphic Eye Tracking for Low-Latency Pupil Detection</p>
<p>【速读】：该论文旨在解决可穿戴系统中眼动追踪（eye tracking）面临的低延迟与毫瓦级功耗需求难题，传统基于帧的处理流程因运动模糊、高计算成本及有限的时间分辨率而难以满足增强现实（AR）和虚拟现实（VR）等场景下的实时交互要求。其解决方案的关键在于将高性能事件驱动的眼动追踪模型重构为脉冲神经网络（spiking neural network, SNN），通过用轻量级LIF（Leaky Integrate-and-Fire）层替代原模型中的循环和注意力模块，并引入深度可分离卷积（depth-wise separable convolutions）以显著降低模型复杂度，从而在保持3.7–4.1像素均方误差精度的同时，实现模型尺寸缩小20倍、理论计算量减少850倍，并预计可在3.9–4.9 mW功耗下达到1 kHz采样率和3 ms延迟，适用于实时可穿戴部署。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09969">https://arxiv.org/abs/2512.09969</a><br>
<strong>作者</strong>: Paul Hueber,Luca Peres,Florian Pitters,Alejandro Gloriani,Oliver Rhodes<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Neural and Evolutionary Computing (<a target="_blank" rel="noopener" href="http://cs.NE">cs.NE</a>)<br>
<strong>备注</strong>:  8 pages, 2 figures, conference</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Eye tracking for wearable systems demands low latency and milliwatt-level power, but conventional frame-based pipelines struggle with motion blur, high compute cost, and limited temporal resolution. Such capabilities are vital for enabling seamless and responsive interaction in emerging technologies like augmented reality (AR) and virtual reality (VR), where understanding user gaze is key to immersion and interface design. Neuromorphic sensors and spiking neural networks (SNNs) offer a promising alternative, yet existing SNN approaches are either too specialized or fall short of the performance of modern ANN architectures. This paper presents a neuromorphic version of top-performing event-based eye-tracking models, replacing their recurrent and attention modules with lightweight LIF layers and exploiting depth-wise separable convolutions to reduce model complexity. Our models obtain 3.7-4.1px mean error, approaching the accuracy of the application-specific neuromorphic system, Retina (3.24px), while reducing model size by 20x and theoretical compute by 850x, compared to the closest ANN variant of the proposed model. These efficient variants are projected to operate at an estimated 3.9-4.9 mW with 3 ms latency at 1 kHz. The present results indicate that high-performing event-based eye-tracking architectures can be redesigned as SNNs with substantial efficiency gains, while retaining accuracy suitable for real-time wearable deployment.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-112] Echo-CoPilot: A Multi-View Multi-Task <mark class="hl-label green">Agent</mark>  for Echocardiography Interpretation and Reporting</p>
<p>【速读】：该论文旨在解决超声心动图（Echocardiography）全视角、多任务临床解读仍依赖人工操作的问题，其核心挑战在于现有基础模型虽能在单个感知子任务（如视图分类、结构分割或疾病预测）中表现优异，但缺乏统一且符合临床逻辑的整合能力。解决方案的关键在于提出 Echo-CoPilot，一个基于大语言模型（Large Language Model, LLM）的多视图、多任务代理系统，通过 ReAct 风格的推理循环协调专用工具链：包括视图识别、心脏结构分割、定量测量与疾病预测，并将结果整合为符合指南的问答和叙事摘要，从而实现从离散分析到整体临床决策支持的跃迁。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09944">https://arxiv.org/abs/2512.09944</a><br>
<strong>作者</strong>: Moein Heidari,Mohammad Amin Roohi,Armin Khosravi,Ilker Hacihaliloglu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Machine Learning (cs.LG); Image and Video Processing (eess.IV)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Echocardiography is central to contemporary cardiovascular care, but full-study interpretation remains a cognitively demanding, multi-view task that is still performed manually. While recent foundation models for echocardiography can achieve strong performance on individual perceptual subtasks such as view classification, segmentation, or disease prediction, they typically operate in isolation and do not provide a unified, clinically coherent assessment. In this work, we introduce Echo-CoPilot, a multi-view, multi-task agent that uses a large language model to orchestrate a suite of specialized echocardiography tools. Within a ReAct-style loop, the agent decomposes clinician queries, invokes tools for view recognition, cardiac structure segmentation, measurement and disease prediction, and report synthesis, and integrates their outputs into guideline-aware answers and narrative summaries. We evaluate Echo-CoPilot on the public MIMIC-EchoQA benchmark, where it achieves an accuracy of 50.8%, outperforming both general-purpose and biomedical video vision-language models. Qualitative analyses further show that the agent leverages quantitative measurements and physiologic context to resolve challenging cases near clinical decision thresholds, such as borderline left ventricular hypertrophy or pericardial effusion severity. The code will be released upon acceptance of the paper.<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-113] Benchmarking Document Parsers on Mathematical Formula Extraction from PDFs</p>
<p>【速读】：该论文旨在解决从PDF文档中准确解析数学公式（mathematical formulas）的问题，这一问题对训练大语言模型（large language models, LLMs）和构建科学知识库至关重要。现有基准测试要么完全忽略公式，要么缺乏语义层面的评估指标，导致无法有效衡量解析质量。解决方案的关键在于提出一个基于合成PDF的新型基准框架，其中包含精确的LaTeX真实值（ground truth），并实现对布局、公式及内容特征的系统性控制；同时，首次将大型语言模型作为裁判（LLM-as-a-judge）用于语义层面的公式评估，并结合稳健的两阶段匹配流水线以处理解析输出不一致的问题，从而显著提升评估与人工判断的相关性（Pearson r=0.78）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09874">https://arxiv.org/abs/2512.09874</a><br>
<strong>作者</strong>: Pius Horn,Janis Keuper<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Correctly parsing mathematical formulas from PDFs is critical for training large language models and building scientific knowledge bases from academic literature, yet existing benchmarks either exclude formulas entirely or lack semantically-aware evaluation metrics. We introduce a novel benchmarking framework centered on synthetically generated PDFs with precise LaTeX ground truth, enabling systematic control over layout, formulas, and content characteristics. A key methodological contribution is pioneering LLM-as-a-judge for semantic formula assessment, combined with a robust two-stage matching pipeline that handles parser output inconsistencies. Through human validation on 250 formula pairs (750 ratings from 30 evaluators), we demonstrate that LLM-based evaluation achieves substantially higher correlation with human judgment (Pearson r=0.78) compared to CDM (r=0.34) and text similarity (r~0). Evaluating 20+ contemporary PDF parsers (including specialized OCR models, vision-language models, and rule-based approaches) across 100 synthetic documents with 2,000+ formulas reveals significant performance disparities. Our findings provide crucial insights for practitioners selecting parsers for downstream applications and establish a robust, scalable methodology that enables reproducible evaluation of PDF formula extraction quality. Code and benchmark data: this https URL<br>
zh</p>
</div></div>
<div class="note purple no-icon flat"><p>[CV-114] CC-GRMAS: A Multi-<mark class="hl-label green">Agent</mark>  Graph Neural System for Spatiotemporal Landslide Risk Assessment in High Mountain Asia</p>
<p>【速读】：该论文旨在解决高山区因气候变化加剧的滑坡灾害监测与响应滞后问题，特别是在数据获取日益丰富但及时预警和应急响应仍显碎片化的背景下。解决方案的关键在于提出CC-GRMAS框架，该框架通过整合多源卫星观测与环境信号，构建由预测（Prediction）、规划（Planning）和执行（Execution）三个相互关联的智能体组成的协同系统，从而实现对滑坡事件的实时态势感知、响应计划制定与干预行动，其核心创新在于融合局部环境因子并实现多智能体协调操作，为脆弱山地地区提供可扩展且前瞻性的气候韧性灾害准备方案。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2510.20875">https://arxiv.org/abs/2510.20875</a><br>
<strong>作者</strong>: Mihir Panchal,Ying-Jung Chen,Surya Parkash<br>
<strong>机构</strong>: Dwarkadas Jivanlal Sanghvi College of Engineering (达瓦达斯·吉万拉尔·桑格维工程学院); Georgia Institute of Technology (佐治亚理工学院); National Institute of Disaster Management (国家灾害管理研究所)<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computer Vision and Pattern Recognition (<a target="_blank" rel="noopener" href="http://cs.CV">cs.CV</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Landslides are a growing climate induced hazard with severe environmental and human consequences, particularly in high mountain Asia. Despite increasing access to satellite and temporal datasets, timely detection and disaster response remain underdeveloped and fragmented. This work introduces CC-GRMAS, a framework leveraging a series of satellite observations and environmental signals to enhance the accuracy of landslide forecasting. The system is structured around three interlinked agents Prediction, Planning, and Execution, which collaboratively enable real time situational awareness, response planning, and intervention. By incorporating local environmental factors and operationalizing multi agent coordination, this approach offers a scalable and proactive solution for climate resilient disaster preparedness across vulnerable mountainous terrains.<br>
zh</p>
</div></div>
<h3 id="人工智能">人工智能</h3>
<div class="note blue no-icon flat"><p>[AI-0] Hierarchical Dataset Selection for High-Quality Data Sharing</p>
<p>【速读】：该论文试图解决在多源学习场景中，如何从异构数据集中高效选择最优子集以提升下游模型性能的问题。现有方法通常仅对单个样本进行筛选，忽视了数据集之间在相关性、质量与来源上的差异，导致资源利用效率低下。解决方案的关键在于提出Dataset Selection via Hierarchies (DaSH) 方法，该方法通过建模数据集层级（dataset-level）和组别层级（group-level，如机构或集合）的效用，实现从有限观测中高效泛化，从而在资源受限条件下显著提升模型准确率（在Digit-Five和DomainNet两个基准上最高提升26.2%），同时减少探索步骤。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10952">https://arxiv.org/abs/2512.10952</a><br>
<strong>作者</strong>: Xiaona Zhou,Yingyan Zeng,Ran Jin,Ismini Lourentzou<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-1] ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning</p>
<p>【速读】：该论文旨在解决高接触密度操作任务中视觉与力觉信号融合的挑战，即如何在不同时间尺度（视觉提供慢速全局空间信息，力觉捕捉快速局部接触动态）和信息特性上实现有效协同。其核心解决方案是提出ImplicitRDP——一种统一的端到端视觉-力觉扩散策略网络，关键创新在于引入结构化慢-快学习机制（Structural Slow-Fast Learning），利用因果注意力并行处理异步的视觉与力觉token，在保持动作片段时序一致性的前提下实现以力觉频率进行闭环调整；同时设计基于虚拟目标的表征正则化（Virtual-target-based Representation Regularization），通过将力反馈映射至动作空间强化物理感知的学习信号，防止模态坍塌，从而显著提升策略的反应性与任务成功率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10946">https://arxiv.org/abs/2512.10946</a><br>
<strong>作者</strong>: Wendi Chen,Han Xue,Yi Wang,Fangyuan Zhou,Jun Lv,Yang Jin,Shirun Tang,Chuan Wen,Cewu Lu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  Project page: <a target="_blank" rel="noopener" href="https://implicit-rdp.github.io">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Human-level contact-rich manipulation relies on the distinct roles of two key modalities: vision provides spatially rich but temporally slow global context, while force sensing captures rapid, high-frequency local contact dynamics. Integrating these signals is challenging due to their fundamental frequency and informational disparities. In this work, we propose ImplicitRDP, a unified end-to-end visual-force diffusion policy that integrates visual planning and reactive force control within a single network. We introduce Structural Slow-Fast Learning, a mechanism utilizing causal attention to simultaneously process asynchronous visual and force tokens, allowing the policy to perform closed-loop adjustments at the force frequency while maintaining the temporal coherence of action chunks. Furthermore, to mitigate modality collapse where end-to-end models fail to adjust the weights across different modalities, we propose Virtual-target-based Representation Regularization. This auxiliary objective maps force feedback into the same space as the action, providing a stronger, physics-grounded learning signal than raw force prediction. Extensive experiments on contact-rich tasks demonstrate that ImplicitRDP significantly outperforms both vision-only and hierarchical baselines, achieving superior reactivity and success rates with a streamlined training pipeline. Code and videos will be publicly available at this https URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-2] On Decision-Making <mark class="hl-label green">Agents</mark>  and Higher-Order Causal Processes</p>
<p>【速读】：该论文试图解决如何在部分可观测马尔可夫决策过程（Partially Observable Markov Decision Processes, POMDPs）中精确刻画决策代理（decision-making agents）与高阶量子操作经典极限——单输入过程函数（one-input process functions）之间的对应关系问题。其解决方案的关键在于：将代理的策略（policy）与记忆更新机制（memory update）统一为一个过程函数 $ w $，并通过链积（link product）与POMDP环境交互；这一映射不仅揭示了物理视角下过程函数作为环境承载局部操作（即代理干预）的双重解释，也提供了AI视角下将过程函数视为代理本身、插入函数代表环境的等价表述，并进一步将该框架扩展至多智能体系统，识别出无观测依赖的去中心化POMDP（decentralized POMDPs）作为多输入过程函数的自然定义域。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10937">https://arxiv.org/abs/2512.10937</a><br>
<strong>作者</strong>: Matt Wilson<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Quantum Physics (quant-ph)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We establish a precise correspondence between decision-making agents in partially observable Markov decision processes (POMDPs) and one-input process functions, the classical limit of higher-order quantum operations. In this identification an agent’s policy and memory update combine into a process function w that interacts with a POMDP environment via the link product. This suggests a dual interpretation: in the physics view, the process function acts as the environment into which local operations (agent interventions) are inserted, whereas in the AI view it encodes the agent and the inserted functions represent environments. We extend this perspective to multi-agent systems by identifying observation-independent decentralized POMDPs as natural domains for multi-input process functions.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-3] Empirical evaluation of the Frank-Wolfe methods for constructing white-box adversarial attacks</p>
<p>【速读】：该论文旨在解决神经网络在实际部署中面临的对抗攻击构造难题，尤其是如何高效、快速地生成有效的白盒对抗样本以评估模型的鲁棒性。其核心解决方案是从数值优化的角度出发，摒弃传统依赖投影操作或几何直觉的方法，转而采用改进的无投影优化方法——即修正的Frank-Wolfe算法（modified Frank-Wolfe methods），用于直接求解对抗攻击对应的优化问题。该方法在理论上具有收敛性保障，并在MNIST和CIFAR-10数据集上通过多类逻辑回归、卷积神经网络（CNN）及视觉Transformer（ViT）模型进行了验证，展现出优于标准方法的效率与有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10936">https://arxiv.org/abs/2512.10936</a><br>
<strong>作者</strong>: Kristina Korotkova,Aleksandr Katrutsa<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The construction of adversarial attacks for neural networks appears to be a crucial challenge for their deployment in various services. To estimate the adversarial robustness of a neural network, a fast and efficient approach is needed to construct adversarial attacks. Since the formalization of adversarial attack construction involves solving a specific optimization problem, we consider the problem of constructing an efficient and effective adversarial attack from a numerical optimization perspective. Specifically, we suggest utilizing advanced projection-free methods, known as modified Frank-Wolfe methods, to construct white-box adversarial attacks on the given input data. We perform a theoretical and numerical evaluation of these methods and compare them with standard approaches based on projection operations or geometrical intuition. Numerical experiments are performed on the MNIST and CIFAR-10 datasets, utilizing a multiclass logistic regression model, the convolutional neural networks (CNNs), and the Vision Transformer (ViT).<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-4] Decoupled Q-Chunking</p>
<p>【速读】：该论文旨在解决时序差分（Temporal-difference, TD）学习中因自bootstrap机制导致的bootstrapping bias问题，即值函数目标中的误差在多步传播过程中累积，从而造成估计偏差。同时，现有基于chunked critics的方法虽能通过估计短动作序列（chunk）的价值来加速值更新，但其策略生成需输出完整动作chunk进行开环执行，这在需要策略反应性的环境中表现不佳，且随着chunk长度增加，建模难度显著上升。解决方案的关键在于<strong>解耦critic与策略的chunk长度</strong>：通过构造一个“蒸馏后的部分动作chunk critic”，利用乐观回溯（optimistic backup）从原始chunked critic中近似扩展部分动作chunk所能达到的最大价值，从而允许策略在较短的动作chunk上运行，既保留了多步值传播的优势，又避免了开环策略的次优性和长chunk策略建模困难。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10926">https://arxiv.org/abs/2512.10926</a><br>
<strong>作者</strong>: Qiyang Li,Seohong Park,Sergey Levine<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
<strong>备注</strong>:  76 pages, 14 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Temporal-difference (TD) methods learn state and action values efficiently by bootstrapping from their own future value predictions, but such a self-bootstrapping mechanism is prone to bootstrapping bias, where the errors in the value targets accumulate across steps and result in biased value estimates. Recent work has proposed to use chunked critics, which estimate the value of short action sequences (“chunks”) rather than individual actions, speeding up value backup. However, extracting policies from chunked critics is challenging: policies must output the entire action chunk open-loop, which can be sub-optimal for environments that require policy reactivity and also challenging to model especially when the chunk length grows. Our key insight is to decouple the chunk length of the critic from that of the policy, allowing the policy to operate over shorter action chunks. We propose a novel algorithm that achieves this by optimizing the policy against a distilled critic for partial action chunks, constructed by optimistically backing up from the original chunked critic to approximate the maximum value achievable when a partial action chunk is extended to a complete one. This design retains the benefits of multi-step value propagation while sidestepping both the open-loop sub-optimality and the difficulty of learning action chunking policies for long action chunks. We evaluate our method on challenging, long-horizon offline goal-conditioned tasks and show that it reliably outperforms prior methods. Code: this http URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-5] SparseSwaps: Tractable <mark class="hl-label green">LLM</mark>  Pruning Mask Refinement at Scale</p>
<p>【速读】：该论文旨在解决大规模语言模型（Large Language Models, LLMs）在剪枝（pruning）后性能下降的问题，特别是针对Transformer架构中传统全局幅度剪枝方法效果不佳的情况。其核心挑战在于如何在不进行全量重训练的前提下，通过层级掩码选择（layer-wise mask selection）优化每层的剪枝误差，从而最小化校准数据上的损失。解决方案的关键在于：首先通过强制每行保持相同的稀疏度（equal sparsity levels per row）来解耦行间约束，使得问题结构更易处理；进而利用校准数据的Gram矩阵高效计算最优的1-交换（1-swap）操作——即交换一个保留权重与一个被剪枝权重，从而显著降低每层剪枝误差。该方法设计了一个简单且可扩展的1-swap算法，无需超参数调优，在GPU上高效运行，适用于LLM规模，并在多个GPT架构上实现了显著的困惑度（perplexity）和零样本准确率提升。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10922">https://arxiv.org/abs/2512.10922</a><br>
<strong>作者</strong>: Max Zimmer,Christophe Roux,Moritz Wagner,Deborah Hendrych,Sebastian Pokutta<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  15 pages, 2 figures, 4 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The resource requirements of Neural Networks can be significantly reduced through pruning – the removal of seemingly less important parameters. However, with the rise of Large Language Models (LLMs), full retraining to recover pruning-induced performance degradation is often prohibitive and classical approaches such as global magnitude pruning are suboptimal on Transformer architectures. State-of-the-art methods hence solve a layer-wise mask selection problem, the problem of finding a pruning mask which minimizes the per-layer pruning error on a small set of calibration data. Exactly solving this problem to optimality using Integer Programming (IP) solvers is computationally infeasible due to its combinatorial nature and the size of the search space, and existing approaches therefore rely on approximations or heuristics. In this work, we demonstrate that the mask selection problem can be made drastically more tractable at LLM scale. To that end, we decouple the rows by enforcing equal sparsity levels per row. This allows us to derive optimal 1-swaps (exchanging one kept and one pruned weight) that can be computed efficiently using the Gram matrix of the calibration data. Using these observations, we propose a tractable and simple 1-swap algorithm that warm starts from any pruning mask, runs efficiently on GPUs at LLM scale, and is essentially hyperparameter-free. We demonstrate that our approach reduces per-layer pruning error by up to 60% over Wanda (Sun et al., 2023) and consistently improves perplexity and zero-shot accuracy across state-of-the-art GPT architectures.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-6] Multi-Granular Node Pruning for Circuit Discovery</p>
<p>【速读】：该论文旨在解决大语言模型（Large Language Models, LLMs）中电路发现（circuit discovery）的两个核心问题：一是现有方法依赖迭代式边剪枝（edge pruning），计算成本高且仅能作用于粗粒度单元（如注意力头或MLP模块），忽略了更细粒度的结构（如单个神经元）；二是缺乏对多粒度结构的统一优化能力，难以实现高效压缩与精准定位关键子网络。解决方案的关键在于提出一种基于节点级剪枝（node-level pruning）的框架，通过在统一优化目标下引入可学习掩码（learnable masks），实现从模块到单个神经元的多粒度控制，并利用粒度特定的稀疏性惩罚项（granularity-specific sparsity penalties）引导剪枝过程，从而在一次微调中完成全面压缩，同时保持任务性能并显著降低内存占用（5–10倍）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10903">https://arxiv.org/abs/2512.10903</a><br>
<strong>作者</strong>: Muhammad Umair Haider,Hammad Rizwan,Hassan Sajjad,A.B. Siddique<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP blocks, overlooking finer structures like individual neurons. We propose a node-level pruning framework for circuit discovery that addresses both scalability and granularity limitations. Our method introduces learnable masks across multiple levels of granularity, from entire blocks to individual neurons, within a unified optimization objective. Granularity-specific sparsity penalties guide the pruning process, allowing a comprehensive compression in a single fine-tuning run. Empirically, our approach identifies circuits that are smaller in nodes than those discovered by prior methods; moreover, we demonstrate that many neurons deemed important by coarse methods are actually irrelevant, while still maintaining task performance. Furthermore, our method has a significantly lower memory footprint, 5-10x, as it does not require keeping intermediate activations in the memory to work.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-7] <mark class="hl-label green">LLM</mark> s Can Assist with Proposal Selection at Large User Facilities</p>
<p>【速读】：该论文旨在解决大型用户设施中提案遴选过程依赖人工评审所面临的效率低、一致性差及偏倚问题，尤其在评估多个提案相对强度时，传统人类评分存在弱相关性与主观不一致的缺陷。其解决方案的关键在于引入大语言模型（Large Language Models, LLMs），利用其对高质量历史提案和出版记录的深度理解能力，实现高效且可靠的排序预测；通过配对偏好（pairwise preference）机制克服人工评审的局限性，同时借助嵌入模型（embedding models）进行提案相似性量化分析，从而提升遴选流程的客观性、可扩展性和决策支持能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10895">https://arxiv.org/abs/2512.10895</a><br>
<strong>作者</strong>: Lijie Ding,Janell Thomson,Jon Taylor,Changwoo Do<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  9 pages, 8figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; however, traditional human scoring often suffers from weak inter-proposal correlations and is subject to reviewer bias and inconsistency. A pairwise preference-based approach is logically superior, providing a more rigorous and internally consistent basis for ranking, but its quadratic workload makes it impractical for human reviewers. We address this limitation using LLMs. Leveraging the uniquely well-curated proposals and publication records from three beamlines at the Spallation Neutron Source (SNS), Oak Ridge National Laboratory (ORNL), we show that the LLM rankings correlate strongly with the human rankings (Spearman  \rho\simeq 0.2-0.8 , improving to  \geq 0.5  after 10% outlier removal). Moreover, LLM performance is no worse than that of human reviewers in identifying proposals with high publication potential, while costing over two orders of magnitude less. Beyond ranking, LLMs enable advanced analyses that are challenging for humans, such as quantitative assessment of proposal similarity via embedding models, which provides information crucial for review committees.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-8] UrbanAI 2025 Challenge: Linear vs Transformer Models for Long-Horizon Exogenous Temperature Forecasting <mark class="hl-label red">NEURIPS2025</mark></p>
<p>【速读】：该论文旨在解决长期 horizon 的外生变量仅依赖（exogenous-only）室内温度预测问题，即在仅使用历史温度序列作为输入的情况下进行准确预测，这是一个具有挑战性的单变量时间序列建模任务。其解决方案的关键在于系统性地比较线性模型（Linear、NLinear、DLinear）与 Transformer 家族模型（Transformer、Informer、Autoformer）的性能表现，结果表明经过精心设计的线性模型（尤其是 DLinear）在所有数据划分下均显著优于复杂度更高的 Transformer 架构，揭示了在纯内生依赖场景中，简单而结构合理的线性方法仍是最具竞争力的基线方案。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10866">https://arxiv.org/abs/2512.10866</a><br>
<strong>作者</strong>: Ruslan Gokhman<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  NeurIPS 2025 Workshop UrbanAI</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We study long-horizon exogenous-only temperature forecasting - a challenging univariate setting where only the past values of the indoor temperature are used for prediction - using linear and Transformer-family models. We evaluate Linear, NLinear, DLinear, Transformer, Informer, and Autoformer under standardized train, validation, and test splits. Results show that linear baselines (Linear, NLinear, DLinear) consistently outperform more complex Transformer-family architectures, with DLinear achieving the best overall accuracy across all splits. These findings highlight that carefully designed linear models remain strong baselines for time series forecasting in challenging exogenous-only settings.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-9] Generative Modeling from Black-box Corruptions via Self-Consistent Stochastic Interpolants</p>
<p>【速读】：该论文旨在解决在缺乏干净数据的情况下，如何构建生成模型的问题。具体而言，当观测到的数据受噪声和病态信道污染时，需通过分布级别的逆问题来恢复原始数据的生成模型。解决方案的关键在于提出一种基于随机插值（Stochastic Interpolants）的新方法——自洽随机插值（Self-Consistent Stochastic Interpolant, SCSI），其核心思想是仅利用污染数据集和对污染通道的黑盒访问，迭代更新污染与干净数据样本之间的传输映射（transport map）。在适当条件下，该迭代过程收敛至一个自洽的传输映射，有效实现对污染通道的逆操作，从而支持干净数据的生成建模。该方法兼具计算高效性、灵活性（可处理任意非线性前向模型）及理论保证。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10857">https://arxiv.org/abs/2512.10857</a><br>
<strong>作者</strong>: Chirag Modi,Jiequn Han,Eric Vanden-Eijnden,Joan Bruna<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Transport-based methods have emerged as a leading paradigm for building generative models from large, clean datasets. However, in many scientific and engineering domains, clean data are often unavailable: instead, we only observe measurements corrupted through a noisy, ill-conditioned channel. A generative model for the original data thus requires solving an inverse problem at the level of distributions. In this work, we introduce a novel approach to this task based on Stochastic Interpolants: we iteratively update a transport map between corrupted and clean data samples using only access to the corrupted dataset as well as black box access to the corruption channel. Under appropriate conditions, this iterative procedure converges towards a self-consistent transport map that effectively inverts the corruption channel, thus enabling a generative model for the clean data. We refer to the resulting method as the self-consistent stochastic interpolant (SCSI). It (i) is computationally efficient compared to variational alternatives, (ii) highly flexible, handling arbitrary nonlinear forward models with only black-box access, and (iii) enjoys theoretical guarantees. We demonstrate superior performance on inverse problems in natural image processing and scientific reconstruction, and establish convergence guarantees of the scheme under appropriate assumptions.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-10] V-OCBF: Learning Safety Filters from Offline Data via Value-Guided Offline Control Barrier Functions</p>
<p>【速读】：该论文旨在解决自主系统中安全控制的难题，即如何在不依赖在线交互的情况下，确保控制器满足硬性状态约束并提供前向不变性（forward invariance）的安全保障。现有安全离线强化学习（Safe Offline RL）方法通常仅施加软期望代价约束，无法保证安全性；而控制屏障函数（Control Barrier Functions, CBFs）虽能提供严格安全保证，却往往依赖专家设计的屏障函数或完整的系统动力学模型。本文提出的价值引导离线控制屏障函数（Value-Guided Offline Control Barrier Functions, V-OCBF）框架的关键在于：通过离线演示数据直接学习神经网络形式的CBF，无需已知动力学模型；利用递归有限差分更新机制实现屏障函数的时间传播，从而支持无模型的安全信息传递；同时引入期望分位数（expectile-based）目标函数，避免对分布外动作查询屏障，并将更新限制在数据集支持的动作空间内。最终，学习到的屏障函数结合二次规划（Quadratic Program, QP）实时合成安全控制输入，在多个案例研究中显著减少安全违规次数，且保持优异的任务性能，展现出无需在线交互或人工设计屏障即可构建安全关键控制器的可扩展性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10822">https://arxiv.org/abs/2512.10822</a><br>
<strong>作者</strong>: Mumuksh Tayal,Manan Tayal,Aditya Singh,Shishir Kolathaya,Ravi Prakash<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
<strong>备注</strong>:  23 pages, 8 figure, 7 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Ensuring safety in autonomous systems requires controllers that satisfy hard, state-wise constraints without relying on online interaction. While existing Safe Offline RL methods typically enforce soft expected-cost constraints, they do not guarantee forward invariance. Conversely, Control Barrier Functions (CBFs) provide rigorous safety guarantees but usually depend on expert-designed barrier functions or full knowledge of the system dynamics. We introduce Value-Guided Offline Control Barrier Functions (V-OCBF), a framework that learns a neural CBF entirely from offline demonstrations. Unlike prior approaches, V-OCBF does not assume access to the dynamics model; instead, it derives a recursive finite-difference barrier update, enabling model-free learning of a barrier that propagates safety information over time. Moreover, V-OCBF incorporates an expectile-based objective that avoids querying the barrier on out-of-distribution actions and restricts updates to the dataset-supported action set. The learned barrier is then used with a Quadratic Program (QP) formulation to synthesize real-time safe control. Across multiple case studies, V-OCBF yields substantially fewer safety violations than baseline methods while maintaining strong task performance, highlighting its scalability for offline synthesis of safety-critical controllers without online interaction or hand-engineered barriers.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-11] HAROOD: A Benchmark for Out-of-distribution Generalization in Sensor-based Human Activity Recognition</p>
<p>【速读】：该论文旨在解决传感器驱动的人类活动识别（Sensor-based Human Activity Recognition, HAR）在分布偏移（Out-of-Distribution, OOD）场景下的性能下降问题，即在个体差异、设备变化、环境迁移和时间演化等现实因素导致的数据分布漂移下，现有模型泛化能力不足的挑战。其解决方案的关键在于提出一个系统性的基准测试平台 HAROOD，涵盖四种典型的 OOD 场景（跨个体、跨位置、跨数据集、跨时间）、六个真实数据集、十六种对比方法（包括卷积神经网络 CNN 和 Transformer 架构），以及两种模型选择协议，从而全面评估不同 OOD 算法在 HAR 中的有效性与局限性。该框架不仅揭示了当前无单一方法始终最优的现状，也为未来面向 OOD 的 HAR 研究提供了可扩展、模块化的实验基础。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10807">https://arxiv.org/abs/2512.10807</a><br>
<strong>作者</strong>: Wang Lu,Yao Zhu,Jindong Wang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  18 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Sensor-based human activity recognition (HAR) mines activity patterns from the time-series sensory data. In realistic scenarios, variations across individuals, devices, environments, and time introduce significant distributional shifts for the same activities. Recent efforts attempt to solve this challenge by applying or adapting existing out-of-distribution (OOD) algorithms, but only in certain distribution shift scenarios (e.g., cross-device or cross-position), lacking comprehensive insights on the effectiveness of these algorithms. For instance, is OOD necessary to HAR? Which OOD algorithm performs the best? In this paper, we fill this gap by proposing HAROOD, a comprehensive benchmark for HAR in OOD settings. We define 4 OOD scenarios: cross-person, cross-position, cross-dataset, and cross-time, and build a testbed covering 6 datasets, 16 comparative methods (implemented with CNN-based and Transformer-based architectures), and two model selection protocols. Then, we conduct extensive experiments and present several findings for future research, e.g., no single method consistently outperforms others, highlighting substantial opportunity for advancement. Our codebase is highly modular and easy to extend for new datasets, algorithms, comparisons, and analysis, with the hope to facilitate the research in OOD-based HAR. Our implementation is released and can be found at this https URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-12] Natural Language Interface for Firewall Configuration</p>
<p>【速读】：该论文旨在解决企业防火墙配置中因策略表达复杂、易出错且难以维护而导致的管理难题，尤其针对管理员需手动编写厂商特定命令行配置（CLI）所引发的效率低和误操作风险。其解决方案的关键在于构建一个自然语言接口框架，将用户用自然语言表述的访问控制策略转化为结构化的中间表示（Intermediate Representation, IR），该IR抽象了人类意图与设备语法之间的差异，并可编译为具体厂商（如Palo Alto PAN OS）的配置指令。系统通过三重验证机制确保安全性：静态语法检查、安全阈值过滤（如阻止“any to any”规则）以及基于Batfish的仿真验证，从而实现可审计、可扩展且以用户为中心的防火墙策略管理流程。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10789">https://arxiv.org/abs/2512.10789</a><br>
<strong>作者</strong>: F. Taghiyev,A. Aslanbayli<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Networking and Internet Architecture (<a target="_blank" rel="noopener" href="http://cs.NI">cs.NI</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  7 pages, 3 figures. Preliminary version of an ongoing research project on natural language interfaces for firewall configuration</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper presents the design and prototype implementation of a natural language interface for configuring enterprise firewalls. The framework allows administrators to express access control policies in plain language, which are then translated into vendor specific configurations. A compact schema bound intermediate representation separates human intent from device syntax and in the current prototype compiles to Palo Alto PAN OS command line configuration while remaining extensible to other platforms. Large language models are used only as assistive parsers that generate typed intermediate representation objects, while compilation and enforcement remain deterministic. The prototype integrates three validation layers, namely a static linter that checks structural and vendor specific constraints, a safety gate that blocks overly permissive rules such as any to any allows, and a Batfish based simulator that validates configuration syntax and referential integrity against a synthetic device model. The paper describes the architecture, implementation, and test methodology on synthetic network context datasets and discusses how this approach can evolve into a scalable auditable and human centered workflow for firewall policy management.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-13] Designing AI-Resilient Assessments Using Interconnected Problems: A Theoretically Grounded and Empirically Validated Framework</p>
<p>【速读】：该论文旨在解决生成式 AI（Generative AI）在计算教育中迅速普及所引发的传统模块化评估方式失效问题，即学术评价与行业实践之间出现脱节，导致学生可能通过AI工具获取虚假成绩，从而削弱评估的公平性与有效性。其解决方案的关键在于提出一个理论驱动的、可实证验证的“AI抗性评估设计框架”，核心策略包括：一是采用相互关联的问题结构（interconnected problems），使输出结果成为后续步骤输入，利用当前语言模型在多步推理和上下文维持上的局限性提升抗AI作弊能力；二是引入具有确定性成功标准的半结构化任务（semi-structured problems），以减少AI对熟悉模式的依赖，提高对学生真实能力的测量可靠性。该框架通过多轮实证数据验证（N=138）表明，此类设计不仅能有效抵抗AI滥用，还能促进整合性思维，并更贴近现实世界中AI增强的工作流程。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10758">https://arxiv.org/abs/2512.10758</a><br>
<strong>作者</strong>: Kaihua Ding<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  8 pages, 3 figures and 3 tables, under submission to IEEE FIE</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The rapid adoption of generative AI has undermined traditional modular assessments in computing education, creating a disconnect between academic evaluation and industry practice. This paper presents a theoretically grounded framework for designing AI-resilient assessments, supported by formal analysis and multi-year empirical validation. We make three contributions. First, we establish two theoretical results: (1) assessments composed of interconnected problems, where outputs feed into subsequent stages, are more AI-resilient than modular assessments because current language models struggle with sustained multi-step reasoning and context; and (2) semi-structured problems with deterministic success criteria provide more reliable measures of student competency than fully open-ended projects, which allow AI systems to default to familiar solution patterns. These results challenge common policy and institutional guidance that promotes open-ended assessments as the primary safeguard for academic integrity. Second, we validate these results using data from four university data science courses (N = 138). While students achieve near-perfect scores on AI-assisted modular homework, performance drops by roughly 30 percentage points on proctored exams, indicating substantial AI score inflation. Interconnected projects remain strongly correlated with modular assessments, suggesting they measure the same underlying skills while resisting AI misuse. Proctored exams show weaker alignment, implying they may assess test-taking ability rather than intended learning outcomes. Third, we translate these findings into a practical assessment design framework. The proposed approach enables educators to create assessments that promote integrative thinking, reflect real-world AI-augmented workflows, and naturally resist trivial delegation to generative AI, thereby helping restore academic integrity.          Comments: 8 pages, 3 figures and 3 tables, under submission to IEEE FIE   Subjects:  Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)  Cite as: arXiv:2512.10758 [<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>]    (or  arXiv:2512.10758v1 [<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10758">https://doi.org/10.48550/arXiv.2512.10758</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)        Submission history From: Kaihua Ding [view email]       [v1]         Thu, 11 Dec 2025 15:53:19 UTC (503 KB)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-14] LGAN: An Efficient High-Order Graph Neural Network via the Line Graph Aggregation</p>
<p>【速读】：该论文旨在解决现有图神经网络（Graph Neural Networks, GNNs）在图分类任务中表达能力受限以及可解释性不足的问题。具体而言，传统GNNs依赖邻接节点间的消息传递机制，其表达能力受限于1维Weisfeiler-Lehman（1-WL）测试；而现有的k-WL增强型GNN虽能提升表达能力，但计算复杂度随k显著上升，且因基于节点元组操作难以保留细粒度的节点或边级语义信息，导致无法有效支持如集成梯度（Integrated Gradients）等归因方法。本文提出一种新颖的线图聚合网络（Line Graph Aggregation Network, LGAN），其关键在于：从每个节点为中心的诱导子图构造线图（Line Graph），通过该结构实现高阶聚合，理论证明其在注入聚合假设下表达能力优于2-WL，同时时间复杂度更低，并在多个基准数据集上验证了其性能优越性和更好的可解释性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10735">https://arxiv.org/abs/2512.10735</a><br>
<strong>作者</strong>: Lin Du,Lu Bai,Jincheng Li,Lixin Cui,Hangyuan Du,Lichi Zhang,Yuting Chen,Zhao Li<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Graph Neural Networks (GNNs) have emerged as a dominant paradigm for graph classification. Specifically, most existing GNNs mainly rely on the message passing strategy between neighbor nodes, where the expressivity is limited by the 1-dimensional Weisfeiler-Lehman (1-WL) test. Although a number of k-WL-based GNNs have been proposed to overcome this limitation, their computational cost increases rapidly with k, significantly restricting the practical applicability. Moreover, since the k-WL models mainly operate on node tuples, these k-WL-based GNNs cannot retain fine-grained node- or edge-level semantics required by attribution methods (e.g., Integrated Gradients), leading to the less interpretable problem. To overcome the above shortcomings, in this paper, we propose a novel Line Graph Aggregation Network (LGAN), that constructs a line graph from the induced subgraph centered at each node to perform the higher-order aggregation. We theoretically prove that the LGAN not only possesses the greater expressive power than the 2-WL under injective aggregation assumptions, but also has lower time complexity. Empirical evaluations on benchmarks demonstrate that the LGAN outperforms state-of-the-art k-WL-based GNNs, while offering better interpretability.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-15] PACIFIC: a framework for generating benchmarks to check Precise Automatically Checked Instruction Following In Code</p>
<p>【速读】：该论文旨在解决当前大型语言模型（Large Language Model, LLM）在代码相关任务中对用户指令理解与执行能力评估的不足问题，尤其是缺乏能够精确衡量模型逐步推理代码行为（dry running）和严格遵循多步指令能力的自动化基准测试方法。解决方案的关键在于提出PACIFIC框架，该框架通过自动生成具有明确预期输出的基准变体，实现对LLM内在指令遵循能力和代码干运行（dry-running）能力的隔离评估；同时，其设计避免了训练数据污染，支持高效生成多样化且难度可控的新基准，从而为先进模型提供可扩展、抗污染的评测手段。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10713">https://arxiv.org/abs/2512.10713</a><br>
<strong>作者</strong>: Itay Dreyfuss,Antonio Abu Nassar,Samuel Ackerman,Axel Ben David,Rami Katan,Orna Raz,Marcel Zalmanovici<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: oftware Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Model (LLM)-based code assistants have emerged as a powerful application of generative AI, demonstrating impressive capabilities in code generation and comprehension. A key requirement for these systems is their ability to accurately follow user instructions. We present Precise Automatically Checked Instruction Following In Code (PACIFIC), a novel framework designed to automatically generate benchmarks that rigorously assess sequential instruction-following and code dry-running capabilities in LLMs, while allowing control over benchmark difficulty. PACIFIC produces benchmark variants with clearly defined expected outputs, enabling straightforward and reliable evaluation through simple output comparisons. In contrast to existing approaches that often rely on tool usage or agentic behavior, our work isolates and evaluates the LLM’s intrinsic ability to reason through code behavior step-by-step without execution (dry running) and to follow instructions. Furthermore, our framework mitigates training data contamination by facilitating effortless generation of novel benchmark variations. We validate our framework by generating a suite of benchmarks spanning a range of difficulty levels and evaluating multiple state-of-the-art LLMs. Our results demonstrate that PACIFIC can produce increasingly challenging benchmarks that effectively differentiate instruction-following and dry running capabilities, even among advanced models. Overall, our framework offers a scalable, contamination-resilient methodology for assessing core competencies of LLMs in code-related tasks.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-16] COMPARE: Clinical Optimization with Modular <mark class="hl-label green">Planning</mark>  and Assessment via <mark class="hl-label green">RAG</mark> -Enhanced AI-OCT: Superior Decision Support for Percutaneous Coronary Intervention Compared to Chat<mark class="hl-label green">GPT</mark> -5 and Junior Operators</p>
<p>【速读】：该论文旨在解决血管内成像（特别是光学相干断层扫描，OCT）在经皮冠状动脉介入治疗（PCI）中因操作者依赖性导致的解读一致性差的问题。传统方法易受医生经验影响，而通用型人工智能（AI）模型在特定医学场景下缺乏可靠性。解决方案的关键在于开发并验证一种专为心血管影像优化的大语言模型——CA-GPT，并将其部署于AI-OCT系统中，实现对PCI术前规划与术后评估的标准化决策支持。结果显示，CA-GPT在多项预设指标上显著优于通用模型ChatGPT-5和低年资医师，尤其在复杂病例中表现稳健，表明其具备提升OCT引导PCI诊疗质量与一致性的潜力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10702">https://arxiv.org/abs/2512.10702</a><br>
<strong>作者</strong>: Wei Fang,Chiyao Wang,Wenshuai Ma,Hui Liu,Jianqiang Hu,Xiaona Niu,Yi Chu,Mingming Zhang,Jingxiao Yang,Dongwei Zhang,Zelin Li,Pengyun Liu,Jiawei Zheng,Pengke Zhang,Chaoshi Qin,Wangang Guo,Bin Wang,Yugang Xue,Wei Zhang,Zikuan Wang,Rui Zhu,Yihui Cao,Quanmao Lu,Rui Meng,Yan Li<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Background: While intravascular imaging, particularly optical coherence tomography (OCT), improves percutaneous coronary intervention (PCI) outcomes, its interpretation is operator-dependent. General-purpose artificial intelligence (AI) shows promise but lacks domain-specific reliability. We evaluated the performance of CA-GPT, a novel large model deployed on an AI-OCT system, against that of the general-purpose ChatGPT-5 and junior physicians for OCT-guided PCI planning and assessment. Methods: In this single-center analysis of 96 patients who underwent OCT-guided PCI, the procedural decisions generated by the CA-GPT, ChatGPT-5, and junior physicians were compared with an expert-derived procedural record. Agreement was assessed using ten pre-specified metrics across pre-PCI and post-PCI phases. Results: For pre-PCI planning, CA-GPT demonstrated significantly higher median agreement scores (5[IQR 3.75-5]) compared to both ChatGPT-5 (3[2-4], P0.001) and junior physicians (4[3-4], P0.001). CA-GPT significantly outperformed ChatGPT-5 across all individual pre-PCI metrics and showed superior performance to junior physicians in stent diameter (90.3% vs. 72.2%, P0.05) and length selection (80.6% vs. 52.8%, P0.01). In post-PCI assessment, CA-GPT maintained excellent overall agreement (5[4.75-5]), significantly higher than both ChatGPT-5 (4[4-5], P0.001) and junior physicians (5[4-5], P0.05). Subgroup analysis confirmed CA-GPT’s robust performance advantage in complex scenarios. Conclusion: The CA-GPT-based AI-OCT system achieved superior decision-making agreement versus a general-purpose large language model and junior physicians across both PCI planning and assessment phases. This approach provides a standardized and reliable method for intravascular imaging interpretation, demonstrating significant potential to augment operator expertise and optimize OCT-guided PCI.         Subjects:  Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)  Cite as: arXiv:2512.10702 [<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>]    (or  arXiv:2512.10702v1 [<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10702">https://doi.org/10.48550/arXiv.2512.10702</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)        Submission history From: Wei Fang [view email]       [v1]         Thu, 11 Dec 2025 14:41:37 UTC (1,434 KB)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-17] How to Brake? Ethical Emergency Braking with Deep Reinforcement Learning</p>
<p>【速读】：该论文旨在解决多车跟驰场景下紧急制动时的协同安全优化问题，核心挑战在于如何在不可避免碰撞的情况下实现整体（集体）三车伤害最小化或碰撞规避，而非仅保障单个车辆的安全。解决方案的关键在于提出一种融合深度强化学习（Deep Reinforcement Learning, DRL）与基于解析表达式的恒定减速度最优选择方法的混合策略：该策略利用DRL学习复杂交互下的决策模式以提升整体性能，同时引入已有解析方法增强可靠性，从而在保证安全性的同时显著优于纯DRL方法，在整体伤害减少和碰撞避免方面表现更优。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10698">https://arxiv.org/abs/2512.10698</a><br>
<strong>作者</strong>: Jianbo Wang,Galina Sidorenko,Johan Thunberg<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Connected and automated vehicles (CAVs) have the potential to enhance driving safety, for example by enabling safe vehicle following and more efficient traffic scheduling. For such future deployments, safety requirements should be addressed, where the primary such are avoidance of vehicle collisions and substantial mitigating of harm when collisions are unavoidable. However, conservative worst-case-based control strategies come at the price of reduced flexibility and may compromise overall performance. In light of this, we investigate how Deep Reinforcement Learning (DRL) can be leveraged to improve safety in multi-vehicle-following scenarios involving emergency braking. Specifically, we investigate how DRL with vehicle-to-vehicle communication can be used to ethically select an emergency breaking profile in scenarios where overall, or collective, three-vehicle harm reduction or collision avoidance shall be obtained instead of single-vehicle such. As an algorithm, we provide a hybrid approach that combines DRL with a previously published method based on analytical expressions for selecting optimal constant deceleration. By combining DRL with the previous method, the proposed hybrid approach increases the reliability compared to standalone DRL, while achieving superior performance in terms of overall harm reduction and collision avoidance.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-18] Rethinking Popularity Bias in Collaborative Filtering via Analytical Vector Decomposition <mark class="hl-label red">KDD2026</mark></p>
<p>【速读】：该论文旨在解决协同过滤（Collaborative Filtering, CF）模型中存在的流行度偏差（Popularity Bias）问题，即模型在训练过程中倾向于推荐高交互频率的热门物品，从而削弱了对用户个性化偏好（genuine preference）的捕捉能力。现有方法通常将流行度偏差视为外部混淆因素，而本文通过数学分析揭示其本质为贝叶斯成对排序（Bayesian Pairwise Ranking, BPR）优化中嵌入空间的内在几何畸变——BPR会强制物品嵌入沿主导的“流行度方向”排列，导致用户嵌入不得不同时处理个性化偏好与全局流行度校准任务，陷入次优配置。解决方案的关键在于提出方向分解与校正（Directional Decomposition and Correction, DDC）框架，通过不对称的方向性更新机制，引导正样本沿个性化偏好方向优化，同时将负样本远离全局流行度方向，从嵌入空间的几何源头上解耦偏好与流行度，实现更公平且高质量的推荐。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10688">https://arxiv.org/abs/2512.10688</a><br>
<strong>作者</strong>: Lingfeng Liu,Yixin Song,Dazhong Shen,Bing Yin,Hao Li,Yanyong Zhang,Chao Wang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Accepted by SIGKDD 2026(First Cycle)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Popularity bias fundamentally undermines the personalization capabilities of collaborative filtering (CF) models, causing them to disproportionately recommend popular items while neglecting users’ genuine preferences for niche content. While existing approaches treat this as an external confounding factor, we reveal that popularity bias is an intrinsic geometric artifact of Bayesian Pairwise Ranking (BPR) optimization in CF models. Through rigorous mathematical analysis, we prove that BPR systematically organizes item embeddings along a dominant “popularity direction” where embedding magnitudes directly correlate with interaction frequency. This geometric distortion forces user embeddings to simultaneously handle two conflicting tasks-expressing genuine preference and calibrating against global popularity-trapping them in suboptimal configurations that favor popular items regardless of individual tastes. We propose Directional Decomposition and Correction (DDC), a universally applicable framework that surgically corrects this embedding geometry through asymmetric directional updates. DDC guides positive interactions along personalized preference directions while steering negative interactions away from the global popularity direction, disentangling preference from popularity at the geometric source. Extensive experiments across multiple BPR-based architectures demonstrate that DDC significantly outperforms state-of-the-art debiasing methods, reducing training loss to less than 5% of heavily-tuned baselines while achieving superior recommendation quality and fairness. Code is available in this https URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-19] Challenges of Evaluating <mark class="hl-label green">LLM</mark>  Safety for User Welfare</p>
<p>【速读】：该论文试图解决当前大型语言模型（Large Language Models, LLMs）安全评估中忽视个体用户福祉的问题，即现有框架多关注通用风险（如危险能力或不良倾向），而对高风险场景下（如金融与健康建议）因用户情境差异导致的个体性危害缺乏有效评估方法。解决方案的关键在于提出一种<strong>情境感知的用户福利安全评估方法</strong>：通过引入多样化的用户画像（user profiles）作为评估基准，使评价者能够基于具体用户脆弱性水平判断模型输出的安全性。研究发现，仅依赖用户主动披露的情境信息不足以提升评估准确性，必须系统性地将不同用户背景纳入评估设计，从而实现对个体福祉更精准的风险识别与量化。这一方法突破了传统通用风险框架的局限，为构建面向真实应用场景的个性化安全评估体系提供了基础。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10687">https://arxiv.org/abs/2512.10687</a><br>
<strong>作者</strong>: Manon Kempermann,Sai Suresh Macharla Vasu,Mahalakshmi Raveenthiran,Theo Farrell,Ingmar Weber<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>)<br>
<strong>备注</strong>:  Paper accepted at IASEAI’26; please cite that peer-reviewed version instead</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Safety evaluations of large language models (LLMs) typically focus on universal risks like dangerous capabilities or undesirable propensities. However, millions use LLMs for personal advice on high-stakes topics like finance and health, where harms are context-dependent rather than universal. While frameworks like the OECD’s AI classification recognize the need to assess individual risks, user-welfare safety evaluations remain underdeveloped. We argue that developing such evaluations is non-trivial due to fundamental questions about accounting for user context in evaluation design. In this exploratory study, we evaluated advice on finance and health from GPT-5, Claude Sonnet 4, and Gemini 2.5 Pro across user profiles of varying vulnerability. First, we demonstrate that evaluators must have access to rich user context: identical LLM responses were rated significantly safer by context-blind evaluators than by those aware of user circumstances, with safety scores for high-vulnerability users dropping from safe (5/7) to somewhat unsafe (3/7). One might assume this gap could be addressed by creating realistic user prompts containing key contextual information. However, our second study challenges this: we rerun the evaluation on prompts containing context users report they would disclose, finding no significant improvement. Our work establishes that effective user-welfare safety evaluation requires evaluators to assess responses against diverse user profiles, as realistic user context disclosure alone proves insufficient, particularly for vulnerable populations. By demonstrating a methodology for context-aware evaluation, this study provides both a starting point for such assessments and foundational evidence that evaluating individual welfare demands approaches distinct from existing universal-risk frameworks. We publish our code and dataset to aid future developments.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-20] AEBNAS: Strengthening Exit Branches in Early-Exit Networks through Hardware-Aware Neural Architecture Search</p>
<p>【速读】：该论文旨在解决早期退出网络（early-exit networks）设计中效率与性能难以平衡的问题，尤其是在资源受限设备上实现低延迟和低能耗的同时保持高准确率。其解决方案的关键在于引入硬件感知的神经架构搜索（hardware-aware NAS），通过优化退出分支（exit branches）的深度和层类型，并结合自适应阈值调整策略，在保证模型精度的前提下显著降低平均乘加操作数（MACs），从而实现更高效的早期退出网络结构设计。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10671">https://arxiv.org/abs/2512.10671</a><br>
<strong>作者</strong>: Oscar Robben,Saeed Khalilian,Nirvana Meratnia<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Early-exit networks are effective solutions for reducing the overall energy consumption and latency of deep learning models by adjusting computation based on the complexity of input data. By incorporating intermediate exit branches into the architecture, they provide less computation for simpler samples, which is particularly beneficial for resource-constrained devices where energy consumption is crucial. However, designing early-exit networks is a challenging and time-consuming process due to the need to balance efficiency and performance. Recent works have utilized Neural Architecture Search (NAS) to design more efficient early-exit networks, aiming to reduce average latency while improving model accuracy by determining the best positions and number of exit branches in the architecture. Another important factor affecting the efficiency and accuracy of early-exit networks is the depth and types of layers in the exit branches. In this paper, we use hardware-aware NAS to strengthen exit branches, considering both accuracy and efficiency during optimization. Our performance evaluation on the CIFAR-10, CIFAR-100, and SVHN datasets demonstrates that our proposed framework, which considers varying depths and layers for exit branches along with adaptive threshold tuning, designs early-exit networks that achieve higher accuracy with the same or lower average number of MACs compared to the state-of-the-art approaches.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-21] On the Dynamics of Multi-<mark class="hl-label green">Agent</mark>  <mark class="hl-label green">LLM</mark>  Communities Driven by Value Diversity</p>
<p>【速读】：该论文试图解决的问题是：价值多样性如何塑造由大型语言模型（Large Language Models, LLM）驱动的AI群体的集体行为。其解决方案的关键在于基于Schwartz基本人类价值观理论，通过自然主义的价值提取方法构建多智能体仿真系统，在其中让具有不同数量智能体的社区进行开放式的互动与制度形成。研究发现，适度的价值多样性能够增强价值稳定性、促进涌现行为，并在无外部干预的情况下催生更具创造性的原则；但极端异质性则会导致不稳定性。这一成果将价值多样性确立为未来AI能力的新维度，连接了AI能力与制度演化社会学研究。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10665">https://arxiv.org/abs/2512.10665</a><br>
<strong>作者</strong>: Muhua Huang,Qinlin Zhao,Xiaoyuan Yi,Xing Xie<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Working Paper</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:As Large Language Models (LLM) based multi-agent systems become increasingly prevalent, the collective behaviors, e.g., collective intelligence, of such artificial communities have drawn growing attention. This work aims to answer a fundamental question: How does diversity of values shape the collective behavior of AI communities? Using naturalistic value elicitation grounded in the prevalent Schwartz’s Theory of Basic Human Values, we constructed multi-agent simulations where communities with varying numbers of agents engaged in open-ended interactions and constitution formation. The results show that value diversity enhances value stability, fosters emergent behaviors, and brings more creative principles developed by the agents themselves without external guidance. However, these effects also show diminishing returns: extreme heterogeneity induces instability. This work positions value diversity as a new axis of future AI capability, bridging AI ability and sociological studies of institutional emergence.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-22] CAPTAIN: Semantic Feature Injection for Memorization Mitigation in Text-to-Image Diffusion Models</p>
<p>【速读】：该论文旨在解决扩散模型（Diffusion Models）在训练过程中可能无意中重现训练样本的问题，这引发了隐私和版权方面的担忧。现有推理阶段的缓解方法通常通过调整无分类器引导（Classifier-Free Guidance, CFG）或扰动提示嵌入来实现，但往往难以在不损害与条件提示对齐性的情况下有效降低记忆化程度。论文提出的解决方案CAPTAIN是一种无需重新训练的框架，其关键在于：在去噪过程中直接修改潜在特征（latent features），首先采用基于频率的噪声初始化策略，减少早期去噪阶段对记忆模式的复现倾向；随后识别最优去噪时间步以注入特征，并定位记忆区域；最后将来自非记忆参考图像的语义对齐特征注入到局部潜在空间，从而抑制记忆化行为，同时保持提示一致性与视觉质量。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10655">https://arxiv.org/abs/2512.10655</a><br>
<strong>作者</strong>: Tong Zhang,Carlos Hinojosa,Bernard Ghanem<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Diffusion models can unintentionally reproduce training examples, raising privacy and copyright concerns as these systems are increasingly deployed at scale. Existing inference-time mitigation methods typically manipulate classifier-free guidance (CFG) or perturb prompt embeddings; however, they often struggle to reduce memorization without compromising alignment with the conditioning prompt. We introduce CAPTAIN, a training-free framework that mitigates memorization by directly modifying latent features during denoising. CAPTAIN first applies frequency-based noise initialization to reduce the tendency to replicate memorized patterns early in the denoising process. It then identifies the optimal denoising timesteps for feature injection and localizes memorized regions. Finally, CAPTAIN injects semantically aligned features from non-memorized reference images into localized latent regions, suppressing memorization while preserving prompt fidelity and visual quality. Our experiments show that CAPTAIN achieves substantial reductions in memorization compared to CFG-based baselines while maintaining strong alignment with the intended prompt.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-23] Refinement Contrastive Learning of Cell-Gene Associations for Unsupervised Cell Type Identification</p>
<p>【速读】：该论文旨在解决单细胞组学研究中无监督细胞类型识别的问题，特别是现有聚类方法因忽视细胞-基因关联而难以区分高度相似细胞类型的问题。其解决方案的关键在于提出了一种精炼对比学习框架（scRCL），通过引入两个对比分布对齐组件来挖掘可靠的细胞内在结构，并设计了一个精炼模块以整合基因相关性结构学习，从而增强细胞嵌入表示并捕捉潜在的细胞-基因关联关系，最终提升细胞类型识别的准确性与生物学合理性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10640">https://arxiv.org/abs/2512.10640</a><br>
<strong>作者</strong>: Liang Peng,Haopeng Liu,Yixuan Ye,Cheng Liu,Wenjun Shen,Si Wu,Hau-San Wong<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Unsupervised cell type identification is crucial for uncovering and characterizing heterogeneous populations in single cell omics studies. Although a range of clustering methods have been developed, most focus exclusively on intrinsic cellular structure and ignore the pivotal role of cell-gene associations, which limits their ability to distinguish closely related cell types. To this end, we propose a Refinement Contrastive Learning framework (scRCL) that explicitly incorporates cell-gene interactions to derive more informative representations. Specifically, we introduce two contrastive distribution alignment components that reveal reliable intrinsic cellular structures by effectively exploiting cell-cell structural relationships. Additionally, we develop a refinement module that integrates gene-correlation structure learning to enhance cell embeddings by capturing underlying cell-gene associations. This module strengthens connections between cells and their associated genes, refining the representation learning to exploiting biologically meaningful relationships. Extensive experiments on several single-cell RNA-seq and spatial transcriptomics benchmark datasets demonstrate that our method consistently outperforms state-of-the-art baselines in cell-type identification accuracy. Moreover, downstream biological analyses confirm that the recovered cell populations exhibit coherent gene-expression signatures, further validating the biological relevance of our approach. The code is available at this https URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-24] Phythesis: Physics-Guided Evolutionary Scene Synthesis for Energy-Efficient Data Center Design via <mark class="hl-label green">LLM</mark> s</p>
<p>【速读】：该论文旨在解决数据中心（Data Center, DC）设计中传统方法难以应对系统复杂性增长的问题，尤其是现有基于生成式AI的方案忽视物理规律与量化运行目标，导致设计方案不可靠、不满足严格的物理约束。其解决方案的关键在于提出Phythesis框架，通过融合大语言模型（Large Language Models, LLMs）与物理引导的进化优化策略，实现可直接用于仿真的场景自动生成（Simulation-Ready, SimReady），从而在保证物理合理性的同时提升能效。该框架采用双层迭代优化架构：第一层由LLM驱动生成三维布局并进行自评优化以改进拓扑结构，第二层基于物理信息识别最优设备参数及组合，最终在多尺度生成实验中显著提升生成成功率（+57.3%）和功率使用效率（PUE改善11.5%）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10611">https://arxiv.org/abs/2512.10611</a><br>
<strong>作者</strong>: Minghao LI,Ruihang Wang,Rui Tan,Yonggang Wen<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Neural and Evolutionary Computing (<a target="_blank" rel="noopener" href="http://cs.NE">cs.NE</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Data center (DC) infrastructure serves as the backbone to support the escalating demand for computing capacity. Traditional design methodologies that blend human expertise with specialized simulation tools scale poorly with the increasing system complexity. Recent studies adopt generative artificial intelligence to design plausible human-centric indoor layouts. However, they do not consider the underlying physics, making them unsuitable for the DC design that sets quantifiable operational objectives and strict physical constraints. To bridge the gap, we propose Phythesis, a novel framework that synergizes large language models (LLMs) and physics-guided evolutionary optimization to automate simulation-ready (SimReady) scene synthesis for energy-efficient DC design. Phythesis employs an iterative bi-level optimization architecture, where (i) the LLM-driven optimization level generates physically plausible three-dimensional layouts and self-criticizes them to refine the scene topology, and (ii) the physics-informed optimization level identifies the optimal asset parameters and selects the best asset combination. Experiments on three generation scales show that Phythesis achieves 57.3% generation success rate increase and 11.5% power usage effectiveness (PUE) improvement, compared with the vanilla LLM-based solution.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-25] NormCode: A Semi-Formal Language for Context-Isolated AI <mark class="hl-label green">Planning</mark></p>
<p>【速读】：该论文旨在解决多步工作流中大型语言模型（Large Language Model, LLM）调用所面临的上下文污染问题，即随着步骤推进，信息累积导致模型幻觉、混淆中间输出并偏离任务约束。其解决方案的关键在于提出 NormCode —— 一种半形式化语言，用于构建推理计划，通过结构化分解使每个步骤在数据隔离环境中运行，仅接收显式传递的输入，从而从设计上杜绝跨步骤污染。NormCode 明确区分语义操作（LLM驱动的推理，非确定性）与语法操作（确定性的数据重构），实现对成本和可靠性的精确追踪，并支持从草图到生产的渐进式形式化，最终提升高风险领域（如法律推理、医疗决策和金融分析）中AI工作流的可审计性和透明度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10563">https://arxiv.org/abs/2512.10563</a><br>
<strong>作者</strong>: Xin Guan<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multistep workflows that chain large language model (LLM) calls suffer from context pollution: as information accumulates across steps, models hallucinate, confuse intermediate outputs, and lose track of task constraints. We present NormCode, a semiformal language for constructing plans of inferences, structured decompositions where each step operates in data isolation and receives only explicitly passed inputs, which eliminates crossstep contamination by design. NormCode enforces a strict separation between semantic operations (LLMdriven reasoning, nondeterministic) and syntactic operations (deterministic data restructuring), enabling precise cost and reliability tracing. The language exists in three isomorphic formats: .ncds for human authoring, .ncd for machine execution, and .ncn for human verification, supporting progressive formalization from sketch to production. We validate NormCode through two demonstrations: (1) a base X addition algorithm achieving 100 percent accuracy on arbitrary length inputs, and (2) self hosted execution of NormCode’s own five phase compiler pipeline. The working orchestrator provides dependency driven scheduling, SQLite backed checkpointing, and loop management, making AI workflows auditable by design and addressing a critical need for transparency in high stakes domains such as legal reasoning, medical decision making, and financial analysis.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-26] <mark class="hl-label green">LLM</mark> -Auction: Generative Auction towards <mark class="hl-label green">LLM</mark> -Native Advertising</p>
<p>【速读】：该论文旨在解决生成式 AI（Generative AI）时代下大语言模型（Large Language Models, LLMs）原生广告（LLM-native advertising）中拍卖机制设计的挑战，即如何在不增加额外推理开销的前提下，将广告分配与LLM生成过程深度融合，从而实现对用户体验和广告主价值的协同优化。其解决方案的关键在于提出一种基于学习的生成式拍卖机制——LLM-Auction，该机制首次将拍卖决策与LLM生成过程统一建模，通过将分配优化转化为LLM输出与机制目标之间的偏好对齐问题，并引入迭代奖励-偏好优化（Iterative Reward-Preference Optimization, IRPO）算法，交替优化奖励模型与LLM本身，使LLM天然建模分配外部性（allocation externalities），同时保证分配单调性和连续性，进而支持简单的一价支付规则并具备良好激励相容性质。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10551">https://arxiv.org/abs/2512.10551</a><br>
<strong>作者</strong>: Chujie Zhao,Qun Hu,Shiping Song,Dagui Chen,Han Zhu,Jian Xu,Bo Zheng<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Science and Game Theory (<a target="_blank" rel="noopener" href="http://cs.GT">cs.GT</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The rapid advancement of large language models (LLMs) necessitates novel monetization strategies, among which LLM-native advertising has emerged as a promising paradigm by naturally integrating advertisement within LLM-generated responses. However, this paradigm fundamentally shifts the auction object from discrete ad slots to the distribution over LLM outputs, posing new challenges for designing auction mechanisms. Existing mechanisms for LLM-native advertising adopt frameworks that decouple auction and generation, which either ignore externalities or require multiple LLM inferences for ad allocation, rendering them impractical for industrial scenarios. To address these challenges, we propose LLM-Auction, which to the best of our knowledge is the first learning-based generative auction mechanism that integrates auction and LLM generation for LLM-native advertising. By formulating the allocation optimization as a preference alignment problem between LLM outputs and the mechanism’s objective which reflects both advertisers’ expected value and user experience, we introduce Iterative Reward-Preference Optimization (IRPO) algorithm that alternately optimizes the reward model and the LLM. This approach enables the LLM to inherently model allocation externalities without any extra inference cost. We further identify the allocation monotonicity and continuity of LLM-Auction, which allows us to prove that a simple first-price payment rule exhibits favorable incentive properties. Additionally, we design an LLM-as-a-judge simulation environment to facilitate large-scale data construction and enable comprehensive quantitative evaluation of the mechanism’s performance. Extensive quantitative and qualitative experiments demonstrate that LLM-Auction significantly outperforms existing baselines in allocation efficiency, while achieving the desired mechanism properties.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-27] Achieving Olympia-Level Geometry Large Language Model <mark class="hl-label green">Agent</mark>  via Complexity Boosting Reinforcement Learning</p>
<p>【速读】：该论文旨在解决生成式 AI 在几何问题求解中因辅助构造（auxiliary construction）启发式策略薄弱而导致的性能瓶颈问题，这一瓶颈使得当前基于大语言模型（Large Language Model, LLM）的代理在专家级几何任务上仍难以超越依赖大规模数据合成与搜索的专用模型（如AlphaGeometry 2）。解决方案的关键在于提出InternGeometry——一个具备迭代式命题提议、符号引擎验证与反馈反思机制的LLM代理架构，通过动态记忆机制实现单题超过200次与符号引擎的交互，并引入复杂度增强强化学习（Complexity-Boosting Reinforcement Learning, CBRL）逐步提升训练问题难度，从而以极低的数据量（仅13K训练样本）达成44/50道IMO几何题的准确率，超越金牌平均得分，且能提出人类未见的新辅助构造。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10534">https://arxiv.org/abs/2512.10534</a><br>
<strong>作者</strong>: Haiteng Zhao,Junhao Shen,Yiming Zhang,Songyang Gao,Kuikun Liu,Tianyou Ma,Fan Zheng,Dahua Lin,Wenwei Zhang,Kai Chen<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language model (LLM) agents exhibit strong mathematical problem-solving abilities and can even solve International Mathematical Olympiad (IMO) level problems with the assistance of formal proof systems. However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. In this work, we make the first attempt to build a medalist-level LLM agent for geometry and present InternGeometry. InternGeometry overcomes the heuristic limitations in geometry by iteratively proposing propositions and auxiliary constructions, verifying them with a symbolic engine, and reflecting on the engine’s feedback to guide subsequent proposals. A dynamic memory mechanism enables InternGeometry to conduct more than two hundred interactions with the symbolic engine per problem. To further accelerate learning, we introduce Complexity-Boosting Reinforcement Learning (CBRL), which gradually increases the complexity of synthesized problems across training stages. Built on InternThinker-32B, InternGeometry solves 44 of 50 IMO geometry problems (2000-2024), exceeding the average gold medalist score (40.9), using only 13K training examples, just 0.004% of the data used by AlphaGeometry 2, demonstrating the potential of LLM agents on expert-level geometry tasks. InternGeometry can also propose novel auxiliary constructions for IMO problems that do not appear in human solutions. We will release the model, data, and symbolic engine to support future research.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-28] Adaptive Replay Buffer for Offline-to-Online Reinforcement Learning</p>
<p>【速读】：该论文旨在解决离线到在线强化学习（Offline-to-Online Reinforcement Learning, O2O RL）中如何平衡固定离线数据集与新收集的在线经验之间的矛盾问题，尤其针对传统方法依赖固定数据混合比例导致早期学习不稳定和最终性能受限的挑战。其解决方案的关键在于提出一种无需学习的自适应回放缓冲区（Adaptive Replay Buffer, ARB），该机制基于一个轻量级指标“在线策略性”（on-policyness）动态调整数据采样权重：通过评估轨迹与当前策略行为的匹配程度，为每个transition分配相应采样权重，从而在初期有效利用离线数据保障稳定性，并随训练推进逐步聚焦于高回报的在线经验，实现行为感知的自适应学习。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10510">https://arxiv.org/abs/2512.10510</a><br>
<strong>作者</strong>: Chihyeon Song,Jaewoo Lee,Jinkyoo Park<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  15 pages, 3 figures, 7 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Offline-to-Online Reinforcement Learning (O2O RL) faces a critical dilemma in balancing the use of a fixed offline dataset with newly collected online experiences. Standard methods, often relying on a fixed data-mixing ratio, struggle to manage the trade-off between early learning stability and asymptotic performance. To overcome this, we introduce the Adaptive Replay Buffer (ARB), a novel approach that dynamically prioritizes data sampling based on a lightweight metric we call ‘on-policyness’. Unlike prior methods that rely on complex learning procedures or fixed ratios, ARB is designed to be learning-free and simple to implement, seamlessly integrating into existing O2O RL algorithms. It assesses how closely collected trajectories align with the current policy’s behavior and assigns a proportional sampling weight to each transition within that trajectory. This strategy effectively leverages offline data for initial stability while progressively focusing learning on the most relevant, high-rewarding online experiences. Our extensive experiments on D4RL benchmarks demonstrate that ARB consistently mitigates early performance degradation and significantly improves the final performance of various O2O RL algorithms, highlighting the importance of an adaptive, behavior-aware replay buffer design.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-29] Zero-shot 3D Map Generation with <mark class="hl-label green">LLM</mark>  <mark class="hl-label green">Agents</mark> <mark class="hl-label green">Agent</mark> s: A Dual-Agent Architecture for Procedural Content Generation</p>
<p>【速读】：该论文旨在解决生成式内容生成（Procedural Content Generation, PCG）中参数配置难以控制的问题，即如何将自然语言指令准确映射到复杂的、不透明的技术参数上。传统方法依赖人工调参或任务特定的模型训练，效率低且泛化能力差。解决方案的关键在于提出一种无需训练的架构，通过协作式双代理系统——Actor代理负责生成初始参数配置，Critic代理则评估并反馈优化建议，形成迭代推理流程，从而在无需微调的前提下实现对PCG工具的零样本（zero-shot）参数配置。该方法利用现成的大语言模型（Large Language Models, LLMs）作为通用智能体，显著提升了PCG系统对用户意图的理解与执行能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10501">https://arxiv.org/abs/2512.10501</a><br>
<strong>作者</strong>: Lim Chien Her,Ming Yan,Yunshu Bai,Ruihao Li,Hao Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Procedural Content Generation (PCG) offers scalable methods for algorithmically creating complex, customizable worlds. However, controlling these pipelines requires the precise configuration of opaque technical parameters. We propose a training-free architecture that utilizes LLM agents for zero-shot PCG parameter configuration. While Large Language Models (LLMs) promise a natural language interface for PCG tools, off-the-shelf models often fail to bridge the semantic gap between abstract user instructions and strict parameter specifications. Our system pairs an Actor agent with a Critic agent, enabling an iterative workflow where the system autonomously reasons over tool parameters and refines configurations to progressively align with human design preferences. We validate this approach on the generation of various 3D maps, establishing a new benchmark for instruction-following in PCG. Experiments demonstrate that our approach outperforms single-agent baselines, producing diverse and structurally valid environments from natural language descriptions. These results demonstrate that off-the-shelf LLMs can be effectively repurposed as generalized agents for arbitrary PCG tools. By shifting the burden from model training to architectural reasoning, our method offers a scalable framework for mastering complex software without task-specific fine-tuning.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-30] UACER: An Uncertainty-Aware Critic Ensemble Framework for Robust Adversarial Reinforcement Learning</p>
<p>【速读】：该论文旨在解决对抗性强化学习（Adversarial Reinforcement Learning, Adversarial RL）中由于对手（adversary）可训练性导致的学习动态非平稳性问题，从而引发训练不稳定和收敛困难，尤其在高维复杂环境中的表现受限。其解决方案的关键在于提出一种名为不确定性感知的评论家集成方法（Uncertainty-Aware Critic Ensemble for robust adversarial Reinforcement learning, UACER），包含两个核心策略：一是采用并行的多样化评论家集成（Diversified critic ensemble），通过K个独立评论家网络实现Q值估计的方差降低与鲁棒性增强；二是引入时间变化衰减不确定性（Time-varying Decay Uncertainty, TDU）机制，基于认知不确定性（epistemic uncertainty）设计方差驱动的Q值聚合策略，动态调节探索-利用权衡，同时提升训练稳定性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10492">https://arxiv.org/abs/2512.10492</a><br>
<strong>作者</strong>: Jiaxi Wu,Tiantian Zhang,Yuxing Wang,Yongzhe Chang,Xueqian Wang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Robust adversarial reinforcement learning has emerged as an effective paradigm for training agents to handle uncertain disturbance in real environments, with critical applications in sequential decision-making domains such as autonomous driving and robotic control. Within this paradigm, agent training is typically formulated as a zero-sum Markov game between a protagonist and an adversary to enhance policy robustness. However, the trainable nature of the adversary inevitably induces non-stationarity in the learning dynamics, leading to exacerbated training instability and convergence difficulties, particularly in high-dimensional complex environments. In this paper, we propose a novel approach, Uncertainty-Aware Critic Ensemble for robust adversarial Reinforcement learning (UACER), which consists of two strategies: 1) Diversified critic ensemble: a diverse set of K critic networks is exploited in parallel to stabilize Q-value estimation rather than conventional single-critic architectures for both variance reduction and robustness enhancement. 2) Time-varying Decay Uncertainty (TDU) mechanism: advancing beyond simple linear combinations, we develop a variance-derived Q-value aggregation strategy that explicitly incorporates epistemic uncertainty to dynamically regulate the exploration-exploitation trade-off while simultaneously stabilizing the training process. Comprehensive experiments across several MuJoCo control problems validate the superior effectiveness of UACER, outperforming state-of-the-art methods in terms of overall performance, stability, and efficiency.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-31] -SKM-Net: Trainable Neural Network Framework for Linear Constraint Satisfaction via Sampling Kaczmarz-Motzkin Method</p>
<p>【速读】：该论文旨在解决神经网络在安全关键场景下约束满足问题的效率与适用性权衡难题，特别是针对传统硬约束方法因计算复杂度高或对约束结构假设过于严格而导致的应用局限。其解决方案的关键在于首次系统性地将采样Kaczmarz-Motzkin（Sampling Kaczmarz-Motzkin, SKM）类算法集成到神经网络约束满足框架中，提出可训练的SKM网络（Trainable Sampling Kaczmarz-Motzkin Network, T-SKM-Net）。该框架通过零空间变换将混合约束问题转化为纯不等式问题，利用SKM进行迭代求解，并将解映射回原始约束空间，从而高效处理等式与不等式约束；同时理论证明了后处理机制在期望下的有效性及端到端可训练性，基于无偏梯度估计器确保即使存在非可微的argmax操作仍支持标准反向传播。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10461">https://arxiv.org/abs/2512.10461</a><br>
<strong>作者</strong>: Haoyu Zhu,Yao Zhang,Jiashen Ren,Qingchun Hou<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Optimization and Control (math.OC)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Neural network constraint satisfaction is crucial for safety-critical applications such as power system optimization, robotic path planning, and autonomous driving. However, existing constraint satisfaction methods face efficiency-applicability trade-offs, with hard constraint methods suffering from either high computational complexity or restrictive assumptions on constraint structures. The Sampling Kaczmarz-Motzkin (SKM) method is a randomized iterative algorithm for solving large-scale linear inequality systems with favorable convergence properties, but its argmax operations introduce non-differentiability, posing challenges for neural network applications. This work proposes the Trainable Sampling Kaczmarz-Motzkin Network (T-SKM-Net) framework and, for the first time, systematically integrates SKM-type methods into neural network constraint satisfaction. The framework transforms mixed constraint problems into pure inequality problems through null space transformation, employs SKM for iterative solving, and maps solutions back to the original constraint space, efficiently handling both equality and inequality constraints. We provide theoretical proof of post-processing effectiveness in expectation and end-to-end trainability guarantees based on unbiased gradient estimators, demonstrating that despite non-differentiable operations, the framework supports standard backpropagation. On the DCOPF case118 benchmark, our method achieves 4.27ms/item GPU serial forward inference with 0.0025% max optimality gap with post-processing mode and 5.25ms/item with 0.0008% max optimality gap with joint training mode, delivering over 25 \times  speedup compared to the pandapower solver while maintaining zero constraint violations under given tolerance.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-32] Clustered Federated Learning with Hierarchical Knowledge Distillation</p>
<p>【速读】：该论文旨在解决传统聚类联邦学习（Clustered Federated Learning, CFL）中因独立训练各簇全局模型而导致的学习碎片化问题，以及无法有效利用跨簇集体知识的局限性。其解决方案的关键在于提出一种分层CFL框架（Hierarchical CFL），通过双层聚合机制实现边缘侧的簇特定模型与云端统一全局模型的协同训练；并进一步设计CFLHKD方法，基于多教师知识蒸馏（multi-teacher knowledge distillation）实现簇间知识共享的同时保持簇内个性化，从而在提升模型准确率（相较基线提升3.32%-7.57%）的同时优化通信效率和学习一致性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10443">https://arxiv.org/abs/2512.10443</a><br>
<strong>作者</strong>: Sabtain Ahmad,Meerzhan Kanatbekova,Ivona Brandic,Atakan Aral<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Clustered Federated Learning (CFL) has emerged as a powerful approach for addressing data heterogeneity and ensuring privacy in large distributed IoT environments. By clustering clients and training cluster-specific models, CFL enables personalized models tailored to groups of heterogeneous clients. However, conventional CFL approaches suffer from fragmented learning for training independent global models for each cluster and fail to take advantage of collective cluster insights. This paper advocates a shift to hierarchical CFL, allowing bi-level aggregation to train cluster-specific models at the edge and a unified global model at the cloud. This shift improves training efficiency yet might introduce communication challenges. To this end, we propose CFLHKD, a novel personalization scheme for integrating hierarchical cluster knowledge into CFL. Built upon multi-teacher knowledge distillation, CFLHKD enables inter-cluster knowledge sharing while preserving cluster-specific personalization. CFLHKD adopts a bi-level aggregation to bridge the gap between local and global learning. Extensive evaluations of standard benchmark datasets demonstrate that CFLHKD outperforms representative baselines in cluster-specific and global model accuracy and achieves a performance improvement of 3.32-7.57%.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-33] argeted Data Protection for Diffusion Model by Matching Training Trajectory <mark class="hl-label red">AAAI2026</mark></p>
<p>【速读】：该论文旨在解决扩散模型（diffusion models）在个性化微调过程中存在的未经授权数据使用和隐私侵犯问题，尤其是现有保护方法仅能被动降低图像质量而缺乏稳定控制能力的局限性。针对这一挑战，论文提出了一种名为TAFAP（Trajectory Alignment via Fine-tuning with Adversarial Perturbations）的新方案，其关键在于通过对抗扰动引导微调轨迹（fine-tuning trajectory）实现对模型学习过程的全程可控，而非依赖于训练快照匹配的局部优化策略。TAFAP借鉴数据蒸馏（dataset distillation）思想，确保在整个训练过程中持续、可验证地将模型输出导向用户指定的目标概念，从而首次实现了在保持高图像质量的同时，对身份与视觉模式的双重可控重定向，显著优于现有目标数据保护（Targeted Data Protection, TDP）方法。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10433">https://arxiv.org/abs/2512.10433</a><br>
<strong>作者</strong>: Hojun Lee,Mijin Koo,Yeji Song,Nojun Kwak<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  AAAI 2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advancements in diffusion models have made fine-tuning text-to-image models for personalization increasingly accessible, but have also raised significant concerns regarding unauthorized data usage and privacy infringement. Current protection methods are limited to passively degrading image quality, failing to achieve stable control. While Targeted Data Protection (TDP) offers a promising paradigm for active redirection toward user-specified target concepts, existing TDP attempts suffer from poor controllability due to snapshot-matching approaches that fail to account for complete learning dynamics. We introduce TAFAP (Trajectory Alignment via Fine-tuning with Adversarial Perturbations), the first method to successfully achieve effective TDP by controlling the entire training trajectory. Unlike snapshot-based methods whose protective influence is easily diluted as training progresses, TAFAP employs trajectory-matching inspired by dataset distillation to enforce persistent, verifiable transformations throughout fine-tuning. We validate our method through extensive experiments, demonstrating the first successful targeted transformation in diffusion models with simultaneous control over both identity and visual patterns. TAFAP significantly outperforms existing TDP attempts, achieving robust redirection toward target concepts while maintaining high image quality. This work enables verifiable safeguards and provides a new framework for controlling and tracing alterations in diffusion model outputs.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-34] Representation of the structure of graphs by sequences of instructions</p>
<p>【速读】：该论文试图解决的问题是：如何将图结构数据（graph）转化为适合深度学习语言模型处理的表示形式。当前基于邻接矩阵（adjacency matrix）的传统图表示方法无法直接适配以文本处理为核心的深度学习模型。解决方案的关键在于提出一种新的图表示方法，即通过一系列简单指令字符串来逐步构建邻接矩阵，该表示方式具有可逆性（即可从图生成字符串，也可从字符串还原图），且保持了图的局部结构特征，从而为利用生成式 AI (Generative AI) 等强大文本处理模型提升图数据的计算效率提供了可能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10429">https://arxiv.org/abs/2512.10429</a><br>
<strong>作者</strong>: Ezequiel Lopez-Rubio<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The representation of graphs is commonly based on the adjacency matrix concept. This formulation is the foundation of most algebraic and computational approaches to graph processing. The advent of deep learning language models offers a wide range of powerful computational models that are specialized in the processing of text. However, current procedures to represent graphs are not amenable to processing by these models. In this work, a new method to represent graphs is proposed. It represents the adjacency matrix of a graph by a string of simple instructions. The instructions build the adjacency matrix step by step. The transformation is reversible, i.e. given a graph the string can be produced and vice versa. The proposed representation is compact and it maintains the local structural patterns of the graph. Therefore, it is envisaged that it could be useful to boost the processing of graphs by deep learning models. A tentative computational experiment is reported, with favorable results.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-35] How to Trick Your AI TA: A Systematic Study of Academic Jailbreaking in <mark class="hl-label green">LLM</mark>  Code Evaluation</p>
<p>【速读】：该论文旨在解决生成式 AI（Generative AI）在学术代码评估中因学生采用对抗性提示（adversarial prompting）策略而导致误判和不公平评分的问题。其解决方案的关键在于：首次系统性地构建了一类名为“学术越狱”（academic jailbreaking）的攻击方法，涵盖20余种攻击策略，并发布了一个包含25,000条对抗样本的学生提交数据集，配套真实课程评分标准与人工标注参考答案；同时定义了三种量化指标（越狱成功率、分数膨胀率和危害性）以全面评估攻击效果。实验表明，当前六种主流大语言模型（LLMs）对说服型和角色扮演型攻击尤为脆弱（最高越狱成功率达97%），该研究为开发更具鲁棒性的下一代学术代码自动评估系统奠定了基础。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10415">https://arxiv.org/abs/2512.10415</a><br>
<strong>作者</strong>: Devanshu Sahoo,Vasudev Majhi,Arjun Neekhra,Yash Sinha,Murari Mandal,Dhruv Kumar<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: oftware Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Under Review</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The use of Large Language Models (LLMs) as automatic judges for code evaluation is becoming increasingly prevalent in academic environments. But their reliability can be compromised by students who may employ adversarial prompting strategies in order to induce misgrading and secure undeserved academic advantages. In this paper, we present the first large-scale study of jailbreaking LLM-based automated code evaluators in academic context. Our contributions are: (i) We systematically adapt 20+ jailbreaking strategies for jailbreaking AI code evaluators in the academic context, defining a new class of attacks termed academic jailbreaking. (ii) We release a poisoned dataset of 25K adversarial student submissions, specifically designed for the academic code-evaluation setting, sourced from diverse real-world coursework and paired with rubrics and human-graded references, and (iii) In order to capture the multidimensional impact of academic jailbreaking, we systematically adapt and define three jailbreaking metrics (Jailbreak Success Rate, Score Inflation, and Harmfulness). (iv) We comprehensively evalulate the academic jailbreaking attacks using six LLMs. We find that these models exhibit significant vulnerability, particularly to persuasive and role-play-based attacks (up to 97% JSR). Our adversarial dataset and benchmark suite lay the groundwork for next-generation robust LLM-based evaluators in academic code assessment.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-36] Boosting RL-Based Visual <mark class="hl-label green">Reasoning</mark>  with Selective Adversarial Entropy Intervention</p>
<p>【速读】：该论文旨在解决当前基于强化学习（Reinforcement Learning, RL）的视觉语言模型（Vision-Language Models, VLMs）微调中，策略熵不足导致推理能力受限的问题。现有方法通常仅在RL策略优化阶段通过控制特定token的更新来干预熵，忽略了在RL采样阶段引入熵干预对提升响应多样性与探索能力的重要性。其解决方案的关键在于提出一种选择性对抗熵干预（Selective-adversarial Entropy Intervention, SaEI），包含两个核心组件：一是熵引导的对抗采样（Entropy-guided Adversarial Sampling, EgAS），将采样响应的熵作为对抗目标，生成对抗样本以扩展策略在采样阶段的答案空间；二是token选择性熵计算（Token-selective Entropy Computation, TsEC），在不破坏VLM中事实知识的前提下最大化对抗攻击的有效性。实验证明，该方法显著提升了策略探索能力，从而增强VLM的推理性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10414">https://arxiv.org/abs/2512.10414</a><br>
<strong>作者</strong>: Yang Yu,Zhuangzhuang Chen,Siqi Wang,Lanqing Li,Xiaomeng Li<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recently, reinforcement learning (RL) has become a common choice in enhancing the reasoning capabilities of vision-language models (VLMs). Considering existing RL- based finetuning methods, entropy intervention turns out to be an effective way to benefit exploratory ability, thereby improving policy performance. Notably, most existing stud- ies intervene in entropy by simply controlling the update of specific tokens during policy optimization of RL. They ig- nore the entropy intervention during the RL sampling that can boost the performance of GRPO by improving the di- versity of responses. In this paper, we propose Selective- adversarial Entropy Intervention, namely SaEI, which en- hances policy entropy by distorting the visual input with the token-selective adversarial objective coming from the en- tropy of sampled responses. Specifically, we first propose entropy-guided adversarial sampling (EgAS) that formu- lates the entropy of sampled responses as an adversarial ob- jective. Then, the corresponding adversarial gradient can be used to attack the visual input for producing adversarial samples, allowing the policy model to explore a larger an- swer space during RL sampling. Then, we propose token- selective entropy computation (TsEC) to maximize the ef- fectiveness of adversarial attack in EgAS without distorting factual knowledge within VLMs. Extensive experiments on both in-domain and out-of-domain datasets show that our proposed method can greatly improve policy exploration via entropy intervention, to boost reasoning capabilities. Code will be released once the paper is accepted.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-37] he Eminence in Shadow: Exploiting Feature Boundary Ambiguity for Robust Backdoor Attacks <mark class="hl-label red">KDD2026</mark></p>
<p>【速读】：该论文旨在解决深度神经网络（Deep Neural Networks, DNNs）在关键应用中易受后门攻击（Backdoor Attacks）的问题，尤其针对现有方法依赖启发式暴力搜索、缺乏理论支撑导致攻击不可预测和难以适应的局限性。解决方案的关键在于通过理论分析揭示稀疏决策边界（Sparse Decision Boundaries）如何使模型对少量标记样本的扰动高度敏感，并由此推导出一个闭合形式的模糊边界区域（Ambiguous Boundary Region），在此区域内极小比例的污染样本即可引发显著误分类；进一步利用影响函数（Influence Function）量化了这些边缘样本引起的参数偏移，证明其对干净准确率影响微弱，从而从理论上解释为何低毒率（如0.1%）即可实现高效攻击。基于此，作者提出Eminence框架，该框架具备可解释性和鲁棒性，能在黑盒场景下生成视觉上隐蔽的通用触发器（Universal Trigger），并提供可证明的理论保障与内在隐蔽特性，实验证明其在保持90%以上攻击成功率的同时几乎不损失干净准确率，且具有强迁移性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10402">https://arxiv.org/abs/2512.10402</a><br>
<strong>作者</strong>: Zhou Feng,Jiahao Chen,Chunyi Zhou,Yuwen Pu,Tianyu Du,Jinbao Li,Jianhai Chen,Shouling Ji<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Accepted by KDD2026 Cycle 1 Research Track</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Deep neural networks (DNNs) underpin critical applications yet remain vulnerable to backdoor attacks, typically reliant on heuristic brute-force methods. Despite significant empirical advancements in backdoor research, the lack of rigorous theoretical analysis limits understanding of underlying mechanisms, constraining attack predictability and adaptability. Therefore, we provide a theoretical analysis targeting backdoor attacks, focusing on how sparse decision boundaries enable disproportionate model manipulation. Based on this finding, we derive a closed-form, ambiguous boundary region, wherein negligible relabeled samples induce substantial misclassification. Influence function analysis further quantifies significant parameter shifts caused by these margin samples, with minimal impact on clean accuracy, formally grounding why such low poison rates suffice for efficacious attacks. Leveraging these insights, we propose Eminence, an explainable and robust black-box backdoor framework with provable theoretical guarantees and inherent stealth properties. Eminence optimizes a universal, visually subtle trigger that strategically exploits vulnerable decision boundaries and effectively achieves robust misclassification with exceptionally low poison rates ( 0.1%, compared to SOTA methods typically requiring  1%). Comprehensive experiments validate our theoretical discussions and demonstrate the effectiveness of Eminence, confirming an exponential relationship between margin poisoning and adversarial boundary manipulation. Eminence maintains  90% attack success rate, exhibits negligible clean-accuracy loss, and demonstrates high transferability across diverse models, datasets and scenarios.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-38] Cross-modal Retrieval Models for Stripped Binary Analysis</p>
<p>【速读】：该论文旨在解决在无符号信息（stripped binary code）环境下，基于大语言模型（LLM）的Agent工作流中如何从数千个二进制函数中高效检索与用户查询语义相关的正样本这一挑战。传统源代码检索依赖符号信息，而二进制代码缺乏此类结构化语义线索，使得跨模态匹配尤为困难。解决方案的关键在于提出首个两阶段跨模态检索框架BinSeek：第一阶段使用BinSeekEmbedding模型在大规模数据集上学习二进制代码与自然语言描述之间的语义关联；第二阶段通过BinSeek-Reranker模型结合上下文增强机制精细判断候选代码与描述的相关性。此外，作者构建了基于LLM的数据合成流水线以自动化训练数据生成，并建立了领域专用基准，显著提升了检索性能，在Rec@3和MRR@3指标上超越同等规模模型31.42%和27.17%，并优于参数量大16倍的通用先进模型。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10393">https://arxiv.org/abs/2512.10393</a><br>
<strong>作者</strong>: Guoqiang Chen,Lingyun Ying,Ziyang Song,Daguang Liu,Qiang Wang,Zhiqi Wang,Li Hu,Shaoyin Cheng,Weiming Zhang,Nenghai Yu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: oftware Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:LLM-agent based binary code analysis has demonstrated significant potential across a wide range of software security scenarios, including vulnerability detection, malware analysis, etc. In agent workflow, however, retrieving the positive from thousands of stripped binary functions based on user query remains under-studied and challenging, as the absence of symbolic information distinguishes it from source code retrieval. In this paper, we introduce, BinSeek, the first two-stage cross-modal retrieval framework for stripped binary code analysis. It consists of two models: BinSeekEmbedding is trained on large-scale dataset to learn the semantic relevance of the binary code and the natural language description, furthermore, BinSeek-Reranker learns to carefully judge the relevance of the candidate code to the description with context augmentation. To this end, we built an LLM-based data synthesis pipeline to automate training construction, also deriving a domain benchmark for future research. Our evaluation results show that BinSeek achieved the state-of-the-art performance, surpassing the the same scale models by 31.42% in Rec@3 and 27.17% in MRR@3, as well as leading the advanced general-purpose models that have 16 times larger parameters.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-39] he Best of the Two Worlds: Harmonizing Semantic and Hash IDs for Sequential Recommendation</p>
<p>【速读】：该论文旨在解决传统序列推荐系统（Sequential Recommender Systems, SRS）中因使用唯一哈希ID（Hash ID, HID）构建物品嵌入而导致的长尾问题（long-tail problem），即大多数物品因历史交互稀疏而难以有效建模；同时，现有融合辅助信息的方法常受共现信号噪声或扁平密集嵌入导致的语义同质性影响。其解决方案的关键在于提出一种名为\name的新框架，通过双分支建模架构同时保留HID的独特协同身份与语义ID（Semantic ID, SID）的多粒度语义建模能力，并引入双层对齐策略实现两种表示间的知识迁移与互补，从而在头部和尾部物品上均实现更稳健的推荐性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10388">https://arxiv.org/abs/2512.10388</a><br>
<strong>作者</strong>: Ziwei Liu,Yejing Wang,Qidong Liu,Zijian Zhang,Chong Chen,Wei Huang,Xiangyu Zhao<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Conventional Sequential Recommender Systems (SRS) typically assign unique Hash IDs (HID) to construct item embeddings. These HID embeddings effectively learn collaborative information from historical user-item interactions, making them vulnerable to situations where most items are rarely consumed (the long-tail problem). Recent methods that incorporate auxiliary information often suffer from noisy collaborative sharing caused by co-occurrence signals or semantic homogeneity caused by flat dense embeddings. Semantic IDs (SIDs), with their capability of code sharing and multi-granular semantic modeling, provide a promising alternative. However, the collaborative overwhelming phenomenon hinders the further development of SID-based methods. The quantization mechanisms commonly compromise the uniqueness of identifiers required for modeling head items, creating a performance seesaw between head and tail items. To address this dilemma, we propose \textbf\name, a novel framework that harmonizes the SID and HID. Specifically, we devise a dual-branch modeling architecture that enables the model to capture both the multi-granular semantics within SID while preserving the unique collaborative identity of HID. Furthermore, we introduce a dual-level alignment strategy that bridges the two representations, facilitating knowledge transfer and supporting robust preference modeling. Extensive experiments on three real-world datasets show that \name~ effectively balances recommendation quality for both head and tail items while surpassing the existing baselines. The implementation code can be found online\footnotethis https URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-40] Neural personal sound zones with flexible bright zone control</p>
<p>【速读】：该论文旨在解决个人声区（Personal Sound Zone, PSZ）再现系统在实际应用中因需使用固定接收麦克风阵列来测量重建目标，导致系统灵活性差且成本高的问题。解决方案的关键在于提出一种基于三维卷积神经网络（3D CNN）的PSZ再现方法，该方法以虚拟目标声场作为输入，输出对应的PSZ预滤波器，从而实现仅通过一次训练即可适应灵活的控制麦克风网格和不同的再现目标，并能从稀疏分布的采样点中学习全局空间信息，显著提升了系统的实用性与适应性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10375">https://arxiv.org/abs/2512.10375</a><br>
<strong>作者</strong>: Wenye Zhu,Jun Tang,Xiaofei Li<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: ound (<a target="_blank" rel="noopener" href="http://cs.SD">cs.SD</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Personal sound zone (PSZ) reproduction system, which attempts to create distinct virtual acoustic scenes for different listeners at their respective positions within the same spatial area using one loudspeaker array, is a fundamental technology in the application of virtual reality. For practical applications, the reconstruction targets must be measured on the same fixed receiver array used to record the local room impulse responses (RIRs) from the loudspeaker array to the control points in each PSZ, which makes the system inconvenient and costly for real-world use. In this paper, a 3D convolutional neural network (CNN) designed for PSZ reproduction with flexible control microphone grid and alternative reproduction target is presented, utilizing the virtual target scene as inputs and the PSZ pre-filters as output. Experimental results of the proposed method are compared with the traditional method, demonstrating that the proposed method is able to handle varied reproduction targets on flexible control point grid using only one training session. Furthermore, the proposed method also demonstrates the capability to learn global spatial information from sparse sampling points distributed in PSZs.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-41] D2M: A Decentralized Privacy-Preserving Incentive-Compatible Data Marketplace for Collaborative Learning</p>
<p>【速读】：该论文旨在解决协同机器学习与数据分析中数据隐私保护、信任机制与激励相容性难以兼顾的问题。现有方案如联邦学习（Federated Learning, FL）依赖可信聚合节点且缺乏拜占庭鲁棒性，而基于区块链的数据市场在计算密集型训练任务和激励机制整合方面存在瓶颈。其核心解决方案是提出 \prot，一个统一联邦学习、区块链仲裁与经济激励的去中心化数据交易平台：通过智能合约管理竞拍、资金托管与争议解决；将训练任务委托给链下分布式执行层 \cone（Compute Network for Execution）以提升效率；引入改进的 YODA 协议实现抗恶意行为的共识机制，并采用 Corrected OSMD 算法抑制低质量或恶意贡献，确保所有协议激励相容，理论分析证明诚实参与为占优策略。实验表明，\prot 在 MNIST 和 Fashion-MNIST 上准确率达 99% 和 90%，即使面对高达 30% 的拜占庭节点仍保持稳定性能，且在复杂 CIFAR-10 数据集上达到 56% 准确率，验证了其隐私保护能力、抗干扰鲁棒性和可扩展性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10372">https://arxiv.org/abs/2512.10372</a><br>
<strong>作者</strong>: Yash Srivastava,Shalin Jain,Sneha Awathare,Nitin Awathare<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The rising demand for collaborative machine learning and data analytics calls for secure and decentralized data sharing frameworks that balance privacy, trust, and incentives. Existing approaches, including federated learning (FL) and blockchain-based data markets, fall short: FL often depends on trusted aggregators and lacks Byzantine robustness, while blockchain frameworks struggle with computation-intensive training and incentive integration. We present \prot, a decentralized data marketplace that unifies federated learning, blockchain arbitration, and economic incentives into a single framework for privacy-preserving data sharing. \prot\ enables data buyers to submit bid-based requests via blockchain smart contracts, which manage auctions, escrow, and dispute resolution. Computationally intensive training is delegated to \cone\ (\ulineCompute \ulineNetwork for \ulineExecution), an off-chain distributed execution layer. To safeguard against adversarial behavior, \prot\ integrates a modified YODA protocol with exponentially growing execution sets for resilient consensus, and introduces Corrected OSMD to mitigate malicious or low-quality contributions from sellers. All protocols are incentive-compatible, and our game-theoretic analysis establishes honesty as the dominant strategy. We implement \prot\ on Ethereum and evaluate it over benchmark datasets – MNIST, Fashion-MNIST, and CIFAR-10 – under varying adversarial settings. \prot\ achieves up to 99% accuracy on MNIST and 90% on Fashion-MNIST, with less than 3% degradation up to 30% Byzantine nodes, and 56% accuracy on CIFAR-10 despite its complexity. Our results show that \prot\ ensures privacy, maintains robustness under adversarial conditions, and scales efficiently with the number of participants, making it a practical foundation for real-world decentralized data sharing.         Subjects:  Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)  Cite as: arXiv:2512.10372 [<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>]    (or  arXiv:2512.10372v1 [<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10372">https://doi.org/10.48550/arXiv.2512.10372</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-42] <mark class="hl-label green">Agent</mark> Prog: Empowering Long-Horizon GUI <mark class="hl-label green">Agents</mark>  with Program-Guided Context Management</p>
<p>【速读】：该论文旨在解决移动图形用户界面（GUI）智能体在执行长时程任务自动化时面临的上下文管理瓶颈问题，即交互历史不断增长导致的上下文开销过大，而现有上下文管理和压缩技术往往无法保留关键语义信息，从而造成任务性能下降。其解决方案的关键在于提出AgentProg，一种基于程序引导的上下文管理方法，将交互历史重构为具有变量和控制流结构的程序，利用程序结构提供一种原则性的机制来决定保留或丢弃信息；同时引入受Belief MDP框架启发的全局信念状态机制，以应对部分可观测性并适应环境中的意外变化，从而在AndroidWorld及扩展的长时程任务基准上实现最优成功率，并保持对长时程任务的鲁棒性表现。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10371">https://arxiv.org/abs/2512.10371</a><br>
<strong>作者</strong>: Shizuo Tian,Hao Wen,Yuxuan Chen,Jiacheng Liu,Shanhui Zhao,Guohong Liu,Ju Ren,Yunxin Liu,Yuanchun Li<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  16 pages, 8 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The rapid development of mobile GUI agents has stimulated growing research interest in long-horizon task automation. However, building agents for these tasks faces a critical bottleneck: the reliance on ever-expanding interaction history incurs substantial context overhead. Existing context management and compression techniques often fail to preserve vital semantic information, leading to degraded task performance. We propose AgentProg, a program-guided approach for agent context management that reframes the interaction history as a program with variables and control flow. By organizing information according to the structure of program, this structure provides a principled mechanism to determine which information should be retained and which can be discarded. We further integrate a global belief state mechanism inspired by Belief MDP framework to handle partial observability and adapt to unexpected environmental changes. Experiments on AndroidWorld and our extended long-horizon task suite demonstrate that AgentProg has achieved the state-of-the-art success rates on these benchmarks. More importantly, it maintains robust performance on long-horizon tasks while baseline methods experience catastrophic degradation. Our system is open-sourced at this https URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-43] <mark class="hl-label green">LLM</mark> -Empowered Representation Learning for Emerging Item Recommendation</p>
<p>【速读】：该论文旨在解决新兴物品（emerging items）推荐问题，即在物品交互数据随时间逐步积累的过程中，如何有效学习其代表性嵌入表示。现有方法通常假设新兴物品缺乏历史交互数据，忽略了其动态演化特性，导致无法充分捕捉新兴物品的独特性与已有物品之间的共享模式。解决方案的关键在于提出EmerFlow框架，该框架利用大语言模型（LLM）增强新兴物品的原始特征表示，并通过元学习机制将新交互信息融入嵌入空间，从而在仅有少量交互的情况下生成具有表达力的嵌入表示。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10370">https://arxiv.org/abs/2512.10370</a><br>
<strong>作者</strong>: Ziying Zhang,Quanming Yao,Yaqing Wang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In this work, we tackle the challenge of recommending emerging items, whose interactions gradually accumulate over time. Existing methods often overlook this dynamic process, typically assuming that emerging items have few or even no historical interactions. Such an assumption oversimplifies the problem, as a good model must preserve the uniqueness of emerging items while leveraging their shared patterns with established ones. To address this challenge, we propose EmerFlow, a novel LLM-empowered representation learning framework that generates distinctive embeddings for emerging items. It first enriches the raw features of emerging items through LLM reasoning, then aligns these representations with the embedding space of the existing recommendation model. Finally, new interactions are incorporated through meta-learning to refine the embeddings. This enables EmerFlow to learn expressive embeddings for emerging items from only limited interactions. Extensive experiments across diverse domains, including movies and pharmaceuticals, show that EmerFlow consistently outperforms existing methods.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-44] Dynamics of <mark class="hl-label green">Agent</mark> ic Loops in <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark> : A Geometric Theory of Trajectories</p>
<p>【速读】：该论文旨在解决基于大语言模型（Large Language Models, LLMs）的智能体系统（Agentic Systems）在迭代反馈循环中几何行为不明确的问题，特别是这些循环是否收敛、发散或呈现更复杂的动力学特性。其核心挑战在于现有方法难以对语义嵌入空间中的轨迹进行精确测量，且常用相似度指标（如余弦相似度）受嵌入各向异性干扰，导致结果偏差。解决方案的关键在于构建一个几何框架，将语言变换过程与嵌入空间中的几何分析分离，并引入各向同性校准（isotonic calibration）以消除系统性偏差，使相似度度量更贴近人类语义判断，同时保持局部稳定性。这一方法使得能够准确刻画轨迹、聚类和吸引子结构，并通过控制实验识别出两种基本动力学模式：收缩重写环（contractive rewriting loop）趋向稳定吸引子，而探索式总结与否定环（exploratory summarize and negate loop）则呈现无界发散，从而揭示提示设计直接决定迭代LLM变换的动力学状态，实现对收敛性、发散性和轨迹结构的系统性调控。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10350">https://arxiv.org/abs/2512.10350</a><br>
<strong>作者</strong>: Nicolas Tacheny<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Agentic systems built on large language models operate through recursive feedback loops, where each output becomes the next input. Yet the geometric behavior of these agentic loops (whether they converge, diverge, or exhibit more complex dynamics) remains poorly understood. This paper introduces a geometric framework for analyzing agentic trajectories in semantic embedding space, treating iterative transformations as discrete dynamical systems. We distinguish the artifact space, where linguistic transformations occur, from the embedding space, where geometric measurements are performed. Because cosine similarity is biased by embedding anisotropy, we introduce an isotonic calibration that eliminates systematic bias and aligns similarities with human semantic judgments while preserving high local stability. This enables rigorous measurement of trajectories, clusters and attractors. Through controlled experiments on singular agentic loops, we identify two fundamental regimes. A contractive rewriting loop converges toward a stable attractor with decreasing dispersion, while an exploratory summarize and negate loop produces unbounded divergence with no cluster formation. These regimes display qualitatively distinct geometric signatures of contraction and expansion. Our results show that prompt design directly governs the dynamical regime of an agentic loop, enabling systematic control of convergence, divergence and trajectory structure in iterative LLM transformations.         Subjects:  Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)  Cite as: arXiv:2512.10350 [cs.LG]    (or  arXiv:2512.10350v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10350">https://doi.org/10.48550/arXiv.2512.10350</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)        Submission history From: Nicolas Tacheny [view email]       [v1]         Thu, 11 Dec 2025 07:06:14 UTC (3,716 KB)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-45] REMISVFU: Vertical Federated Unlearning via Representation Misdirection for Intermediate Output Feature <mark class="hl-label red">AAAI</mark></p>
<p>【速读】：该论文旨在解决垂直联邦学习（Vertical Federated Learning, VFL）场景下“被遗忘权”（right to be forgotten）的实现问题，即如何在不损害其他参与方模型性能的前提下，高效地从联合模型中移除特定客户端的数据贡献。现有方法主要针对水平联邦学习（Horizontal Federated Learning, HFL），难以适配VFL中特征分区的架构。其解决方案的关键在于提出一种即插即用的表示误导框架REMISVFU：当收到删除请求时，遗忘方将其编码输出投影至单位球面上的随机锚点，从而切断其特征与全局模型之间的统计关联；同时，服务器通过联合优化保留损失和遗忘损失，并利用正交投影对齐梯度，避免破坏性干扰，确保剩余参与方的模型性能不受显著影响。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10348">https://arxiv.org/abs/2512.10348</a><br>
<strong>作者</strong>: Wenhan Wu,Zhili He,Huanghuang Liang,Yili Gong,Jiawei Jiang,Chuang Hu,Dazhao Cheng<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  The 40th Annual AAAI Conference on Artificial Intelligence</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Data-protection regulations such as the GDPR grant every participant in a federated system a right to be forgotten. Federated unlearning has therefore emerged as a research frontier, aiming to remove a specific party’s contribution from the learned model while preserving the utility of the remaining parties. However, most unlearning techniques focus on Horizontal Federated Learning (HFL), where data are partitioned by samples. In contrast, Vertical Federated Learning (VFL) allows organizations that possess complementary feature spaces to train a joint model without sharing raw data. The resulting feature-partitioned architecture renders HFL-oriented unlearning methods ineffective. In this paper, we propose REMISVFU, a plug-and-play representation misdirection framework that enables fast, client-level unlearning in splitVFL systems. When a deletion request arrives, the forgetting party collapses its encoder output to a randomly sampled anchor on the unit sphere, severing the statistical link between its features and the global model. To maintain utility for the remaining parties, the server jointly optimizes a retention loss and a forgetting loss, aligning their gradients via orthogonal projection to eliminate destructive interference. Evaluations on public benchmarks show that REMISVFU suppresses back-door attack success to the natural class-prior level and sacrifices only about 2.5% points of clean accuracy, outperforming state-of-the-art baselines.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-46] A Privacy-Preserving Cloud Architecture for Distributed Machine Learning at Scale</p>
<p>【速读】：该论文旨在解决分布式机器学习系统在多云环境中的隐私保护、合规性验证与可扩展部署难题，尤其是在异构基础设施下如何确保敏感数据不被集中化且仍能实现安全的模型训练与推理。其解决方案的关键在于构建一个云原生的隐私保护架构，融合联邦学习（Federated Learning）、差分隐私（Differential Privacy）、零知识合规证明（Zero-Knowledge Compliance Proofs）以及基于强化学习的自适应治理机制，从而实现无需集中数据即可保障模型训练的安全性，并通过密码学手段验证跨机构和云平台的政策执行一致性，同时维持模型性能稳定与最小开销。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10341">https://arxiv.org/abs/2512.10341</a><br>
<strong>作者</strong>: Vinoth Punniyamoorthy,Ashok Gadi Parthi,Mayilsamy Palanigounder,Ravi Kiran Kodali,Bikesh Kumar,Kabilan Kannan<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Distributed machine learning systems require strong privacy guarantees, verifiable compliance, and scalable deploy- ment across heterogeneous and multi-cloud environments. This work introduces a cloud-native privacy-preserving architecture that integrates federated learning, differential privacy, zero- knowledge compliance proofs, and adaptive governance powered by reinforcement learning. The framework supports secure model training and inference without centralizing sensitive data, while enabling cryptographically verifiable policy enforcement across institutions and cloud platforms. A full prototype deployed across hybrid Kubernetes clusters demonstrates reduced membership- inference risk, consistent enforcement of formal privacy budgets, and stable model performance under differential privacy. Ex- perimental evaluation across multi-institution workloads shows that the architecture maintains utility with minimal overhead while providing continuous, risk-aware governance. The pro- posed framework establishes a practical foundation for deploying trustworthy and compliant distributed machine learning systems at scale.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-47] On the Collapse of Generative Paths: A Criterion and Correction for Diffusion Steering</p>
<p>【速读】：该论文旨在解决<strong>推理时引导（inference-time steering）<strong>中因组合异构模型（如不同噪声调度或数据集训练的模型）而导致的</strong>边际路径坍塌（marginal path collapse）<strong>问题，即中间时间步的概率密度不可归一化，尽管起点和终点仍有效。这一问题严重限制了比率密度法（ratio-of-densities method）在复杂任务（如柔性构象支架修饰）中的稳定性与实用性。解决方案的关键在于：首先提出一个</strong>路径存在性判据</strong>，仅基于噪声调度和指数参数即可准确预测坍塌发生；其次引入<strong>自适应路径校正与指数调整（Adaptive path Correction with Exponents, ACE）</strong>，将Feynman-Kac引导扩展至时变指数，从而保证生成路径始终为合法概率路径。ACE在合成2D基准和柔性构象支架修饰任务上显著优于固定指数基线及专用模型，使异构专家模型的组合引导从不稳定启发式方法变为可靠可控生成工具。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10339">https://arxiv.org/abs/2512.10339</a><br>
<strong>作者</strong>: Ziseok Lee,Minyeong Hwang,Sanghyun Jo,Wooyeol Lee,Jihyung Ko,Young Bin Park,Jae-Mun Choi,Eunho Yang,Kyungsu Kim<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Inference-time steering enables pretrained diffusion/flow models to be adapted to new tasks without retraining. A widely used approach is the ratio-of-densities method, which defines a time-indexed target path by reweighting probability-density trajectories from multiple models with positive, or in some cases, negative exponents. This construction, however, harbors a critical and previously unformalized failure mode: Marginal Path Collapse, where intermediate densities become non-normalizable even though endpoints remain valid. Collapse arises systematically when composing heterogeneous models trained on different noise schedules or datasets, including a common setting in molecular design where de-novo, conformer, and pocket-conditioned models must be combined for tasks such as flexible-pose scaffold decoration. We provide a novel and complete solution for the problem. First, we derive a simple path existence criterion that predicts exactly when collapse occurs from noise schedules and exponents alone. Second, we introduce Adaptive path Correction with Exponents (ACE), which extends Feynman-Kac steering to time-varying exponents and guarantees a valid probability path. On a synthetic 2D benchmark and on flexible-pose scaffold decoration, ACE eliminates collapse and enables high-guidance compositional generation, improving distributional and docking metrics over constant-exponent baselines and even specialized task-specific scaffold decoration models. Our work turns ratio-of-densities steering with heterogeneous experts from an unstable heuristic into a reliable tool for controllable generation.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-48] User-Feedback-Driven Continual Adaptation for Vision-and-Language Navigation</p>
<p>【速读】：该论文旨在解决当前通用场景适应的视觉-语言导航（General Scene Adaptation for Vision-and-Language Navigation, GSA-VLN）框架中缺乏用户反馈引入的问题，即现有方法仅依赖环境重复暴露进行无监督适应，未能充分利用用户提供的自然且有价值的监督信号。解决方案的关键在于提出一种由用户反馈驱动的持续学习框架，通过将用户反馈（包括导航指令和修正信号）转化为高质量、环境对齐的训练数据，实现高效且真实的环境适应；同时引入记忆库热启动机制，复用先前获得的环境知识以缓解冷启动问题并保障部署稳定性，从而在GSA-R2R基准上显著提升导航成功率与路径效率，并在持续和混合适应设置下展现出鲁棒性和泛化能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10322">https://arxiv.org/abs/2512.10322</a><br>
<strong>作者</strong>: Yongqiang Yu,Xuhui Li,Hazza Mahmood,Jinxing Zhou,Haodong Hong,Longtao Jiang,Zhiqiang Xu,Qi Wu,Xiaojun Chang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Vision-and-Language Navigation (VLN) requires agents to navigate complex environments by following natural-language instructions. General Scene Adaptation for VLN (GSA-VLN) shifts the focus from zero-shot generalization to continual, environment-specific adaptation, narrowing the gap between static benchmarks and real-world deployment. However, current GSA-VLN frameworks exclude user feedback, relying solely on unsupervised adaptation from repeated environmental exposure. In practice, user feedback offers natural and valuable supervision that can significantly enhance adaptation quality. We introduce a user-feedback-driven adaptation framework that extends GSA-VLN by systematically integrating human interactions into continual learning. Our approach converts user feedback-navigation instructions and corrective signals-into high-quality, environment-aligned training data, enabling efficient and realistic adaptation. A memory-bank warm-start mechanism further reuses previously acquired environmental knowledge, mitigating cold-start degradation and ensuring stable redeployment. Experiments on the GSA-R2R benchmark show that our method consistently surpasses strong baselines such as GR-DUET, improving navigation success and path efficiency. The memory-bank warm start stabilizes early navigation and reduces performance drops after updates. Results under both continual and hybrid adaptation settings confirm the robustness and generality of our framework, demonstrating sustained improvement across diverse deployment conditions.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-49] ranslating Informal Proofs into Formal Proofs Using a Chain of States</p>
<p>【速读】：该论文旨在解决在受限计算预算下，将自然语言表述的非正式数学证明转化为Lean4形式化证明的问题。其核心挑战在于非正式证明通常通过一系列逻辑转换（如蕴含或等价关系）推进，但不显式说明中间结果或辅助引理，而形式化系统如Lean要求对每个证明状态及连接它们的策略进行明确表达。解决方案的关键在于提出一个两阶段框架：首先提取“状态链”（Chain of States, CoS），即与非正式论证逻辑结构对齐的一系列中间形式化证明状态；随后生成用于在CoS相邻状态间迁移的策略，从而构建完整的正式证明。该中间表示显著降低了策略生成的复杂性，并提升了与非正式推理模式的一致性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10317">https://arxiv.org/abs/2512.10317</a><br>
<strong>作者</strong>: Ziyu Wang,Bowen Yang,Shihao Zhou,Chenyi Li,Yuan Zhang,Bin Dong,Zaiwen Wen<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Logic in Computer Science (cs.LO); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  31 pages, 5 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We address the problem of translating informal mathematical proofs expressed in natural language into formal proofs in Lean4 under a constrained computational budget. Our approach is grounded in two key insights. First, informal proofs tend to proceed via a sequence of logical transitions - often implications or equivalences - without explicitly specifying intermediate results or auxiliary lemmas. In contrast, formal systems like Lean require an explicit representation of each proof state and the tactics that connect them. Second, each informal reasoning step can be viewed as an abstract transformation between proof states, but identifying the corresponding formal tactics often requires nontrivial domain knowledge and precise control over proof context. To bridge this gap, we propose a two stage framework. Rather than generating formal tactics directly, we first extract a Chain of States (CoS), a sequence of intermediate formal proof states aligned with the logical structure of the informal argument. We then generate tactics to transition between adjacent states in the CoS, thereby constructing the full formal proof. This intermediate representation significantly reduces the complexity of tactic generation and improves alignment with informal reasoning patterns. We build dedicated datasets and benchmarks for training and evaluation, and introduce an interactive framework to support tactic generation from formal states. Empirical results show that our method substantially outperforms existing baselines, achieving higher proof success rates.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-50] EpiPlan<mark class="hl-label green">Agent</mark> : <mark class="hl-label green">Agent</mark> ic Automated Epidemic Response <mark class="hl-label green">Planning</mark></p>
<p>【速读】：该论文旨在解决传统流行病应对规划依赖人工、耗时且效率低下的问题，其核心挑战在于如何实现应急响应计划的自动化生成与验证。解决方案的关键在于设计并实现了一个基于智能体（agent-based）的系统——EpiPlanAgent，该系统利用大语言模型（Large Language Models, LLMs）构建多智能体框架，集成任务分解、知识锚定（knowledge grounding）和模拟模块，从而在保证计划完整性与指南一致性的同时，显著缩短制定时间，并通过专家评估和用户反馈验证了AI生成内容与人工编写内容的高度一致性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10313">https://arxiv.org/abs/2512.10313</a><br>
<strong>作者</strong>: Kangkun Mao,Fang Xu,Jinru Ding,Yidong Jiang,Yujun Yao,Yirong Chen,Junming Liu,Xiaoqin Wu,Qian Wu,Xiaoyan Huang,Jie Xu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Epidemic response planning is essential yet traditionally reliant on labor-intensive manual methods. This study aimed to design and evaluate EpiPlanAgent, an agent-based system using large language models (LLMs) to automate the generation and validation of digital emergency response plans. The multi-agent framework integrated task decomposition, knowledge grounding, and simulation modules. Public health professionals tested the system using real-world outbreak scenarios in a controlled evaluation. Results demonstrated that EpiPlanAgent significantly improved the completeness and guideline alignment of plans while drastically reducing development time compared to manual workflows. Expert evaluation confirmed high consistency between AI-generated and human-authored content. User feedback indicated strong perceived utility. In conclusion, EpiPlanAgent provides an effective, scalable solution for intelligent epidemic response planning, demonstrating the potential of agentic AI to transform public health preparedness.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-51] High-Dimensional Data Processing: Benchmarking Machine Learning and Deep Learning Architectures in Local and Distributed Environments</p>
<p>【速读】：该论文旨在解决大数据处理与分析中的实践教学问题，即如何通过系统化的课程设计帮助学生掌握从数据预处理到分布式计算的完整技术链条。其解决方案的关键在于构建一个由浅入深的实践流程：首先对Epsilon数据集采用分组与个体策略进行处理，随后利用RestMex进行文本分析与分类，并结合IMDb电影特征数据开展分析；最终通过在Linux环境下使用Scala实现Apache Spark分布式计算集群的技术部署，从而将理论知识转化为可执行的大数据处理能力。整个方案强调了端到端的数据处理流程和工具链整合，为大数据课程提供了可复用的教学范式。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10312">https://arxiv.org/abs/2512.10312</a><br>
<strong>作者</strong>: Julian Rodriguez,Piotr Lopez,Emiliano Lerma,Rafael Medrano,Jacobo Hernandez<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  8 pages, 3 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This document reports the sequence of practices and methodologies implemented during the Big Data course. It details the workflow beginning with the processing of the Epsilon dataset through group and individual strategies, followed by text analysis and classification with RestMex and movie feature analysis with IMDb. Finally, it describes the technical implementation of a distributed computing cluster with Apache Spark on Linux using Scala.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-52] InfoCom: Kilobyte-Scale Communication-Efficient Collaborative Perception with Information Bottleneck <mark class="hl-label red">AAAI</mark> <mark class="hl-label red">AAAI-26</mark></p>
<p>【速读】：该论文旨在解决自动驾驶系统中协同感知（collaborative perception）面临的通信效率与感知性能之间的根本性权衡问题。现有方法通常假设每轮协作传输MB级数据，但在实际网络约束下可能失效。其解决方案的关键在于提出InfoCom框架，该框架基于扩展的信息瓶颈（Information Bottleneck, IB）理论，引入了一种全新的信息净化范式（information purification paradigm），理论上优化了在IB约束下提取最小充分任务相关信息的能力。核心创新包括：信息感知编码（Information-Aware Encoding）以压缩特征为最小信息消息，稀疏掩码生成（Sparse Mask Generation）识别低通信成本的空间线索，以及多尺度解码（Multi-Scale Decoding）通过掩码引导机制逐步恢复感知信息，而非简单特征重建。实验表明，该方法可在保持近无损感知性能的同时，将单个代理的通信开销从MB级降至KB级，较Where2comm和ERMVP分别减少440倍和90倍。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10305">https://arxiv.org/abs/2512.10305</a><br>
<strong>作者</strong>: Quanmin Wei,Penglin Dai,Wei Li,Bingyi Liu,Xiao Wu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Accepted by the 40th AAAI Conference on Artificial Intelligence (AAAI-26)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Precise environmental perception is critical for the reliability of autonomous driving systems. While collaborative perception mitigates the limitations of single-agent perception through information sharing, it encounters a fundamental communication-performance trade-off. Existing communication-efficient approaches typically assume MB-level data transmission per collaboration, which may fail due to practical network constraints. To address these issues, we propose InfoCom, an information-aware framework establishing the pioneering theoretical foundation for communication-efficient collaborative perception via extended Information Bottleneck principles. Departing from mainstream feature manipulation, InfoCom introduces a novel information purification paradigm that theoretically optimizes the extraction of minimal sufficient task-critical information under Information Bottleneck constraints. Its core innovations include: i) An Information-Aware Encoding condensing features into minimal messages while preserving perception-relevant information; ii) A Sparse Mask Generation identifying spatial cues with negligible communication cost; and iii) A Multi-Scale Decoding that progressively recovers perceptual information through mask-guided mechanisms rather than simple feature reconstruction. Comprehensive experiments across multiple datasets demonstrate that InfoCom achieves near-lossless perception while reducing communication overhead from megabyte to kilobyte-scale, representing 440-fold and 90-fold reductions per agent compared to Where2comm and ERMVP, respectively.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-53] rustworthy Orchestration Artificial Intelligence by the Ten Criteria with Control-Plane Governance</p>
<p>【速读】：该论文旨在解决人工智能（Artificial Intelligence, AI）系统在承担重要决策角色时，技术能力与制度问责之间日益扩大的鸿沟问题。传统伦理指导不足以应对这一挑战，亟需将治理机制嵌入AI生态系统的执行架构中。解决方案的关键在于提出“可信编排AI的十项标准”（Ten Criteria for Trustworthy Orchestration AI），构建一个集成人类输入、语义一致性及审计溯源完整性的统一控制面板（Control-Panel）架构，从而实现对AI组件、使用者及人类参与者全链条的治理覆盖，并确保系统具备可验证性、透明性、可复现性和有意义的人类控制能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10304">https://arxiv.org/abs/2512.10304</a><br>
<strong>作者</strong>: Byeong Ho Kang,Wenli Yang,Muhammad Bilal Amin<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Emerging Technologies (<a target="_blank" rel="noopener" href="http://cs.ET">cs.ET</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:As Artificial Intelligence (AI) systems increasingly assume consequential decision-making roles, a widening gap has emerged between technical capabilities and institutional accountability. Ethical guidance alone is insufficient to counter this challenge; it demands architectures that embed governance into the execution fabric of the ecosystem. This paper presents the Ten Criteria for Trustworthy Orchestration AI, a comprehensive assurance framework that integrates human input, semantic coherence, audit and provenance integrity into a unified Control-Panel architecture. Unlike conventional agentic AI initiatives that primarily focus on AI-to-AI coordination, the proposed framework provides an umbrella of governance to the entire AI components, their consumers and human participants. By taking aspiration from international standards and Australia’s National Framework for AI Assurance initiative, this work demonstrates that trustworthiness can be systematically incorporated (by engineering) into AI systems, ensuring the execution fabric remains verifiable, transparent, reproducible and under meaningful human control.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-54] Investigating The Functional Roles of Attention Heads in Vision Language Models: Evidence for <mark class="hl-label green">Reasoning</mark>  Modules</p>
<p>【速读】：该论文旨在解决视觉语言模型（Vision-Language Models, VLMs）在多模态推理过程中内部机制不透明的问题，即其“黑箱”特性限制了对模型认知功能的理解与优化。解决方案的关键在于提出一种新颖的可解释性框架——CogVision，该框架通过构建一个分步子问题的数据集来模拟人类链式思维（chain-of-thought）推理过程，并结合探针（probing-based）方法识别出具有特定功能的注意力头（functional heads），这些注意力头对应于高阶视觉感知、推理等认知功能。研究表明，这类功能性注意力头在不同VLM架构中普遍稀疏且分布异质，干预实验进一步证实其对多模态推理性能具有决定性作用，从而为设计更符合人类感知与推理模式的模型提供了理论依据和实践路径。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10300">https://arxiv.org/abs/2512.10300</a><br>
<strong>作者</strong>: Yanbei Jiang,Xueqi Ma,Shu Liu,Sarah Monazam Erfani,Tongliang Liu,James Bailey,Jey Han Lau,Krista A. Ehinger<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Despite excelling on multimodal benchmarks, vision-language models (VLMs) largely remain a black box. In this paper, we propose a novel interpretability framework to systematically analyze the internal mechanisms of VLMs, focusing on the functional roles of attention heads in multimodal reasoning. To this end, we introduce CogVision, a dataset that decomposes complex multimodal questions into step-by-step subquestions designed to simulate human reasoning through a chain-of-thought paradigm, with each subquestion associated with specific receptive or cognitive functions such as high-level visual reception and inference. Using a probing-based methodology, we identify attention heads that specialize in these functions and characterize them as functional heads. Our analysis across diverse VLM families reveals that these functional heads are universally sparse, vary in number and distribution across functions, and mediate interactions and hierarchical organization. Furthermore, intervention experiments demonstrate their critical role in multimodal reasoning: removing functional heads leads to performance degradation, while emphasizing them enhances accuracy. These findings provide new insights into the cognitive organization of VLMs and suggest promising directions for designing models with more human-aligned perceptual and reasoning abilities.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-55] FLARE: A Wireless Side-Channel Fingerprinting Attack on Federated Learning</p>
<p>【速读】：该论文旨在解决联邦学习（Federated Learning, FL）系统中一个尚未被充分研究的隐私安全问题：外部攻击者如何通过分析加密无线流量中的侧信道信息来推断客户端设备上部署的深度学习模型架构（如卷积神经网络 CNN 或循环神经网络 RNN）。这一泄露可能使攻击者发起针对性更强的下一步攻击。解决方案的关键在于提出了一种名为 FLARE 的新型指纹识别框架，其核心机制是利用从 FL 客户端发出的加密无线流量中的流级和包级统计特征，实现对模型架构的高精度识别。实验表明，在封闭世界和开放世界场景下，FLARE 分别实现了超过 98% 和高达 91% 的 F1 分数，首次证明了即使在真实环境下的硬件、软件和数据异构性条件下，也能通过嗅探加密无线流量完成模型架构指纹识别，揭示了当前 FL 系统中存在的关键侧信道漏洞。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10296">https://arxiv.org/abs/2512.10296</a><br>
<strong>作者</strong>: Md Nahid Hasan Shuvo,Moinul Hossain,Anik Mallik,Jeffrey Twigg,Fikadu Dagefu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  This paper has been accepted for publication in IEEE INFOCOM 2026 - IEEE Conference on Computer Communications</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Federated Learning (FL) enables collaborative model training across distributed devices while safeguarding data and user privacy. However, FL remains susceptible to privacy threats that can compromise data via direct means. That said, indirectly compromising the confidentiality of the FL model architecture (e.g., a convolutional neural network (CNN) or a recurrent neural network (RNN)) on a client device by an outsider remains unexplored. If leaked, this information can enable next-level attacks tailored to the architecture. This paper proposes a novel side-channel fingerprinting attack, leveraging flow-level and packet-level statistics of encrypted wireless traffic from an FL client to infer its deep learning model architecture. We name it FLARE, a fingerprinting framework based on FL Architecture REconnaissance. Evaluation across various CNN and RNN variants-including pre-trained and custom models trained over IEEE 802.11 Wi-Fi-shows that FLARE achieves over 98% F1-score in closed-world and up to 91% in open-world scenarios. These results reveal that CNN and RNN models leak distinguishable traffic patterns, enabling architecture fingerprinting even under realistic FL settings with hardware, software, and data heterogeneity. To our knowledge, this is the first work to fingerprint FL model architectures by sniffing encrypted wireless traffic, exposing a critical side-channel vulnerability in current FL systems.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-56] Neuronal Attention Circuit (NAC) for Representation Learning <mark class="hl-label red">ICML2026</mark></p>
<p>【速读】：该论文旨在解决传统注意力机制在连续时间（Continuous-Time, CT）建模中的局限性，尤其是其离散特性难以适应动态、非均匀采样数据的问题。解决方案的关键在于提出一种生物可解释的连续时间注意力机制——神经元注意力电路（Neuronal Attention Circuit, NAC），其核心创新是将注意力logits的计算重构为一个带有非线性耦合门控结构的一阶线性常微分方程（ODE）求解问题，并借鉴秀丽隐杆线虫（C. elegans）神经回路策略（Neuronal Circuit Policies, NCPs）的连接机制实现稀疏感知门控与分层结构设计。NAC通过稀疏感官门控替代密集投影、引入双头骨干网络以生成内容-目标和可学习时间常数门控，实现了高效自适应动力学建模，并支持三种数值积分模式（显式欧拉法、闭式解、稳态近似），从而在保持理论保证（状态稳定性、有界误差、通用逼近能力）的同时显著提升内存效率与任务性能。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10282">https://arxiv.org/abs/2512.10282</a><br>
<strong>作者</strong>: Waleed Razzaq,Izis Kankaraway,Yun-Bo Zhao<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  Paper for ICML2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Attention improves representation learning over RNNs, but its discrete nature limits continuous-time (CT) modeling. We introduce Neuronal Attention Circuit (NAC), a novel, biologically plausible CT-Attention mechanism that reformulates attention logits computation as the solution to a linear first-order ODE with nonlinear interlinked gates derived from repurposing \textitC. elegans Neuronal Circuit Policies (NCPs) wiring mechanism. NAC replaces dense projections with sparse sensory gates for key-query projections and a sparse backbone network with two heads for computing \textitcontent-target and \textitlearnable time-constant gates, enabling efficient adaptive dynamics. NAC supports three attention logit computation modes: (i) explicit Euler integration, (ii) exact closed-form solution, and (iii) steady-state approximation. To improve memory intensity, we implemented a sparse Top-\emphK pairwise concatenation scheme that selectively curates key-query interactions. We provide rigorous theoretical guarantees, including state stability, bounded approximation errors, and universal approximation. Empirically, we implemented NAC in diverse domains, including irregular time-series classification, lane-keeping for autonomous vehicles, and industrial prognostics. We observed that NAC matches or outperforms competing baselines in accuracy and occupies an intermediate position in runtime and memory efficiency compared with several CT baselines.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-57] Graph Neural Network Based Adaptive Threat Detection for Cloud Identity and Access Management Logs</p>
<p>【速读】：该论文旨在解决现代企业中因云基础设施和分布式身份系统扩展而导致的身份与访问管理（Identity and Access Management, IAM）日志中新型或演变威胁难以被传统基于规则或签名的检测系统识别的问题。其核心挑战在于异常行为可能在统计上看似正常，但具有上下文恶意性。解决方案的关键在于提出一种基于图神经网络（Graph Neural Network, GNN）的自适应威胁检测框架，通过将IAM审计日志建模为异构动态图，捕捉用户、角色、会话和访问动作等实体间的时序、关系和上下文依赖，并引入注意力机制聚合与图嵌入更新策略，实现对多租户云环境的持续适应能力，从而显著提升对内部威胁、权限提升和横向移动攻击的检测精度与召回率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10280">https://arxiv.org/abs/2512.10280</a><br>
<strong>作者</strong>: Venkata Tanuja Madireddy<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The rapid expansion of cloud infrastructures and distributed identity systems has significantly increased the complexity and attack surface of modern enterprises. Traditional rule based or signature driven detection systems are often inadequate in identifying novel or evolving threats within Identity and Access Management logs, where anomalous behavior may appear statistically benign but contextually malicious. This paper presents a Graph Neural Network Based Adaptive Threat Detection framework designed to learn latent user resource interaction patterns from IAM audit trails in real time. By modeling IAM logs as heterogeneous dynamic graphs, the proposed system captures temporal, relational, and contextual dependencies across entities such as users, roles, sessions, and access actions. The model incorporates attention based aggregation and graph embedding updates to enable continual adaptation to changing cloud environments. Experimental evaluation on synthesized and real world IAM datasets demonstrates that the proposed method achieves higher detection precision and recall than baseline LSTM and GCN classifiers, while maintaining scalability across multi tenant cloud environments. The frameworks adaptability enables proactive mitigation of insider threats, privilege escalation, and lateral movement attacks, contributing to the foundation of AI driven zero trust access analytics. This work bridges the gap between graph based machine learning and operational cloud security intelligence.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-58] Computing Evolutionarily Stable Strategies in Imperfect-Information Games</p>
<p>【速读】：该论文致力于解决对称完美回忆的不完美信息扩展形式博弈中演化稳定策略（Evolutionarily Stable Strategies, ESSs）的计算问题。其核心挑战在于，这类博弈中存在复杂的策略空间和可能的退化情况（degenerate games），导致传统方法难以高效识别所有ESSs。解决方案的关键在于提出一种声名正确的算法，能够准确计算非退化博弈中的全部ESSs，并在退化博弈中找到包含无限连续统对称纳什均衡的一部分ESSs；该算法具有“随时中断”（anytime）特性，允许早期终止以获得一个或多个ESSs，从而兼顾精度与效率，且在癌症信号博弈和随机博弈上的实验验证了其可扩展性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10279">https://arxiv.org/abs/2512.10279</a><br>
<strong>作者</strong>: Sam Ganzfried<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computer Science and Game Theory (<a target="_blank" rel="noopener" href="http://cs.GT">cs.GT</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Multiagent Systems (<a target="_blank" rel="noopener" href="http://cs.MA">cs.MA</a>); Theoretical Economics (<a target="_blank" rel="noopener" href="http://econ.TH">econ.TH</a>); Populations and Evolution (<a target="_blank" rel="noopener" href="http://q-bio.PE">q-bio.PE</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present an algorithm for computing evolutionarily stable strategies (ESSs) in symmetric perfect-recall extensive-form games of imperfect information. Our main algorithm is for two-player games, and we describe how it can be extended to multiplayer games. The algorithm is sound and computes all ESSs in nondegenerate games and a subset of them in degenerate games which contain an infinite continuum of symmetric Nash equilibria. The algorithm is anytime and can be stopped early to find one or more ESSs. We experiment on an imperfect-information cancer signaling game as well as random games to demonstrate scalability.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-59] Reverse Thinking Enhances Missing Information Detection in <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark></p>
<p>【速读】：该论文旨在解决大型语言模型（Large Language Models, LLMs）在处理涉及缺失信息的问题时，常出现响应不完整、事实性错误及幻觉（hallucination）等逻辑不完整性问题。传统前向推理方法如思维链（Chain-of-Thought, CoT）和思维树（Tree-of-Thought, ToT）虽在结构化任务中表现良好，但难以系统识别和恢复遗漏信息。论文提出一种基于逆向思维（reverse thinking）的新框架，其关键在于将缺失信息检测任务转化为可管理的后向推理问题，通过引导模型识别必要条件并定位缺失要素，从而显著提升模型在逻辑完备性和推理鲁棒性方面的表现。实验表明，该方法相较传统前向推理策略取得显著性能提升。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10273">https://arxiv.org/abs/2512.10273</a><br>
<strong>作者</strong>: Yuxin Liu,Chaojie Gu,Yihang Zhang,Bin Qian,Shibo He<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  10 pages, 2 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) have demonstrated remarkable capabilities in various reasoning tasks, yet they often struggle with problems involving missing information, exhibiting issues such as incomplete responses, factual errors, and hallucinations. While forward reasoning approaches like Chain-of-Thought (CoT) and Tree-of-Thought (ToT) have shown success in structured problem-solving, they frequently fail to systematically identify and recover omitted information. In this paper, we explore the potential of reverse thinking methodologies to enhance LLMs’ performance on missing information detection tasks. Drawing inspiration from recent work on backward reasoning, we propose a novel framework that guides LLMs through reverse thinking to identify necessary conditions and pinpoint missing elements. Our approach transforms the challenging task of missing information identification into a more manageable backward reasoning problem, significantly improving model accuracy. Experimental results demonstrate that our reverse thinking approach achieves substantial performance gains compared to traditional forward reasoning methods, providing a promising direction for enhancing LLMs’ logical completeness and reasoning robustness.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-60] Hybrid Learning and Optimization-Based Dynamic Scheduling for DL Workloads on Heterogeneous GPU Clusters</p>
<p>【速读】：该论文旨在解决大规模深度学习（Deep Learning, DL）工作负载在异构GPU集群中调度效率低下的问题，尤其是在现有调度器依赖离线性能分析或特定应用假设时，难以适应多样化和动态变化的工作负载特性。其解决方案的关键在于提出一种无应用特性的强化学习（Reinforcement Learning, RL）调度框架RLTune，通过RL驱动的动态优先级排序与混合整数线性规划（Mixed Integer Linear Programming, MILP）相结合的作业到节点映射机制，实现对系统级目标（如作业完成时间、排队延迟和资源利用率）的联合优化。该方法无需针对每个作业进行单独性能 profiling，具备良好的泛化能力，已在微软Philly、Helios及阿里云的真实生产数据上验证，显著提升GPU利用率、降低排队延迟并缩短作业完成时间。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10271">https://arxiv.org/abs/2512.10271</a><br>
<strong>作者</strong>: Shruti Dongare,Redwan Ibne Seraj Khan,Hadeel Albahar,Nannan Zhao,Diego Melendez Maita,Ali R. Butt<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Modern cloud platforms increasingly host large-scale deep learning (DL) workloads, demanding high-throughput, low-latency GPU scheduling. However, the growing heterogeneity of GPU clusters and limited visibility into application characteristics pose major challenges for existing schedulers, which often rely on offline profiling or application-specific assumptions. We present RLTune, an application-agnostic reinforcement learning (RL)-based scheduling framework that dynamically prioritizes and allocates DL jobs on heterogeneous GPU clusters. RLTune integrates RL-driven prioritization with MILP-based job-to-node mapping to optimize system-wide objectives such as job completion time (JCT), queueing delay, and resource utilization. Trained on large-scale production traces from Microsoft Philly, Helios, and Alibaba, RLTune improves GPU utilization by up to 20%, reduces queueing delay by up to 81%, and shortens JCT by as much as 70 percent. Unlike prior approaches, RLTune generalizes across diverse workloads without requiring per-job profiling, making it practical for cloud providers to deploy at scale for more efficient, fair, and sustainable DL workload management.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-61] InFerActive: Towards Scalable Human Evaluation of <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  through Interactive Inference</p>
<p>【速读】：该论文旨在解决大型语言模型（Large Language Models, LLMs）输出在人工评估中面临的可扩展性问题，即传统评估范式需逐条审查大量独立生成结果，效率低下。其核心解决方案是提出InFerActive——一个交互式推理系统，通过概率驱动的过滤与评估功能实现按需探索，并借助自适应可视化技术弥合计算标记（token）与人类可读文本之间的语义鸿沟，从而显著提升评估效率并支持对模型行为的更全面分析。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10234">https://arxiv.org/abs/2512.10234</a><br>
<strong>作者</strong>: Junhyeong Hwangbo,Soohyun Lee,Minsoo Cheong,Hyeon Jeon,Jinwook Seo<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Human-Computer Interaction (cs.HC); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Human evaluation remains the gold standard for evaluating outputs of Large Language Models (LLMs). The current evaluation paradigm reviews numerous individual responses, leading to significant scalability challenges. LLM outputs can be more efficiently represented as a tree structure, reflecting their autoregressive generation process and stochastic token selection. However, conventional tree visualization cannot scale to the exponentially large trees generated by modern sampling methods of LLMs. To address this problem, we present InFerActive, an interactive inference system for scalable human evaluation. InFerActive enables on-demand exploration through probability-based filtering and evaluation features, while bridging the semantic gap between computational tokens and human-readable text through adaptive visualization techniques. Through a technical evaluation and user study (N=12), we demonstrate that InFerActive significantly improves evaluation efficiency and enables more comprehensive assessment of model behavior. We further conduct expert case studies that demonstrate InFerActive’s practical applicability and potential for transforming LLM evaluation workflows.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-62] Adaptive Information Routing for Multimodal Time Series Forecasting</p>
<p>【速读】：该论文旨在解决传统时间序列预测方法在实际应用中因仅依赖历史时间序列数据而导致预测精度不足的问题。其核心挑战在于，单一模态的时间序列信息往往不足以捕捉复杂动态系统中的关键影响因素。为此，论文提出了一种名为自适应信息路由（Adaptive Information Routing, AIR）的新型多模态时间序列预测框架，其关键创新在于：不再将文本数据视为与时间序列数据等价的辅助特征，而是利用文本信息动态调控时间序列模型的行为，通过控制多变量时间序列信息的融合方式和程度来优化预测过程。此外，作者还设计了一个基于大语言模型（Large Language Model, LLM）的文本精炼管道，将原始文本转化为适用于多模态预测的结构化表示，并构建了一个基准测试平台以支持相关实验。实证结果表明，AIR能够有效提升多种真实市场数据（如原油价格、汇率）的时间序列预测准确性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10229">https://arxiv.org/abs/2512.10229</a><br>
<strong>作者</strong>: Jun Seo,Hyeokjun Choe,Seohui Bae,Soyeon Park,Wonbin Ahn,Taeyoon Lim,Junhyuk Kang,Sangjun Han,Jaehoon Lee,Dongwan Kang,Minjae Kim,Sungdong Yoo,Soonyoung Lee<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Time series forecasting is a critical task for artificial intelligence with numerous real-world applications. Traditional approaches primarily rely on historical time series data to predict the future values. However, in practical scenarios, this is often insufficient for accurate predictions due to the limited information available. To address this challenge, multimodal time series forecasting methods which incorporate additional data modalities, mainly text data, alongside time series data have been explored. In this work, we introduce the Adaptive Information Routing (AIR) framework, a novel approach for multimodal time series forecasting. Unlike existing methods that treat text data on par with time series data as interchangeable auxiliary features for forecasting, AIR leverages text information to dynamically guide the time series model by controlling how and to what extent multivariate time series information should be combined. We also present a text-refinement pipeline that employs a large language model to convert raw text data into a form suitable for multimodal forecasting, and we introduce a benchmark that facilitates multimodal forecasting experiments based on this pipeline. Experiment results with the real world market data such as crude oil price and exchange rates demonstrate that AIR effectively modulates the behavior of the time series model using textual inputs, significantly enhancing forecasting accuracy in various time series forecasting tasks.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-63] ID-PaS : Identity-Aware Predict-and-Search for General Mixed-Integer Linear Programs</p>
<p>【速读】：该论文旨在解决现有Predict-and-Search（PaS）方法在处理混合整数线性规划（Mixed-Integer Linear Programs, MIPs）时存在的局限性，特别是其仅适用于二值变量且未考虑实际问题中常见的固定变量（fixed variables）的问题。解决方案的关键在于提出ID-PaS框架，这是一种具备身份感知能力的学习机制（identity-aware learning framework），能够有效区分和处理异质变量（heterogeneous variables），从而提升模型对参数化MIP问题的建模与求解能力。实验表明，ID-PaS在多个真实世界大规模问题上显著优于当前最先进的求解器Gurobi和传统PaS方法。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10211">https://arxiv.org/abs/2512.10211</a><br>
<strong>作者</strong>: Junyang Cai,El Mehdi Er Raqabi,Pascal Van Hentenryck,Bistra Dilkina<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Mixed-Integer Linear Programs (MIPs) are powerful and flexible tools for modeling a wide range of real-world combinatorial optimization problems. Predict-and-Search methods operate by using a predictive model to estimate promising variable assignments and then guiding a search procedure toward high-quality solutions. Recent research has demonstrated that incorporating machine learning (ML) into the Predict-and-Search framework significantly enhances its performance. Still, it is restricted to binary problems and overlooks the presence of fixed variables that commonly arise in practical settings. This work extends the Predict-and-Search (PaS) framework to parametric MIPs and introduces ID-PaS, an identity-aware learning framework that enables the ML model to handle heterogeneous variables more effectively. Experiments on several real-world large-scale problems demonstrate that ID-PaS consistently achieves superior performance compared to the state-of-the-art solver Gurobi and PaS.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-64] An exploration for higher efficiency in multi objective optimisation with reinforcement learning</p>
<p>【速读】：该论文试图解决多目标优化（Multi-Objective Optimization）中因单一操作算子导致搜索效率受限的问题，尤其是在如何有效组合多个操作算子以提升局部搜索性能方面缺乏系统研究。其解决方案的关键在于提出一种基于多目标强化学习（Multi-Objective Reinforcement Learning, MORL）的通用化方法，通过学习历史经验来动态选择最优或近优的操作算子序列，从而增强算法在多目标场景下的适应性和收敛效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10208">https://arxiv.org/abs/2512.10208</a><br>
<strong>作者</strong>: Mehmet Emin Aydin<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Neural and Evolutionary Computing (<a target="_blank" rel="noopener" href="http://cs.NE">cs.NE</a>)<br>
<strong>备注</strong>:  13th International Symposium on Intelligent Manufacturing and Service Systems, Duzce University, Duzce, Turkiye, 25-27 September 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Efficiency in optimisation and search processes persists to be one of the challenges, which affects the performance and use of optimisation algorithms. Utilising a pool of operators instead of a single operator to handle move operations within a neighbourhood remains promising, but an optimum or near optimum sequence of operators necessitates further investigation. One of the promising ideas is to generalise experiences and seek how to utilise it. Although numerous works are done around this issue for single objective optimisation, multi-objective cases have not much been touched in this regard. A generalised approach based on multi-objective reinforcement learning approach seems to create remedy for this issue and offer good solutions. This paper overviews a generalisation approach proposed with certain stages completed and phases outstanding that is aimed to help demonstrate the efficiency of using multi-objective reinforcement learning.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-65] CP-Env: Evaluating <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  on Clinical Pathways in a Controllable Hospital Environment</p>
<p>【速读】：该论文旨在解决当前医疗人工智能评估基准难以有效衡量大语言模型（Large Language Models, LLMs）在动态临床路径中表现的问题，因为现有评测多聚焦于静态考试或孤立对话，无法反映真实医疗场景中的决策连续性和流程复杂性。其解决方案的关键在于构建了一个可控制的代理型医院环境（Controllable Agentic Hospital Environment, CP-Env），该环境模拟包含患者与医生代理的医院生态系统，支持从分诊、专科会诊到诊断检测及多学科团队讨论等全流程交互，并具备分支逻辑和长程任务执行能力，从而实现对LLMs在端到端临床路径上的系统性评估。同时，提出涵盖临床疗效、流程胜任力和职业伦理的三级评价框架，揭示了模型在路径复杂性下的局限性及其内部知识整合能力的重要性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10206">https://arxiv.org/abs/2512.10206</a><br>
<strong>作者</strong>: Yakun Zhu,Zhongzhen Huang,Qianhan Feng,Linjie Mu,Yannian Gu,Shaoting Zhang,Qi Dou,Xiaofan Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Medical care follows complex clinical pathways that extend beyond isolated physician-patient encounters, emphasizing decision-making and transitions between different stages. Current benchmarks focusing on static exams or isolated dialogues inadequately evaluate large language models (LLMs) in dynamic clinical scenarios. We introduce CP-Env, a controllable agentic hospital environment designed to evaluate LLMs across end-to-end clinical pathways. CP-Env simulates a hospital ecosystem with patient and physician agents, constructing scenarios ranging from triage and specialist consultation to diagnostic testing and multidisciplinary team meetings for agent interaction. Following real hospital adaptive flow of healthcare, it enables branching, long-horizon task execution. We propose a three-tiered evaluation framework encompassing Clinical Efficacy, Process Competency, and Professional Ethics. Results reveal that most models struggle with pathway complexity, exhibiting hallucinations and losing critical diagnostic details. Interestingly, excessive reasoning steps can sometimes prove counterproductive, while top models tend to exhibit reduced tool dependency through internalized knowledge. CP-Env advances medical AI agents development through comprehensive end-to-end clinical evaluation. We provide the benchmark and evaluation tools for further research and development at this https URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-66] he 2025 Foundation Model Transparency Index</p>
<p>【速读】：该论文旨在解决基础模型（Foundation Model）开发者在透明度方面的实践不足问题，特别是随着这些公司在全球影响力日益增强，其数据获取、训练计算、部署后使用情况及影响等关键信息的披露程度亟需系统评估与改进。解决方案的关键在于通过构建年度《基础模型透明度指数》（Foundation Model Transparency Index, FMTI），量化并追踪各开发者的透明度表现，引入涵盖数据采集、使用数据和监控的新指标，并揭示当前行业整体透明度下降的趋势（从2024年平均58分降至2025年40分），从而为政策制定者提供依据，识别出如IBM等表现优异的例外案例以及xAI和Midjourney等低分代表，进而推动更具针对性的政策干预以填补关键信息缺口。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10169">https://arxiv.org/abs/2512.10169</a><br>
<strong>作者</strong>: Alexander Wan,Kevin Klyman,Sayash Kapoor,Nestor Maslej,Shayne Longpre,Betty Xiong,Percy Liang,Rishi Bommasani<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  Website: <a target="_blank" rel="noopener" href="https://crfm.stanford.edu/fmti/December-2025/index.html">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Foundation model developers are among the world’s most important companies. As these companies become increasingly consequential, how do their transparency practices evolve? The 2025 Foundation Model Transparency Index is the third edition of an annual effort to characterize and quantify the transparency of foundation model developers. The 2025 FMTI introduces new indicators related to data acquisition, usage data, and monitoring and evaluates companies like Alibaba, DeepSeek, and xAI for the first time. The 2024 FMTI reported that transparency was improving, but the 2025 FMTI finds this progress has deteriorated: the average score out of 100 fell from 58 in 2024 to 40 in 2025. Companies are most opaque about their training data and training compute as well as the post-deployment usage and impact of their flagship models. In spite of this general trend, IBM stands out as a positive outlier, scoring 95, in contrast to the lowest scorers, xAI and Midjourney, at just 14. The five members of the Frontier Model Forum we score end up in the middle of the Index: we posit that these companies avoid reputational harms from low scores but lack incentives to be transparency leaders. As policymakers around the world increasingly mandate certain types of transparency, this work reveals the current state of transparency for foundation model developers, how it may change given newly enacted policy, and where more aggressive policy interventions are necessary to address critical information deficits.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-67] Enhancing <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  for End-to-End Circuit Analysis Problem Solving</p>
<p>【速读】：该论文旨在解决大语言模型（Large Language Models, LLMs）在电路分析等工程任务中因多模态理解不足和数学推理不准确而导致的可靠性问题，尤其是在同时处理文本描述与电路图时易产生识别和推理层面的幻觉（hallucination）。其核心解决方案包括两个关键环节：一是通过微调YOLO目标检测器与OpenCV图像处理技术，精准定位并裁剪电压源和电流源区域，从而显著降低电路识别中的幻觉错误（如电源极性误判）；二是引入基于ngspice的验证循环机制，使模型生成电路网表文件（.cir），由仿真工具验证结果一致性，并根据差异触发迭代修正，必要时辅以人工审核，有效减少推理过程中的逻辑错误（如电流方向判断失误）。该方法在83道本科电路题上将成功率从原始Gemini 2.5 Pro的79.52%提升至97.59%，实现了面向工程教育场景的高可靠、端到端电路问题求解系统。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10159">https://arxiv.org/abs/2512.10159</a><br>
<strong>作者</strong>: Liangliang Chen,Weiyu Sun,Ying Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Human-Computer Interaction (cs.HC)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language models (LLMs) have shown strong performance in data-rich domains such as programming, but their reliability in engineering tasks remains limited. Circuit analysis – requiring multimodal understanding and precise mathematical reasoning – highlights these challenges. Although Gemini 2.5 Pro improves diagram interpretation and analog-circuit reasoning, it still struggles to consistently produce correct solutions when given both text and circuit diagrams. At the same time, engineering education needs scalable AI tools capable of generating accurate solutions for tasks such as automated homework feedback and question-answering. This paper presents an enhanced, end-to-end circuit problem solver built on Gemini 2.5 Pro. We first benchmark Gemini on a representative set of undergraduate circuit problems and identify two major failure modes: 1) circuit-recognition hallucinations, particularly incorrect source polarity detection, and 2) reasoning-process hallucinations, such as incorrect current directions. To address recognition errors, we integrate a fine-tuned YOLO detector and OpenCV processing to isolate voltage and current sources, enabling Gemini to re-identify source polarities from cropped images with near-perfect accuracy. To reduce reasoning errors, we introduce an ngspice-based verification loop in which Gemini generates a .cir file, ngspice simulates the circuit, and discrepancies trigger iterative regeneration with optional human-in-the-loop review. Across 83 problems, the proposed pipeline achieves a 97.59% success rate (81 correct solutions), substantially outperforming Gemini 2.5 Pro’s original 79.52% accuracy. This system extends LLM capabilities for multimodal engineering problem-solving and supports the creation of high-quality educational datasets and AI-powered instructional tools.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-68] Universal Hirschberg for Width Bounded Dynamic Programs</p>
<p>【速读】：该论文试图解决动态规划（Dynamic Programming, DP）中回溯（traceback）过程的空间复杂度优化问题，尤其是在空间受限场景下如何高效重构最优路径。传统方法在网格型DP（如最长公共子序列问题）中需存储整个DP表，空间复杂度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N^2)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0641em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，而Hirschberg算法通过递归中点分割将空间降至 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>N</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(N)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mclose">)</span></span></span></span>。本文将其思想推广至更广泛的具有局部依赖关系的有向无环图（DP DAG）上的动态规划问题，提出一种通用框架：将原DP建模为拓扑序下的确定性演化过程，利用“前段宽度”<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ω</mi></mrow><annotation encoding="application/x-tex">\omega</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span></span></span></span> 和有界入度特性，构造一个高度压缩的递归树结构，在每个节点暴露小规模“中段前段”（middle frontier），使得所有最优路径必经其上；进而通过仅向前重计算的方式实现确定性回溯，空间复杂度为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>ω</mi><mi>log</mi><mo>⁡</mo><mi>T</mi><mo>+</mo><mo stretchy="false">(</mo><mi>log</mi><mo>⁡</mo><mi>T</mi><msup><mo stretchy="false">)</mo><mrow><mi>O</mi><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(\omega \log T + (\log T)^{O(1)})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.03588em;">ω</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1.138em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.02778em;">O</span><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> 为状态数。该方案的关键在于用前向单遍重算替代后向追踪，并以结构化递归组织时间顺序，从而揭示了空间高效的回溯本质上是宽度受限DP DAG的结构性属性，而非仅限于网格类算法的特例。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10132">https://arxiv.org/abs/2512.10132</a><br>
<strong>作者</strong>: Logan Nye<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Data Structures and Algorithms (cs.DS); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  31 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Hirschberg’s algorithm (1975) reduces the space complexity for the longest common subsequence problem from  O(N^2)  to  O(N)  via recursive midpoint bisection on a grid dynamic program (DP). We show that the underlying idea generalizes to a broad class of dynamic programs with local dependencies on directed acyclic graphs (DP DAGs). Modeling a DP as deterministic time evolution over a topologically ordered DAG with frontier width  \omega  and bounded in-degree, and assuming a max-type semiring with deterministic tie breaking, we prove that in a standard offline random-access model any such DP admits deterministic traceback in space  O(\omega \log T + (\log T)^O(1))  cells over a fixed finite alphabet, where  T  is the number of states. Our construction replaces backward dynamic programs by forward-only recomputation and organizes the time order into a height-compressed recursion tree whose nodes expose small &quot;middle frontiers’’ across which every optimal path must pass. The framework yields near-optimal traceback bounds for asymmetric and banded sequence alignment, one-dimensional recurrences, and dynamic-programming formulations on graphs of bounded pathwidth. We also show that an  \Omega(\omega)  space term (in bits) is unavoidable in forward single-pass models and discuss conjectured  \sqrtT -type barriers in streaming settings, supporting the view that space-efficient traceback is a structural property of width-bounded DP DAGs rather than a peculiarity of grid-based algorithms.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-69] VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio</p>
<p>【速读】：该论文旨在解决通用音频表示学习中<strong>内容身份不变性（content identity invariance）<strong>的评估问题，即如何在不依赖标注数据和参数微调的前提下，衡量预训练模型生成的音频嵌入（embedding）在几何空间中的内在对齐能力。传统监督分类基准通过参数更新来评估适应性，而本文提出</strong>VocSim</strong>——一个无需训练的基准测试框架，通过局部纯度（Precision@k）与点级类别分离度（Global Separation Rate, GSR）量化嵌入的空间结构质量。其关键解决方案是：构建包含125k单源音频片段的数据集（覆盖人类语音、动物叫声及环境声），并采用冻结的Whisper编码器特征、时频池化与无标签PCA的简单流水线，实现强零样本性能；同时发现尽管整体表现优于随机基线，但在低资源语音场景下存在显著泛化差距，表明当前模型尚未充分建模未见音位学结构（phonotactics）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10120">https://arxiv.org/abs/2512.10120</a><br>
<strong>作者</strong>: Maris Basha,Anja Zai,Sabine Stoll,Richard Hahnloser<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: ound (<a target="_blank" rel="noopener" href="http://cs.SD">cs.SD</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:General-purpose audio representations aim to map acoustically variable instances of the same event to nearby points, resolving content identity in a zero-shot setting. Unlike supervised classification benchmarks that measure adaptability via parameter updates, we introduce VocSim, a training-free benchmark probing the intrinsic geometric alignment of frozen embeddings. VocSim aggregates 125k single-source clips from 19 corpora spanning human speech, animal vocalizations, and environmental sounds. By restricting to single-source audio, we isolate content representation from the confound of source separation. We evaluate embeddings using Precision@k for local purity and the Global Separation Rate (GSR) for point-wise class separation. To calibrate GSR, we report lift over an empirical permutation baseline. Across diverse foundation models, a simple pipeline, frozen Whisper encoder features, time-frequency pooling, and label-free PCA, yields strong zero-shot performance. However, VocSim also uncovers a consistent generalization gap. On blind, low-resource speech, local retrieval drops sharply. While performance remains statistically distinguishable from chance, the absolute geometric structure collapses, indicating a failure to generalize to unseen phonotactics. As external validation, our top embeddings predict avian perceptual similarity, improve bioacoustic classification, and achieve state-of-the-art results on the HEAR benchmark. We posit that the intrinsic geometric quality measured here proxies utility in unlisted downstream applications. We release data, code, and a public leaderboard to standardize the evaluation of intrinsic audio geometry.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-70] CHyLL: Learning Continuous Neural Representations of Hybrid Systems</p>
<p>【速读】：该论文旨在解决混合系统（Hybrid Systems）中连续与离散时间动态耦合带来的学习挑战，尤其是现有方法在每个离散模式下分别学习动力学时所面临的模式切换与流不连续性问题。其解决方案的关键在于提出CHyLL（Continuous Hybrid System Learning in Latent Space），通过将状态空间重构为一个分段光滑的商流形（quotient manifold），利用重置映射（reset map）在守卫面（guard surface）上粘合状态空间，从而使得流在空间上保持连续；在此基础上，结合微分拓扑中的嵌入定理，CHyLL同时学习高维空间中的无奇点神经嵌入（singularity-free neural embedding）和其中的连续流，实现无需轨迹分割、事件函数或模式切换的统一建模。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10117">https://arxiv.org/abs/2512.10117</a><br>
<strong>作者</strong>: Sangli Teng,Hang Liu,Jingyu Song,Koushil Sreenath<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Signal Processing (eess.SP); Systems and Control (<a target="_blank" rel="noopener" href="http://eess.SY">eess.SY</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Learning the flows of hybrid systems that have both continuous and discrete time dynamics is challenging. The existing method learns the dynamics in each discrete mode, which suffers from the combination of mode switching and discontinuities in the flows. In this work, we propose CHyLL (Continuous Hybrid System Learning in Latent Space), which learns a continuous neural representation of a hybrid system without trajectory segmentation, event functions, or mode switching. The key insight of CHyLL is that the reset map glues the state space at the guard surface, reformulating the state space as a piecewise smooth quotient manifold where the flow becomes spatially continuous. Building upon these insights and the embedding theorems grounded in differential topology, CHyLL concurrently learns a singularity-free neural embedding in a higher-dimensional space and the continuous flow in it. We showcase that CHyLL can accurately predict the flow of hybrid systems with superior accuracy and identify the topological invariants of the hybrid systems. Finally, we apply CHyLL to the stochastic optimal control problem.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-71] AgriRegion: Region-Aware Retrieval for High-Fidelity Agricultural Advice</p>
<p>【速读】：该论文旨在解决通用大语言模型（Large Language Models, LLMs）在农业领域应用中因缺乏地域敏感性而导致的上下文幻觉（contextual hallucination）问题，即模型生成的农事建议可能在某一地区科学合理，但在另一地区因土壤、气候或法规差异而造成误导甚至灾难性后果。解决方案的关键在于提出一种专为农业场景设计的检索增强生成（Retrieval-Augmented Generation, RAG）框架 AgriRegion，其核心创新包括：引入地理空间元数据注入层以增强检索的区域约束能力，并采用基于区域优先级的重排序机制，在知识库检索阶段严格限定于经验证的本地农业推广服务数据，从而确保种植时间表、病虫害防治和施肥等建议具备局部准确性与可信赖性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10114">https://arxiv.org/abs/2512.10114</a><br>
<strong>作者</strong>: Mesafint Fanuel,Mahmoud Nabil Mahmoud,Crystal Cook Marshal,Vishal Lakhotia,Biswanath Dari,Kaushik Roy,Shaohu Zhang<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  15 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) have demonstrated significant potential in democratizing access to information. However, in the domain of agriculture, general-purpose models frequently suffer from contextual hallucination, which provides non-factual advice or answers are scientifically sound in one region but disastrous in another due to variations in soil, climate, and local regulations. We introduce AgriRegion, a Retrieval-Augmented Generation (RAG) framework designed specifically for high-fidelity, region-aware agricultural advisory. Unlike standard RAG approaches that rely solely on semantic similarity, AgriRegion incorporates a geospatial metadata injection layer and a region-prioritized re-ranking mechanism. By restricting the knowledge base to verified local agricultural extension services and enforcing geo-spatial constraints during retrieval, AgriRegion ensures that the advice regarding planting schedules, pest control, and fertilization is locally accurate. We create a novel benchmark dataset, AgriRegion-Eval, which comprises 160 domain-specific questions across 12 agricultural subfields. Experiments demonstrate that AgriRegion reduces hallucinations by 10-20% compared to state-of-the-art LLMs systems and significantly improves trust scores according to a comprehensive evaluation.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-72] Modeling Narrative Archetypes in Conspiratorial Narratives: Insights from Singapore-Based Telegram Groups</p>
<p>【速读】：该论文旨在解决在线 conspiratorial discourse（阴谋论话语）在数字通信生态系统中的结构与传播机制难以研究的问题。传统观点认为此类内容局限于孤立的回音室，但本文通过分析新加坡Telegram群组中的海量消息发现，阴谋论内容实际嵌入日常讨论中，而非仅存在于特定极端群体。解决方案的关键在于提出一个两阶段计算框架：第一阶段使用微调后的RoBERTa-large模型对消息进行分类，F1-score达0.866；第二阶段构建带符号的信念图（signed belief graph），并引入Sign Disentanglement Loss的SiBeGNN模型，分离意识形态一致性与文本风格特征。该方法显著提升了聚类质量（cDBI=8.38），识别出七类叙事原型，揭示了阴谋论话语广泛渗透于金融、法律、媒体等常规议题中，从而挑战了关于线上激进化路径的传统假设，并为立场检测、政治传播和内容审核提供新工具。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10105">https://arxiv.org/abs/2512.10105</a><br>
<strong>作者</strong>: Soorya Ram Shimgekar,Abhay Goyal,Lam Yin Cheung,Roy Ka-Wei Lee,Koustuv Saha,Pi Zonooz,Navin Kumar<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Conspiratorial discourse is increasingly embedded within digital communication ecosystems, yet its structure and spread remain difficult to study. This work analyzes conspiratorial narratives in Singapore-based Telegram groups, showing that such content is woven into everyday discussions rather than confined to isolated echo chambers. We propose a two-stage computational framework. First, we fine-tune RoBERTa-large to classify messages as conspiratorial or not, achieving an F1-score of 0.866 on 2,000 expert-labeled messages. Second, we build a signed belief graph in which nodes represent messages and edge signs reflect alignment in belief labels, weighted by textual similarity. We introduce a Signed Belief Graph Neural Network (SiBeGNN) that uses a Sign Disentanglement Loss to learn embeddings that separate ideological alignment from stylistic features. Using hierarchical clustering on these embeddings, we identify seven narrative archetypes across 553,648 messages: legal topics, medical concerns, media discussions, finance, contradictions in authority, group moderation, and general chat. SiBeGNN yields stronger clustering quality (cDBI = 8.38) than baseline methods (13.60 to 67.27), supported by 88 percent inter-rater agreement in expert evaluations. Our analysis shows that conspiratorial messages appear not only in clusters focused on skepticism or distrust, but also within routine discussions of finance, law, and everyday matters. These findings challenge common assumptions about online radicalization by demonstrating that conspiratorial discourse operates within ordinary social interaction. The proposed framework advances computational methods for belief-driven discourse analysis and offers applications for stance detection, political communication studies, and content moderation policy.         Subjects:  Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)  Cite as: arXiv:2512.10105 [<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>]    (or  arXiv:2512.10105v1 [<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10105">https://doi.org/10.48550/arXiv.2512.10105</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-73] Robust AI Security and Alignment: A Sisyphean Endeavor?</p>
<p>【速读】：该论文试图解决人工智能（AI）安全与对齐（alignment）鲁棒性的信息论极限问题，通过将哥德尔不完备定理（Gödel’s incompleteness theorem）扩展至AI领域，揭示了在理论上无法完全保证AI系统在复杂环境下的安全性和对齐性。其解决方案的关键在于识别并量化这些由逻辑不可判定性带来的根本性限制，并提出实用的应对策略以缓解相关风险；同时，论文进一步证明了AI认知推理能力存在类似的局限性，为构建更可信、可控的AI系统提供了理论基础和实践指导。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10100">https://arxiv.org/abs/2512.10100</a><br>
<strong>作者</strong>: Apostol Vassilev<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This manuscript establishes information-theoretic limitations for robustness of AI security and alignment by extending Gödel’s incompleteness theorem to AI. Knowing these limitations and preparing for the challenges they bring is critically important for the responsible adoption of the AI technology. Practical approaches to dealing with these challenges are provided as well. Broader implications for cognitive reasoning limitations of AI systems are also proven.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-74] MedXAI: A Retrieval-Augmented and Self-Verifying Framework for Knowledge-Guided Medical Image Analysis</p>
<p>【速读】：该论文旨在解决医学图像诊断中深度学习模型在域转移（domain shift）和罕见类别（rare-class）条件下泛化能力差、存在偏倚且缺乏可解释性的问题。其解决方案的关键在于提出一个名为MedXAI的可解释框架，该框架将深度视觉模型与临床专家知识相结合，通过引入符号化（symbolic）的临床先验作为正则化项，不仅提升了模型在跨域场景下的鲁棒性和罕见类别的F1分数（提升10%），还通过定位相关诊断特征提供人类可理解的解释，而非依赖于技术后处理方法（如显著图或LIME）。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10098">https://arxiv.org/abs/2512.10098</a><br>
<strong>作者</strong>: Midhat Urooj,Ayan Banerjee,Farhat Shaikh,Kuntal Thakur,Sandeep Gupta<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:   <a target="_blank" rel="noopener" href="https://cmsworkshops.com/Asilomar2025/Papers/Uploads/FinalPapers/Original/1527/20251130102314_899554_1527.pdf">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Accurate and interpretable image-based diagnosis remains a fundamental challenge in medical AI, particularly un- der domain shifts and rare-class conditions. Deep learning mod- els often struggle with real-world distribution changes, exhibit bias against infrequent pathologies, and lack the transparency required for deployment in safety-critical clinical environments. We introduce MedXAI (An Explainable Framework for Med- ical Imaging Classification), a unified expert knowledge based framework that integrates deep vision models with clinician- derived expert knowledge to improve generalization, reduce rare- class bias, and provide human-understandable explanations by localizing the relevant diagnostic features rather than relying on technical post-hoc methods (e.g., Saliency Maps, LIME). We evaluate MedXAI across heterogeneous modalities on two challenging tasks: (i) Seizure Onset Zone localization from resting-state fMRI, and (ii) Diabetic Retinopathy grading. Ex periments on ten multicenter datasets show consistent gains, including a 3% improvement in cross-domain generalization and a 10% improvmnet in F1 score of rare class, substantially outperforming strong deep learning baselines. Ablations confirm that the symbolic components act as effective clinical priors and regularizers, improving robustness under distribution shift. MedXAI delivers clinically aligned explanations while achieving superior in-domain and cross-domain performance, particularly for rare diseases in multimodal medical AI.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-75] Interpretable Embeddings with Sparse Autoencoders: A Data Analysis Toolkit</p>
<p>【速读】：该论文旨在解决大规模文本语料分析中缺乏高效、可控且可解释的表示方法的问题，尤其针对当前依赖昂贵的大语言模型（LLM）标注或密集嵌入（dense embeddings）进行数据差异识别与偏见检测时所存在的成本高、控制力弱等局限。其解决方案的关键在于引入稀疏自动编码器（sparse autoencoders, SAEs）构建SAE嵌入：这类嵌入的维度对应于可解释的概念（interpretable concepts），从而在保持计算效率的同时赋予分析过程更强的可控性与可解释性。通过四个具体任务验证，SAE嵌入在揭示语义差异、发现意外概念关联、基于属性聚类及检索等方面均优于传统方法，且成本仅为LLM方案的1/2–1/8。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10092">https://arxiv.org/abs/2512.10092</a><br>
<strong>作者</strong>: Nick Jiang,Xiaoqing Sun,Lisa Dunlap,Lewis Smith,Neel Nanda<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:  Code: <a target="_blank" rel="noopener" href="https://github.com/nickjiang2378/interp_embed">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Analyzing large-scale text corpora is a core challenge in machine learning, crucial for tasks like identifying undesirable model behaviors or biases in training data. Current methods often rely on costly LLM-based techniques (e.g. annotating dataset differences) or dense embedding models (e.g. for clustering), which lack control over the properties of interest. We propose using sparse autoencoders (SAEs) to create SAE embeddings: representations whose dimensions map to interpretable concepts. Through four data analysis tasks, we show that SAE embeddings are more cost-effective and reliable than LLMs and more controllable than dense embeddings. Using the large hypothesis space of SAEs, we can uncover insights such as (1) semantic differences between datasets and (2) unexpected concept correlations in documents. For instance, by comparing model responses, we find that Grok-4 clarifies ambiguities more often than nine other frontier models. Relative to LLMs, SAE embeddings uncover bigger differences at 2-8x lower cost and identify biases more reliably. Additionally, SAE embeddings are controllable: by filtering concepts, we can (3) cluster documents along axes of interest and (4) outperform dense embeddings on property-based retrieval. Using SAE embeddings, we study model behavior with two case studies: investigating how OpenAI model behavior has changed over time and finding “trigger” phrases learned by Tulu-3 (Lambert et al., 2024) from its training data. These results position SAEs as a versatile tool for unstructured data analysis and highlight the neglected importance of interpreting models through their data.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-76] Defining the Scope of Learning Analytics: An Axiomatic Approach for Analytic Practice and Measurable Learning Phenomena</p>
<p>【速读】：该论文旨在解决学习分析（Learning Analytics, LA）领域长期存在的理论基础不明确问题，即尽管LA在实践和技术层面迅速发展，但其核心结构、边界和限制尚未得到形式化的理论定义。解决方案的关键在于提出首个公理化理论，通过五个基于心理学学习定义和LA方法论要求的公理，明确定义了LA的本质结构：离散观测、经验建构、状态转移与推断。由此推导出的一系列定理和命题澄清了LA的认识论立场，如学习者状态的不可观测性、时间顺序的不可约性、可达状态的约束以及未来学习无法被确定性预测等关键特性。该理论将LA结构与LA实践建模为形式对象，证明了公理的充分性和必要性，并统一解释了包括贝叶斯知识追踪（Bayesian Knowledge Tracing）和仪表板（dashboards）在内的多种LA方法，从而为分析方法设计和学习数据解释提供了严谨的理论框架，避免了行为主义误区和范畴错误。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10081">https://arxiv.org/abs/2512.10081</a><br>
<strong>作者</strong>: Kensuke Takii,Changhao Liang,Hiroaki Ogata<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
<strong>备注</strong>:  27 pages, 1 figure, 2 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Learning Analytics (LA) has rapidly expanded through practical and technological innovation, yet its foundational identity has remained theoretically under-specified. This paper addresses this gap by proposing the first axiomatic theory that formally defines the essential structure, scope, and limitations of LA. Derived from the psychological definition of learning and the methodological requirements of LA, the framework consists of five axioms specifying discrete observation, experience construction, state transition, and inference. From these axioms, we derive a set of theorems and propositions that clarify the epistemological stance of LA, including the inherent unobservability of learner states, the irreducibility of temporal order, constraints on reachable states, and the impossibility of deterministically predicting future learning. We further define LA structure and LA practice as formal objects, demonstrating the sufficiency and necessity of the axioms and showing that diverse LA approaches – such as Bayesian Knowledge Tracing and dashboards – can be uniformly explained within this framework. The theory provides guiding principles for designing analytic methods and interpreting learning data while avoiding naive behaviorism and category errors by establishing an explicit theoretical inference layer between observations and states. This work positions LA as a rigorous science of state transition systems based on observability, establishing the theoretical foundation necessary for the field’s maturation as a scholarly discipline.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-77] Linear socio-demographic representations emerge in <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  from indirect cues</p>
<p>【速读】：该论文旨在解决大语言模型（Large Language Models, LLMs）如何通过间接线索（如姓名和职业）编码用户社会人口学属性的问题，以及这些隐式表征如何影响模型的下游行为。其关键解决方案在于发现并验证了LLMs在激活空间中对用户 demographics 建立线性表示，其中与刻板印象相关的属性沿可解释的几何方向编码；通过探测四个基于Transformer的开源模型（Magistral 24B、Qwen3 14B、GPT-OSS 20B、OLMo2-1B）的残差流，研究者证明相同探针不仅能预测显式披露的人口统计信息，还能从隐式线索（如姓名激活性别与种族表征，职业触发与现实劳动力统计数据相关的表征）中准确推断出用户属性。这一机制揭示了LLMs在对话中形成的隐式偏见，并表明即使模型通过了传统偏见基准测试，仍可能利用此类隐式表征导致不公平决策，如职业推荐偏差。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10065">https://arxiv.org/abs/2512.10065</a><br>
<strong>作者</strong>: Paul Bouchaud,Pedro Ramaciotti<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Human-Computer Interaction (cs.HC)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We investigate how LLMs encode sociodemographic attributes of human conversational partners inferred from indirect cues such as names and occupations. We show that LLMs develop linear representations of user demographics within activation space, wherein stereotypically associated attributes are encoded along interpretable geometric directions. We first probe residual streams across layers of four open transformer-based LLMs (Magistral 24B, Qwen3 14B, GPT-OSS 20B, OLMo2-1B) prompted with explicit demographic disclosure. We show that the same probes predict demographics from implicit cues: names activate census-aligned gender and race representations, while occupations trigger representations correlated with real-world workforce statistics. These linear representations allow us to explain demographic inferences implicitly formed by LLMs during conversation. We demonstrate that these implicit demographic representations actively shape downstream behavior, such as career recommendations. Our study further highlights that models that pass bias benchmark tests may still harbor and leverage implicit biases, with implications for fairness when applied at scale.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-78] Mind the Gap! Pathways Towards Unifying AI Safety and Ethics Research</p>
<p>【速读】：该论文试图解决人工智能（Artificial Intelligence, AI）领域中安全（safety）与伦理（ethics）研究路径日益分化的问题，这种分化导致对“对齐”（alignment）概念的理解分歧和协作隔离，进而影响构建既稳健又公正的AI系统的能力。其解决方案的关键在于推动技术安全工作与规范性伦理的整合，具体包括建立共享基准、创建跨机构交流平台以及采用混合方法论，以促进两个领域之间的实质性合作，从而提升AI系统的整体安全性与社会正当性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10058">https://arxiv.org/abs/2512.10058</a><br>
<strong>作者</strong>: Dani Roytburg,Beck Miller<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>); Human-Computer Interaction (cs.HC); Social and Information Networks (<a target="_blank" rel="noopener" href="http://cs.SI">cs.SI</a>)<br>
<strong>备注</strong>:  Accepted for presentation at IASEAI 2026</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:While much research in artificial intelligence (AI) has focused on scaling capabilities, the accelerating pace of development makes countervailing work on producing harmless, “aligned” systems increasingly urgent. Yet research on alignment has diverged along two largely parallel tracks: safety–centered on scaled intelligence, deceptive or scheming behaviors, and existential risk–and ethics–focused on present harms, the reproduction of social bias, and flaws in production pipelines. Although both communities warn of insufficient investment in alignment, they disagree on what alignment means or ought to mean. As a result, their efforts have evolved in relative isolation, shaped by distinct methodologies, institutional homes, and disciplinary genealogies. We present a large-scale, quantitative study showing the structural split between AI safety and AI ethics. Using a bibliometric and co-authorship network analysis of 6,442 papers from twelve major ML and NLP conferences (2020-2025), we find that over 80% of collaborations occur within either the safety or ethics communities, and cross-field connectivity is highly concentrated: roughly 5% of papers account for more than 85% of bridging links. Removing a small number of these brokers sharply increases segregation, indicating that cross-disciplinary exchange depends on a handful of actors rather than broad, distributed collaboration. These results show that the safety-ethics divide is not only conceptual but institutional, with implications for research agendas, policy, and venues. We argue that integrating technical safety work with normative ethics–via shared benchmarks, cross-institutional venues, and mixed-method methodologies–is essential for building AI systems that are both robust and just.          Comments: Accepted for presentation at IASEAI 2026   Subjects:  Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computers and Society (<a target="_blank" rel="noopener" href="http://cs.CY">cs.CY</a>); Human-Computer Interaction (cs.HC); Social and Information Networks (<a target="_blank" rel="noopener" href="http://cs.SI">cs.SI</a>)  Cite as: arXiv:2512.10058 [<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>]    (or  arXiv:2512.10058v1 [<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10058">https://doi.org/10.48550/arXiv.2512.10058</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-79] DB2-TransF: All You Need Is Learnable Daubechies Wavelets for Time Series Forecasting</p>
<p>【速读】：该论文旨在解决时间序列预测中Transformer架构因自注意力机制导致的二次计算复杂度问题，从而限制了其在大规模和高维场景下的可扩展性与适应性。解决方案的关键在于提出一种名为DB2-TransF的新颖Transformer-inspired架构，其核心创新是用可学习的Daubechies小波系数层替代传统的自注意力模块，该模块能够高效捕捉多尺度的局部与全局模式，并增强对多个时间序列间相关性的建模能力，从而在保持或提升预测精度的同时显著降低内存消耗。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10051">https://arxiv.org/abs/2512.10051</a><br>
<strong>作者</strong>: Moulik Gupta,Achyut Mani Tripathi<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Signal Processing (eess.SP)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Time series forecasting requires models that can efficiently capture complex temporal dependencies, especially in large-scale and high-dimensional settings. While Transformer-based architectures excel at modeling long-range dependencies, their quadratic computational complexity poses limitations on scalability and adaptability. To overcome these challenges, we introduce DB2-TransF, a novel Transformer-inspired architecture that replaces the self-attention mechanism with a learnable Daubechies wavelet coefficient layer. This wavelet-based module efficiently captures multi-scale local and global patterns and enhances the modeling of correlations across multiple time series for the time series forecasting task. Extensive experiments on 13 standard forecasting benchmarks demonstrate that DB2-TransF achieves comparable or superior predictive accuracy to conventional Transformers, while substantially reducing memory usage for the time series forecasting task. The obtained experimental results position DB2-TransF as a scalable and resource-efficient framework for advanced time series forecasting. Our code is available at this https URL<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-80] Detailed balance in large language model-driven <mark class="hl-label green">agents</mark></p>
<p>【速读】：该论文试图解决的问题是：当前基于大语言模型（Large Language Model, LLM）驱动的智能体在复杂任务中表现出显著的实践成效，但缺乏一个统一的理论框架来理解其宏观动态行为。为应对这一挑战，作者提出了一种基于最小作用量原理（least action principle）的方法，用于估计嵌入于智能体中的LLM所具有的潜在生成方向性。解决方案的关键在于通过实验测量LLM生成状态间的转移概率，发现其满足细致平衡（detailed balance）特性，这表明LLM的生成机制并非依赖显式规则或策略学习，而是隐式地学习了一类超越具体模型架构与提示模板的潜在势函数（potential function）。这一发现首次揭示了LLM生成动力学中存在的宏观物理规律，不依赖于特定模型细节，为构建可预测、可量化的大规模AI系统宏观动力学理论奠定了基础。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10047">https://arxiv.org/abs/2512.10047</a><br>
<strong>作者</strong>: Zhuo-Yang Song,Qing-Hong Cao,Ming-xing Luo,Hua Xing Zhu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Statistical Mechanics (cond-mat.stat-mech); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Adaptation and Self-Organizing Systems (<a target="_blank" rel="noopener" href="http://nlin.AO">nlin.AO</a>); Data Analysis, Statistics and Probability (physics.data-an)<br>
<strong>备注</strong>:  20 pages, 12 figures, 5 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large language model (LLM)-driven agents are emerging as a powerful new paradigm for solving complex problems. Despite the empirical success of these practices, a theoretical framework to understand and unify their macroscopic dynamics remains lacking. This Letter proposes a method based on the least action principle to estimate the underlying generative directionality of LLMs embedded within agents. By experimentally measuring the transition probabilities between LLM-generated states, we statistically discover a detailed balance in LLM-generated transitions, indicating that LLM generation may not be achieved by generally learning rule sets and strategies, but rather by implicitly learning a class of underlying potential functions that may transcend different LLM architectures and prompt templates. To our knowledge, this is the first discovery of a macroscopic physical law in LLM generative dynamics that does not depend on specific model details. This work is an attempt to establish a macroscopic dynamics theory of complex AI systems, aiming to elevate the study of AI agents from a collection of engineering practices to a science built on effective measurements that are predictable and quantifiable.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-81] SimWorld-Robotics: Synthesizing Photorealistic and Dynamic Urban Environments for Multimodal Robot Navigation and Collaboration <mark class="hl-label red">NEURIPS2025</mark></p>
<p>【速读】：该论文旨在解决当前机器人研究中缺乏在大规模、高保真城市环境中评估多模态感知、复杂导航与多机器人协作能力的仿真平台和基准任务的问题。现有工作主要局限于室内家庭场景，难以验证模型在真实城市动态环境中的泛化性和鲁棒性。解决方案的关键在于构建SimWorld-Robotics（SWR）仿真平台，其基于Unreal Engine 5实现无限生成的高保真城市场景，并集成行人、交通系统等动态元素，支持多机器人控制与通信；在此基础上设计了两个新型机器人基准任务：一是视觉-语言指令跟随导航任务，要求机器人在存在行人和交通干扰下完成长距离安全导航；二是多智能体协同搜索任务，考验机器人之间的语义通信与协作定位能力。这两个任务共同评估了包括多模态指令理解、三维空间推理、安全长距导航、多机器人协作及具身通信在内的关键能力，实验表明当前最先进的视觉-语言模型（VLMs）在这些任务中表现不足，凸显了面向城市级机器人应用的挑战与研究必要性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10046">https://arxiv.org/abs/2512.10046</a><br>
<strong>作者</strong>: Yan Zhuang,Jiawei Ren,Xiaokang Ye,Jianzhi Shen,Ruixuan Zhang,Tianai Yue,Muhammad Faayez,Xuhong He,Ziqiao Ma,Lianhui Qin,Zhiting Hu,Tianmin Shu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  Conference: NeurIPS 2025 (main)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advances in foundation models have shown promising results in developing generalist robotics that can perform diverse tasks in open-ended scenarios given multimodal inputs. However, current work has been mainly focused on indoor, household scenarios. In this work, we present SimWorld-Robotics~(SWR), a simulation platform for embodied AI in large-scale, photorealistic urban environments. Built on Unreal Engine 5, SWR procedurally generates unlimited photorealistic urban scenes populated with dynamic elements such as pedestrians and traffic systems, surpassing prior urban simulations in realism, complexity, and scalability. It also supports multi-robot control and communication. With these key features, we build two challenging robot benchmarks: (1) a multimodal instruction-following task, where a robot must follow vision-language navigation instructions to reach a destination in the presence of pedestrians and traffic; and (2) a multi-agent search task, where two robots must communicate to cooperatively locate and meet each other. Unlike existing benchmarks, these two new benchmarks comprehensively evaluate a wide range of critical robot capacities in realistic scenarios, including (1) multimodal instructions grounding, (2) 3D spatial reasoning in large environments, (3) safe, long-range navigation with people and traffic, (4) multi-robot collaboration, and (5) grounded communication. Our experimental results demonstrate that state-of-the-art models, including vision-language models (VLMs), struggle with our tasks, lacking robust perception, reasoning, and planning abilities necessary for urban environments.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-82] Intelligently Weighting Multiple Reference Models for Direct Preference Optimization of <mark class="hl-label green">LLM</mark> s</p>
<p>【速读】：该论文旨在解决多参考偏好优化（Multiple-Reference Preference Optimization, MRPO）中参考模型权重设定缺乏统计严谨性的问题，当前方法多为经验性设定，导致性能不稳定。其解决方案的关键在于提出四种新的加权策略：两种离线方法利用保留验证集信号进行优化；一种在线方法采用滑动窗口估计器降低过拟合风险；另一种将参考权重选择建模为K-臂赌博机问题并使用Thompson采样进行动态调整。实验表明，这四种策略在UltraFeedback和SafeRLHF数据集上均优于现有MRPO方法，但更令人深思的是，单参考DPO（使用7个参考模型中的任意6个）始终优于所有多参考方法，挑战了多参考策略的实际有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10040">https://arxiv.org/abs/2512.10040</a><br>
<strong>作者</strong>: Skyler Wu,Aymen Echarghaoui<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
<strong>备注</strong>:  Working paper. 13 pages, 4 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Fine-tuning is integral for aligning large language models (LLMs) with human preferences. Multiple-Reference Preference Optimization (MRPO) builds on Direct Preference Optimization (DPO) by fine-tuning LLMs on preference datasets while regularizing the policy towards a mixture of reference models to leverage their collective desirable properties. However, current methods for setting the reference weights are ad-hoc and statistically unsound, leading to unreliable performance. To address this, we introduce four new weighting strategies: two offline methods that leverage held-out validation signal; one online method that uses a sliding-window estimator to reduce overfitting; and an online method that treats reference weighting as a  K -armed bandit via Thompson Sampling. Experiments using Qwen2.5-0.5B as the policy model and seven reference models from the Llama, Mistral, Qwen, Yi, and Phi families (0.5B-14B each) show that all 4 of our strategies outperform the current MRPO weighting methods on UltraFeedback and SafeRLHF in preference accuracy. More thought-provokingly, however, we find that single-reference DPO, using any of 6 out of 7 references, consistently outperforms all tested multiple-reference approaches – calling into question the practical appeal of multiple-reference approaches.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-83] DynaMate: An Autonomous <mark class="hl-label green">Agent</mark>  for Protein-Ligand Molecular Dynamics Simulations</p>
<p>【速读】：该论文旨在解决分子动力学（Molecular Dynamics, MD）模拟在生物分子系统（如蛋白质及其配体复合物）研究中因参数化、输入准备和软件配置等技术复杂性而导致的广泛应用障碍。其核心解决方案是提出一个名为DynaMate的模块化多智能体框架，通过动态工具调用、网络搜索、PaperQA信息提取以及自我纠错机制，实现从实验设计到模拟执行再到结果分析的全流程自动化。该框架的关键创新在于将多个专业化模块协同集成，不仅提升了MD工作流的可靠性与适应性，还支持基于MM/PB(GB)SA方法的结合自由能计算，从而显著增强分子建模流程的标准化、可扩展性和效率。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10034">https://arxiv.org/abs/2512.10034</a><br>
<strong>作者</strong>: Salomé Guilbert,Cassandra Masschelein,Jeremy Goumaz,Bohdan Naida,Philippe Schwaller<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Computational Engineering, Finance, and Science (cs.CE)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Force field-based molecular dynamics (MD) simulations are indispensable for probing the structure, dynamics, and functions of biomolecular systems, including proteins and protein-ligand complexes. Despite their broad utility in drug discovery and protein engineering, the technical complexity of MD setup, encompassing parameterization, input preparation, and software configuration, remains a major barrier for widespread and efficient usage. Agentic LLMs have demonstrated their capacity to autonomously execute multi-step scientific processes, and to date, they have not successfully been used to automate protein-ligand MD workflows. Here, we present DynaMate, a modular multi-agent framework that autonomously designs and executes complete MD workflows for both protein and protein-ligand systems, and offers free energy binding affinity calculations with the MM/PB(GB)SA method. The framework integrates dynamic tool use, web search, PaperQA, and a self-correcting behavior. DynaMate comprises three specialized modules, interacting to plan the experiment, perform the simulation, and analyze the results. We evaluated its performance across twelve benchmark systems of varying complexity, assessing success rate, efficiency, and adaptability. DynaMate reliably performed full MD simulations, corrected runtime errors through iterative reasoning, and produced meaningful analyses of protein-ligand interactions. This automated framework paves the way toward standardized, scalable, and time-efficient molecular modeling pipelines for future biomolecular and drug design applications.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-84] Cluster-Dags as Powerful Background Knowledge For Causal Discovery</p>
<p>【速读】：该论文旨在解决高维数据下因果发现（causal discovery）中因复杂依赖关系和缺乏有效先验知识而导致的准确性与效率问题。其解决方案的关键在于引入Cluster-DAGs作为结构先验，以引导因果发现过程：相较于传统基于分层背景知识的方法，Cluster-DAGs提供了更高的灵活性；在此基础上，作者提出了两种改进的约束基算法——Cluster-PC（适用于完全观测场景）和Cluster-FCI（适用于部分观测场景），通过利用Cluster-DAGs中的聚类结构信息来加速收敛并提升因果图恢复的准确性。实验证明，这两种方法在模拟数据上显著优于不使用先验知识的基线模型。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10032">https://arxiv.org/abs/2512.10032</a><br>
<strong>作者</strong>: Jan Marco Ruiz de Vargas,Kirtan Padh,Niki Kilbertus<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
<strong>备注</strong>:  23 pages, 5 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Finding cause-effect relationships is of key importance in science. Causal discovery aims to recover a graph from data that succinctly describes these cause-effect relationships. However, current methods face several challenges, especially when dealing with high-dimensional data and complex dependencies. Incorporating prior knowledge about the system can aid causal discovery. In this work, we leverage Cluster-DAGs as a prior knowledge framework to warm-start causal discovery. We show that Cluster-DAGs offer greater flexibility than existing approaches based on tiered background knowledge and introduce two modified constraint-based algorithms, Cluster-PC and Cluster-FCI, for causal discovery in the fully and partially observed setting, respectively. Empirical evaluation on simulated data demonstrates that Cluster-PC and Cluster-FCI outperform their respective baselines without prior knowledge.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-85] Fuzzy Hierarchical Multiplex</p>
<p>【速读】：该论文旨在解决服务流程设计中信息传输的服务优化问题，其核心挑战在于如何有效建模概念之间的逻辑蕴含关系与层次结构，以提升服务效率。解决方案的关键在于提出一种扩展的模糊优化框架（fuzzy optimization framework），该框架基于FCM（Fuzzy Cognitive Map）因果关系，通过动态映射将数据转化为度量指标，并利用多层网络（multiplex）结构分析概念间的逻辑蕴含与层级关系，从而为服务过程的信息传输优化提供理论支撑与方法基础。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09976">https://arxiv.org/abs/2512.09976</a><br>
<strong>作者</strong>: Alexis Kafantaris<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG); Systems and Control (<a target="_blank" rel="noopener" href="http://eess.SY">eess.SY</a>)<br>
<strong>备注</strong>:  11 pages, 2 figures, 1 double figure, 1 table, 12 references. This will be part of my PhD dissertation and it is a White paper-theoretical framewor. As is, it s meant for a basis that will be later used to further developed an FHM. It might not be math-logic related and I am willing to change it, I just felt that it belonged to mathematical modeling. Yours truly, AK</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:A new fuzzy optimization framework that extends FCM causality is proposed. This model utilizes the dynamics to map data into metrics and create a framework that examines logical implication and hierarchy of concepts using a multiplex. Moreover, this is a white-theoretical paper introducing the framework and analyzing the logic and math behind it. Upon this extension the main objectives and the orientation of this framework is expounded and exemplified; this framework is meant for service optimization of information transmission in service process design. Lastly, a thorough analysis of the FHM is included which is done following the logical steps in a simple and elegant manner.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-86] ZK-APEX: Zero-Knowledge Approximate Personalized Unlearning with Executable Proofs</p>
<p>【速读】：该论文旨在解决边缘设备上个性化模型的可验证删除（verifiable personalized unlearning）问题，即在分布式学习场景中，当用户请求删除其私有数据时，如何确保客户端正确执行遗忘操作而不泄露隐私或影响本地模型性能，同时提供轻量级且无需重新训练的验证机制。解决方案的关键在于提出 ZK APEX 方法，它通过在提供商端采用稀疏掩码（sparse masking）与客户端侧的小规模 Group OBS 补偿步骤相结合，并利用分块经验 Fisher 矩阵（blockwise empirical Fisher matrix）设计曲率感知更新，实现低开销的个性化遗忘；进一步结合 Halo2 零知识证明（zero-knowledge proofs），使提供商可在不访问客户端私有数据或参数的情况下验证遗忘操作的正确性，从而首次实现了边缘设备上的可验证个性化遗忘框架。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09953">https://arxiv.org/abs/2512.09953</a><br>
<strong>作者</strong>: Mohammad M Maheri,Sunil Cotterill,Alex Davidson,Hamed Haddadi<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Machine unlearning aims to remove the influence of specific data points from a trained model to satisfy privacy, copyright, and safety requirements. In real deployments, providers distribute a global model to many edge devices, where each client personalizes the model using private data. When a deletion request is issued, clients may ignore it or falsely claim compliance, and providers cannot check their parameters or data. This makes verification difficult, especially because personalized models must forget the targeted samples while preserving local utility, and verification must remain lightweight on edge devices. We introduce ZK APEX, a zero-shot personalized unlearning method that operates directly on the personalized model without retraining. ZK APEX combines sparse masking on the provider side with a small Group OBS compensation step on the client side, using a blockwise empirical Fisher matrix to create a curvature-aware update designed for low overhead. Paired with Halo2 zero-knowledge proofs, it enables the provider to verify that the correct unlearning transformation was applied without revealing any private data or personalized parameters. On Vision Transformer classification tasks, ZK APEX recovers nearly all personalization accuracy while effectively removing the targeted information. Applied to the OPT125M generative model trained on code data, it recovers around seventy percent of the original accuracy. Proof generation for the ViT case completes in about two hours, more than ten million times faster than retraining-based checks, with less than one gigabyte of memory use and proof sizes around four hundred megabytes. These results show the first practical framework for verifiable personalized unlearning on edge devices.         Subjects:  Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)  Cite as: arXiv:2512.09953 [<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>]    (or  arXiv:2512.09953v1 [<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.09953">https://doi.org/10.48550/arXiv.2512.09953</a>   Focus to learn more                      arXiv-issued DOI via DataCite<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-87] ELANA: A Simple Energy and Latency Analyzer for <mark class="hl-label green">LLM</mark> s</p>
<p>【速读】：该论文旨在解决大语言模型（Large Language Models, LLMs）在不同硬件平台（从移动边缘设备到云端GPU集群）上部署时面临的延迟（latency）和功耗（power consumption）瓶颈问题，这对模型效率优化与下一代模型设计至关重要。解决方案的关键在于提出并开源了一个轻量级、面向学术研究的 profiling 工具 ELANA，其可统一评估 LLM 的模型规模、键值缓存（key-value cache）大小、预填充延迟（Time-to-first-token, TTFT）、生成延迟（Time-per-output-token, TPOT）及端到端延迟（Time-to-last-token, TTLT），支持多GPU与边缘GPU平台，并兼容 Hugging Face 生态系统，具备命令行接口和可选能耗日志功能，适用于高效 LLM 研究及小规模概念验证实验。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09946">https://arxiv.org/abs/2512.09946</a><br>
<strong>作者</strong>: Hung-Yueh Chiang,Bokun Wang,Diana Marculescu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Distributed, Parallel, and Cluster Computing (cs.DC); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The latency and power consumption of large language models (LLMs) are major constraints when serving them across a wide spectrum of hardware platforms, from mobile edge devices to cloud GPU clusters. Benchmarking is crucial for optimizing efficiency in both model deployment and next-generation model development. To address this need, we open-source a simple profiling tool, \textbfELANA, for evaluating LLMs. ELANA is designed as a lightweight, academic-friendly profiler for analyzing model size, key-value (KV) cache size, prefilling latency (Time-to-first-token, TTFT), generation latency (Time-per-output-token, TPOT), and end-to-end latency (Time-to-last-token, TTLT) of LLMs on both multi-GPU and edge GPU platforms. It supports all publicly available models on Hugging Face and offers a simple command-line interface, along with optional energy consumption logging. Moreover, ELANA is fully compatible with popular Hugging Face APIs and can be easily customized or adapted to compressed or low bit-width models, making it ideal for research on efficient LLMs or for small-scale proof-of-concept studies. We release the ELANA profiling tool at: this https URL.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-88] Norm-Governed Multi-<mark class="hl-label green">Agent</mark>  Decision-Making in Simulator-Coupled Environments:The Reinsurance Constrained Multi-<mark class="hl-label green">Agent</mark>  Simulation Process (R-CMASP)</p>
<p>【速读】：该论文旨在解决再保险决策中因信息分布不均、可观测性受限、责任异质性及监管约束严格等复杂因素导致的传统确定性自动化流程难以满足机构风险转移需求的问题。其核心挑战在于如何实现具有认知灵活性、协作协调机制和规范敏感性的多智能体决策系统。解决方案的关键在于提出一种形式化模型——再保险约束多智能体仿真过程（Reinsurance Constrained Multi-Agent Simulation Process, R-CMASP），该模型通过三个关键扩展增强传统随机博弈与Dec-POMDP框架：(i) 基于灾害、资本和投资组合引擎的模拟器耦合状态转移动力学；(ii) 具备结构化可观测性、信念更新和类型化通信的角色专业化智能体；(iii) 将偿付能力、监管和组织规则编码为联合动作的可接受性约束的规范可行性层。实验表明，基于大语言模型（LLM）并具备工具访问和类型化消息协议的多智能体协同机制，在校准后的合成环境中显著优于确定性自动化或单体LLM基线，表现为定价方差降低、资本效率提升及条款解释准确率提高，验证了将审慎规范嵌入为可接受性约束并结构化通信方式对均衡稳定性的改善作用。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09939">https://arxiv.org/abs/2512.09939</a><br>
<strong>作者</strong>: Stella C. Dong<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Multiagent Systems (<a target="_blank" rel="noopener" href="http://cs.MA">cs.MA</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Reinsurance decision-making exhibits the core structural properties that motivate multi-agent models: distributed and asymmetric information, partial observability, heterogeneous epistemic responsibilities, simulator-driven environment dynamics, and binding prudential and regulatory constraints. Deterministic workflow automation cannot meet these requirements, as it lacks the epistemic flexibility, cooperative coordination mechanisms, and norm-sensitive behaviour required for institutional risk-transfer. We propose the Reinsurance Constrained Multi-Agent Simulation Process (R-CMASP), a formal model that extends stochastic games and Dec-POMDPs by adding three missing elements: (i) simulator-coupled transition dynamics grounded in catastrophe, capital, and portfolio engines; (ii) role-specialized agents with structured observability, belief updates, and typed communication; and (iii) a normative feasibility layer encoding solvency, regulatory, and organizational rules as admissibility constraints on joint actions. Using LLM-based agents with tool access and typed message protocols, we show in a domain-calibrated synthetic environment that governed multi-agent coordination yields more stable, coherent, and norm-adherent behaviour than deterministic automation or monolithic LLM baselines–reducing pricing variance, improving capital efficiency, and increasing clause-interpretation accuracy. Embedding prudential norms as admissibility constraints and structuring communication into typed acts measurably enhances equilibrium stability. Overall, the results suggest that regulated, simulator-driven decision environments are most naturally modelled as norm-governed, simulator-coupled multi-agent systems.         Subjects:  Multiagent Systems (<a target="_blank" rel="noopener" href="http://cs.MA">cs.MA</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)  Cite as: arXiv:2512.09939 [<a target="_blank" rel="noopener" href="http://cs.MA">cs.MA</a>]    (or  arXiv:2512.09939v1 [<a target="_blank" rel="noopener" href="http://cs.MA">cs.MA</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.09939">https://doi.org/10.48550/arXiv.2512.09939</a>   Focus to learn more                      arXiv-issued DOI via DataCite        Submission history From: Stella Dong [view email]       [v1]         Thu, 4 Dec 2025 10:30:26 UTC (33 KB)<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-89] Exploring Health Misinformation Detection with Multi-<mark class="hl-label green">Agent</mark>  Debate</p>
<p>【速读】：该论文旨在解决健康类虚假信息（health misinformation）在线传播加剧背景下，如何有效验证健康相关声明的真实性问题。其核心挑战在于：一方面需要从海量信息中检索高质量证据，另一方面需进行严谨的推理以形成可信结论。解决方案的关键在于提出一个两阶段框架：第一阶段通过大语言模型（Large Language Models, LLMs）独立评估检索到的文章，并计算聚合一致得分（agreement score）以反映整体证据立场；若得分低于预设阈值，则进入第二阶段——多个智能体（agents）开展结构化辩论，整合冲突证据并生成具有明确论证依据的最终判断。该方法结合了自动化评分与协作式推理机制，在复杂验证任务中展现出优于基线方法的性能优势。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09935">https://arxiv.org/abs/2512.09935</a><br>
<strong>作者</strong>: Chih-Han Chen,Chen-Han Tsai,Yu-Shao Peng<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Fact-checking health-related claims has become increasingly critical as misinformation proliferates online. Effective verification requires both the retrieval of high-quality evidence and rigorous reasoning processes. In this paper, we propose a two-stage framework for health misinformation detection: Agreement Score Prediction followed by Multi-Agent Debate. In the first stage, we employ large language models (LLMs) to independently evaluate retrieved articles and compute an aggregated agreement score that reflects the overall evidence stance. When this score indicates insufficient consensus-falling below a predefined threshold-the system proceeds to a second stage. Multiple agents engage in structured debate to synthesize conflicting evidence and generate well-reasoned verdicts with explicit justifications. Experimental results demonstrate that our two-stage approach achieves superior performance compared to baseline methods, highlighting the value of combining automated scoring with collaborative reasoning for complex verification tasks.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-90] IoTEdu: Access Control Detection and Automatic Incident Response in Academic IoT Networks</p>
<p>【速读】：该论文旨在解决学术环境中物联网（IoT）设备日益增多所带来的运营复杂性和安全漏洞问题，尤其是在缺乏统一注册、监控和事件响应政策的机构中。解决方案的关键在于提出一个集成平台IoTEdu，其核心功能包括访问控制、事件检测与自动阻断机制，通过在受控环境中模拟攻击测试，实现了平均28.6秒的从检测到阻断的时间延迟，从而显著减少了人工干预、标准化了响应流程，并统一了注册、监控与事件响应的管理过程。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09934">https://arxiv.org/abs/2512.09934</a><br>
<strong>作者</strong>: Joner Assolin,Diego Kreutz,Leandro Bertholdo<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Networking and Internet Architecture (<a target="_blank" rel="noopener" href="http://cs.NI">cs.NI</a>); Software Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>)<br>
<strong>备注</strong>:  5 pages, 2 figures, and 3 tables, accepted for presentation at ERRC/WRSeg 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The growing presence of IoT devices in academic environments has increased operational complexity and exposed security weaknesses, especially in academic institutions without unified policies for registration, monitoring, and incident response involving IoT. This work presents IoTEdu, an integrated platform that combines access control, incident detection, and automatic blocking of IoT devices. The solution was evaluated in a controlled environment with simulated attacks, achieving an average time of 28.6 seconds between detection and blocking. The results show a reduction in manual intervention, standardization of responses, and unification of the processes of registration, monitoring, and incident response.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-91] Suzume-chan: Your Personal Navigator as an Embodied Information Hub</p>
<p>【速读】：该论文试图解决的问题是：数字工具虽能提升信息获取效率，但难以营造深度理解所需的“人际连接感”，即缺乏社会存在感（Social Presence）导致知识传递过程中的心理距离过远。解决方案的关键在于提出一种“具身化信息枢纽”（Embodied Information Hub），通过物理形态与对话交互的结合来增强用户与AI之间的亲近感；其原型Suzume-chan是一个本地运行的小型软体AI代理，采用语言模型与检索增强生成（Retrieval-Augmented Generation, RAG）技术，能够从语音讲解中学习并以对话方式回应，从而有效降低心理距离，使知识共享更具人性化和温度。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09932">https://arxiv.org/abs/2512.09932</a><br>
<strong>作者</strong>: Maya Grace Torii,Takahito Murakami,Shuka Koseki,Yoichi Ochiai<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Human-Computer Interaction (cs.HC)<br>
<strong>备注</strong>:  3 pages, 1 figure, This study will demonstrate at WISS 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Access to expert knowledge often requires real-time human communication. Digital tools improve access to information but rarely create the sense of connection needed for deep understanding. This study addresses this issue using Social Presence Theory, which explains how a feeling of “being together” enhances communication. An “Embodied Information Hub” is proposed as a new way to share knowledge through physical and conversational interaction. The prototype, Suzume-chan, is a small, soft AI agent running locally with a language model and retrieval-augmented generation (RAG). It learns from spoken explanations and responds through dialogue, reducing psychological distance and making knowledge sharing warmer and more human-centered.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-92] ExaCraft: Dynamic Learning Context Adaptation for Personalized Educational Examples</p>
<p>【速读】：该论文旨在解决当前教育人工智能（Educational AI）工具在个性化教学支持方面的不足，即缺乏生成与学习者个人背景相关且能动态适应其理解变化、学习困难和技能提升的示例能力。解决方案的关键在于开发ExaCraft系统，该系统通过整合用户定义的个人特征（如地理位置、教育背景、职业及复杂度偏好）与实时学习行为分析，实现对五类关键学习情境维度的动态响应：挣扎指标、掌握模式、主题进展历史、会话边界以及学习进度信号。这一机制使生成的示例能够从基础概念逐步演进至高级技术实现，并根据重复学习、重新生成请求及主题推进模式灵活调整，从而显著提升学习的相关性与有效性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09931">https://arxiv.org/abs/2512.09931</a><br>
<strong>作者</strong>: Akaash Chatterjee(1),Suman Kundu(1) ((1) Indian Institute of Technology Jodhpur)<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Human-Computer Interaction (cs.HC)<br>
<strong>备注</strong>:  5 pages, 1 Figure</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Learning is most effective when it’s connected to relevant, relatable examples that resonate with learners on a personal level. However, existing educational AI tools don’t focus on generating examples or adapting to learners’ changing understanding, struggles, or growing skills. We’ve developed ExaCraft, an AI system that generates personalized examples by adapting to the learner’s dynamic context. Through the Google Gemini AI and Python Flask API, accessible via a Chrome extension, ExaCraft combines user-defined profiles (including location, education, profession, and complexity preferences) with real-time analysis of learner behavior. This ensures examples are both culturally relevant and tailored to individual learning needs. The system’s core innovation is its ability to adapt to five key aspects of the learning context: indicators of struggle, mastery patterns, topic progression history, session boundaries, and learning progression signals. Our demonstration will show how ExaCraft’s examples evolve from basic concepts to advanced technical implementations, responding to topic repetition, regeneration requests, and topic progression patterns in different use cases.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-93] UniExtreme: A Universal Foundation Model for Extreme Weather Forecasting <mark class="hl-label red">KDD2026</mark></p>
<p>【速读】：该论文旨在解决当前基础模型（Foundation Models, FMs）在极端天气事件预测能力上的局限性问题，即现有方法要么仅关注一般天气条件，要么局限于特定类型的极端事件，未能充分捕捉现实大气中多样化极端事件的复杂模式。解决方案的关键在于提出UniExtreme模型，其核心创新包括：(1) 自适应频率调制（Adaptive Frequency Modulation, AFM）模块，通过可学习的Beta分布滤波器和多粒度频谱聚合机制，捕获正常与极端天气之间的区域差异性频谱特征；(2) 事件先验增强（Event Prior Augmentation, EPA）模块，利用双层记忆融合网络引入区域特异性极端事件先验信息，以解析极端事件的层次驱动机制与地理混合特性，从而实现对多样化极端天气场景的统一建模与高精度预测。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2508.01426">https://arxiv.org/abs/2508.01426</a><br>
<strong>作者</strong>: Hang Ni,Weijia Zhang,Hao Liu<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (cs.LG); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:  35 pages, 80 figures, submitted to ACM KDD 2026 conference</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recent advancements in deep learning have led to the development of Foundation Models (FMs) for weather forecasting, yet their ability to predict extreme weather events remains limited. Existing approaches either focus on general weather conditions or specialize in specific-type extremes, neglecting the real-world atmospheric patterns of diversified extreme events. In this work, we identify two key characteristics of extreme events: (1) the spectral disparity against normal weather regimes, and (2) the hierarchical drivers and geographic blending of diverse extremes. Along this line, we propose UniExtreme, a universal extreme weather forecasting foundation model that integrates (1) an Adaptive Frequency Modulation (AFM) module that captures region-wise spectral differences between normal and extreme weather, through learnable Beta-distribution filters and multi-granularity spectral aggregation, and (2) an Event Prior Augmentation (EPA) module which incorporates region-specific extreme event priors to resolve hierarchical extreme diversity and composite extreme schema, via a dual-level memory fusion network. Extensive experiments demonstrate that UniExtreme outperforms state-of-the-art baselines in both extreme and general weather forecasting, showcasing superior adaptability across diverse extreme scenarios.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-94] Developing and Evaluating a Large Language Model-Based Automated Feedback System Grounded in Evidence-Centered Design for Supporting Physics Problem Solving</p>
<p>【速读】：该论文旨在解决生成式 AI（Generative AI）在复杂领域任务中，如物理问题求解，提供高质量、可靠反馈的挑战。现有大语言模型（Large Language Model, LLM）虽在简单概念性任务中能生成有效反馈，但在需要高级专业知识的任务中仍存在准确性不足的问题。研究的关键解决方案是基于证据中心设计（Evidence-Centered Design, ECD）框架构建一个LLM驱动的反馈系统，并在德国物理奥林匹克竞赛场景中进行评估。结果表明，尽管学生普遍认为反馈有用且准确，但20%的反馈存在事实性错误，且常被学生忽略，凸显了对LLM反馈系统进行更精准适应性和可靠性优化的必要性。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10785">https://arxiv.org/abs/2512.10785</a><br>
<strong>作者</strong>: Holger Maus,Paul Tschisgale,Fabian Kieser,Stefan Petersen,Peter Wulff<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Physics Education (physics.ed-ph); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Human-Computer Interaction (cs.HC)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Generative AI offers new opportunities for individualized and adaptive learning, particularly through large language model (LLM)-based feedback systems. While LLMs can produce effective feedback for relatively straightforward conceptual tasks, delivering high-quality feedback for tasks that require advanced domain expertise, such as physics problem solving, remains a substantial challenge. This study presents the design of an LLM-based feedback system for physics problem solving grounded in evidence-centered design (ECD) and evaluates its performance within the German Physics Olympiad. Participants assessed the usefulness and accuracy of the generated feedback, which was generally perceived as useful and highly accurate. However, an in-depth analysis revealed that the feedback contained factual errors in 20% of cases; errors that often went unnoticed by the students. We discuss the risks associated with uncritical reliance on LLM-based feedback systems and outline potential directions for generating more adaptive and reliable LLM-based feedback in the future.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-95] Maximum Risk Minimization with Random Forests</p>
<p>【速读】：该论文旨在解决<strong>分布外（out-of-distribution, OOD）泛化</strong>问题，即在训练环境中学习到的模型难以适应测试环境中的分布变化。针对这一挑战，作者提出基于<strong>最大风险最小化（MaxRM, Maximum Risk Minimization）<strong>原则的随机森林变体方法，其核心在于通过最小化不同环境下的最大风险来提升模型在未见分布上的鲁棒性。解决方案的关键创新包括：设计了计算高效的算法、证明了所提方法的统计一致性，并首次为以</strong> regret（超额风险）作为损失函数的 MaxRM 方法</strong>提供了针对未见测试分布的样本外保证。该方法可适配均方误差、负奖励（与解释方差相关）和 regret 三种风险形式，从而在理论上和实践中增强了模型对分布偏移的适应能力。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10445">https://arxiv.org/abs/2512.10445</a><br>
<strong>作者</strong>: Francesco Freni,Anya Fries,Linus Kühne,Markus Reichstein,Jonas Peters<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>); Machine Learning (cs.LG); Methodology (<a target="_blank" rel="noopener" href="http://stat.ME">stat.ME</a>)<br>
<strong>备注</strong>:  47 pages, 13 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We consider a regression setting where observations are collected in different environments modeled by different data distributions. The field of out-of-distribution (OOD) generalization aims to design methods that generalize better to test environments whose distributions differ from those observed during training. One line of such works has proposed to minimize the maximum risk across environments, a principle that we refer to as MaxRM (Maximum Risk Minimization). In this work, we introduce variants of random forests based on the principle of MaxRM. We provide computationally efficient algorithms and prove statistical consistency for our primary method. Our proposed method can be used with each of the following three risks: the mean squared error, the negative reward (which relates to the explained variance), and the regret (which quantifies the excess risk relative to the best predictor). For MaxRM with regret as the risk, we prove a novel out-of-sample guarantee over unseen test distributions. Finally, we evaluate the proposed methods on both simulated and real-world data.<br>
zh</p>
</div></div>
<div class="note blue no-icon flat"><p>[AI-96] Classifying Metamorphic versus Single-Fold Proteins with Statistical Learning and AlphaFold2</p>
<p>【速读】：该论文旨在解决如何准确分类蛋白质是否为变构蛋白（metamorphic protein）的问题，这类蛋白能够采取多种不同的构象状态，而传统基于AlphaFold2的单一序列-单一结构映射方法难以建模其构象多样性。解决方案的关键在于重新利用AlphaFold2，通过多序列比对采样生成构象集合（conformational ensemble），并从中提取表征构象模态性和结构分散性的特征集；进而使用随机森林分类器在精心构建的基准数据集上进行训练，实现了平均AUC达0.869的分类性能，从而有效识别潜在的变构蛋白候选者。</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10066">https://arxiv.org/abs/2512.10066</a><br>
<strong>作者</strong>: Yongkai Chen,Samuel WK Wong,SC Kou<br>
<strong>机构</strong>: 未知<br>
<strong>类目</strong>: Applications (stat.AP); Artificial Intelligence (<a target="_blank" rel="noopener" href="http://cs.AI">cs.AI</a>)<br>
<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The remarkable success of AlphaFold2 in providing accurate atomic-level prediction of protein structures from their amino acid sequence has transformed approaches to the protein folding problem. However, its core paradigm of mapping one sequence to one structure may only be appropriate for single-fold proteins with one stable conformation. Metamorphic proteins, which can adopt multiple distinct conformations, have conformational diversity that cannot be adequately modeled by AlphaFold2. Hence, classifying whether a given protein is metamorphic or single-fold remains a critical challenge for both laboratory experiments and computational methods. To address this challenge, we developed a novel classification framework by re-purposing AlphaFold2 to generate conformational ensembles via a multiple sequence alignment sampling method. From these ensembles, we extract a comprehensive set of features characterizing the conformational ensemble’s modality and structural dispersion. A random forest classifier trained on a carefully curated benchmark dataset of known metamorphic and single-fold proteins achieves a mean AUC of 0.869 with cross-validation, demonstrating the effectiveness of our integrated approach. Furthermore, by applying our classifier to 600 randomly sampled proteins from the Protein Data Bank, we identified several potential metamorphic protein candidates – including the 40S ribosomal protein S30, whose conformational change is crucial for its secondary function in antimicrobial defense. By combining AI-driven protein structure prediction with statistical learning, our work provides a powerful new approach for discovering metamorphic proteins and deepens our understanding of their role in their molecular function.<br>
zh</p>
</div></div>
<h3 id="机器学习">机器学习</h3>
<div class="note pink no-icon flat"><p>[LG-0] Curriculum-Based Reinforcement Learning for Autonomous UAV Navigation in Unknown Curved Tubular Conduit</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10934">https://arxiv.org/abs/2512.10934</a><br>
<strong>作者</strong>: Zamirddine Mari,Jérôme Pasquet,Julien Seinturier<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Autonomous drone navigation in confined tubular environments remains a major challenge due to the constraining geometry of the conduits, the proximity of the walls, and the perceptual limitations inherent to such scenarios. We propose a reinforcement learning approach enabling a drone to navigate unknown three-dimensional tubes without any prior knowledge of their geometry, relying solely on local observations from LiDAR and a conditional visual detection of the tube center. In contrast, the Pure Pursuit algorithm, used as a deterministic baseline, benefits from explicit access to the centerline, creating an information asymmetry designed to assess the ability of RL to compensate for the absence of a geometric model. The agent is trained through a progressive Curriculum Learning strategy that gradually exposes it to increasingly curved geometries, where the tube center frequently disappears from the visual field. A turning-negotiation mechanism, based on the combination of direct visibility, directional memory, and LiDAR symmetry cues, proves essential for ensuring stable navigation under such partial observability conditions. Experiments show that the PPO policy acquires robust and generalizable behavior, consistently outperforming the deterministic controller despite its limited access to geometric information. Validation in a high-fidelity 3D environment further confirms the transferability of the learned behavior to a continuous physical dynamics. The proposed approach thus provides a complete framework for autonomous navigation in unknown tubular environments and opens perspectives for industrial, underground, or medical applications where progressing through narrow and weakly perceptive conduits represents a central challenge.         Subjects:  Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Machine Learning (cs.LG)  Cite as: arXiv:2512.10934 [<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>]    (or  arXiv:2512.10934v1 [<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10934">https://doi.org/10.48550/arXiv.2512.10934</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-1] Digital Twin Supervised Reinforcement Learning Framework for Autonomous Underwater Navigation</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10925">https://arxiv.org/abs/2512.10925</a><br>
<strong>作者</strong>: Zamirddine Mari,Mohamad Motasem Nawaf,Pierre Drap<br>
<strong>类目</strong>: Machine Learning (cs.LG); Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Autonomous navigation in underwater environments remains a major challenge due to the absence of GPS, degraded visibility, and the presence of submerged obstacles. This article investigates these issues through the case of the BlueROV2, an open platform widely used for scientific experimentation. We propose a deep reinforcement learning approach based on the Proximal Policy Optimization (PPO) algorithm, using an observation space that combines target-oriented navigation information, a virtual occupancy grid, and ray-casting along the boundaries of the operational area. The learned policy is compared against a reference deterministic kinematic planner, the Dynamic Window Approach (DWA), commonly employed as a robust baseline for obstacle avoidance. The evaluation is conducted in a realistic simulation environment and complemented by validation on a physical BlueROV2 supervised by a 3D digital twin of the test site, helping to reduce risks associated with real-world experimentation. The results show that the PPO policy consistently outperforms DWA in highly cluttered environments, notably thanks to better local adaptation and reduced collisions. Finally, the experiments demonstrate the transferability of the learned behavior from simulation to the real world, confirming the relevance of deep RL for autonomous navigation in underwater robotics.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-2] Iterative Compositional Data Generation for Robot Control</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10891">https://arxiv.org/abs/2512.10891</a><br>
<strong>作者</strong>: Anh-Quan Pham,Marcel Hussing,Shubhankar P. Patankar,Dani S. Bassett,Jorge Mendez-Mendez,Eric Eaton<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Collecting robotic manipulation data is expensive, making it impractical to acquire demonstrations for the combinatorially large space of tasks that arise in multi-object, multi-robot, and multi-environment settings. While recent generative models can synthesize useful data for individual tasks, they do not exploit the compositional structure of robotic domains and struggle to generalize to unseen task combinations. We propose a semantic compositional diffusion transformer that factorizes transitions into robot-, object-, obstacle-, and objective-specific components and learns their interactions through attention. Once trained on a limited subset of tasks, we show that our model can zero-shot generate high-quality transitions from which we can learn control policies for unseen task combinations. Then, we introduce an iterative self-improvement procedure in which synthetic data is validated via offline reinforcement learning and incorporated into subsequent training rounds. Our approach substantially improves zero-shot performance over monolithic and hard-coded compositional baselines, ultimately solving nearly all held-out tasks and demonstrating the emergence of meaningful compositional structure in the learned representations.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-3] Physics-Informed Learning of Flow Distribution and Receiver Heat Losses in Parabolic Trough Solar Fields</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10886">https://arxiv.org/abs/2512.10886</a><br>
<strong>作者</strong>: Stefan Matthes,Markus Schramm<br>
<strong>类目</strong>: Machine Learning (cs.LG); Computational Engineering, Finance, and Science (cs.CE)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Parabolic trough Concentrating Solar Power (CSP) plants operate large hydraulic networks of collector loops that must deliver a uniform outlet temperature despite spatially heterogeneous optical performance, heat losses, and pressure drops. While loop temperatures are measured, loop-level mass flows and receiver heat-loss parameters are unobserved, making it impossible to diagnose hydraulic imbalances or receiver degradation using standard monitoring tools. We present a physics-informed learning framework that infers (i) loop-level mass-flow ratios and (ii) time-varying receiver heat-transfer coefficients directly from routine operational data. The method exploits nocturnal homogenization periods – when hot oil is circulated through a non-irradiated field – to isolate hydraulic and thermal-loss effects. A differentiable conjugate heat-transfer model is discretized and embedded into an end-to-end learning pipeline optimized using historical plant data from the 50 MW Andasol 3 solar field. The model accurately reconstructs loop temperatures (RMSE  2^\circ C) and produces physically meaningful estimates of loop imbalances and receiver heat losses. Comparison against drone-based infrared thermography (QScan) shows strong correspondence, correctly identifying all areas with high-loss receivers. This demonstrates that noisy real-world CSP operational data contain enough information to recover latent physical parameters when combined with appropriate modeling and differentiable optimization.         Subjects:  Machine Learning (cs.LG); Computational Engineering, Finance, and Science (cs.CE)  Cite as: arXiv:2512.10886 [cs.LG]    (or  arXiv:2512.10886v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10886">https://doi.org/10.48550/arXiv.2512.10886</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-4] Classifier Reconstruction Through Counterfactual-Aware Wasserstein Prototypes <mark class="hl-label red">ICML2025</mark></p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10878">https://arxiv.org/abs/2512.10878</a><br>
<strong>作者</strong>: Xuan Zhao,Zhuo Cao,Arya Bangun,Hanno Scharr,Ira Assent<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  Accepted by Actionable Interpretability Workshop at ICML 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Counterfactual explanations provide actionable insights by identifying minimal input changes required to achieve a desired model prediction. Beyond their interpretability benefits, counterfactuals can also be leveraged for model reconstruction, where a surrogate model is trained to replicate the behavior of a target model. In this work, we demonstrate that model reconstruction can be significantly improved by recognizing that counterfactuals, which typically lie close to the decision boundary, can serve as informative though less representative samples for both classes. This is particularly beneficial in settings with limited access to labeled data. We propose a method that integrates original data samples with counterfactuals to approximate class prototypes using the Wasserstein barycenter, thereby preserving the underlying distributional structure of each class. This approach enhances the quality of the surrogate model and mitigates the issue of decision boundary shift, which commonly arises when counterfactuals are naively treated as ordinary training instances. Empirical results across multiple datasets show that our method improves fidelity between the surrogate and target models, validating its effectiveness.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-5] Guided Transfer Learning for Discrete Diffusion Models</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10877">https://arxiv.org/abs/2512.10877</a><br>
<strong>作者</strong>: Julian Kleutgens,Claudio Battiloro,Lingkai Kong,Benjamin Grewe,Francesca Dominici,Mauricio Tec<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  7 pages (main text) + appendix</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Discrete diffusion models achieve strong performance across language and other discrete domains, providing a powerful alternative to autoregressive models. However, their strong performance relies on large training datasets, which are costly or risky to obtain, especially when adapting to new domains. Transfer learning is the natural way to adapt pretrained discrete diffusion models, but current methods require fine-tuning large diffusion models, which is computationally expensive and often impractical. Building on ratio-based transfer learning for continuous diffusion, we provide Guided Transfer Learning for discrete diffusion models (GTL). This enables sampling from a target distribution without modifying the pretrained denoiser. The same guidance formulation applies to both discrete-time diffusion and continuous-time score-based discrete diffusion, yielding a unified treatment. Guided discrete diffusion often requires many forward passes of the guidance network, which becomes impractical for large vocabularies and long sequences. To address this, we further present an efficient guided sampler that concentrates evaluations on planner-selected positions and top candidate tokens, thus lowering sampling time and computation. This makes guided language modeling practical at scale for large vocabularies and long sequences. We evaluate GTL on sequential data, including synthetic Markov chains and language modeling, and provide empirical analyses of its behavior.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-6] A Differentiable Digital Twin of Distributed Link Scheduling for Contention-Aware Networking</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10874">https://arxiv.org/abs/2512.10874</a><br>
<strong>作者</strong>: Zhongyuan Zhao,Yujun Ming,Kevin Chan,Ananthram Swami,Santiago Segarra<br>
<strong>类目</strong>: Networking and Internet Architecture (<a target="_blank" rel="noopener" href="http://cs.NI">cs.NI</a>); Machine Learning (cs.LG); Signal Processing (eess.SP); Systems and Control (<a target="_blank" rel="noopener" href="http://eess.SY">eess.SY</a>)<br>
*<strong>备注</strong>:  5 pages, 8 figures, presented in Asilomar Conference on Signals, Systems, and Computers 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Many routing and flow optimization problems in wired networks can be solved efficiently using minimum cost flow formulations. However, this approach does not extend to wireless multi-hop networks, where the assumptions of fixed link capacity and linear cost structure collapse due to contention for shared spectrum resources. The key challenge is that the long-term capacity of a wireless link becomes a non-linear function of its network context, including network topology, link quality, and the traffic assigned to neighboring links. In this work, we pursue a new direction of modeling wireless network under randomized medium access control by developing an analytical network digital twin (NDT) that predicts link duty cycles from network context. We generalize randomized contention as finding a Maximal Independent Set (MIS) on the conflict graph using weighted Luby’s algorithm, derive an analytical model of link duty cycles, and introduce an iterative procedure that resolves the circular dependency among duty cycle, link capacity, and contention probability. Our numerical experiments show that the proposed NDT accurately predicts link duty cycles and congestion patterns with up to a 5000x speedup over packet-level simulation, and enables us to optimize link scheduling using gradient descent for reduced congestion and radio footprint.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-7] Scaling Behavior of Discrete Diffusion Language Models</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10858">https://arxiv.org/abs/2512.10858</a><br>
<strong>作者</strong>: Dimitri von Rütte,Janis Fluri,Omead Pooladzandi,Bernhard Schölkopf,Thomas Hofmann,Antonio Orvieto<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Modern LLM pre-training consumes vast amounts of compute and training data, making the scaling behavior, or scaling laws, of different models a key distinguishing factor. Discrete diffusion language models (DLMs) have been proposed as an alternative to autoregressive language models (ALMs). However, their scaling behavior has not yet been fully explored, with prior work suggesting that they require more data and compute to match the performance of ALMs. We study the scaling behavior of DLMs on different noise types by smoothly interpolating between masked and uniform diffusion while paying close attention to crucial hyperparameters such as batch size and learning rate. Our experiments reveal that the scaling behavior of DLMs strongly depends on the noise type and is considerably different from ALMs. While all noise types converge to similar loss values in compute-bound scaling, we find that uniform diffusion requires more parameters and less data for compute-efficient training compared to masked diffusion, making them a promising candidate in data-bound settings. We scale our uniform diffusion model up to 10B parameters trained for  10^22  FLOPs, confirming the predicted scaling behavior and making it the largest publicly known uniform diffusion model to date.         Subjects:  Machine Learning (cs.LG)  Cite as: arXiv:2512.10858 [cs.LG]    (or  arXiv:2512.10858v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10858">https://doi.org/10.48550/arXiv.2512.10858</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-8] Bayesian Symbolic Regression via Posterior Sampling</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10849">https://arxiv.org/abs/2512.10849</a><br>
<strong>作者</strong>: Geoffrey F. Bomarito,Patrick E. Leser<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Symbolic regression is a powerful tool for discovering governing equations directly from data, but its sensitivity to noise hinders its broader application. This paper introduces a Sequential Monte Carlo (SMC) framework for Bayesian symbolic regression that approximates the posterior distribution over symbolic expressions, enhancing robustness and enabling uncertainty quantification for symbolic regression in the presence of noise. Differing from traditional genetic programming approaches, the SMC-based algorithm combines probabilistic selection, adaptive tempering, and the use of normalized marginal likelihood to efficiently explore the search space of symbolic expressions, yielding parsimonious expressions with improved generalization. When compared to standard genetic programming baselines, the proposed method better deals with challenging, noisy benchmark datasets. The reduced tendency to overfit and enhanced ability to discover accurate and interpretable equations paves the way for more robust symbolic regression in scientific discovery and engineering design applications.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-9] Learning Controllable and Diverse Player Behaviors in Multi-<mark class="hl-label green">Agent</mark>  Environments</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10835">https://arxiv.org/abs/2512.10835</a><br>
<strong>作者</strong>: Atahan Cilan,Atay Özgövde<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  Submitted to IEEE Transactions on Games</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper introduces a reinforcement learning framework that enables controllable and diverse player behaviors without relying on human gameplay data. Existing approaches often require large-scale player trajectories, train separate models for different player types, or provide no direct mapping between interpretable behavioral parameters and the learned policy, limiting their scalability and controllability. We define player behavior in an N-dimensional continuous space and uniformly sample target behavior vectors from a region that encompasses the subset representing real human styles. During training, each agent receives both its current and target behavior vectors as input, and the reward is based on the normalized reduction in distance between them. This allows the policy to learn how actions influence behavioral statistics, enabling smooth control over attributes such as aggressiveness, mobility, and cooperativeness. A single PPO-based multi-agent policy can reproduce new or unseen play styles without retraining. Experiments conducted in a custom multi-player Unity game show that the proposed framework produces significantly greater behavioral diversity than a win-only baseline and reliably matches specified behavior vectors across diverse targets. The method offers a scalable solution for automated playtesting, game balancing, human-like behavior simulation, and replacing disconnected players in online games.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-10] mplate-Free Retrosynthesis with Graph-Prior Augmented Transformers</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10770">https://arxiv.org/abs/2512.10770</a><br>
<strong>作者</strong>: Youjun Zhao<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Retrosynthesis reaction prediction seeks to infer plausible reactant molecules for a given product and is a central problem in computer-aided organic synthesis. Despite recent progress, many existing models still fall short of the accuracy and robustness required for practical deployment. This work studies a template-free, Transformer-based framework that eliminates reliance on handcrafted reaction templates or additional chemical rule engines. The model injects molecular graph information into the attention mechanism to jointly exploit \SMILES\ sequences and structural cues, and further applies a paired data augmentation strategy to enhance training diversity and scale. On the USPTO-50K benchmark, our proposed approach achieves state-of-the-art performance among template-free methods and substantially outperforming a vanilla Transformer baseline.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-11] Generalized Spherical Neural Operators: Greens Function Formulation</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10723">https://arxiv.org/abs/2512.10723</a><br>
<strong>作者</strong>: Hao Tang,Hao Chen,Chao Li<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Neural operators offer powerful approaches for solving parametric partial differential equations, but extending them to spherical domains remains challenging due to the need to preserve intrinsic geometry while avoiding distortions that break rotational consistency. Existing spherical operators rely on rotational equivariance but often lack the flexibility for real-world complexity. We propose a general operator-design framework based on the designable spherical Green’s function and its harmonic expansion, establishing a solid operator-theoretic foundation for spherical learning. Based on this, we propose an absolute and relative position-dependent Green’s function that enables flexible balance of equivariance and invariance for real-world modeling. The resulting operator, Green’s-function Spherical Neural Operator (GSNO) with a novel spectral learning method, can adapt to anisotropic, constraint-rich systems while retaining spectral efficiency. To exploit GSNO, we develop GSHNet, a hierarchical architecture that combines multi-scale spectral modeling with spherical up-down sampling, enhancing global feature representation. Evaluations on diffusion MRI, shallow water dynamics, and global weather forecasting, GSNO and GSHNet consistently outperform state-of-the-art methods. Our results position GSNO as a principled and general framework for spherical operator learning, bridging rigorous theory with real-world complexity.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-12] Beyond the Black Box: Identifiable Interpretation and Control in Generative Models via Causal Minimality</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10720">https://arxiv.org/abs/2512.10720</a><br>
<strong>作者</strong>: Lingjing Kong,Shaoan Xie,Guangyi Chen,Yuewen Sun,Xiangchen Song,Eric P. Xing,Kun Zhang<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Deep generative models, while revolutionizing fields like image and text generation, largely operate as opaque black boxes, hindering human understanding, control, and alignment. While methods like sparse autoencoders (SAEs) show remarkable empirical success, they often lack theoretical guarantees, risking subjective insights. Our primary objective is to establish a principled foundation for interpretable generative models. We demonstrate that the principle of causal minimality – favoring the simplest causal explanation – can endow the latent representations of diffusion vision and autoregressive language models with clear causal interpretation and robust, component-wise identifiable control. We introduce a novel theoretical framework for hierarchical selection models, where higher-level concepts emerge from the constrained composition of lower-level variables, better capturing the complex dependencies in data generation. Under theoretically derived minimality conditions (manifesting as sparsity or compression constraints), we show that learned representations can be equivalent to the true latent variables of the data-generating process. Empirically, applying these constraints to leading generative models allows us to extract their innate hierarchical concept graphs, offering fresh insights into their internal knowledge organization. Furthermore, these causally grounded concepts serve as levers for fine-grained model steering, paving the way for transparent, reliable systems.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-13] HybridVFL: Disentangled Feature Learning for Edge-Enabled Vertical Federated Multimodal Classification</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10701">https://arxiv.org/abs/2512.10701</a><br>
<strong>作者</strong>: Mostafa Anoosha,Zeinab Dehghani,Kuniko Paxton,Koorosh Aslansefat,Dhavalkumar Thakker<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  6 pages, 2 figures, 1 table. Accepted at UCC '25 (IEEE/ACM 18th International Conference on Utility and Cloud Computing), December 1-4, 2025, Nantes, France. DOI to be activated upon final publication</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Vertical Federated Learning (VFL) offers a privacy-preserving paradigm for Edge AI scenarios like mobile health diagnostics, where sensitive multimodal data reside on distributed, resource-constrained devices. Yet, standard VFL systems often suffer performance limitations due to simplistic feature fusion. This paper introduces HybridVFL, a novel framework designed to overcome this bottleneck by employing client-side feature disentanglement paired with a server-side cross-modal transformer for context-aware fusion. Through systematic evaluation on the multimodal HAM10000 skin lesion dataset, we demonstrate that HybridVFL significantly outperforms standard federated baselines, validating the criticality of advanced fusion mechanisms in robust, privacy-preserving systems.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-14] Learning by Analogy: A Causal Framework for Composition Generalization</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10669">https://arxiv.org/abs/2512.10669</a><br>
<strong>作者</strong>: Lingjing Kong,Shaoan Xie,Yang Jiao,Yetian Chen,Yanhui Guo,Simone Shao,Yan Gao,Guangyi Chen,Kun Zhang<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Compositional generalization – the ability to understand and generate novel combinations of learned concepts – enables models to extend their capabilities beyond limited experiences. While effective, the data structures and principles that enable this crucial capability remain poorly understood. We propose that compositional generalization fundamentally requires decomposing high-level concepts into basic, low-level concepts that can be recombined across similar contexts, similar to how humans draw analogies between concepts. For example, someone who has never seen a peacock eating rice can envision this scene by relating it to their previous observations of a chicken eating rice. In this work, we formalize these intuitive processes using principles of causal modularity and minimal changes. We introduce a hierarchical data-generating process that naturally encodes different levels of concepts and their interaction mechanisms. Theoretically, we demonstrate that this approach enables compositional generalization supporting complex relations between composed concepts, advancing beyond prior work that assumes simpler interactions like additive effects. Critically, we also prove that this latent hierarchical structure is provably recoverable (identifiable) from observable data like text-image pairs, a necessary step for learning such a generative process. To validate our theory, we apply insights from our theoretical framework and achieve significant improvements on benchmark datasets.         Subjects:  Machine Learning (cs.LG)  Cite as: arXiv:2512.10669 [cs.LG]    (or  arXiv:2512.10669v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10669">https://doi.org/10.48550/arXiv.2512.10669</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-15] DCFO Additional Material</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10659">https://arxiv.org/abs/2512.10659</a><br>
<strong>作者</strong>: Tommaso Amico,Pernille Matthews,Lena Krieger,Arthur Zimek,Ira Assent<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Outlier detection identifies data points that significantly deviate from the majority of the data distribution. Explaining outliers is crucial for understanding the underlying factors that contribute to their detection, validating their significance, and identifying potential biases or errors. Effective explanations provide actionable insights, facilitating preventive measures to avoid similar outliers in the future. Counterfactual explanations clarify why specific data points are classified as outliers by identifying minimal changes required to alter their prediction. Although valuable, most existing counterfactual explanation methods overlook the unique challenges posed by outlier detection, and fail to target classical, widely adopted outlier detection algorithms. Local Outlier Factor (LOF) is one the most popular unsupervised outlier detection methods, quantifying outlierness through relative local density. Despite LOF’s widespread use across diverse applications, it lacks interpretability. To address this limitation, we introduce Density-based Counterfactuals for Outliers (DCFO), a novel method specifically designed to generate counterfactual explanations for LOF. DCFO partitions the data space into regions where LOF behaves smoothly, enabling efficient gradient-based optimisation. Extensive experimental validation on 50 OpenML datasets demonstrates that DCFO consistently outperforms benchmarked competitors, offering superior proximity and validity of generated counterfactuals.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-16] oken Sample Complexity of Attention</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10656">https://arxiv.org/abs/2512.10656</a><br>
<strong>作者</strong>: Léa Bohbot,Cyril Letrouit,Gabriel Peyré,François-Xavier Vialard<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:As context windows in large language models continue to expand, it is essential to characterize how attention behaves at extreme sequence lengths. We introduce token-sample complexity: the rate at which attention computed on  n  tokens converges to its infinite-token limit. We estimate finite- n  convergence bounds at two levels: pointwise uniform convergence of the attention map, and convergence of moments for the transformed token distribution. For compactly supported (and more generally sub-Gaussian) distributions, our first result shows that the attention map converges uniformly on a ball of radius  R  at rate  C®/\sqrtn , where  C®  grows exponentially with  R . For large  R , this estimate loses practical value, and our second result addresses this issue by establishing convergence rates for the moments of the transformed distribution (the token output of the attention layer). In this case, the rate is  C’®/n^\beta  with  \beta\tfrac12 , and  C’®  depends polynomially on the size of the support of the distribution. The exponent  \beta  depends on the attention geometry and the spectral properties of the tokens distribution. We also examine the regime in which the attention parameter tends to infinity and the softmax approaches a hardmax, and in this setting, we establish a logarithmic rate of convergence. Experiments on synthetic Gaussian data and real BERT models on Wikipedia text confirm our predictions.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-17] Virtual camera detection: Catching video injection attacks in remote biometric systems</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10653">https://arxiv.org/abs/2512.10653</a><br>
<strong>作者</strong>: Daniyar Kurmankhojayev,Andrei Shadrikov,Dmitrii Gordin,Mikhail Shkorin,Danijar Gabdullin,Aigerim Kambetbayeva,Kanat Kuatov<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Face anti-spoofing (FAS) is a vital component of remote biometric authentication systems based on facial recognition, increasingly used across web-based applications. Among emerging threats, video injection attacks – facilitated by technologies such as deepfakes and virtual camera software – pose significant challenges to system integrity. While virtual camera detection (VCD) has shown potential as a countermeasure, existing literature offers limited insight into its practical implementation and evaluation. This study introduces a machine learning-based approach to VCD, with a focus on its design and validation. The model is trained on metadata collected during sessions with authentic users. Empirical results demonstrate its effectiveness in identifying video injection attempts and reducing the risk of malicious users bypassing FAS systems.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-18] Adaptive Intrusion Detection System Leve<mark class="hl-label green">rag</mark> ing Dynamic Neural Models with Adversarial Learning for 5G/6G Networks</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10637">https://arxiv.org/abs/2512.10637</a><br>
<strong>作者</strong>: Neha,Tarunpreet Bhatia<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  6 pages,2 figures, 1 Table</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Intrusion Detection Systems (IDS) are critical components in safeguarding 5G/6G networks from both internal and external cyber threats. While traditional IDS approaches rely heavily on signature-based methods, they struggle to detect novel and evolving attacks. This paper presents an advanced IDS framework that leverages adversarial training and dynamic neural networks in 5G/6G networks to enhance network security by providing robust, real-time threat detection and response capabilities. Unlike conventional models, which require costly retraining to update knowledge, the proposed framework integrates incremental learning algorithms, reducing the need for frequent retraining. Adversarial training is used to fortify the IDS against poisoned data. By using fewer features and incorporating statistical properties, the system can efficiently detect potential threats. Extensive evaluations using the NSL- KDD dataset demonstrate that the proposed approach provides better accuracy of 82.33% for multiclass classification of various network attacks while resisting dataset poisoning. This research highlights the potential of adversarial-trained, dynamic neural networks for building resilient IDS solutions.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-19] Supporting Migration Policies with Forecasts: Illegal Border Crossings in Europe through a Mixed Approach</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10633">https://arxiv.org/abs/2512.10633</a><br>
<strong>作者</strong>: C. Bosco,U. Minora,D. de Rigo,J. Pingsdorf,R. Cortinovis<br>
<strong>类目</strong>: Machine Learning (cs.LG); Social and Information Networks (<a target="_blank" rel="noopener" href="http://cs.SI">cs.SI</a>); Applications (stat.AP)<br>
*<strong>备注</strong>:  17 pages, 6 figures, 2 tables + supplementary material with 20 pages, 21 figures, 2 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper presents a mixed-methodology to forecast illegal border crossings in Europe across five key migratory routes, with a one-year time horizon. The methodology integrates machine learning techniques with qualitative insights from migration experts. This approach aims at improving the predictive capacity of data-driven models through the inclusion of a human-assessed covariate, an innovation that addresses challenges posed by sudden shifts in migration patterns and limitations in traditional datasets. The proposed methodology responds directly to the forecasting needs outlined in the EU Pact on Migration and Asylum, supporting the Asylum and Migration Management Regulation (AMMR). It is designed to provide policy-relevant forecasts that inform strategic decisions, early warning systems, and solidarity mechanisms among EU Member States. By joining data-driven modeling with expert judgment, this work aligns with existing academic recommendations and introduces a novel operational tool tailored for EU migration governance. The methodology is tested and validated with known data to demonstrate its applicability and reliability in migration-related policy context.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-20] Uncertainty-Preserving QBNNs: Multi-Level Quantization of SVI-Based Bayesian Neural Networks for Image Classification</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10602">https://arxiv.org/abs/2512.10602</a><br>
<strong>作者</strong>: Hendrik Borras,Yong Wu,Bernhard Klein,Holger Fröning<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Bayesian Neural Networks (BNNs) provide principled uncertainty quantification but suffer from substantial computational and memory overhead compared to deterministic networks. While quantization techniques have successfully reduced resource requirements in standard deep learning models, their application to probabilistic models remains largely unexplored. We introduce a systematic multi-level quantization framework for Stochastic Variational Inference based BNNs that distinguishes between three quantization strategies: Variational Parameter Quantization (VPQ), Sampled Parameter Quantization (SPQ), and Joint Quantization (JQ). Our logarithmic quantization for variance parameters, and specialized activation functions to preserve the distributional structure are essential for calibrated uncertainty estimation. Through comprehensive experiments on Dirty-MNIST, we demonstrate that BNNs can be quantized down to 4-bit precision while maintaining both classification accuracy and uncertainty disentanglement. At 4 bits, Joint Quantization achieves up to 8x memory reduction compared to floating-point implementations with minimal degradation in epistemic and aleatoric uncertainty estimation. These results enable deployment of BNNs on resource-constrained edge devices and provide design guidelines for future analog “Bayesian Machines” operating at inherently low precision.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-21] Multi-Objective Reward and Preference Optimization: Theory and Algorithms</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10601">https://arxiv.org/abs/2512.10601</a><br>
<strong>作者</strong>: Akhil Agnihotri<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  PhD thesis</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This thesis develops theoretical frameworks and algorithms that advance constrained reinforcement learning (RL) across control, preference learning, and alignment of large language models. The first contribution addresses constrained Markov Decision Processes (CMDPs) under the average-cost criterion through the Average-Constrained Policy Optimization (ACPO) algorithm. ACPO integrates sensitivity analysis with trust-region updates to ensure stable constraint handling, achieving state-of-the-art empirical performance with theoretical guarantees. Constrained RL is then extended to finite-horizon settings via e-COP, the first policy optimization method for episodic CMDPs. Built on an episodic policy difference lemma, e-COP offers provable performance, simplicity, and scalability in safety-critical environments. The thesis then investigates reinforcement learning from human preferences. warmPref-PS introduces a posterior sampling strategy for linear bandits that integrates offline preference data from heterogeneous raters into online learning. Explicit modeling of rater competence yields substantial regret reduction and more efficient data collection for RLHF. The PSPL algorithm further advances preference-based RL by jointly sampling reward models and transition dynamics from pairwise trajectory comparisons, providing Bayesian simple-regret guarantees and robust empirical identification of optimal policies. The final contribution applies these methods to large-scale model alignment. A multi-objective constrained optimization view yields MOPO, an iterative algorithm with closed-form updates that scales to multi-billion-parameter language models and remains robust across alignment settings. Collectively, the thesis unifies constrained RL across average-cost, episodic, and preference-driven paradigms, delivering theoretical advances and practical tools for safe and aligned decision-making.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-22] Authority Backdoor: A Certifiable Backdoor Mechanism for Authoring DNNs <mark class="hl-label red">AAAI2026</mark></p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10600">https://arxiv.org/abs/2512.10600</a><br>
<strong>作者</strong>: Han Yang,Shaofeng Li,Tian Dong,Xiangyu Xu,Guangchi Liu,Zhen Ling<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  Accepted to AAAI 2026 (Main Track). Code is available at: <a target="_blank" rel="noopener" href="https://github.com/PlayerYangh/Authority-Trigger">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Deep Neural Networks (DNNs), as valuable intellectual property, face unauthorized use. Existing protections, such as digital watermarking, are largely passive; they provide only post-hoc ownership verification and cannot actively prevent the illicit use of a stolen model. This work proposes a proactive protection scheme, dubbed ``Authority Backdoor,&quot; which embeds access constraints directly into the model. In particular, the scheme utilizes a backdoor learning framework to intrinsically lock a model’s utility, such that it performs normally only in the presence of a specific trigger (e.g., a hardware fingerprint). But in its absence, the DNN’s performance degrades to be useless. To further enhance the security of the proposed authority scheme, the certifiable robustness is integrated to prevent an adaptive attacker from removing the implanted backdoor. The resulting framework establishes a secure authority mechanism for DNNs, combining access control with certifiable robustness against adversarial attacks. Extensive experiments on diverse architectures and datasets validate the effectiveness and certifiable robustness of the proposed framework.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-23] HeGAU: Type-Aware Heterogeneous Graph Autoencoder and Augmentation</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10589">https://arxiv.org/abs/2512.10589</a><br>
<strong>作者</strong>: Ming-Yi Hong,Miao-Chen Chiang,Youchen Teng,Yu-Hsiang Wang,Chih-Yu Wang,Che Lin<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Heterogeneous Graph Neural Networks (HGNNs) are effective for modeling Heterogeneous Information Networks (HINs), which encode complex multi-typed entities and relations. However, HGNNs often suffer from type information loss and structural noise, limiting their representational fidelity and generalization. We propose THeGAU, a model-agnostic framework that combines a type-aware graph autoencoder with guided graph augmentation to improve node classification. THeGAU reconstructs schema-valid edges as an auxiliary task to preserve node-type semantics and introduces a decoder-driven augmentation mechanism to selectively refine noisy structures. This joint design enhances robustness, accuracy, and efficiency while significantly reducing computational overhead. Extensive experiments on three benchmark HIN datasets (IMDB, ACM, and DBLP) demonstrate that THeGAU consistently outperforms existing HGNN methods, achieving state-of-the-art performance across multiple backbones.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-24] Is the Information Bottleneck Robust Enough? Towards Label-Noise Resistant Information Bottleneck Learning <mark class="hl-label red">AAAI</mark> <mark class="hl-label red">AAAI-2026</mark></p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10573">https://arxiv.org/abs/2512.10573</a><br>
<strong>作者</strong>: Yi Huang,Qingyun Sun,Yisen Gao,Haonan Yuan,Xingcheng Fu,Jianxin Li<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  Accepted by the Main Technical Track of the 40th Annual AAAI Conference on Artificial Intelligence (AAAI-2026)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The Information Bottleneck (IB) principle facilitates effective representation learning by preserving label-relevant information while compressing irrelevant information. However, its strong reliance on accurate labels makes it inherently vulnerable to label noise, prevalent in real-world scenarios, resulting in significant performance degradation and overfitting. To address this issue, we propose LaT-IB, a novel Label-Noise ResistanT Information Bottleneck method which introduces a “Minimal-Sufficient-Clean” (MSC) criterion. Instantiated as a mutual information regularizer to retain task-relevant information while discarding noise, MSC addresses standard IB’s vulnerability to noisy label supervision. To achieve this, LaT-IB employs a noise-aware latent disentanglement that decomposes the latent representation into components aligned with to the clean label space and the noise space. Theoretically, we first derive mutual information bounds for each component of our objective including prediction, compression, and disentanglement, and moreover prove that optimizing it encourages representations invariant to input noise and separates clean and noisy label information. Furthermore, we design a three-phase training framework: Warmup, Knowledge Injection and Robust Training, to progressively guide the model toward noise-resistant representations. Extensive experiments demonstrate that LaT-IB achieves superior robustness and efficiency under label noise, significantly enhancing robustness and applicability in real-world scenarios with label noise.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-25] Unlocking the Address Book: Dissecting the Sparse Semantic Structure of <mark class="hl-label green">LLM</mark>  Key-Value Caches via Sparse Autoencoders</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10547">https://arxiv.org/abs/2512.10547</a><br>
<strong>作者</strong>: Qingsen Ma,Dianyun Wang,Jiaming Lyu,Yaoye Wang,Lechen Ning,Sujie Zhu,Zhenbo Xu,Liuyu Xiang,Huining Li,Huijia Wu,Zhaofeng He<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The Key-Value (KV) cache is the primary memory bottleneck in long-context Large Language Models, yet it is typically treated as an opaque numerical tensor. In this work, we propose \textbfSTA-Attention, a framework that utilizes Top-K Sparse Autoencoders (SAEs) to decompose the KV cache into interpretable <code>semantic atoms.'' Unlike standard  L_1 -regularized SAEs, our Top-K approach eliminates shrinkage bias, preserving the precise dot-product geometry required for attention. Our analysis uncovers a fundamental \textbfKey-Value Asymmetry: while Key vectors serve as highly sparse routers dominated by a </code>Semantic Elbow,‘’ deep Value vectors carry dense content payloads requiring a larger budget. Based on this structure, we introduce a Dual-Budget Strategy that selectively preserves the most informative semantic components while filtering representational noise. Experiments on Yi-6B, Mistral-7B, Qwen2.5-32B, and others show that our semantic reconstructions maintain perplexity and zero-shot performance comparable to the original models, effectively bridging the gap between mechanistic interpretability and faithful attention modeling.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-26] Disentangled and Distilled Encoder for Out-of-Distribution <mark class="hl-label green">Reasoning</mark>  with Rademacher Guarantees</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10522">https://arxiv.org/abs/2512.10522</a><br>
<strong>作者</strong>: Zahra Rahiminasab,Michael Yuhas,Arvind Easwaran<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Recently, the disentangled latent space of a variational autoencoder (VAE) has been used to reason about multi-label out-of-distribution (OOD) test samples that are derived from different distributions than training samples. Disentangled latent space means having one-to-many maps between latent dimensions and generative factors or important characteristics of an image. This paper proposes a disentangled distilled encoder (DDE) framework to decrease the OOD reasoner size for deployment on resource-constrained devices while preserving disentanglement. DDE formalizes student-teacher distillation for model compression as a constrained optimization problem while preserving disentanglement with disentanglement constraints. Theoretical guarantees for disentanglement during distillation based on Rademacher complexity are established. The approach is evaluated empirically by deploying the compressed model on an NVIDIA</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-27] From Lab to Reality: A Practical Evaluation of Deep Learning Models and <mark class="hl-label green">LLM</mark> s for Vulnerability Detection</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10485">https://arxiv.org/abs/2512.10485</a><br>
<strong>作者</strong>: Chaomeng Lu,Bert Lagaisse<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Machine Learning (cs.LG); Software Engineering (<a target="_blank" rel="noopener" href="http://cs.SE">cs.SE</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Vulnerability detection methods based on deep learning (DL) have shown strong performance on benchmark datasets, yet their real-world effectiveness remains underexplored. Recent work suggests that both graph neural network (GNN)-based and transformer-based models, including large language models (LLMs), yield promising results when evaluated on curated benchmark datasets. These datasets are typically characterized by consistent data distributions and heuristic or partially noisy labels. In this study, we systematically evaluate two representative DL models-ReVeal and LineVul-across four representative datasets: Juliet, Devign, BigVul, and ICVul. Each model is trained independently on each respective dataset, and their code representations are analyzed using t-SNE to uncover vulnerability related patterns. To assess realistic applicability, we deploy these models along with four pretrained LLMs, Claude 3.5 Sonnet, GPT-o3-mini, GPT-4o, and GPT-5 on a curated dataset, VentiVul, comprising 20 recently (May 2025) fixed vulnerabilities from the Linux kernel. Our experiments reveal that current models struggle to distinguish vulnerable from non-vulnerable code in representation space and generalize poorly across datasets with differing distributions. When evaluated on VentiVul, our newly constructed time-wise out-of-distribution dataset, performance drops sharply, with most models failing to detect vulnerabilities reliably. These results expose a persistent gap between academic benchmarks and real-world deployment, emphasizing the value of our deployment-oriented evaluation framework and the need for more robust code representations and higher-quality datasets.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-28] Hybrid Physics-ML Model for Forward Osmosis Flux with Complete Uncertainty Quantification</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10457">https://arxiv.org/abs/2512.10457</a><br>
<strong>作者</strong>: Shiv Ratn,Shivang Rampriyan,Bahni Ray<br>
<strong>类目</strong>: Machine Learning (cs.LG); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:  12 pages, 6 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Forward Osmosis (FO) is a promising low-energy membrane separation technology, but challenges in accurately modelling its water flux (Jw) persist due to complex internal mass transfer phenomena. Traditional mechanistic models struggle with empirical parameter variability, while purely data-driven models lack physical consistency and rigorous uncertainty quantification (UQ). This study introduces a novel Robust Hybrid Physics-ML framework employing Gaussian Process Regression (GPR) for highly accurate, uncertainty-aware Jw prediction. The core innovation lies in training the GPR on the residual error between the detailed, non-linear FO physical model prediction (Jw_physical) and the experimental water flux (Jw_actual). Crucially, we implement a full UQ methodology by decomposing the total predictive variance (sigma2_total) into model uncertainty (epistemic, from GPR’s posterior variance) and input uncertainty (aleatoric, analytically propagated via the Delta method for multi-variate correlated inputs). Leveraging the inherent strength of GPR in low-data regimes, the model, trained on a meagre 120 data points, achieved a state-of-the-art Mean Absolute Percentage Error (MAPE) of 0.26% and an R2 of 0.999 on the independent test data, validating a truly robust and reliable surrogate model for advanced FO process optimization and digital twin development.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-29] Metacognitive Sensitivity for Test-Time Dynamic Model Selection <mark class="hl-label red">NEURIPS2025</mark></p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10451">https://arxiv.org/abs/2512.10451</a><br>
<strong>作者</strong>: Le Tuan Minh Trinh,Le Minh Vu Pham,Thi Minh Anh Pham,An Duc Nguyen<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  Accepted at the NeurIPS 2025 CogInterp Workshop</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:A key aspect of human cognition is metacognition - the ability to assess one’s own knowledge and judgment reliability. While deep learning models can express confidence in their predictions, they often suffer from poor calibration, a cognitive bias where expressed confidence does not reflect true competence. Do models truly know what they know? Drawing from human cognitive science, we propose a new framework for evaluating and leveraging AI metacognition. We introduce meta-d’, a psychologically-grounded measure of metacognitive sensitivity, to characterise how reliably a model’s confidence predicts its own accuracy. We then use this dynamic sensitivity score as context for a bandit-based arbiter that performs test-time model selection, learning which of several expert models to trust for a given task. Our experiments across multiple datasets and deep learning model combinations (including CNNs and VLMs) demonstrate that this metacognitive approach improves joint-inference accuracy over constituent models. This work provides a novel behavioural account of AI models, recasting ensemble selection as a problem of evaluating both short-term signals (confidence prediction scores) and medium-term traits (metacognitive sensitivity).</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-30] he Operator Origins of Neural Scaling Laws: A Generalized Spectral Transport Dynamics of Deep Learning</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10427">https://arxiv.org/abs/2512.10427</a><br>
<strong>作者</strong>: Yizhou Zhang<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Modern deep networks operate in a rough, finite-regularity regime where Jacobian-induced operators exhibit heavy-tailed spectra and strong basis drift. In this work, we derive a unified operator-theoretoretic description of neural training dynamics directly from gradient descent. Starting from the exact evolution  \dot e_t = -M(t)e_t  in function space, we apply Kato perturbation theory to obtain a rigorous system of coupled mode ODEs and show that, after coarse-graining, these dynamics converge to a spectral transport–dissipation PDE [ \partial_t g + \partial_\lambda (v g) = -\lambda g + S, ] where  v  captures eigenbasis drift and  S  encodes nonlocal spectral coupling. We prove that neural training preserves functional regularity, forcing the drift to take an asymptotic power-law form  v(\lambda,t)\sim -c(t)\lambda^b . In the weak-coupling regime – naturally induced by spectral locality and SGD noise – the PDE admits self-similar solutions with a resolution frontier, polynomial amplitude growth, and power-law dissipation. This structure yields explicit scaling-law exponents, explains the geometry of double descent, and shows that the effective training time satisfies  \tau(t)=t^\alpha L(t)  for slowly varying  L . Finally, we show that NTK training and feature learning arise as two limits of the same PDE:  v\equiv 0  recovers lazy dynamics, while  v\neq 0  produces representation drift. Our results provide a unified spectral framework connecting operator geometry, optimization dynamics, and the universal scaling behavior of modern deep networks.         Subjects:  Machine Learning (cs.LG)  Cite as: arXiv:2512.10427 [cs.LG]    (or  arXiv:2512.10427v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10427">https://doi.org/10.48550/arXiv.2512.10427</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-31] RoboNeuron: A Modular Framework Linking Foundation Models and ROS for Embodied AI</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10394">https://arxiv.org/abs/2512.10394</a><br>
<strong>作者</strong>: Weifan Guan,Huasen Xi,Chenxiao Zhang,Aosheng Li,Qinghao Hu,Jian Cheng<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Current embodied AI systems face severe engineering impediments, primarily characterized by poor cross-scenario adaptability, rigid inter-module coupling, and fragmented inference acceleration. To overcome these limitations, we propose RoboNeuron, a universal deployment framework for embodied intelligence. RoboNeuron is the first framework to deeply integrate the cognitive capabilities of Large Language Models (LLMs) and Vision-Language-Action (VLA) models with the real-time execution backbone of the Robot Operating System (ROS). We utilize the Model Context Protocol (MCP) as a semantic bridge, enabling the LLM to dynamically orchestrate underlying robotic tools. The framework establishes a highly modular architecture that strictly decouples sensing, reasoning, and control by leveraging ROS’s unified communication interfaces. Crucially, we introduce an automated tool to translate ROS messages into callable MCP functions, significantly streamlining development. RoboNeuron significantly enhances cross-scenario adaptability and component flexibility, while establishing a systematic platform for horizontal performance benchmarking, laying a robust foundation for scalable real-world embodied applications.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-32] Fitting magnetization data using continued fraction of straight lines</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10390">https://arxiv.org/abs/2512.10390</a><br>
<strong>作者</strong>: Vijay Prakash S<br>
<strong>类目</strong>: Machine Learning (cs.LG); Materials Science (cond-mat.mtrl-sci); Classical Physics (physics.class-ph)<br>
*<strong>备注</strong>:  17 pages, 12 figures, 4 tables</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Magnetization of a ferromagnetic substance in response to an externally applied magnetic field increases with the strength of the field. This is because at the microscopic level, magnetic moments in certain regions or domains of the substance increasingly align with the applied field, while the amount of misaligned domains decreases. The alignment of such magnetic domains with an applied magnetic field forms the physical basis for the nonlinearity of magnetization. In this paper, the nonlinear function is approximated as a combination of continued fraction of straight lines. The resulting fit is used to interpret the nonlinear behavior in both growing and shrinking magnetic domains. The continued fraction of straight lines used here is an algebraic expression which can be used to estimate parameters using nonlinear regression.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-33] Better Prevent than Tackle: Valuing Defense in Soccer Based on Graph Neural Networks</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10355">https://arxiv.org/abs/2512.10355</a><br>
<strong>作者</strong>: Hyunsung Kim,Sangwoo Seo,Hoyoung Choi,Tom Boomstra,Jinsung Yoon,Chanyoung Park<br>
<strong>类目</strong>: Machine Learning (cs.LG); Multiagent Systems (<a target="_blank" rel="noopener" href="http://cs.MA">cs.MA</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Evaluating defensive performance in soccer remains challenging, as effective defending is often expressed not through visible on-ball actions such as interceptions and tackles, but through preventing dangerous opportunities before they arise. Existing approaches have largely focused on valuing on-ball actions, leaving much of defenders’ true impact unmeasured. To address this gap, we propose DEFCON (DEFensive CONtribution evaluator), a comprehensive framework that quantifies player-level defensive contributions for every attacking situation in soccer. Leveraging Graph Attention Networks, DEFCON estimates the success probability and expected value of each attacking option, along with each defender’s responsibility for stopping it. These components yield an Expected Possession Value (EPV) for the attacking team before and after each action, and DEFCON assigns positive or negative credits to defenders according to whether they reduced or increased the opponent’s EPV. Trained on 2023-24 and evaluated on 2024-25 Eredivisie event and tracking data, DEFCON’s aggregated player credits exhibit strong positive correlations with market valuations. Finally, we showcase several practical applications, including in-game timelines of defensive contributions, spatial analyses across pitch zones, and pairwise summaries of attacker-defender interactions.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-34] An Interpretable AI Tool for SAVR vs TAVR in Low to Intermediate Risk Patients with Severe Aortic Stenosis</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10308">https://arxiv.org/abs/2512.10308</a><br>
<strong>作者</strong>: Vasiliki Stoumpou,Maciej Tysarowski,Talhat Azemi,Jawad Haider,Howard L. Haronian,Robert C. Hagberg,Dimitris Bertsimas<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Background. Treatment selection for low to intermediate risk patients with severe aortic stenosis between surgical (SAVR) and transcatheter (TAVR) aortic valve replacement remains variable in clinical practice, driven by patient heterogeneity and institutional preferences. While existing models predict postprocedural risk, there is a lack of interpretable, individualized treatment recommendations that directly optimize long-term outcomes. Methods. We introduce an interpretable prescriptive framework that integrates prognostic matching, counterfactual outcome modeling, and an Optimal Policy Tree (OPT) to recommend the treatment minimizing expected 5-year mortality. Using data from Hartford Hospital and St. Vincent’s Hospital, we emulate randomization via prognostic matching and sample weighting and estimate counterfactual mortality under both SAVR and TAVR. The policy model, trained on these counterfactual predictions, partitions patients into clinically coherent subgroups and prescribes the treatment associated with lower estimated risk. Findings. If the OPT prescriptions are applied, counterfactual evaluation showed an estimated reduction in 5-year mortality of 20.3% in Hartford and 13.8% in St. Vincent’s relative to real-life prescriptions, showing promising generalizability to unseen data from a different institution. The learned decision boundaries aligned with real-world outcomes and clinical observations. Interpretation. Our interpretable prescriptive framework is, to the best of our knowledge, the first to provide transparent, data-driven recommendations for TAVR versus SAVR that improve estimated long-term outcomes both in an internal and external cohort, while remaining clinically grounded and contributing toward a more systematic and evidence-based approach to precision medicine in structural heart disease.         Subjects:  Machine Learning (cs.LG)  Cite as: arXiv:2512.10308 [cs.LG]    (or  arXiv:2512.10308v1 [cs.LG] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10308">https://doi.org/10.48550/arXiv.2512.10308</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)        Submission history From: Vasiliki Stoumpou [view email]       [v1]         Thu, 11 Dec 2025 05:54:22 UTC (260 KB)</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-35] A Kernel-based Resource-efficient Neural Surrogate for Multi-fidelity Prediction of Aerodynamic Field</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10287">https://arxiv.org/abs/2512.10287</a><br>
<strong>作者</strong>: Apurba Sarker,Reza T. Batley,Darshan Sarojini,Sourav Saha<br>
<strong>类目</strong>: Machine Learning (cs.LG); Fluid Dynamics (physics.flu-dyn)<br>
*<strong>备注</strong>:  24 pages, 15 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Surrogate models provide fast alternatives to costly aerodynamic simulations and are extremely useful in design and optimization applications. This study proposes the use of a recent kernel-based neural surrogate, KHRONOS. In this work, we blend sparse high-fidelity (HF) data with low-fidelity (LF) information to predict aerodynamic fields under varying constraints in computational resources. Unlike traditional approaches, KHRONOS is built upon variational principles, interpolation theory, and tensor decomposition. These elements provide a mathematical basis for heavy pruning compared to dense neural networks. Using the AirfRANS dataset as a high-fidelity benchmark and NeuralFoil to generate low-fidelity counterparts, this work compares the performance of KHRONOS with three contemporary model architectures: a multilayer perceptron (MLP), a graph neural network (GNN), and a physics-informed neural network (PINN). We consider varying levels of high-fidelity data availability (0%, 10%, and 30%) and increasingly complex geometry parameterizations. These are used to predict the surface pressure coefficient distribution over the airfoil. Results indicate that, whilst all models eventually achieve comparable predictive accuracy, KHRONOS excels in resource-constrained conditions. In this domain, KHRONOS consistently requires orders of magnitude fewer trainable parameters and delivers much faster training and inference than contemporary dense neural networks at comparable accuracy. These findings highlight the potential of KHRONOS and similar architectures to balance accuracy and efficiency in multi-fidelity aerodynamic field prediction.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-36] R2-HGP: A Double-Regularized Gaussian Process for Heterogeneous Transfer Learning</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10258">https://arxiv.org/abs/2512.10258</a><br>
<strong>作者</strong>: Duo Wang,Xinming Wang,Chao Wang,Xiaowei Yue,Jianguo Wu<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  17 pages, 9 figures. Under review for IEEE TPAMI</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multi-output Gaussian process (MGP) models have attracted significant attention for their flexibility and uncertainty-quantification capabilities, and have been widely adopted in multi-source transfer learning scenarios due to their ability to capture inter-task correlations. However, they still face several challenges in transfer learning. First, the input spaces of the source and target domains are often heterogeneous, which makes direct knowledge transfer difficult. Second, potential prior knowledge and physical information are typically ignored during heterogeneous transfer, hampering the utilization of domain-specific insights and leading to unstable mappings. Third, inappropriate information sharing among target and sources can easily lead to negative transfer. Traditional models fail to address these issues in a unified way. To overcome these limitations, this paper proposes a Double-Regularized Heterogeneous Gaussian Process framework (R^2-HGP). Specifically, a trainable prior probability mapping model is first proposed to align the heterogeneous input domains. The resulting aligned inputs are treated as latent variables, upon which a multi-source transfer GP model is constructed and the entire structure is integrated into a novel conditional variational autoencoder (CVAE) based framework. Physical insights is further incorporated as a regularization term to ensure that the alignment results adhere to known physical knowledge. Next, within the multi-source transfer GP model, a sparsity penalty is imposed on the transfer coefficients, enabling the model to adaptively select the most informative source outputs and suppress negative transfer. Extensive simulations and real-world engineering case studies validate the effectiveness of our R^2-HGP, demonstrating consistent superiority over state-of-the-art benchmarks across diverse evaluation metrics.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-37] Design Space Exploration of DMA based Finer-Grain Compute Communication Overlap</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10236">https://arxiv.org/abs/2512.10236</a><br>
<strong>作者</strong>: Shagnik Pal,Shaizeen Aga,Suchita Pati,Mahzabeen Islam,Lizy K. John<br>
<strong>类目</strong>: Distributed, Parallel, and Cluster Computing (cs.DC); Hardware Architecture (<a target="_blank" rel="noopener" href="http://cs.AR">cs.AR</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:As both ML training and inference are increasingly distributed, parallelization techniques that shard (divide) ML model across GPUs of a distributed system, are often deployed. With such techniques, there is a high prevalence of data-dependent communication and computation operations where communication is exposed, leaving as high as 1.7x ideal performance on the table. Prior works harness the fact that ML model state and inputs are already sharded, and employ careful overlap of individual computation/communication shards. While such coarse-grain overlap is promising, in this work, we instead make a case for finer-grain compute-communication overlap which we term FiCCO, where we argue for finer-granularity, one-level deeper overlap than at shard-level, to unlock compute/communication overlap for a wider set of network topologies, finer-grain dataflow and more. We show that FiCCO opens up a wider design space of execution schedules than possible at shard-level alone. At the same time, decomposition of ML operations into smaller operations (done in both shard-based and finer-grain techniques) causes operation-level inefficiency losses. To balance the two, we first present a detailed characterization of these inefficiency losses, then present a design space of FiCCO schedules, and finally overlay the schedules with concomitant inefficiency signatures. Doing so helps us design heuristics that frameworks and runtimes can harness to select bespoke FiCCO schedules based on the nature of underlying ML operations. Finally, to further minimize contention inefficiencies inherent with operation overlap, we offload communication to GPU DMA engines. We evaluate several scenarios from realistic ML deployments and demonstrate that our proposed bespoke schedules deliver up to 1.6x speedup and our heuristics provide accurate guidance in 81% of unseen scenarios.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-38] Exact Recovery of Non-Random Missing Multidimensional Time Series via Temporal Isometric Delay-Embedding Transform</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10191">https://arxiv.org/abs/2512.10191</a><br>
<strong>作者</strong>: Hao Shu,Jicheng Li,Yu Jin,Ling Zhou<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Non-random missing data is a ubiquitous yet undertreated flaw in multidimensional time series, fundamentally threatening the reliability of data-driven analysis and decision-making. Pure low-rank tensor completion, as a classical data recovery method, falls short in handling non-random missingness, both methodologically and theoretically. Hankel-structured tensor completion models provide a feasible approach for recovering multidimensional time series with non-random missing patterns. However, most Hankel-based multidimensional data recovery methods both suffer from unclear sources of Hankel tensor low-rankness and lack an exact recovery theory for non-random missing data. To address these issues, we propose the temporal isometric delay-embedding transform, which constructs a Hankel tensor whose low-rankness is naturally induced by the smoothness and periodicity of the underlying time series. Leveraging this property, we develop the \textitLow-Rank Tensor Completion with Temporal Isometric Delay-embedding Transform (LRTC-TIDT) model, which characterizes the low-rank structure under the \textitTensor Singular Value Decomposition (t-SVD) framework. Once the prescribed non-random sampling conditions and mild incoherence assumptions are satisfied, the proposed LRTC-TIDT model achieves exact recovery, as confirmed by simulation experiments under various non-random missing patterns. Furthermore, LRTC-TIDT consistently outperforms existing tensor-based methods across multiple real-world tasks, including network flow reconstruction, urban traffic estimation, and temperature field prediction. Our implementation is publicly available at this https URL.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-39] MiniF2F-Dafny: <mark class="hl-label green">LLM</mark> -Guided Mathematical Theorem Proving via Auto-Active Verification</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10187">https://arxiv.org/abs/2512.10187</a><br>
<strong>作者</strong>: Mantas Baksys,Stefan Zetzsche,Olivier Bouissou<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present miniF2F-Dafny, the first translation of the mathematical reasoning benchmark miniF2F to an automated theorem prover: Dafny. Previously, the benchmark existed only in interactive theorem provers (Lean, Isabelle, HOL Light, Metamath). We find that Dafny’s automation verifies 99/244 (40.6%) of the test set and 109/244 (44.7%) of the validation set with empty proofs–requiring no manual proof steps. For problems where empty proofs fail, we evaluate 12 off-the-shelf LLMs on providing proof hints. The best model we test achieves 55.7% pass@4 success rate employing iterative error correction. These preliminary results highlight an effective division of labor: LLMs provide high-level guidance while automation handles low-level details. Our benchmark can be found on GitHub at this http URL .</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-40] Assessing Neuromorphic Computing for Fingertip Force Decoding from Electromyography</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10179">https://arxiv.org/abs/2512.10179</a><br>
<strong>作者</strong>: Abolfazl Shahrooei,Luke Arthur,Om Patel,Derek Kamper<br>
<strong>类目</strong>: Machine Learning (cs.LG); Signal Processing (eess.SP)<br>
*<strong>备注</strong>:  5 pages, 6 figures. Poster included as ancillary file ( <a target="_blank" rel="noopener" href="http://IEEE_NER2025_NeuromorphicEMG_poster.pdf">this http URL</a> ). Presented at IEEE EMBS NER 2025, also at NC State College of Engineering Applied AI Symposium and NC State ECE Graduate Research Symposium (tied for Best Poster)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:High-density surface electromyography (HD-sEMG) provides a noninvasive neural interface for assistive and rehabilitation control, but mapping neural activity to user motor intent remains challenging. We assess a spiking neural network (SNN) as a neuromorphic architecture against a temporal convolutional network (TCN) for decoding fingertip force from motor-unit (MU) firing derived from HD-sEMG. Data were collected from a single participant (10 trials) with two forearm electrode arrays; MU activity was obtained via FastICA-based decomposition, and models were trained on overlapping windows with end-to-end causal convolutions. On held-out trials, the TCN achieved 4.44% MVC RMSE (Pearson r = 0.974) while the SNN achieved 8.25% MVC (r = 0.922). While the TCN was more accurate, we view the SNN as a realistic neuromorphic baseline that could close much of this gap with modest architectural and hyperparameter refinements.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-41] Semantic-Aware Confidence Calibration for Automated Audio Captioning</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10170">https://arxiv.org/abs/2512.10170</a><br>
<strong>作者</strong>: Lucas Dunker,Sai Akshay Menta,Snigdha Mohana Addepalli,Venkata Krishna Rayalu Garapati<br>
<strong>类目</strong>: ound (<a target="_blank" rel="noopener" href="http://cs.SD">cs.SD</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  5 pages, 2 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Automated audio captioning models frequently produce overconfident predictions regardless of semantic accuracy, limiting their reliability in deployment. This deficiency stems from two factors: evaluation metrics based on n-gram overlap that fail to capture semantic correctness, and the absence of calibrated confidence estimation. We present a framework that addresses both limitations by integrating confidence prediction into audio captioning and redefining correctness through semantic similarity. Our approach augments a Whisper-based audio captioning model with a learned confidence prediction head that estimates uncertainty from decoder hidden states. We employ CLAP audio-text embeddings and sentence transformer similarities (FENSE) to define semantic correctness, enabling Expected Calibration Error (ECE) computation that reflects true caption quality rather than surface-level text overlap. Experiments on Clotho v2 demonstrate that confidence-guided beam search with semantic evaluation achieves dramatically improved calibration (CLAP-based ECE of 0.071) compared to greedy decoding baselines (ECE of 0.488), while simultaneously improving caption quality across standard metrics. Our results establish that semantic similarity provides a more meaningful foundation for confidence calibration in audio captioning than traditional n-gram metrics.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-42] Rethinking Causal Discovery Through the Lens of Exchangeability</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10152">https://arxiv.org/abs/2512.10152</a><br>
<strong>作者</strong>: Tiago Brogueira,Mário Figueiredo<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  37 pages, 4 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Causal discovery methods have traditionally been developed under two distinct regimes: independent and identically distributed (i.i.d.) and timeseries data, each governed by separate modelling assumptions. In this paper, we argue that the i.i.d. setting can and should be reframed in terms of exchangeability, a strictly more general symmetry principle. We present the implications of this reframing, alongside two core arguments: (1) a conceptual argument, based on extending the dependency of experimental causal inference on exchangeability to causal discovery; and (2) an empirical argument, showing that many existing i.i.d. causal-discovery methods are predicated on exchangeability assumptions, and that the sole extensive widely-used real-world “i.i.d.” benchmark (the Tübingen dataset) consists mainly of exchangeable (and not i.i.d.) examples. Building on this insight, we introduce a novel synthetic dataset that enforces only the exchangeability assumption, without imposing the stronger i.i.d. assumption. We show that our exchangeable synthetic dataset mirrors the statistical structure of the real-world “i.i.d.” dataset more closely than all other i.i.d. synthetic datasets. Furthermore, we demonstrate the predictive capability of this dataset by proposing a neural-network-based causal-discovery algorithm trained exclusively on our synthetic dataset, and which performs similarly to other state-of-the-art i.i.d. methods on the real-world benchmark.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-43] STARS: Semantic Tokens with Augmented Representations for Recommendation at Scale</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10149">https://arxiv.org/abs/2512.10149</a><br>
<strong>作者</strong>: Han Chen,Steven Zhu,Yingrui Li<br>
<strong>类目</strong>: Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Real-world ecommerce recommender systems must deliver relevant items under strict tens-of-milliseconds latency constraints despite challenges such as cold-start products, rapidly shifting user intent, and dynamic context including seasonality, holidays, and promotions. We introduce STARS, a transformer-based sequential recommendation framework built for large-scale, low-latency ecommerce settings. STARS combines several innovations: dual-memory user embeddings that separate long-term preferences from short-term session intent; semantic item tokens that fuse pretrained text embeddings, learnable deltas, and LLM-derived attribute tags, strengthening content-based matching, long-tail coverage, and cold-start performance; context-aware scoring with learned calendar and event offsets; and a latency-conscious two-stage retrieval pipeline that performs offline embedding generation and online maximum inner-product search with filtering, enabling tens-of-milliseconds response times. In offline evaluations on production-scale data, STARS improves Hit@5 by more than 75 percent relative to our existing LambdaMART system. A large-scale A/B test on 6 million visits shows statistically significant lifts, including Total Orders +0.8%, Add-to-Cart on Home +2.0%, and Visits per User +0.5%. These results demonstrate that combining semantic enrichment, multi-intent modeling, and deployment-oriented design can yield state-of-the-art recommendation quality in real-world environments without sacrificing serving efficiency.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-44] Murmur2Vec: A Hashing Based Solution For Embedding Generation Of COVID-19 Spike Sequences</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10147">https://arxiv.org/abs/2512.10147</a><br>
<strong>作者</strong>: Sarwan Ali,Taslim Murad<br>
<strong>类目</strong>: Machine Learning (cs.LG); Genomics (<a target="_blank" rel="noopener" href="http://q-bio.GN">q-bio.GN</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Early detection and characterization of coronavirus disease (COVID-19), caused by SARS-CoV-2, remain critical for effective clinical response and public-health planning. The global availability of large-scale viral sequence data presents significant opportunities for computational analysis; however, existing approaches face notable limitations. Phylogenetic tree-based methods are computationally intensive and do not scale efficiently to today’s multi-million-sequence datasets. Similarly, current embedding-based techniques often rely on aligned sequences or exhibit suboptimal predictive performance and high runtime costs, creating barriers to practical large-scale analysis. In this study, we focus on the most prevalent SARS-CoV-2 lineages associated with the spike protein region and introduce a scalable embedding method that leverages hashing to generate compact, low-dimensional representations of spike sequences. These embeddings are subsequently used to train a variety of machine learning models for supervised lineage classification. We conduct an extensive evaluation comparing our approach with multiple baseline and state-of-the-art biological sequence embedding methods across diverse metrics. Our results demonstrate that the proposed embeddings offer substantial improvements in efficiency, achieving up to 86.4% classification accuracy while reducing embedding generation time by as much as 99.81%. This highlights the method’s potential as a fast, effective, and scalable solution for large-scale viral sequence analysis.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-45] Sequence-to-Image Transformation for Sequence Classification Using Rips Complex Construction and Chaos Game Representation</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10141">https://arxiv.org/abs/2512.10141</a><br>
<strong>作者</strong>: Sarwan Ali,Taslim Murad,Imdadullah Khan<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Traditional feature engineering approaches for molecular sequence classification suffer from sparsity issues and computational complexity, while deep learning models often underperform on tabular biological data. This paper introduces a novel topological approach that transforms molecular sequences into images by combining Chaos Game Representation (CGR) with Rips complex construction from algebraic topology. Our method maps sequence elements to 2D coordinates via CGR, computes pairwise distances, and constructs Rips complexes to capture both local structural and global topological features. We provide formal guarantees on representation uniqueness, topological stability, and information preservation. Extensive experiments on anticancer peptide datasets demonstrate superior performance over vector-based, sequence language models, and existing image-based methods, achieving 86.8% and 94.5% accuracy on breast and lung cancer datasets, respectively. The topological representation preserves critical sequence information while enabling effective utilization of vision-based deep learning architectures for molecular sequence analysis.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-46] Partitioning the Sample Space for a More Precise Shannon Entropy Estimation</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10133">https://arxiv.org/abs/2512.10133</a><br>
<strong>作者</strong>: Gabriel F.A. Bastos,Jugurta Montalvão<br>
<strong>类目</strong>: Machine Learning (cs.LG); Statistics Theory (<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>)<br>
*<strong>备注</strong>:  The manuscript contains 6 pages and 10 figures. It has been accepted for International Conference on Artificial Intelligence, Computer, Data Sciences and Applications (ACDSA 2026)</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Reliable data-driven estimation of Shannon entropy from small data sets, where the number of examples is potentially smaller than the number of possible outcomes, is a critical matter in several applications. In this paper, we introduce a discrete entropy estimator, where we use the decomposability property in combination with estimations of the missing mass and the number of unseen outcomes to compensate for the negative bias induced by them. Experimental results show that the proposed method outperforms some classical estimators in undersampled regimes, and performs comparably with some well-established state-of-the-art estimators.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-47] Push Smarter Not Harder: Hierarchical RL-Diffusion Policy for Efficient Nonprehensile Manipulation</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10099">https://arxiv.org/abs/2512.10099</a><br>
<strong>作者</strong>: Steven Caro,Stephen L. Smith<br>
<strong>类目</strong>: Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  8 pages, 8 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Nonprehensile manipulation, such as pushing objects across cluttered environments, presents a challenging control problem due to complex contact dynamics and long-horizon planning requirements. In this work, we propose HeRD, a hierarchical reinforcement learning-diffusion policy that decomposes pushing tasks into two levels: high-level goal selection and low-level trajectory generation. We employ a high-level reinforcement learning (RL) agent to select intermediate spatial goals, and a low-level goal-conditioned diffusion model to generate feasible, efficient trajectories to reach them. This architecture combines the long-term reward maximizing behaviour of RL with the generative capabilities of diffusion models. We evaluate our method in a 2D simulation environment and show that it outperforms the state-of-the-art baseline in success rate, path efficiency, and generalization across multiple environment configurations. Our results suggest that hierarchical control with generative low-level planning is a promising direction for scalable, goal-directed nonprehensile manipulation. Code, documentation, and trained models are available: this https URL.          Comments: 8 pages, 8 figures   Subjects:  Robotics (<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>); Machine Learning (cs.LG)  Cite as: arXiv:2512.10099 [<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>]    (or  arXiv:2512.10099v1 [<a target="_blank" rel="noopener" href="http://cs.RO">cs.RO</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10099">https://doi.org/10.48550/arXiv.2512.10099</a>   Focus to learn more                      arXiv-issued DOI via DataCite</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-48] textscText2Graph: Combining Lightweight <mark class="hl-label green">LLM</mark> s and GNNs for Efficient Text Classification in Label-Scarce Scenarios</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10061">https://arxiv.org/abs/2512.10061</a><br>
<strong>作者</strong>: João Lucas Luz Lima Sarcinelli,Ricardo Marcondes Marcacini<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) have become effective zero-shot classifiers, but their high computational requirements and environmental costs limit their practicality for large-scale annotation in high-performance computing (HPC) environments. To support more sustainable workflows, we present \textscText2Graph, an open-source Python package that provides a modular implementation of existing text-to-graph classification approaches. The framework enables users to combine LLM-based partial annotation with Graph Neural Network (GNN) label propagation in a flexible manner, making it straightforward to swap components such as feature extractors, edge construction methods, and sampling strategies. We benchmark \textscText2Graph on a zero-shot setting using five datasets spanning topic classification and sentiment analysis tasks, comparing multiple variants against other zero-shot approaches for text classification. In addition to reporting performance, we provide detailed estimates of energy consumption and carbon emissions, showing that graph-based propagation achieves competitive results at a fraction of the energy and environmental cost.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-49] Mitigating Exposure Bias in Risk-Aware Time Series Forecasting with Soft Tokens</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10056">https://arxiv.org/abs/2512.10056</a><br>
<strong>作者</strong>: Alireza Namazi,Amirreza Dolatpour Fathkouhi,Heman Shakeri<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Autoregressive forecasting is central to predictive control in diabetes and hemodynamic management, where different operating zones carry different clinical risks. Standard models trained with teacher forcing suffer from exposure bias, yielding unstable multi-step forecasts for closed-loop use. We introduce Soft-Token Trajectory Forecasting (SoTra), which propagates continuous probability distributions (``soft tokens’') to mitigate exposure bias and learn calibrated, uncertainty-aware trajectories. A risk-aware decoding module then minimizes expected clinical harm. In glucose forecasting, SoTra reduces average zone-based risk by 18%; in blood-pressure forecasting, it lowers effective clinical risk by approximately 15%. These improvements support its use in safety-critical predictive control.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-50] Local <mark class="hl-label green">LLM</mark>  Ensembles for Zero-shot Portuguese Named Entity Recognition</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10043">https://arxiv.org/abs/2512.10043</a><br>
<strong>作者</strong>: João Lucas Luz Lima Sarcinelli,Diego Furtado Silva<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Large Language Models (LLMs) excel in many Natural Language Processing (NLP) tasks through in-context learning but often under-perform in Named Entity Recognition (NER), especially for lower-resource languages like Portuguese. While open-weight LLMs enable local deployment, no single model dominates all tasks, motivating ensemble approaches. However, existing LLM ensembles focus on text generation or classification, leaving NER under-explored. In this context, this work proposes a novel three-step ensemble pipeline for zero-shot NER using similarly capable, locally run LLMs. Our method outperforms individual LLMs in four out of five Portuguese NER datasets by leveraging a heuristic to select optimal model combinations with minimal annotated data. Moreover, we show that ensembles obtained on different source datasets generally outperform individual LLMs in cross-dataset configurations, potentially eliminating the need for annotated data for the current task. Our work advances scalable, low-resource, and zero-shot NER by effectively combining multiple small LLMs without fine-tuning. Code is available at this https URL.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-51] SEMDICE: Off-policy State Entropy Maximization via Stationary Distribution Correction Estimation <mark class="hl-label red">ICLR2025</mark></p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10042">https://arxiv.org/abs/2512.10042</a><br>
<strong>作者</strong>: Jongmin Lee,Meiqi Sun,Pieter Abbeel<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  ICLR 2025</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In the unsupervised pre-training for reinforcement learning, the agent aims to learn a prior policy for downstream tasks without relying on task-specific reward functions. We focus on state entropy maximization (SEM), where the goal is to learn a policy that maximizes the entropy of the state stationary distribution. In this paper, we introduce SEMDICE, a principled off-policy algorithm that computes an SEM policy from an arbitrary off-policy dataset, which optimizes the policy directly within the space of stationary distributions. SEMDICE computes a single, stationary Markov state-entropy-maximizing policy from an arbitrary off-policy dataset. Experimental results demonstrate that SEMDICE outperforms baseline algorithms in maximizing state entropy while achieving the best adaptation efficiency for downstream tasks among SEM-based unsupervised RL pre-training methods.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-52] Robust Gradient Descent via Heavy-Ball Momentum with Predictive Extrapolation</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10033">https://arxiv.org/abs/2512.10033</a><br>
<strong>作者</strong>: Sarwan Ali<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Accelerated gradient methods like Nesterov’s Accelerated Gradient (NAG) achieve faster convergence on well-conditioned problems but often diverge on ill-conditioned or non-convex landscapes due to aggressive momentum accumulation. We propose Heavy-Ball Synthetic Gradient Extrapolation (HB-SGE), a robust first-order method that combines heavy-ball momentum with predictive gradient extrapolation. Unlike classical momentum methods that accumulate historical gradients, HB-SGE estimates future gradient directions using local Taylor approximations, providing adaptive acceleration while maintaining stability. We prove convergence guarantees for strongly convex functions and demonstrate empirically that HB-SGE prevents divergence on problems where NAG and standard momentum fail. On ill-conditioned quadratics (condition number  \kappa=50 ), HB-SGE converges in 119 iterations while both SGD and NAG diverge. On the non-convex Rosenbrock function, HB-SGE achieves convergence in 2,718 iterations where classical momentum methods diverge within 10 steps. While NAG remains faster on well-conditioned problems, HB-SGE provides a robust alternative with speedup over SGD across diverse landscapes, requiring only  O(d)  memory overhead and the same hyperparameters as standard momentum.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-53] Latent Action World Models for Control with Unlabeled Trajectories</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10016">https://arxiv.org/abs/2512.10016</a><br>
<strong>作者</strong>: Marvin Alles,Xingyuan Zhang,Patrick van der Smagt,Philip Becker-Ehmck<br>
<strong>类目</strong>: Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Inspired by how humans combine direct interaction with action-free experience (e.g., videos), we study world models that learn from heterogeneous data. Standard world models typically rely on action-conditioned trajectories, which limits effectiveness when action labels are scarce. We introduce a family of latent-action world models that jointly use action-conditioned and action-free data by learning a shared latent action representation. This latent space aligns observed control signals with actions inferred from passive observations, enabling a single dynamics model to train on large-scale unlabeled trajectories while requiring only a small set of action-labeled ones. We use the latent-action world model to learn a latent-action policy through offline reinforcement learning (RL), thereby bridging two traditionally separate domains: offline RL, which typically relies on action-conditioned data, and action-free training, which is rarely used with subsequent RL. On the DeepMind Control Suite, our approach achieves strong performance while using about an order of magnitude fewer action-labeled samples than purely action-conditioned baselines. These results show that latent actions enable training on both passive and interactive data, which makes world models learn more efficiently.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-54] Enhancing Fake-News Detection with Node-Level Topological Features</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09974">https://arxiv.org/abs/2512.09974</a><br>
<strong>作者</strong>: Kaiyuan Xu<br>
<strong>类目</strong>: ocial and Information Networks (<a target="_blank" rel="noopener" href="http://cs.SI">cs.SI</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In recent years, the proliferation of misinformation and fake news has posed serious threats to individuals and society, spurring intense research into automated detection methods. Previous work showed that integrating content, user preferences, and propagation structure achieves strong performance, but leaves all graph-level representation learning entirely to the GNN, hiding any explicit topological cues. To close this gap, we introduce a lightweight enhancement: for each node, we append two classical graph-theoretic metrics, degree centrality and local clustering coefficient, to its original BERT and profile embeddings, thus explicitly flagging the roles of hub and community. In the UPFD Politifact subset, this simple modification boosts macro F1 from 0.7753 to 0.8344 over the original baseline. Our study not only demonstrates the practical value of explicit topology features in fake-news detection but also provides an interpretable, easily reproducible template for fusing graph metrics in other information-diffusion tasks.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-55] DC-Cache: A Trustworthy Decentralized Cooperative Caching Framework for Web3.0</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09961">https://arxiv.org/abs/2512.09961</a><br>
<strong>作者</strong>: Jinyu Chen,Long Shi,Taotao Wang,Jiaheng Wang,Wei Zhang<br>
<strong>类目</strong>: Distributed, Parallel, and Cluster Computing (cs.DC); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The rapid growth of Web3.0 is transforming the Internet from a centralized structure to decentralized, which empowers users with unprecedented self-sovereignty over their own data. However, in the context of decentralized data access within Web3.0, it is imperative to cope with efficiency concerns caused by the replication of redundant data, as well as security vulnerabilities caused by data inconsistency. To address these challenges, we develop a Trustworthy Decentralized Cooperative Caching (TDC-Cache) framework for Web3.0 to ensure efficient caching and enhance system resilience against adversarial threats. This framework features a two-layer architecture, wherein the Decentralized Oracle Network (DON) layer serves as a trusted intermediary platform for decentralized caching, bridging the contents from decentralized storage and the content requests from users. In light of the complexity of Web3.0 network topologies and data flows, we propose a Deep Reinforcement Learning-Based Decentralized Caching (DRL-DC) for TDC-Cache to dynamically optimize caching strategies of distributed oracles. Furthermore, we develop a Proof of Cooperative Learning (PoCL) consensus to maintain the consistency of decentralized caching decisions within DON. Experimental results show that, compared with existing approaches, the proposed framework reduces average access latency by 20%, increases the cache hit rate by at most 18%, and improves the average success consensus rate by 10%. Overall, this paper serves as a first foray into the investigation of decentralized caching framework and strategy for Web3.0.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-56] HGC-Herd: Efficient Heterogeneous Graph Condensation via Representative Node Herding</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09947">https://arxiv.org/abs/2512.09947</a><br>
<strong>作者</strong>: Fuyan Ou,Siqi Ai,Yulin Hu<br>
<strong>类目</strong>: Machine Learning (cs.LG); Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
*<strong>备注</strong>:  8 pages, 2 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Heterogeneous graph neural networks (HGNNs) have demonstrated strong capability in modeling complex semantics across multi-type nodes and relations. However, their scalability to large-scale graphs remains challenging due to structural redundancy and high-dimensional node features. Existing graph condensation approaches, such as GCond, are primarily developed for homogeneous graphs and rely on gradient matching, resulting in considerable computational, memory, and optimization overhead. We propose HGC-Herd, a training-free condensation framework that generates compact yet informative heterogeneous graphs while maintaining both semantic and structural fidelity. HGC-Herd integrates lightweight feature propagation to encode multi-hop relational context and employs a class-wise herding mechanism to identify representative nodes per class, producing balanced and discriminative subsets for downstream learning tasks. Extensive experiments on ACM, DBLP, and Freebase validate that HGC-Herd attains comparable or superior accuracy to full-graph training while markedly reducing both runtime and memory consumption. These results underscore its practical value for efficient and scalable heterogeneous graph representation learning.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-57] QSTAformer: A Quantum-Enhanced Transformer for Robust Short-Term Voltage Stability Assessment against Adversarial Attacks</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.09936">https://arxiv.org/abs/2512.09936</a><br>
<strong>作者</strong>: Yang Li,Chong Ma,Yuanzheng Li,Sen Li,Yanbo Chen,Zhaoyang Dong<br>
<strong>类目</strong>: ystems and Control (<a target="_blank" rel="noopener" href="http://eess.SY">eess.SY</a>); Machine Learning (cs.LG); Quantum Physics (quant-ph)<br>
*<strong>备注</strong>:  15 pages, 12 figures. Accepted by Applied Energy</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Short-term voltage stability assessment (STVSA) is critical for secure power system operation. While classical machine learning-based methods have demonstrated strong performance, they still face challenges in robustness under adversarial conditions. This paper proposes QSTAformer-a tailored quantum-enhanced Transformer architecture that embeds parameterized quantum circuits (PQCs) into attention mechanisms-for robust and efficient STVSA. A dedicated adversarial training strategy is developed to defend against both white-box and gray-box attacks. Furthermore, diverse PQC architectures are benchmarked to explore trade-offs between expressiveness, convergence, and efficiency. To the best of our knowledge, this is the first work to systematically investigate the adversarial vulnerability of quantum machine learning-based STVSA. Case studies on the IEEE 39-bus system demonstrate that QSTAformer achieves competitive accuracy, reduced complexity, and stronger robustness, underscoring its potential for secure and scalable STVSA under adversarial conditions.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-58] Noisy Quantum Learning Theory</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10929">https://arxiv.org/abs/2512.10929</a><br>
<strong>作者</strong>: Jordan Cotler,Weiyuan Gong,Ishaan Kannan<br>
<strong>类目</strong>: Quantum Physics (quant-ph); Computational Complexity (<a target="_blank" rel="noopener" href="http://cs.CC">cs.CC</a>); Information Theory (<a target="_blank" rel="noopener" href="http://cs.IT">cs.IT</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  11+53 pages, 3 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We develop a framework for learning from noisy quantum experiments, focusing on fault-tolerant devices accessing uncharacterized systems through noisy couplings. Our starting point is the complexity class  \textsfNBQP  (“noisy BQP”), modeling noisy fault-tolerant quantum computers that cannot, in general, error-correct the oracle systems they query. Using this class, we show that for natural oracle problems, noise can eliminate exponential quantum learning advantages of ideal noiseless learners while preserving a superpolynomial gap between NISQ and fault-tolerant devices. Beyond oracle separations, we study concrete noisy learning tasks. For purity testing, the exponential two-copy advantage collapses under a single application of local depolarizing noise. Nevertheless, we identify a setting motivated by AdS/CFT in which noise-resilient structure restores a quantum learning advantage in a noisy regime. We then analyze noisy Pauli shadow tomography, deriving lower bounds that characterize how instance size, quantum memory, and noise control sample complexity, and design algorithms with parametrically similar scalings. Together, our results show that the Bell-basis and SWAP-test primitives underlying most exponential quantum learning advantages are fundamentally fragile to noise unless the experimental system has latent noise-robust structure. Thus, realizing meaningful quantum advantages in future experiments will require understanding how noise-robust physical properties interface with available algorithmic techniques.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-59] Hermitian Yang–Mills connections on general vector bundles: geometry and physical Yukawa couplings</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10907">https://arxiv.org/abs/2512.10907</a><br>
<strong>作者</strong>: Challenger Mishra,Justin Tan<br>
<strong>类目</strong>: High Energy Physics - Theory (hep-th); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  51 pages, Associated code open–sourced at <a target="_blank" rel="noopener" href="https://github.com/Justin-Tan/cymyc">this https URL</a></p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We compute solutions to the Hermitian Yang-Mills equations on holomorphic vector bundles  V  via an alternating optimisation procedure founded on geometric machine learning. The proposed method is fully general with respect to the rank and structure group of  V , requiring only the ability to enumerate a basis of global sections for a given bundle. This enables us to compute the physically normalised Yukawa couplings in a broad class of heterotic string compactifications. Using this method, we carry out this computation in full for a heterotic compactification incorporating a gauge bundle with non-Abelian structure group.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-60] Distributionally Robust Regret Optimal Control Under Moment-Based Ambiguity Sets</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10906">https://arxiv.org/abs/2512.10906</a><br>
<strong>作者</strong>: Feras Al Taha,Eilyan Bitar<br>
<strong>类目</strong>: Optimization and Control (math.OC); Machine Learning (cs.LG); Systems and Control (<a target="_blank" rel="noopener" href="http://eess.SY">eess.SY</a>)<br>
*<strong>备注</strong>:  21 pages, 2 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:In this paper, we consider a class of finite-horizon, linear-quadratic stochastic control problems, where the probability distribution governing the noise process is unknown but assumed to belong to an ambiguity set consisting of all distributions whose mean and covariance lie within norm balls centered at given nominal values. To address the distributional ambiguity, we explore the design of causal affine control policies to minimize the worst-case expected regret over all distributions in the given ambiguity set. The resulting minimax optimal control problem is shown to admit an equivalent reformulation as a tractable convex program that corresponds to a regularized version of the nominal linear-quadratic stochastic control problem. While this convex program can be recast as a semidefinite program, semidefinite programs are typically solved using primal-dual interior point methods that scale poorly with the problem size in practice. To address this limitation, we propose a scalable dual projected subgradient method to compute optimal controllers to an arbitrary accuracy. Numerical experiments are presented to benchmark the proposed method against state-of-the-art data-driven and distributionally robust control design approaches.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-61] Physics-informed Polynomial Chaos Expansion with Enhanced Constrained Optimization Solver and D-optimal Sampling</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10873">https://arxiv.org/abs/2512.10873</a><br>
<strong>作者</strong>: Qitian Lu,Himanshu Sharma,Michael D. Shields,Lukáš Novák<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Physics-informed polynomial chaos expansions (PC ^2 ) provide an efficient physically constrained surrogate modeling framework by embedding governing equations and other physical constraints into the standard data-driven polynomial chaos expansions (PCE) and solving via the Karush-Kuhn-Tucker (KKT) conditions. This approach improves the physical interpretability of surrogate models while achieving high computational efficiency and accuracy. However, the performance and efficiency of PC ^2  can still be degraded with high-dimensional parameter spaces, limited data availability, or unrepresentative training data. To address this problem, this study explores two complementary enhancements to the PC ^2  framework. First, a numerically efficient constrained optimization solver, straightforward updating of Lagrange multipliers (SULM), is adopted as an alternative to the conventional KKT solver. The SULM method significantly reduces computational cost when solving physically constrained problems with high-dimensionality and derivative boundary conditions that require a large number of virtual points. Second, a D-optimal sampling strategy is utilized to select informative virtual points to improve the stability and achieve the balance of accuracy and efficiency of the PC ^2 . The proposed methods are integrated into the PC ^2  framework and evaluated through numerical examples of representative physical systems governed by ordinary or partial differential equations. The results demonstrate that the enhanced PC ^2  has better comprehensive capability than standard PC ^2 , and is well-suited for high-dimensional uncertainty quantification tasks.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-62] An Elementary Proof of the Near Optimality of LogSumExp Smoothing</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10825">https://arxiv.org/abs/2512.10825</a><br>
<strong>作者</strong>: Thabo Samakhoana,Benjamin Grimmer<br>
<strong>类目</strong>: atistics Theory (<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>); Machine Learning (cs.LG); Optimization and Control (math.OC)<br>
*<strong>备注</strong>:  10 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We consider the design of smoothings of the (coordinate-wise) max function in  \mathbbR^d  in the infinity norm. The LogSumExp function  f(x)=\ln(\sum^d_i\exp(x_i))  provides a classical smoothing, differing from the max function in value by at most  \ln(d) . We provide an elementary construction of a lower bound, establishing that every overestimating smoothing of the max function must differ by at least  \sim 0.8145\ln(d) . Hence, LogSumExp is optimal up to constant factors. However, in small dimensions, we provide stronger, exactly optimal smoothings attaining our lower bound, showing that the entropy-based LogSumExp approach to smoothing is not exactly optimal.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-63] Deep sets and event-level maximum-likelihood estimation for fast pile-up jet rejection in ATLAS</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10819">https://arxiv.org/abs/2512.10819</a><br>
<strong>作者</strong>: Mohammed Aboelela<br>
<strong>类目</strong>: High Energy Physics - Experiment (hep-ex); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  6 pages, 3 figures, European Physical Society Conference on High Energy Physics (EPS-HEP2025), On behalf of the ATLAS Collaboration</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Multiple proton-proton collisions (pile-up) occur at every bunch crossing at the LHC, with the mean number of interactions expected to reach 80 during Run 3 and up to 200 at the High-Luminosity LHC. As a direct consequence, events with multijet signatures will occur at increasingly high rates. To cope with the increased luminosity, being able to efficiently group jets according to their origin along the beamline is crucial, particularly at the trigger level. In this work, a novel uncertainty-aware jet regression model based on a Deep Sets architecture is introduced, DIPz, to regress on a jet origin position along the beamline. The inputs to the DIPz algorithm are the charged particle tracks associated to each jet. An event-level discriminant, the Maximum Log Product of Likelihoods (MLPL), is constructed by combining the DIPz per-jet predictions. MLPL is cut-optimized to select events compatible with targeted multi-jet signature selection. This combined approach provides a robust and computationally efficient method for pile-up rejection in multi-jet final states, applicable to real-time event selections at the ATLAS High Level Trigger.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-64] Quantum Approaches to Urban Logistics: From Core QAOA to Clustered Scalability</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10813">https://arxiv.org/abs/2512.10813</a><br>
<strong>作者</strong>: F. Picariello,G. Turati,R. Antonelli,I. Bailo,S. Bonura,G. Ciarfaglia,S. Cipolla,P. Cremonesi,M. Ferrari Dacrema,M. Gabusi,I. Gentile,V. Morreale,A. Noto<br>
<strong>类目</strong>: Quantum Physics (quant-ph); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The Traveling Salesman Problem (TSP) is a fundamental challenge in combinatorial optimization, widely applied in logistics and transportation. As the size of TSP instances grows, traditional algorithms often struggle to produce high-quality solutions within reasonable timeframes. This study investigates the potential of the Quantum Approximate Optimization Algorithm (QAOA), a hybrid quantum-classical method, to solve TSP under realistic constraints. We adopt a QUBO-based formulation of TSP that integrates real-world logistical constraints reflecting operational conditions, such as vehicle capacity, road accessibility, and time windows, while ensuring compatibility with the limitations of current quantum hardware. Our experiments are conducted in a simulated environment using high-performance computing (HPC) resources to assess QAOA’s performance across different problem sizes and quantum circuit depths. In order to improve scalability, we propose clustering QAOA (Cl-QAOA), a hybrid approach combining classical machine learning with QAOA. This method decomposes large TSP instances into smaller sub-problems, making quantum optimization feasible even on devices with a limited number of qubits. The results offer a comprehensive evaluation of QAOA’s strengths and limitations in solving constrained TSP scenarios. This study advances quantum optimization and lays groundwork for future large-scale applications.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-65] PMB-NN: Physiology-Centred Hybrid AI for Personalized Hemodynamic Monitoring from Photoplethysmography</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10745">https://arxiv.org/abs/2512.10745</a><br>
<strong>作者</strong>: Yaowen Zhang,Libera Fresiello,Peter H. Veltink,Dirk W. Donker,Ying Wang<br>
<strong>类目</strong>: Medical Physics (physics.med-ph); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Continuous monitoring of blood pressure (BP) and hemodynamic parameters such as peripheral resistance ® and arterial compliance © are critical for early vascular dysfunction detection. While photoplethysmography (PPG) wearables has gained popularity, existing data-driven methods for BP estimation lack interpretability. We advanced our previously proposed physiology-centered hybrid AI method-Physiological Model-Based Neural Network (PMB-NN)-in blood pressure estimation, that unifies deep learning with a 2-element Windkessel based model parameterized by R and C acting as physics constraints. The PMB-NN model was trained in a subject-specific manner using PPG-derived timing features, while demographic information was used to infer an intermediate variable: cardiac output. We validated the model on 10 healthy adults performing static and cycling activities across two days for model’s day-to-day robustness, benchmarked against deep learning (DL) models (FCNN, CNN-LSTM, Transformer) and standalone Windkessel based physiological model (PM). Validation was conducted on three perspectives: accuracy, interpretability and plausibility. PMB-NN achieved systolic BP accuracy (MAE: 7.2 mmHg) comparable to DL benchmarks, diastolic performance (MAE: 3.9 mmHg) lower than DL models. However, PMB-NN exhibited higher physiological plausibility than both DL baselines and PM, suggesting that the hybrid architecture unifies and enhances the respective merits of physiological principles and data-driven techniques. Beyond BP, PMB-NN identified R (ME: 0.15 mmHg \cdot s/ml) and C (ME: -0.35 ml/mmHg) during training with accuracy similar to PM, demonstrating that the embedded physiological constraints confer interpretability to the hybrid AI framework. These results position PMB-NN as a balanced, physiologically grounded alternative to purely data-driven approaches for daily hemodynamic monitoring.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-66] opology-Guided Quantum GANs for Constrained Graph Generation</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10582">https://arxiv.org/abs/2512.10582</a><br>
<strong>作者</strong>: Tobias Rohe,Markus Baumann,Michael Poppel,Gerhard Stenzel,Maximilian Zorn,Claudia Linnhoff-Popien<br>
<strong>类目</strong>: Quantum Physics (quant-ph); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Quantum computing (QC) promises theoretical advantages, benefiting computational problems that would not be efficiently classically simulatable. However, much of this theoretical speedup depends on the quantum circuit design solving the problem. We argue that QC literature has yet to explore more domain specific ansatz-topologies, instead of relying on generic, one-size-fits-all architectures. In this work, we show that incorporating task-specific inductive biases – specifically geometric priors – into quantum circuit design can enhance the performance of hybrid Quantum Generative Adversarial Networks (QuGANs) on the task of generating geometrically constrained K4 graphs. We evaluate a portfolio of entanglement topologies and loss-function designs to assess their impact on both statistical fidelity and compliance with geometric constraints, including the Triangle and Ptolemaic inequalities. Our results show that aligning circuit topology with the underlying problem structure yields substantial benefits: the Triangle-topology QuGAN achieves the highest geometric validity among quantum models and matches the performance of classical Generative Adversarial Networks (GAN). Additionally, we showcase how specific architectural choices, such as entangling gate types, variance regularization and output-scaling govern the trade-off between geometric consistency and distributional accuracy, thus emphasizing the value of structured, task-aware quantum ansatz-topologies.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-67] Flexible Deep Neural Networks for Partially Linear Survival Data</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10570">https://arxiv.org/abs/2512.10570</a><br>
<strong>作者</strong>: Asaf Ben Arie,Malka Gorfine<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We propose a flexible deep neural network (DNN) framework for modeling survival data within a partially linear regression structure. The approach preserves interpretability through a parametric linear component for covariates of primary interest, while a nonparametric DNN component captures complex time-covariate interactions among nuisance variables. We refer to the method as FLEXI-Haz, a flexible hazard model with a partially linear structure. In contrast to existing DNN approaches for partially linear Cox models, FLEXI-Haz does not rely on the proportional hazards assumption. We establish theoretical guarantees: the neural network component attains minimax-optimal convergence rates based on composite Holder classes, and the linear estimator is root-n consistent, asymptotically normal, and semiparametrically efficient. Extensive simulations and real-data analyses demonstrate that FLEXI-Haz provides accurate estimation of the linear effect, offering a principled and interpretable alternative to modern methods based on proportional hazards. Code for implementing FLEXI-Haz, as well as scripts for reproducing data analyses and simulations, is available at: this https URL</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-68] Hyperspectral Image Data Reduction for Endmember Extraction</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10506">https://arxiv.org/abs/2512.10506</a><br>
<strong>作者</strong>: Tomohiko Mizutani<br>
<strong>类目</strong>: Image and Video Processing (eess.IV); Machine Learning (cs.LG); Signal Processing (eess.SP)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Endmember extraction from hyperspectral images aims to identify the spectral signatures of materials present in a scene. Recent studies have shown that self-dictionary methods can achieve high extraction accuracy; however, their high computational cost limits their applicability to large-scale hyperspectral images. Although several approaches have been proposed to mitigate this issue, it remains a major challenge. Motivated by this situation, this paper pursues a data reduction approach. Assuming that the hyperspectral image follows the linear mixing model with the pure-pixel assumption, we develop a data reduction technique that removes pixels that do not contain endmembers. We analyze the theoretical properties of this reduction step and show that it preserves pixels that lie close to the endmembers. Building on this result, we propose a data-reduced self-dictionary method that integrates the data reduction with a self-dictionary method based on a linear programming formulation. Numerical experiments demonstrate that the proposed method can substantially reduce the computational time of the original self-dictionary method without sacrificing endmember extraction accuracy.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-69] Supervised Learning of Random Neural Architectures Structured by Latent Random Fields on Compact Boundaryless Multiply-Connected Manifolds</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10407">https://arxiv.org/abs/2512.10407</a><br>
<strong>作者</strong>: Christian Soize<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  46 pages, 12 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper introduces a new probabilistic framework for supervised learning in neural systems. It is designed to model complex, uncertain systems whose random outputs are strongly non-Gaussian given deterministic inputs. The architecture itself is a random object stochastically generated by a latent anisotropic Gaussian random field defined on a compact, boundaryless, multiply-connected manifold. The goal is to establish a novel conceptual and mathematical framework in which neural architectures are realizations of a geometry-aware, field-driven generative process. Both the neural topology and synaptic weights emerge jointly from a latent random field. A reduced-order parameterization governs the spatial intensity of an inhomogeneous Poisson process on the manifold, from which neuron locations are sampled. Input and output neurons are identified via extremal evaluations of the latent field, while connectivity is established through geodesic proximity and local field affinity. Synaptic weights are conditionally sampled from the field realization, inducing stochastic output responses even for deterministic inputs. To ensure scalability, the architecture is sparsified via percentile-based diffusion masking, yielding geometry-aware sparse connectivity without ad hoc structural assumptions. Supervised learning is formulated as inference on the generative hyperparameters of the latent field, using a negative log-likelihood loss estimated through Monte Carlo sampling from single-observation-per-input datasets. The paper initiates a mathematical analysis of the model, establishing foundational properties such as well-posedness, measurability, and a preliminary analysis of the expressive variability of the induced stochastic mappings, which support its internal coherence and lay the groundwork for a broader theory of geometry-driven stochastic learning.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-70] Diffusion differentiable resampling</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10401">https://arxiv.org/abs/2512.10401</a><br>
<strong>作者</strong>: Jennifer Rosina Andersson,Zheng Zhao<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG); Statistics Theory (<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:This paper is concerned with differentiable resampling in the context of sequential Monte Carlo (e.g., particle filtering). We propose a new informative resampling method that is instantly pathwise differentiable, based on an ensemble score diffusion model. We prove that our diffusion resampling method provides a consistent estimate to the resampling distribution, and we show by experiments that it outperforms the state-of-the-art differentiable resampling methods when used for stochastic filtering and parameter estimation.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-71] Residual subspace evolution strategies for nonlinear inverse problems</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10325">https://arxiv.org/abs/2512.10325</a><br>
<strong>作者</strong>: Francesco Alemanno<br>
<strong>类目</strong>: Optimization and Control (math.OC); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Nonlinear inverse problems often feature noisy, non-differentiable, or expensive residual evaluations that make Jacobian-based solvers unreliable. Popular derivative-free optimizers such as natural evolution strategies (NES) or Powell’s NEWUOA still assume smoothness or expend many evaluations to maintain stability. Ensemble Kalman inversion (EKI) relies on empirical covariances that require preconditioning and scale poorly with residual dimension. We introduce residual subspace evolution strategies (RSES), a derivative-free solver that samples Gaussian probes around the current iterate, builds a residual-only surrogate from their differences, and recombines the probes through a least-squares solve yielding an optimal update without forming Jacobians or covariances. Each iteration costs  k+1  residual evaluations, where  k \ll n  for  n -dimensional problems, with  O(k^3)  linear algebra overhead. Benchmarks on calibration, regression, and deconvolution problems demonstrate consistent misfit reduction in both deterministic and stochastic settings. RSES matches or surpasses xNES and NEWUOA while staying competitive with EKI under matched evaluation budgets, particularly when smoothness or covariance assumptions fail.         Subjects:  Optimization and Control (math.OC); Machine Learning (cs.LG)  Cite as: arXiv:2512.10325 [math.OC]    (or  arXiv:2512.10325v1 [math.OC] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10325">https://doi.org/10.48550/arXiv.2512.10325</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-72] racking large chemical reaction networks and rare events by neural networks</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10309">https://arxiv.org/abs/2512.10309</a><br>
<strong>作者</strong>: Jiayu Weng,Xinyi Zhu,Jing Liu,Linyuan Lü,Pan Zhang,Ying Tang<br>
<strong>类目</strong>: Molecular Networks (<a target="_blank" rel="noopener" href="http://q-bio.MN">q-bio.MN</a>); Machine Learning (cs.LG); Biological Physics (physics.bio-ph)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Chemical reaction networks are widely used to model stochastic dynamics in chemical kinetics, systems biology and epidemiology. Solving the chemical master equation that governs these systems poses a significant challenge due to the large state space exponentially growing with system sizes. The development of autoregressive neural networks offers a flexible framework for this problem; however, its efficiency is limited especially for high-dimensional systems and in scenarios with rare events. Here, we push the frontier of neural-network approach by exploiting faster optimizations such as natural gradient descent and time-dependent variational principle, achieving a 5- to 22-fold speedup, and by leveraging enhanced-sampling strategies to capture rare events. We demonstrate reduced computational cost and higher accuracy over the previous neural-network method in challenging reaction networks, including the mitogen-activated protein kinase (MAPK) cascade network, the hitherto largest biological network handled by the previous approaches of solving the chemical master equation. We further apply the approach to spatially extended reaction-diffusion systems, the Schlögl model with rare events, on two-dimensional lattices, beyond the recent tensor-network approach that handles one-dimensional lattices. The present approach thus enables efficient modeling of chemical reaction networks in general.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-73] Error Analysis of Generalized Langevin Equations with Approximated Memory Kernels</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10256">https://arxiv.org/abs/2512.10256</a><br>
<strong>作者</strong>: Quanjun Lang,Jianfeng Lu<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG); Dynamical Systems (math.DS); Numerical Analysis (<a target="_blank" rel="noopener" href="http://math.NA">math.NA</a>); Probability (<a target="_blank" rel="noopener" href="http://math.PR">math.PR</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We analyze prediction error in stochastic dynamical systems with memory, focusing on generalized Langevin equations (GLEs) formulated as stochastic Volterra equations. We establish that, under a strongly convex potential, trajectory discrepancies decay at a rate determined by the decay of the memory kernel and are quantitatively bounded by the estimation error of the kernel in a weighted norm. Our analysis integrates synchronized noise coupling with a Volterra comparison theorem, encompassing both subexponential and exponential kernel classes. For first-order models, we derive moment and perturbation bounds using resolvent estimates in weighted spaces. For second-order models with confining potentials, we prove contraction and stability under kernel perturbations using a hypocoercive Lyapunov-type distance. This framework accommodates non-translation-invariant kernels and white-noise forcing, explicitly linking improved kernel estimation to enhanced trajectory prediction. Numerical examples validate these theoretical findings.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-74] Galaxy Phase-Space and Field-Level Cosmology: The Strength of Semi-Analytic Models</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10222">https://arxiv.org/abs/2512.10222</a><br>
<strong>作者</strong>: Natalí S. M. de Santi,Francisco Villaescusa-Navarro,Pablo Araya-Araya,Gabriella De Lucia,Fabio Fontanot,Lucia A. Perez,Manuel Arnés-Curto,Violeta Gonzalez-Perez,Ángel Chandro-Gómez,Rachel S. Somerville,Tiago Castro<br>
<strong>类目</strong>: Cosmology and Nongalactic Astrophysics (<a target="_blank" rel="noopener" href="http://astro-ph.CO">astro-ph.CO</a>); Astrophysics of Galaxies (<a target="_blank" rel="noopener" href="http://astro-ph.GA">astro-ph.GA</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  23 pages, 5 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Semi-analytic models are a widely used approach to simulate galaxy properties within a cosmological framework, relying on simplified yet physically motivated prescriptions. They have also proven to be an efficient alternative for generating accurate galaxy catalogs, offering a faster and less computationally expensive option compared to full hydrodynamical simulations. In this paper, we demonstrate that using only galaxy  3 D positions and radial velocities, we can train a graph neural network coupled to a moment neural network to obtain a robust machine learning based model capable of estimating the matter density parameters,  \Omega_\rm m , with a precision of approximately 10%. The network is trained on ( 25 h^-1 Mpc) ^3  volumes of galaxy catalogs from L-Galaxies and can successfully extrapolate its predictions to other semi-analytic models (GAEA, SC-SAM, and Shark) and, more remarkably, to hydrodynamical simulations (Astrid, SIMBA, IllustrisTNG, and SWIFT-EAGLE). Our results show that the network is robust to variations in astrophysical and subgrid physics, cosmological and astrophysical parameters, and the different halo-profile treatments used across simulations. This suggests that the physical relationships encoded in the phase-space of semi-analytic models are largely independent of their specific physical prescriptions, reinforcing their potential as tools for the generation of realistic mock catalogs for cosmological parameter inference.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-75] On Learning-Curve Monotonicity for Maximum Likelihood Estimators</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10220">https://arxiv.org/abs/2512.10220</a><br>
<strong>作者</strong>: Mark Sellke,Steven Yin<br>
<strong>类目</strong>: atistics Theory (<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>); Machine Learning (cs.LG); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)<br>
*<strong>备注</strong>:  24 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The property of learning-curve monotonicity, highlighted in a recent series of work by Loog, Mey and Viering, describes algorithms which only improve in average performance given more data, for any underlying data distribution within a given family. We establish the first nontrivial monotonicity guarantees for the maximum likelihood estimator in a variety of well-specified parametric settings. For sequential prediction with log loss, we show monotonicity (in fact complete monotonicity) of the forward KL divergence for Gaussian vectors with unknown covariance and either known or unknown mean, as well as for Gamma variables with unknown scale parameter. The Gaussian setting was explicitly highlighted as open in the aforementioned works, even in dimension 1. Finally we observe that for reverse KL divergence, a folklore trick yields monotonicity for very general exponential families. All results in this paper were derived by variants of GPT-5.2 Pro. Humans did not provide any proof strategies or intermediate arguments, but only prompted the model to continue developing additional results, and verified and transcribed its proofs.          Comments: 24 pages   Subjects:  Statistics Theory (<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>); Machine Learning (cs.LG); Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>)  Cite as: arXiv:2512.10220 [<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>]    (or  arXiv:2512.10220v1 [<a target="_blank" rel="noopener" href="http://math.ST">math.ST</a>] for this version)                <a target="_blank" rel="noopener" href="https://doi.org/10.48550/arXiv.2512.10220">https://doi.org/10.48550/arXiv.2512.10220</a>   Focus to learn more                      arXiv-issued DOI via DataCite (pending registration)</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-76] he Interplay of Statistics and Noisy Optimization: Learning Linear Predictors with Random Data Weights</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10188">https://arxiv.org/abs/2512.10188</a><br>
<strong>作者</strong>: Gabriel Clara,Yazan Mash’al<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG); Computation (<a target="_blank" rel="noopener" href="http://stat.CO">stat.CO</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We analyze gradient descent with randomly weighted data points in a linear regression model, under a generic weighting distribution. This includes various forms of stochastic gradient descent, importance sampling, but also extends to weighting distributions with arbitrary continuous values, thereby providing a unified framework to analyze the impact of various kinds of noise on the training trajectory. We characterize the implicit regularization induced through the random weighting, connect it with weighted linear regression, and derive non-asymptotic bounds for convergence in first and second moments. Leveraging geometric moment contraction, we also investigate the stationary distribution induced by the added noise. Based on these results, we discuss how specific choices of weighting distribution influence both the underlying optimization problem and statistical properties of the resulting estimator, as well as some examples for which weightings that lead to fast convergence cause bad statistical performance.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-77] Inference for Batched Adaptive Experiments</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10156">https://arxiv.org/abs/2512.10156</a><br>
<strong>作者</strong>: Jan Kemper,Davud Rostam-Afschar<br>
<strong>类目</strong>: Econometrics (econ.EM); Machine Learning (cs.LG); Methodology (<a target="_blank" rel="noopener" href="http://stat.ME">stat.ME</a>)<br>
*<strong>备注</strong>:</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:The advantages of adaptive experiments have led to their rapid adoption in economics, other fields, as well as among practitioners. However, adaptive experiments pose challenges for causal inference. This note suggests a BOLS (batched ordinary least squares) test statistic for inference of treatment effects in adaptive experiments. The statistic provides a precision-equalizing aggregation of per-period treatment-control differences under heteroskedasticity. The combined test statistic is a normalized average of heteroskedastic per-period z-statistics and can be used to construct asymptotically valid confidence intervals. We provide simulation results comparing rejection rates in the typical case with few treatment periods and few (or many) observations per batch.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-78] A Model-Guided Neural Network Method for the Inverse Scattering Problem</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10123">https://arxiv.org/abs/2512.10123</a><br>
<strong>作者</strong>: Olivia Tsang,Owen Melia,Vasileios Charisopoulos,Jeremy Hoskins,Yuehaw Khoo,Rebecca Willett<br>
<strong>类目</strong>: Computational Physics (physics.comp-ph); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  28 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Inverse medium scattering is an ill-posed, nonlinear wave-based imaging problem arising in medical imaging, remote sensing, and non-destructive testing. Machine learning (ML) methods offer increased inference speed and flexibility in capturing prior knowledge of imaging targets relative to classical optimization-based approaches; however, they perform poorly in regimes where the scattering behavior is highly nonlinear. A key limitation is that ML methods struggle to incorporate the physics governing the scattering process, which are typically inferred implicitly from the training data or loosely enforced via architectural design. In this paper, we present a method that endows a machine learning framework with explicit knowledge of problem physics, in the form of a differentiable solver representing the forward model. The proposed method progressively refines reconstructions of the scattering potential using measurements at increasing wave frequencies, following a classical strategy to stabilize recovery. Empirically, we find that our method provides high-quality reconstructions at a fraction of the computational or sampling costs of competing approaches.</p>
</div></div>
<div class="note pink no-icon flat"><p>[LG-79] LxCIM: a new rank-based binary classifier performance metric invariant to local exchange of classes</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10053">https://arxiv.org/abs/2512.10053</a><br>
<strong>作者</strong>: Tiago Brogueira,Mário A. T. Figueiredo<br>
<strong>类目</strong>: Machine Learning (<a target="_blank" rel="noopener" href="http://stat.ML">stat.ML</a>); Machine Learning (cs.LG)<br>
*<strong>备注</strong>:  28 pages, 7 figures</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Binary classification is one of the oldest, most prevalent, and studied problems in machine learning. However, the metrics used to evaluate model performance have received comparatively little attention. The area under the receiver operating characteristic curve (AUROC) has long been a standard choice for model comparison. Despite its advantages, AUROC is not always ideal, particularly for problems that are invariant to local exchange of classes (LxC), a new form of metric invariance introduced in this work. To address this limitation, we propose LxCIM (LxC-invariant metric), which is not only rank-based and invariant under local exchange of classes, but also intuitive, logically consistent, and always computable, while enabling more detailed analysis through the cumulative accuracy-decision rate curve. Moreover, LxCIM exhibits clear theoretical connections to AUROC, accuracy, and the area under the accuracy-decision rate curve (AUDRC). These relationships allow for multiple complementary interpretations: as a symmetric form of AUROC, a rank-based analogue of accuracy, or a more representative and more interpretable variant of AUDRC. Finally, we demonstrate the direct applicability of LxCIM to the bivariate causal discovery problem (which exhibits invariance to local exchange of classes) and show how it addresses the acknowledged limitations of existing metrics used in this field. All code and implementation details are publicly available at this http URL.</p>
</div></div>
<h3 id="信息检索">信息检索</h3>
<div class="note pink no-icon flat"><p>[IR-0] BookReconciler: An Open-Source Tool for Metadata Enrichment and Work-Level Clustering</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10165">https://arxiv.org/abs/2512.10165</a><br>
<strong>作者</strong>: Matt Miller,Dan Sinykin,Melanie Walsh<br>
<strong>类目</strong>: Digital Libraries (cs.DL); Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
*<strong>备注</strong>:  Published in the proceedings of the Joint Conference on Digital Libraries (JCDL) 2025, Resources</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:We present BookReconciler, an open-source tool for enhancing and clustering book data. BookReconciler allows users to take spreadsheets with minimal metadata, such as book title and author, and automatically 1) add authoritative, persistent identifiers like ISBNs 2) and cluster related Expressions and Manifestations of the same Work, e.g., different translations or editions. This enhancement makes it easier to combine related collections and analyze books at scale. The tool is currently designed as an extension for OpenRefine – a popular software application – and connects to major bibliographic services including the Library of Congress, VIAF, OCLC, HathiTrust, Google Books, and Wikidata. Our approach prioritizes human judgment. Through an interactive interface, users can manually evaluate matches and define the contours of a Work (e.g., to include translations or not). We evaluate reconciliation performance on datasets of U.S. prize-winning books and contemporary world fiction. BookReconciler achieves near-perfect accuracy for U.S. works but lower performance for global texts, reflecting structural weaknesses in bibliographic infrastructures for non-English and global literature. Overall, BookReconciler supports the reuse of bibliographic data across domains and applications, contributing to ongoing work in digital libraries and digital humanities.</p>
</div></div>
<div class="note pink no-icon flat"><p>[IR-1] <mark class="hl-label green">LLM</mark> -PEA: Leve<mark class="hl-label green">rag</mark> ing <mark class="hl-label green">Large</mark> <mark class="hl-label green">Language</mark> <mark class="hl-label green">Models</mark>  Against Phishing Email Attacks</p>
</div>
<p><strong>链接</strong>: <a target="_blank" rel="noopener" href="https://arxiv.org/abs/2512.10104">https://arxiv.org/abs/2512.10104</a><br>
<strong>作者</strong>: Najmul Hassan,Prashanth BusiReddyGari,Haitao Zhao,Yihao Ren,Jinsheng Xu,Shaohu Zhang<br>
<strong>类目</strong>: Cryptography and Security (<a target="_blank" rel="noopener" href="http://cs.CR">cs.CR</a>); Information Retrieval (<a target="_blank" rel="noopener" href="http://cs.IR">cs.IR</a>)<br>
*<strong>备注</strong>:  7 pages</p>
<div class="hide-toggle" ><div class="hide-button toggle-title" style=""><i class="fas fa-caret-right fa-fw"></i><span>点击查看摘要</span></div>
    <div class="hide-content"><p>Abstract:Email phishing is one of the most prevalent and globally consequential vectors of cyber intrusion. As systems increasingly deploy Large Language Models (LLMs) applications, these systems face evolving phishing email threats that exploit their fundamental architectures. Current LLMs require substantial hardening before deployment in email security systems, particularly against coordinated multi-vector attacks that exploit architectural vulnerabilities. This paper proposes LLMPEA, an LLM-based framework to detect phishing email attacks across multiple attack vectors, including prompt injection, text refinement, and multilingual attacks. We evaluate three frontier LLMs (e.g., GPT-4o, Claude Sonnet 4, and Grok-3) and comprehensive prompting design to assess their feasibility, robustness, and limitations against phishing email attacks. Our empirical analysis reveals that LLMs can detect the phishing email over 90% accuracy while we also highlight that LLM-based phishing email detection systems could be exploited by adversarial attack, prompt injection, and multilingual attacks. Our findings provide critical insights for LLM-based phishing detection in real-world settings where attackers exploit multiple vulnerabilities in combination.</p>
</div></div>
<h3 id="附件下载">附件下载</h3>
<p><a target="_blank" rel="noopener" href="https://raw.githubusercontent.com/lonePatient/lonePatient.github.io/master/arxiv/arxiv_papers_2025-12-12.txt">点击下载今日全部论文列表</a></p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Weitang Liu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://lonepatient.top/2025/12/12/arxiv_papers_2025-12-12.html">http://lonepatient.top/2025/12/12/arxiv_papers_2025-12-12.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://lonepatient.top" target="_blank">闲记算法</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Arxiv/">Arxiv</a></div><div class="post_share"><div class="social-share" data-image="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/12/15/arxiv_papers_2025-12-15.html"><img class="prev-cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Arxiv今日论文 | 2025-12-15</div></div></a></div><div class="next-post pull-right"><a href="/2025/12/11/arxiv_papers_2025-12-11.html"><img class="next-cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Arxiv今日论文 | 2025-12-11</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2023/10/10/ar5iv.html" title="ar5iv"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20231208121727.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-10-10</div><div class="title">ar5iv</div></div></a></div><div><a href="/2026/02/10/arxiv_papers_2026-02-10.html" title="Arxiv今日论文 | 2026-02-10"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2026-02-10</div><div class="title">Arxiv今日论文 | 2026-02-10</div></div></a></div><div><a href="/2025/12/03/arxiv_papers_2025-12-03.html" title="Arxiv今日论文 | 2025-12-03"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-03</div><div class="title">Arxiv今日论文 | 2025-12-03</div></div></a></div><div><a href="/2025/12/04/arxiv_papers_2025-12-04.html" title="Arxiv今日论文 | 2025-12-04"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-04</div><div class="title">Arxiv今日论文 | 2025-12-04</div></div></a></div><div><a href="/2025/12/05/arxiv_papers_2025-12-05.html" title="Arxiv今日论文 | 2025-12-05"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-05</div><div class="title">Arxiv今日论文 | 2025-12-05</div></div></a></div><div><a href="/2025/12/08/arxiv_papers_2025-12-08.html" title="Arxiv今日论文 | 2025-12-08"><img class="cover" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-08</div><div class="title">Arxiv今日论文 | 2025-12-08</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="twikoo-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" src="/img/touxiang.jpeg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-info__name">Weitang Liu</div><div class="author-info__description">一个致力于记录技术的博客</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">281</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">384</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">92</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/lonePatient"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/lonePatient" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:liuweitangmath@163.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://weibo.com/277974397" target="_blank" title="Weibo"><i class="fab fa-weibo"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录和分享一些学习和开源内容，若有任何问题可通过留言板或者微信公众号给我留言，谢谢！<img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/202602201201102.jpg"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%9B%AE%E5%BD%95"><span class="toc-number">1.</span> <span class="toc-text">目录</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A6%82%E8%A7%88-2025-12-12"><span class="toc-number">1.1.</span> <span class="toc-text">概览 (2025-12-12)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86"><span class="toc-number">1.2.</span> <span class="toc-text">自然语言处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89"><span class="toc-number">1.3.</span> <span class="toc-text">计算机视觉</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD"><span class="toc-number">1.4.</span> <span class="toc-text">人工智能</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.5.</span> <span class="toc-text">机器学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BF%A1%E6%81%AF%E6%A3%80%E7%B4%A2"><span class="toc-number">1.6.</span> <span class="toc-text">信息检索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%99%84%E4%BB%B6%E4%B8%8B%E8%BD%BD"><span class="toc-number">1.7.</span> <span class="toc-text">附件下载</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2026/02/27/arxiv_papers_2026-02-27.html" title="Arxiv今日论文 | 2026-02-27"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-27"/></a><div class="content"><a class="title" href="/2026/02/27/arxiv_papers_2026-02-27.html" title="Arxiv今日论文 | 2026-02-27">Arxiv今日论文 | 2026-02-27</a><time datetime="2026-02-27T12:30:00.000Z" title="发表于 2026-02-27 12:30:00">2026-02-27</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/26/arxiv_papers_2026-02-26.html" title="Arxiv今日论文 | 2026-02-26"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-26"/></a><div class="content"><a class="title" href="/2026/02/26/arxiv_papers_2026-02-26.html" title="Arxiv今日论文 | 2026-02-26">Arxiv今日论文 | 2026-02-26</a><time datetime="2026-02-26T12:30:00.000Z" title="发表于 2026-02-26 12:30:00">2026-02-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/arxiv_papers_2026-02-25.html" title="Arxiv今日论文 | 2026-02-25"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-25"/></a><div class="content"><a class="title" href="/2026/02/25/arxiv_papers_2026-02-25.html" title="Arxiv今日论文 | 2026-02-25">Arxiv今日论文 | 2026-02-25</a><time datetime="2026-02-25T12:30:00.000Z" title="发表于 2026-02-25 12:30:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/2026-02-25-Less-is-Enough-Synthesizing-Diverse-Data-in-Feature-Space-of-LLMs.html" title="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260225222513891.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板"/></a><div class="content"><a class="title" href="/2026/02/25/2026-02-25-Less-is-Enough-Synthesizing-Diverse-Data-in-Feature-Space-of-LLMs.html" title="大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板">大模型数据合成新范式：2K样本打败30万，从特征空间精准狙击任务短板</a><time datetime="2026-02-25T12:00:00.000Z" title="发表于 2026-02-25 12:00:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/25/2026-02-25-Midtraining-%E4%B8%AD%E9%97%B4%E8%AE%AD%E7%BB%83-%E6%9E%84%E5%BB%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%90%8E%E8%AE%AD%E7%BB%83%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%A5%E6%A2%81.html" title="mid-training：构建预训练与后训练之间的分布式桥梁"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260225123005910.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="mid-training：构建预训练与后训练之间的分布式桥梁"/></a><div class="content"><a class="title" href="/2026/02/25/2026-02-25-Midtraining-%E4%B8%AD%E9%97%B4%E8%AE%AD%E7%BB%83-%E6%9E%84%E5%BB%BA%E9%A2%84%E8%AE%AD%E7%BB%83%E4%B8%8E%E5%90%8E%E8%AE%AD%E7%BB%83%E4%B9%8B%E9%97%B4%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E6%A1%A5%E6%A2%81.html" title="mid-training：构建预训练与后训练之间的分布式桥梁">mid-training：构建预训练与后训练之间的分布式桥梁</a><time datetime="2026-02-25T00:00:00.000Z" title="发表于 2026-02-25 00:00:00">2026-02-25</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/24/arxiv_papers_2026-02-24.html" title="Arxiv今日论文 | 2026-02-24"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-24"/></a><div class="content"><a class="title" href="/2026/02/24/arxiv_papers_2026-02-24.html" title="Arxiv今日论文 | 2026-02-24">Arxiv今日论文 | 2026-02-24</a><time datetime="2026-02-24T12:30:00.000Z" title="发表于 2026-02-24 12:30:00">2026-02-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/23/arxiv_papers_2026-02-23.html" title="Arxiv今日论文 | 2026-02-23"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-23"/></a><div class="content"><a class="title" href="/2026/02/23/arxiv_papers_2026-02-23.html" title="Arxiv今日论文 | 2026-02-23">Arxiv今日论文 | 2026-02-23</a><time datetime="2026-02-23T12:30:00.000Z" title="发表于 2026-02-23 12:30:00">2026-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/23/Think-Deep,-Not-Just-Long-Measuring-LLM-Reasoning-Effort-via-Deep-Thinking-Tokens.html" title="用&quot;深度思考率&quot;精准度量LLM推理质量"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/20260223165943195.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="用&quot;深度思考率&quot;精准度量LLM推理质量"/></a><div class="content"><a class="title" href="/2026/02/23/Think-Deep,-Not-Just-Long-Measuring-LLM-Reasoning-Effort-via-Deep-Thinking-Tokens.html" title="用&quot;深度思考率&quot;精准度量LLM推理质量">用&quot;深度思考率&quot;精准度量LLM推理质量</a><time datetime="2026-02-23T12:00:00.000Z" title="发表于 2026-02-23 12:00:00">2026-02-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/20/arxiv_papers_2026-02-20.html" title="Arxiv今日论文 | 2026-02-20"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20210911210134.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Arxiv今日论文 | 2026-02-20"/></a><div class="content"><a class="title" href="/2026/02/20/arxiv_papers_2026-02-20.html" title="Arxiv今日论文 | 2026-02-20">Arxiv今日论文 | 2026-02-20</a><time datetime="2026-02-20T12:30:00.000Z" title="发表于 2026-02-20 12:30:00">2026-02-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2026/02/20/frontier_training_cn.html" title="前沿大模型训练方法：深度解析与实践指南"><img src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/blog_picgo/202602201606857.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="前沿大模型训练方法：深度解析与实践指南"/></a><div class="content"><a class="title" href="/2026/02/20/frontier_training_cn.html" title="前沿大模型训练方法：深度解析与实践指南">前沿大模型训练方法：深度解析与实践指南</a><time datetime="2026-02-20T10:30:00.000Z" title="发表于 2026-02-20 10:30:00">2026-02-20</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2026 By Weitang Liu</div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src="https://img.shields.io/badge/Theme-Butterfly-6513df?style=flat&logo=bitdefender"title="主题采用butterfly"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://www.jsdelivr.com/"><img src="https://img.shields.io/badge/CDN-jsDelivr-orange?style=flat&logo=jsDelivr"title="本站使用JsDelivr为静态资源提供CDN加速"alt="img"></a><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src="https://img.shields.io/badge/Source-Github-d021d6?style=flat&logo=GitHub"title="本站项目由Gtihub托管"alt="img"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"alt="img"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></br></p></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex-copytex@latest/dist/katex-copytex.min.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', '', 'katex-wrap')
  })
})()</script><script>(()=>{
  const $countDom = document.getElementById('twikoo-count')
  const init = () => {
    let initData = {
      el: '#twikoo-wrap',
      envId: 'https://twikoo.lonepatient.top/',
      region: ''
    }

    if (false) {
      const otherData = false
      initData = Object.assign(initData, otherData)
    }
    
    twikoo.init(initData)
  }

  const getCount = () => {
    twikoo.getCommentsCount({
      envId: 'https://twikoo.lonepatient.top/',
      region: '',
      urls: [window.location.pathname],
      includeReply: false
    }).then(function (res) {
      $countDom.innerText = res[0].count
    }).catch(function (err) {
      console.error(err);
    });
  }

  const loadTwikoo = (bool = false) => {
    if (typeof twikoo === 'object') {
      init()
      bool && $countDom && setTimeout(getCount,0)
    } else {
      getScript('https://cdn.jsdelivr.net/npm/twikoo@1.4.11/dist/twikoo.all.min.js').then(()=> {
        init()
        bool && $countDom && setTimeout(getCount,0)
      })
    }
  }

  if ('Twikoo' === 'Twikoo' || !false) {
    if (false) btf.loadComment(document.getElementById('twikoo-wrap'), loadTwikoo)
    else loadTwikoo(true)
  } else {
    window.loadOtherComment = () => {
      loadTwikoo()
    }
  }
})()</script></div><script src="https://cdn.jsdelivr.net/npm/vue@2.6.11"></script><canvas id="universe"></canvas><script defer src="/js/universe.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --> <script data-pjax>if(document.getElementById('recent-posts') && (location.pathname ==='/'|| '/' ==='all')){
    var parent = document.getElementById('recent-posts');
    var child = '<div class="recent-post-item" style="width:100%;height: auto"><div id="catalog_magnet"><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (10)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/自然语言处理/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">📚 自然语言处理 (99)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/计算机视觉/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🎮 计算机视觉 (16)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/知识图谱/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">🐱 知识图谱 (13)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item"><a class="magnet_link" href="http://lonepatient.top/categories/深度学习/"><div class="magnet_link_context" style=""><span style="font-weight:500;flex:1">👩‍💻 深度学习 (139)</span><span style="padding:0px 4px;border-radius: 8px;"><i class="fas fa-arrow-circle-right"></i></span></div></a></div><div class="magnet_item" style="visibility: hidden"></div><a class="magnet_link_more"  href="http://lonepatient.top/categories" style="flex:1;text-align: center;margin-bottom: 10px;">查看更多...</a></div></div>';
    console.log('已挂载magnet')
    parent.insertAdjacentHTML("afterbegin",child)}
     </script><style>#catalog_magnet{flex-wrap: wrap;display: flex;width:100%;justify-content:space-between;padding: 10px 10px 0 10px;align-content: flex-start;}.magnet_item{flex-basis: calc(50% - 5px);background: #f2f2f2;margin-bottom: 10px;border-radius: 8px;transition: all 0.2s ease-in-out;}.magnet_item:hover{background: #b30070}.magnet_link_more{color:#555}.magnet_link{color:black}.magnet_link:hover{color:white}@media screen and (max-width: 600px) {.magnet_item {flex-basis: 100%;}}.magnet_link_context{display:flex;padding: 10px;font-size:16px;transition: all 0.2s ease-in-out;}.magnet_link_context:hover{padding: 10px 20px;}</style>
    <style></style><script data-pjax>function electric_clock_injector_config(){
                var parent_div_git = document.getElementsByClassName('sticky_layout')[0];
                var item_html = '<div class="card-widget card-clock"><div class="card-glass"><div class="card-background"><div class="card-content"><div id="hexo_electric_clock"><img id="card-clock-loading" src="https://cdn.jsdelivr.net/gh/Zfour/Butterfly-clock/clock/images/weather/loading.gif" style="height: 120px; width: 100%;" data-ll-status="loading" class="entered loading"></div></div></div></div></div>';
                console.log('已挂载electric_clock')
                // parent_div_git.innerHTML=item_html+parent_div_git.innerHTML // 无报错，但不影响使用(支持pjax跳转)
                parent_div_git.insertAdjacentHTML("afterbegin",item_html) // 有报错，但不影响使用(支持pjax跳转)
            }if( document.getElementsByClassName('sticky_layout')[0] && (location.pathname ==='all'|| 'all' ==='all')){

            electric_clock_injector_config()
        } </script><script src="https://pv.sohu.com/cityjson?ie=utf-8"></script><script data-pjax  src="https://cdn.jsdelivr.net/gh/Zfour/hexo-electric-clock@1.0.6/clock.js"></script><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230219144729.jpeg" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2023-02-18</span><a class="blog-slider__title" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt="">通向AGI之路：大型语言模型（LLM）技术精要</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2023/02/18/The_Road_to_AGI_Larg_Language_Model_Technical_Essentials.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2022/07/12/gaiic_2022_ner_top10.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20220712181905.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2022-07-12</span><a class="blog-slider__title" href="2022/07/12/gaiic_2022_ner_top10.html" alt="">GAIIC2022商品标题识别二等奖获奖解决思路</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2022/07/12/gaiic_2022_ner_top10.html" alt="">详情   </a></div></div><div class="blog-slider__item swiper-slide" style="width: 750px; opacity: 1; transform: translate3d(0px, 0px, 0px); transition-duration: 0ms;"><a class="blog-slider__img" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt=""><img width="48" height="48" src="https://lonepatient-1257945978.cos.ap-chengdu.myqcloud.com/images/20230807190424.png" alt="" onerror="this.src=https://unpkg.zhimg.com/akilar-candyassets/image/loading.gif; this.onerror = null;"/></a><div class="blog-slider__content"><span class="blog-slider__code">2021-01-20</span><a class="blog-slider__title" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt="">2025-03|高质量中文预训练模型集合</a><div class="blog-slider__text">再怎么看我也不知道怎么描述它的啦！</div><a class="blog-slider__button" href="2021/01/20/awesome-pretrained-chinese-nlp-models.html" alt="">详情   </a></div></div></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>